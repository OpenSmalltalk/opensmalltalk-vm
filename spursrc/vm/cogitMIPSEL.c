/* Automatically generated by
	CCodeGenerator VMMaker.oscog-eem.1662 uuid: 686f2648-1716-445e-8440-ec23d22489a5
   from
	StackToRegisterMappingCogit VMMaker.oscog-eem.1662 uuid: 686f2648-1716-445e-8440-ec23d22489a5
 */
static char __buildInfo[] = "StackToRegisterMappingCogit VMMaker.oscog-eem.1662 uuid: 686f2648-1716-445e-8440-ec23d22489a5 " __DATE__ ;
char *__cogitBuildInfo = __buildInfo;



#include <stddef.h>
#include <asm/cachectl.h>
#include "sq.h"
#include "sqCogStackAlignment.h"
#include "dispdbg.h"
#include "cogmethod.h"
#if COGMTVM
#include "cointerpmt.h"
#else
#include "cointerp.h"
#endif
#include "cogit.h"

typedef struct _AbstractInstruction {
	unsigned char	opcode;
	unsigned char	machineCodeSize;
	unsigned char	maxSize;
	unsigned char	annotation;
	unsigned long		operands [3];
	unsigned long	address;
	struct _AbstractInstruction *dependent;
	unsigned long		machineCode [7];
 } AbstractInstruction;

#define CogMIPSELCompiler AbstractInstruction
#define CogAbstractInstruction AbstractInstruction


typedef struct {
	AbstractInstruction *fakeHeader;
	AbstractInstruction *fillInstruction;
	sqInt	numArgs;
	sqInt	numCopied;
	sqInt	numInitialNils;
	sqInt	startpc;
	AbstractInstruction *entryLabel;
	AbstractInstruction *stackCheckLabel;
	sqInt	span;
	sqInt	hasInstVarRef;
 } BlockStart;

#define CogBlockStart BlockStart


typedef struct _BytecodeDescriptor {
	sqInt (*generator )(void);
	sqInt (*spanFunction )(struct _BytecodeDescriptor *,sqInt,sqInt,sqInt);
	sqInt (*needsFrameFunction )(sqInt);
	signed char	stackDelta;
	unsigned char	opcode;
	unsigned char	numBytes;
	unsigned		isBranchTrue : 1;
	unsigned		isBranchFalse : 1;
	unsigned		isReturn : 1;
	unsigned		isBlockCreation : 1;
	unsigned		isMapped : 1;
	unsigned		isMappedInBlock : 1;
	unsigned		isExtension : 1;
	unsigned		isInstVarRef : 1;
 } BytecodeDescriptor;

#define CogBytecodeDescriptor BytecodeDescriptor


typedef struct {
	sqInt (*primitiveGenerator )(void);
	sqInt	primNumArgs;
 } PrimitiveDescriptor;

#define CogPrimitiveDescriptor PrimitiveDescriptor


typedef struct {
	AbstractInstruction *targetInstruction;
	sqInt	instructionIndex;
	sqInt	simStackPtr;
 } BytecodeFixup;

#define CogSSBytecodeFixup BytecodeFixup
#define CogBytecodeFixup BytecodeFixup


typedef struct {
	char	type;
	char	spilled;
	char	annotateUse;
	sqInt	registerr;
	sqInt	offset;
	sqInt	constant;
	sqInt	bcptr;
 } CogSimStackEntry;


typedef struct {
	sqInt	isReceiverResultRegLive;
	CogSimStackEntry *ssEntry;
 } CogSSOptStatus;



/*** Constants ***/
#define A0 4
#define A1 5
#define A2 6
#define A3 7
#define ADDIU 9
#define ADDU 33
#define AddCheckOverflowCqR 120
#define AddCheckOverflowRR 121
#define AddCqR 95
#define AddCwR 103
#define AddRdRd 110
#define AddRR 89
#define AlignmentNops 3
#define AltBlockCreationBytecodeSize 3
#define AltFirstSpecialSelector 80
#define AltNumSpecialSelectors 32
#define AND 36
#define ANDI 12
#define AndCqR 97
#define AndCqRR 108
#define AndCwR 105
#define AndRR 91
#define AnnotationShift 5
#define Arg0Reg 17
#define Arg1Reg 18
#define ArithmeticShiftRightCqR 80
#define ArithmeticShiftRightRR 81
#define AT 1
#define BadRegisterSet 1
#define BEQ 4
#define BGEZ 1
#define BGTZ 7
#define BLEZ 6
#define BLTZ 0
#define BlockCreationBytecodeSize 4
#define BNE 5
#define BREAK 13
#define BranchTemp 11
#define BrEqualRR 125
#define BrLongEqualRR 135
#define BrLongNotEqualRR 136
#define BrNotEqualRR 126
#define BrSignedGreaterEqualRR 134
#define BrSignedGreaterRR 133
#define BrSignedLessEqualRR 132
#define BrSignedLessRR 131
#define BrUnsignedGreaterEqualRR 130
#define BrUnsignedGreaterRR 129
#define BrUnsignedLessEqualRR 128
#define BrUnsignedLessRR 127
#define BytecodeSetHasDirectedSuperSend 0
#define Call 6
#define CallFull 7
#define ClassArrayCompactIndex 51
#define ClassBlockClosureCompactIndex 37
#define ClassFloatCompactIndex 34
#define ClassMethodContextCompactIndex 36
#define ClassReg 19
#define ClosureFirstCopiedValueIndex 3
#define ClosureIndex 4
#define ClosureNumArgsIndex 2
#define ClosureOuterContextIndex 0
#define ClosureStartPCIndex 1
#define CMBlock 3
#define CMClosedPIC 4
#define CMFree 1
#define CMMaxUsageCount 7
#define CMMethod 2
#define CMOpenPIC 5
#define Cmp 8
#define CmpC32R 102
#define CmpCqR 94
#define CmpCwR 101
#define CmpRdRd 109
#define CmpRR 88
#define CompletePrimitive 4
#define ConcreteVarBaseReg 22
#define ConstZero 1
#define ConvertRRd 115
#define Debug DEBUGVM
#define DIV 26
#define DisplacementMask 0x1F
#define DisplacementX2N 0
#define DivRdRd 113
#define DivRR 117
#undef DPFPReg0
#undef DPFPReg1
#define EncounteredUnknownBytecode -6
#define Fill32 4
#define FirstAnnotation 64
#define FirstJump 11
#define FirstSpecialSelector 176
#define FoxCallerSavedIP 4
#define FoxMethod -4
#define FoxMFReceiver -12
#define FoxSavedFP 0
#define FoxThisContext -8
#define FP 30
#define FPReg 30
#define GCModeBecome 8
#define GCModeFull 1
#define GCModeNewSpace 2
#define HasBytecodePC 4
#define HeaderIndex 0
#define HintLoad 0
#define HintStore 1
#if !defined(IMMUTABILITY) /* Allow this to be overridden on the compiler command line */
#define IMMUTABILITY 0
#endif
#define InstanceSpecificationIndex 2
#define InstructionPointerIndex 1
#define InsufficientCodeSpace -2
#define IsAbsPCReference 3
#define IsAnnotationExtension 1
#define IsDirectedSuperSend 9
#define IsDisplacementX2N 0
#define IsNSDynamicSuperSend null
#define IsNSSelfSend null
#define IsNSSendCall null
#define IsObjectReference 2
#define IsRelativeCall 5
#define IsSendCall 7
#define IsSuperSend 8
#define J 2
#define JAL 3
#define JALR 9
#define JR 8
#define Jump 15
#define JumpAbove 30
#define JumpAboveOrEqual 29
#define JumpBelow 28
#define JumpBelowOrEqual 31
#define JumpCarry 22
#define JumpFPEqual 32
#define JumpFPGreater 36
#define JumpFPGreaterOrEqual 37
#define JumpFPLess 34
#define JumpFPLessOrEqual 35
#define JumpFPNotEqual 33
#define JumpFPOrdered 38
#define JumpFPUnordered 39
#define JumpFull 11
#define JumpGreater 26
#define JumpGreaterOrEqual 25
#define JumpLess 24
#define JumpLessOrEqual 27
#define JumpLong 12
#define JumpLongNonZero 14
#define JumpLongZero 13
#define JumpNegative 18
#define JumpNoCarry 23
#define JumpNonNegative 19
#define JumpNonZero 17
#define JumpNoOverflow 21
#define JumpOverflow 20
#define JumpR 9
#define JumpZero 16
#define Label 1
#define LargeContextSlots 62
#define LastJump 39
#define LB 32
#define LBU 36
#define LH 33
#define LHU 37
#define LinkReg 31
#define Literal 2
#define LiteralStart 1
#define LoadEffectiveAddressMwrR 77
#define LogicalShiftLeftCqR 84
#define LogicalShiftLeftRR 85
#define LogicalShiftRightCqR 82
#define LogicalShiftRightRR 83
#define LUI 15
#define LW 35
#define MapEnd 0
#define MaxCompiledPrimitiveIndex 222
#define MaxMethodSize 65535
#define MaxNegativeErrorCode -8
#define MaxNumArgs 15
#define MaxStackAllocSize 1572864
#define MaxStackCheckOffset 0xFFF
#define MaxX2NDisplacement 992
#define MethodCacheClass 2
#define MethodCacheMask 0xFFC
#define MethodCacheMethod 3
#define MethodCacheSelector 1
#define MethodIndex 3
#define MethodTooBig -4
#define MFHI 16
#define MFLO 18
#define MFMethodFlagHasContextFlag 1
#define MFMethodFlagIsBlockFlag 2
#define MoveAbR 43
#define MoveAwR 41
#define MoveC32R 65
#define MoveCqR 63
#define MoveCwR 64
#define MoveHighR 119
#define MoveLowR 118
#define MoveM16rR 51
#define MoveM64rRd 70
#define MoveMbrR 59
#define MoveMwrR 45
#define MoveRAb 44
#define MoveRAw 42
#define MoveRdM64r 71
#define MoveRdRd 69
#define MoveRM16r 52
#define MoveRMbr 60
#define MoveRMwr 46
#define MoveRR 40
#define MoveRXbrR 62
#define MoveRXwrR 48
#define MoveXbrRR 61
#define MoveXwrRR 47
#define MULT 24
#define MULTIPLEBYTECODESETS 0
#define MulCheckOverflowRR 122
#define MulRdRd 112
#define MulRR 116
#define NegateR 79
#define NewspeakVM 0
#define Nop 5
#define NoReg -1
#define NotFullyInitialized -1
#define NumObjRefsInRuntime 0
#define NumOopsPerNSC 6
#define NumSendTrampolines 4
#define NumSpecialSelectors 32
#define NumTrampolines 54
#define OneInstruction 4
#define OR 37
#define ORI 13
#define OrCqR 98
#define OrCwR 106
#define OrRR 92
#define Overflow 8
#define OverflowTemp1 9
#define OverflowTemp2 10
#undef PCReg
#define PopR 72
#define PREF 51
#define PrefetchAw 76
#define PrimCallCollectsProfileSamples 8
#define PrimCallDoNotJIT 32
#define PrimCallMayCallBack 4
#define PrimCallNeedsNewMethod 1
#define PrimCallNeedsPrimitiveFunction 2
#define PrimErrWritePastObject 17
#define PushCq 74
#define PushCw 75
#define PushR 73
#define RA 31
#define REGIMM 1
#define ReceiverIndex 5
#define ReceiverResultReg 16
#define RetN 8
#define RISCTempReg 1
#define SB 40
#undef Scratch0Reg
#define SelectorCannotInterpret 34
#define SelectorDoesNotUnderstand 20
#define SenderIndex 0
#define SendNumArgsReg 20
#define SH 41
#define ShouldNotJIT -8
#define SistaVM 0
#define SLL 0
#define SLLV 4
#define SLT 42
#define SLTI 10
#define SLTIU 11
#define SLTU 43
#define SmallContextSlots 22
#define SP 29
#define SPECIAL 0
#define SPReg 29
#define SqrtRd 114
#define SRA 3
#define SRAV 7
#define SRL 2
#define SRLV 6
#define SSBaseOffset 1
#define SSConstant 2
#define SSRegister 3
#define SSSpill 4
#define StackPointerIndex 2
#define Stop 10
#define SUBU 35
#define SubCheckOverflowCqR 123
#define SubCheckOverflowRR 124
#define SubCqR 96
#define SubCwR 104
#define SubRdRd 111
#define SubRR 90
#define SW 43
#define T0 8
#define T1 9
#define T2 10
#define T3 11
#define T4 12
#define T5 13
#define T6 14
#define T7 15
#define T8 24
#define T9 25
#define TargetReg 25
#define TempReg 21
#define TstCqR 99
#define UnfailingPrimitive 3
#define UnimplementedPrimitive -7
#define V0 2
#define ValueIndex 1
#define VarBaseReg 22
#define XOR 38
#define XORI 14
#define XorCqR 100
#define XorCwR 107
#define XorRR 93
#define YoungSelectorInPIC -5
#define ZR 0


/*** Function Prototypes ***/


#if !PRODUCTION && defined(PlatformNoDbgRegParms)
# define NoDbgRegParms PlatformNoDbgRegParms
#endif

#if !defined(NoDbgRegParms)
# define NoDbgRegParms /*empty*/
#endif



#if !defined(NeverInline)
# define NeverInline /*empty*/
#endif

static AbstractInstruction * NoDbgRegParms addDependent(AbstractInstruction * self_in_addDependent, AbstractInstruction *anInstruction);
static sqInt NoDbgRegParms availableRegisterOrNoneFor(AbstractInstruction * self_in_availableRegisterOrNoneFor, sqInt liveRegsMask);
static AbstractInstruction * NoDbgRegParms cloneLiteralFrom(AbstractInstruction * self_in_cloneLiteralFrom, AbstractInstruction *existingLiteral);
static sqInt NoDbgRegParms genAlignCStackSavingRegistersnumArgswordAlignment(AbstractInstruction * self_in_genAlignCStackSavingRegistersnumArgswordAlignment, sqInt saveRegs, sqInt numArgs, sqInt alignment);
static AbstractInstruction * NoDbgRegParms genWriteCResultIntoReg(AbstractInstruction * self_in_genWriteCResultIntoReg, sqInt abstractRegister);
static AbstractInstruction * NoDbgRegParms getJmpTarget(AbstractInstruction * self_in_getJmpTarget);
static AbstractInstruction * NoDbgRegParms initializeSharableLiteral(AbstractInstruction * self_in_initializeSharableLiteral, sqInt literal);
static AbstractInstruction * NoDbgRegParms initializeUniqueLiteral(AbstractInstruction * self_in_initializeUniqueLiteral, sqInt literal);
static sqInt NoDbgRegParms isAFixup(AbstractInstruction * self_in_isAFixup, void *fixupOrAddress);
static sqInt NoDbgRegParms isWithinMwOffsetRange(AbstractInstruction * self_in_isWithinMwOffsetRange, sqInt anAddress);
static AbstractInstruction * NoDbgRegParms jmpTarget(AbstractInstruction * self_in_jmpTarget, AbstractInstruction *anAbstractInstruction);
static usqInt NoDbgRegParms labelOffset(AbstractInstruction * self_in_labelOffset);
static sqInt NoDbgRegParms literal32BeforeFollowingAddress(AbstractInstruction * self_in_literal32BeforeFollowingAddress, sqInt followingAddress);
static AbstractInstruction * NoDbgRegParms resolveJumpTarget(AbstractInstruction * self_in_resolveJumpTarget);
static sqInt NoDbgRegParms rewriteCallFullAttarget(AbstractInstruction * self_in_rewriteCallFullAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress);
static sqInt NoDbgRegParms rewriteJumpFullAttarget(AbstractInstruction * self_in_rewriteJumpFullAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress);
static sqInt NoDbgRegParms setLabelOffset(AbstractInstruction * self_in_setLabelOffset, sqInt aValue);
static AbstractInstruction * NoDbgRegParms updateLabel(AbstractInstruction * self_in_updateLabel, AbstractInstruction *labelInstruction);
static sqInt NoDbgRegParms wantsNearAddressFor(AbstractInstruction * self_in_wantsNearAddressFor, sqInt anObject);
static CogMethod * NoDbgRegParms cmHomeMethod(CogBlockMethod * self_in_cmHomeMethod);
static sqInt NoDbgRegParms isBranch(BytecodeDescriptor * self_in_isBranch);
static sqInt NoDbgRegParms isUnconditionalBranch(BytecodeDescriptor * self_in_isUnconditionalBranch);
static AbstractInstruction * NoDbgRegParms gAddCqR(sqInt quickConstant, sqInt reg);
static AbstractInstruction * NoDbgRegParms gAndCqR(sqInt quickConstant, sqInt reg);
static AbstractInstruction * NoDbgRegParms gAndCqRR(sqInt quickConstant, sqInt srcReg, sqInt destReg);
static AbstractInstruction * NoDbgRegParms gArithmeticShiftRightRR(sqInt reg1, sqInt reg2);
extern sqInt abortOffset(void);
static void addCleanBlockStarts(void);
extern void addCogMethodsToHeapMap(void);
static sqInt NoDbgRegParms addressIsInFixups(AbstractInstruction *address);
static sqInt NoDbgRegParms addressIsInInstructions(AbstractInstruction *address);
static sqInt NoDbgRegParms addressOfEndOfCaseinCPIC(sqInt n, CogMethod *cPIC);
static sqInt NoDbgRegParms alignUptoRoutineBoundary(sqInt anAddress);
static sqInt allMachineCodeObjectReferencesValid(void);
static sqInt allMethodsHaveCorrectHeader(void);
static AbstractInstruction * NoDbgRegParms annotateAbsolutePCRef(AbstractInstruction *abstractInstruction);
static AbstractInstruction * NoDbgRegParms annotateBytecode(AbstractInstruction *abstractInstruction);
static AbstractInstruction * NoDbgRegParms annotateobjRef(AbstractInstruction *abstractInstruction, sqInt anOop);
static void NoDbgRegParms assertSaneJumpTarget(AbstractInstruction *jumpTarget);
static sqInt NoDbgRegParms blockCreationBytecodeSizeForHeader(sqInt aMethodHeader);
static sqInt NoDbgRegParms blockDispatchTargetsForperformarg(CogMethod *cogMethod, usqInt (*binaryFunction)(sqInt mcpc, sqInt arg), sqInt arg);
extern sqInt bytecodePCForstartBcpcin(sqInt mcpc, sqInt startbcpc, CogBlockMethod *cogMethod);
static AbstractInstruction * NoDbgRegParms CallRTregistersToBeSavedMask(sqInt callTarget, sqInt registersToBeSaved);
static AbstractInstruction * NoDbgRegParms gCall(sqInt callTarget);
static AbstractInstruction * NoDbgRegParms gCmpCqR(sqInt quickConstant, sqInt reg);
static AbstractInstruction * NoDbgRegParms gCmpCwR(sqInt wordConstant, sqInt reg);
static AbstractInstruction * NoDbgRegParms gCmpRR(sqInt reg1, sqInt reg2);
extern void callCogCodePopReceiver(void);
extern void callCogCodePopReceiverAndClassRegs(void);
extern void ceCPICMissreceiver(CogMethod *cPIC, sqInt receiver);
extern sqInt ceSICMiss(sqInt receiver);
extern void checkAssertsEnabledInCogit(void);
static sqInt NoDbgRegParms checkIfValidOopRefAndTargetpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod);
static sqInt NoDbgRegParms checkIfValidOopRefpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod);
extern sqInt checkIntegrityOfObjectReferencesInCode(sqInt gcModes);
static sqInt NoDbgRegParms checkMaybeObjRefInClosedPIC(sqInt maybeObject);
static sqInt NoDbgRegParms checkValidObjectReferencesInClosedPIC(CogMethod *cPIC);
static sqInt NoDbgRegParms closedPICRefersToUnmarkedObject(CogMethod *cPIC);
extern char * codeEntryFor(char *address);
extern char * codeEntryNameFor(char *address);
extern sqInt cogCodeBase(void);
extern sqInt cogCodeConstituents(void);
static sqInt NoDbgRegParms cogExtendPICCaseNMethodtagisMNUCase(CogMethod *cPIC, sqInt caseNMethod, sqInt caseNTag, sqInt isMNUCase);
extern void cogitPostGCAction(sqInt gcMode);
extern sqInt cogMethodDoesntLookKosher(CogMethod *cogMethod);
extern CogMethod * cogMNUPICSelectorreceivermethodOperandnumArgs(sqInt selector, sqInt rcvr, sqInt methodOperand, sqInt numArgs);
static CogMethod * NoDbgRegParms cogOpenPICSelectornumArgs(sqInt selector, sqInt numArgs);
static CogMethod * NoDbgRegParms cogPICSelectornumArgsCase0MethodCase1MethodtagisMNUCase(sqInt selector, sqInt numArgs, CogMethod *case0CogMethod, sqInt case1MethodOrNil, sqInt case1Tag, sqInt isMNUCase);
extern CogMethod * cogselector(sqInt aMethodObj, sqInt aSelectorOop);
extern void compactCogCompiledCode(void);
static AbstractInstruction * compileAbort(void);
static void NoDbgRegParms compileBlockDispatchFromto(sqInt lowBlockStartIndex, sqInt highBlockStartIndex);
static void NoDbgRegParms compileBlockEntry(BlockStart *blockStart);
static void NoDbgRegParms compileCallFornumArgsargargargargresultRegsaveRegs(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt resultRegOrNone, sqInt saveRegs);
static AbstractInstruction * compileCPICEntry(void);
static void compileEntry(void);
static sqInt compileMethodBody(void);
static sqInt NoDbgRegParms compilePICAbort(sqInt numArgs);
static void NoDbgRegParms compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNone);
static void computeEntryOffsets(void);
static void computeMaximumSizes(void);
static sqInt NoDbgRegParms configureCPICCase0Case1MethodtagisMNUCasenumArgsdelta(CogMethod *cPIC, CogMethod *case0CogMethod, sqInt case1Method, sqInt case1Tag, sqInt isMNUCase, sqInt numArgs, sqInt addrDelta);
static sqInt NoDbgRegParms configureMNUCPICmethodOperandnumArgsdelta(CogMethod *cPIC, sqInt methodOperand, sqInt numArgs, sqInt addrDelta);
static sqInt NoDbgRegParms cPICHasForwardedClass(CogMethod *cPIC);
static sqInt NoDbgRegParms cPICHasFreedTargets(CogMethod *cPIC);
static sqInt cPICPrototypeCaseOffset(void);
static sqInt NoDbgRegParms cPICHasTarget(CogMethod *cPIC, CogMethod *targetMethod);
static AbstractInstruction * NoDbgRegParms gDivRRQuoRem(sqInt rDivisor, sqInt rDividend, sqInt rQuotient, sqInt rRemainder);
extern sqInt defaultCogCodeSize(void);
static sqInt NoDbgRegParms deltaToSkipPrimAndErrorStoreInheader(sqInt aMethodObj, sqInt aMethodHeader);
static sqInt NoDbgRegParms endPCOf(sqInt aMethod);
extern void enterCogCodePopReceiver(void);
static sqInt NoDbgRegParms expectedClosedPICPrototype(CogMethod *cPIC);
static sqInt NoDbgRegParms fillInBlockHeadersAt(sqInt startAddress);
static CogMethod * NoDbgRegParms fillInMethodHeadersizeselector(CogMethod *method, sqInt size, sqInt selector);
static usqInt NoDbgRegParms findBlockMethodWithEntrystartBcpc(sqInt blockEntryMcpc, sqInt startBcpc);
static sqInt NoDbgRegParms findMapLocationForMcpcinMethod(sqInt targetMcpc, CogMethod *cogMethod);
extern CogBlockMethod * findMethodForStartBcpcinHomeMethod(sqInt startbcpc, CogMethod *cogMethod);
static sqInt NoDbgRegParms findIsBackwardBranchMcpcBcpcMatchingMcpc(BytecodeDescriptor *descriptor, sqInt isBackwardBranch, char *mcpc, sqInt bcpc, void *targetMcpc);
extern void followForwardedLiteralsIn(CogMethod *cogMethod);
extern void followForwardedMethods(void);
static sqInt NoDbgRegParms followMaybeObjRefInClosedPICAt(sqInt mcpc);
static sqInt NoDbgRegParms followMethodReferencesInClosedPIC(CogMethod *cPIC);
static void freePICsWithFreedTargets(void);
extern void freeUnmarkedMachineCode(void);
static sqInt genCheckForInterruptsTrampoline(void);
static AbstractInstruction * NoDbgRegParms genConditionalBranchoperand(sqInt opcode, sqInt operandOne);
static void (*genEnilopmartForandandforCallcalled(sqInt regArg1, sqInt regArg2OrNone, sqInt regArg3OrNone, sqInt forCall, char *trampolineName))(void) ;
static void NoDbgRegParms genEnilopmartReturn(sqInt forCall);
static void NoDbgRegParms generateCaptureCStackPointers(sqInt captureFramePointer);
static void generateClosedPICPrototype(void);
static CogMethod * NoDbgRegParms generateCogMethod(sqInt selector);
static sqInt NoDbgRegParms generateInstructionsAt(sqInt eventualAbsoluteAddress);
static sqInt NoDbgRegParms generateMapAtstart(sqInt addressOrNull, sqInt startAddress);
static void generateOpenPICPrototype(void);
static void generateRunTimeTrampolines(void);
static void generateStackPointerCapture(void);
static void generateTrampolines(void);
static void genGetLeafCallStackPointer(void);
static sqInt NoDbgRegParms genInnerPICAbortTrampoline(char *name);
static sqInt genLoadCStackPointersForPrimCall(void);
static void NoDbgRegParms genLoadInlineCacheWithSelector(sqInt selectorIndex);
static sqInt genNonLocalReturnTrampoline(void);
static sqInt NoDbgRegParms genReturnTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0);
static sqInt NoDbgRegParms genSafeTrampolineForcalled(void *aRoutine, char *aString);
static sqInt NoDbgRegParms genSafeTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0);
static sqInt NoDbgRegParms genSafeTrampolineForcalledargarg(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1);
static sqInt NoDbgRegParms genSmalltalkToCStackSwitch(sqInt pushLinkReg);
static sqInt NoDbgRegParms genTrampolineForcalled(void *aRoutine, char *aString);
static sqInt NoDbgRegParms genTrampolineForcalledargargarg(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2);
static sqInt NoDbgRegParms genTrampolineForcalledargargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt resultReg);
static sqInt NoDbgRegParms genTrampolineForcalledargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt resultReg);
static sqInt NoDbgRegParms genTrampolineForcalledargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt resultReg);
static sqInt NoDbgRegParms genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(void *aRoutine, char *trampolineName, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNone, sqInt appendBoolean);
static AbstractInstruction * NoDbgRegParms gen(sqInt opcode);
static AbstractInstruction * NoDbgRegParms genoperand(sqInt opcode, sqInt operand);
static AbstractInstruction * NoDbgRegParms genoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo);
static AbstractInstruction * NoDbgRegParms genoperandoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo, sqInt operandThree);
static sqInt NoDbgRegParms getLiteral(sqInt litIndex);
static sqInt NoDbgRegParms incrementUsageOfTargetIfLinkedSendmcpcignored(sqInt annotation, char *mcpc, sqInt superfluity);
static sqInt NoDbgRegParms indexForSelectorinat(sqInt selector, CogMethod *cogMethod, sqInt mcpc);
static sqInt initialClosedPICUsageCount(void);
static void initializeBackend(void);
extern void initializeCodeZoneFromupTo(sqInt startAddress, sqInt endAddress);
static sqInt initialMethodUsageCount(void);
static sqInt initialOpenPICUsageCount(void);
static sqInt NoDbgRegParms inlineCacheValueForSelectorinat(sqInt selector, sqInt aCogMethod, sqInt mcpc);
static sqInt NoDbgRegParms inverseBranchFor(sqInt opcode);
static sqInt NoDbgRegParms isBackwardBranchatextsin(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj);
static sqInt NoDbgRegParms isPCMappedAnnotation(sqInt annotation);
extern sqInt isPCWithinMethodZone(void *address);
extern sqInt isSendReturnPC(sqInt retpc);
static AbstractInstruction * NoDbgRegParms gJumpFPEqual(void *jumpTarget);
static AbstractInstruction * NoDbgRegParms gJumpFPGreaterOrEqual(void *jumpTarget);
static AbstractInstruction * NoDbgRegParms gJumpFPGreater(void *jumpTarget);
static AbstractInstruction * NoDbgRegParms gJumpFPNotEqual(void *jumpTarget);
static AbstractInstruction * gLabel(void);
static AbstractInstruction * NoDbgRegParms gLogicalShiftLeftCqR(sqInt quickConstant, sqInt reg);
static AbstractInstruction * lastOpcode(void);
extern void linkSendAtintooffsetreceiver(sqInt callSiteReturnAddress, CogMethod *sendingMethod, CogMethod *targetMethod, sqInt theEntryOffset, sqInt receiver);
static void NoDbgRegParms loadSubsequentBytesForDescriptorat(BytecodeDescriptor *descriptor, sqInt pc);
static AbstractInstruction * NoDbgRegParms gMoveAwR(sqInt address, sqInt reg);
static AbstractInstruction * NoDbgRegParms gMoveCwR(sqInt wordConstant, sqInt reg);
static AbstractInstruction * NoDbgRegParms gMoveMwrR(sqInt offset, sqInt baseReg, sqInt destReg);
static AbstractInstruction * NoDbgRegParms gMoveRMwr(sqInt sourceReg, sqInt offset, sqInt baseReg);
static AbstractInstruction * NoDbgRegParms gMoveRR(sqInt reg1, sqInt reg2);
static sqInt NoDbgRegParms mapEndFor(CogMethod *cogMethod);
static sqInt NoDbgRegParms mapForperformUntilarg(CogMethod *cogMethod, sqInt (*functionSymbol)(sqInt annotation, char *mcpc, sqInt arg), sqInt arg);
static sqInt NoDbgRegParms mapObjectReferencesInClosedPIC(CogMethod *cPIC);
static void mapObjectReferencesInGeneratedRuntime(void);
static void mapObjectReferencesInMachineCodeForBecome(void);
static void mapObjectReferencesInMachineCodeForFullGC(void);
static void mapObjectReferencesInMachineCodeForYoungGC(void);
extern void mapObjectReferencesInMachineCode(sqInt gcMode);
extern void markAndTraceMachineCodeOfMarkedMethods(void);
static void markAndTraceObjectReferencesInGeneratedRuntime(void);
static sqInt NoDbgRegParms markAndTraceOrFreeCogMethodfirstVisit(CogMethod *cogMethod, sqInt firstVisit);
static sqInt NoDbgRegParms markAndTraceOrFreePICTargetin(sqInt entryPoint, CogMethod *cPIC);
static sqInt NoDbgRegParms markLiteralsAndUnlinkIfUnmarkedSendpcmethod(sqInt annotation, char *mcpc, sqInt cogMethod);
static sqInt NoDbgRegParms markLiteralspcmethod(sqInt annotation, char *mcpc, sqInt cogMethod);
extern void markMethodAndReferents(CogBlockMethod *aCogMethod);
extern usqInt maxCogMethodAddress(void);
static sqInt maybeAllocAndInitIRCs(void);
static sqInt NoDbgRegParms maybeFreeCogMethodDoesntLookKosher(CogMethod *cogMethod);
static void NoDbgRegParms maybeMarkCountersIn(CogMethod *cogMethod);
static sqInt mclassIsSmallInteger(void);
extern usqInt mcPCForBackwardBranchstartBcpcin(sqInt bcpc, sqInt startbcpc, CogBlockMethod *cogMethod);
static sqInt NoDbgRegParms methodhasSameCodeAscheckPenultimate(sqInt methodA, sqInt methodB, sqInt comparePenultimateLiteral);
extern sqInt minCogMethodAddress(void);
extern sqInt mnuOffset(void);
static AbstractInstruction * NoDbgRegParms gNegateR(sqInt reg);
static sqInt NoDbgRegParms needsFrameIfImmutability(sqInt stackDelta);
static sqInt NoDbgRegParms needsFrameIfInBlock(sqInt stackDelta);
static sqInt NoDbgRegParms needsFrameNever(sqInt stackDelta);
static sqInt NoDbgRegParms noAssertMethodClassAssociationOf(sqInt methodPointer);
static sqInt noCogMethodsMaximallyMarked(void);
static sqInt NoDbgRegParms noTargetsFreeInClosedPIC(sqInt cPIC);
static sqInt NoDbgRegParms outputInstructionsAt(sqInt startAddress);
static sqInt NoDbgRegParms outputInstructionsForGeneratedRuntimeAt(sqInt startAddress);
static AbstractInstruction * NoDbgRegParms gPopR(sqInt reg);
static AbstractInstruction * NoDbgRegParms gPushCw(sqInt wordConstant);
extern sqInt patchToOpenPICFornumArgsreceiver(sqInt selector, sqInt numArgs, sqInt receiver);
static sqInt picAbortDiscriminatorValue(void);
static sqInt picInterpretAbortOffset(void);
static AbstractInstruction * previousInstruction(void);
extern void printCogMethodFor(void *address);
extern void printTrampolineTable(void);
static sqInt processorHasDivQuoRemAndMClassIsSmallInteger(void);
static sqInt processorHasMultiplyAndMClassIsSmallInteger(void);
static void NoDbgRegParms recordGeneratedRunTimeaddress(char *aString, sqInt address);
extern sqInt recordPrimTraceFunc(void);
static void recordRunTimeObjectReferences(void);
static sqInt NoDbgRegParms registerMaskFor(sqInt reg);
static sqInt NoDbgRegParms registerMaskForand(sqInt reg1, sqInt reg2);
static sqInt NoDbgRegParms registerMaskForandandandandandandandandand(sqInt reg1, sqInt reg2, sqInt reg3, sqInt reg4, sqInt reg5, sqInt reg6, sqInt reg7, sqInt reg8, sqInt reg9, sqInt reg10);
static void NoDbgRegParms relocateCallsAndSelfReferencesInMethod(CogMethod *cogMethod);
static void NoDbgRegParms relocateCallsInClosedPIC(CogMethod *cPIC);
static sqInt NoDbgRegParms relocateIfCallOrMethodReferencemcpcdelta(sqInt annotation, char *mcpc, sqInt refDelta);
static sqInt NoDbgRegParms remapIfObjectRefpchasYoung(sqInt annotation, char *mcpc, sqInt hasYoungPtr);
static sqInt NoDbgRegParms remapMaybeObjRefInClosedPICAt(sqInt mcpc);
static void NoDbgRegParms rewriteCPICCaseAttagobjReftarget(sqInt followingAddress, sqInt newTag, sqInt newObjRef, sqInt newTarget);
static AbstractInstruction * NoDbgRegParms gSubCqR(sqInt quickConstant, sqInt reg);
static AbstractInstruction * NoDbgRegParms gSubCwR(sqInt wordConstant, sqInt reg);
static sqInt scanForCleanBlocks(void);
extern void setBreakMethod(sqInt anObj);
extern void setPostCompileHook(void (*aFunction)(CogMethod *));
extern void setSelectorOfto(CogMethod *cogMethod, sqInt aSelectorOop);
static sqInt NoDbgRegParms spanForCleanBlockStartingAt(sqInt startPC);
extern sqInt traceLinkedSendOffset(void);
static sqInt NoDbgRegParms trampolineArgConstant(sqInt booleanOrInteger);
static char * NoDbgRegParms trampolineNamenumArgs(char *routinePrefix, sqInt numArgs);
static char * NoDbgRegParms trampolineNamenumRegArgs(char *routinePrefix, sqInt numArgs);
static sqInt unknownBytecode(void);
extern void unlinkAllSends(void);
static sqInt NoDbgRegParms unlinkIfFreeOrLinkedSendpcof(sqInt annotation, char *mcpc, sqInt theSelector);
static sqInt NoDbgRegParms unlinkIfInvalidClassSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity);
static sqInt NoDbgRegParms unlinkIfLinkedSendToFreepcignored(sqInt annotation, char *mcpc, sqInt superfluity);
static sqInt NoDbgRegParms unlinkIfLinkedSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity);
static sqInt NoDbgRegParms unlinkIfLinkedSendpcto(sqInt annotation, char *mcpc, sqInt theCogMethod);
extern void unlinkSendsLinkedForInvalidClasses(void);
extern void unlinkSendsOfisMNUSelector(sqInt selector, sqInt isMNUSelector);
extern void unlinkSendsToFree(void);
extern void unlinkSendsToandFreeIf(sqInt targetMethodObject, sqInt freeIfTrue);
static AbstractInstruction * NoDbgRegParms gXorCwR(sqInt wordConstant, sqInt reg);
static void zeroOpcodeIndex(void);
extern void addAllToYoungReferrers(void);
static void NoDbgRegParms addToOpenPICList(CogMethod *anOpenPIC);
static void NoDbgRegParms addToYoungReferrers(CogMethod *cogMethod);
static sqInt NoDbgRegParms allocate(sqInt numBytes);
static void clearCogCompiledCode(void);
static void compactCompiledCode(void);
static void NoDbgRegParms ensureInYoungReferrers(CogMethod *cogMethod);
extern void freeMethod(CogMethod *cogMethod);
static void freeOlderMethodsForCompaction(void);
static sqInt kosherYoungReferrers(void);
static void NoDbgRegParms manageFromto(sqInt theStartAddress, sqInt theLimitAddress);
extern CogMethod * methodFor(void *address);
static sqInt numMethods(void);
extern sqInt numMethodsOfType(sqInt cogMethodType);
static sqInt NoDbgRegParms occurrencesInYoungReferrers(CogMethod *cogMethod);
static CogMethod * NoDbgRegParms openPICWithSelector(sqInt aSelector);
static void planCompaction(void);
extern void printCogMethods(void);
extern void printCogMethodsOfType(sqInt cmType);
extern void printCogMethodsWithMethod(sqInt methodOop);
extern void printCogMethodsWithPrimitive(sqInt primIdx);
extern void printCogMethodsWithSelector(sqInt selectorOop);
extern void printCogYoungReferrers(void);
extern void printOpenPICList(void);
static sqInt pruneYoungReferrers(void);
static sqInt relocateAndPruneYoungReferrers(void);
static sqInt relocateMethodsPreCompaction(void);
static sqInt NoDbgRegParms removeFromOpenPICList(CogMethod *anOpenPIC);
static void voidYoungReferrersPostTenureAll(void);
extern char * whereIsMaybeCodeThing(sqInt anOop);
static sqInt NoDbgRegParms addiuRRC(AbstractInstruction * self_in_addiuRRC, sqInt destReg, sqInt srcReg, sqInt imm);
static sqInt NoDbgRegParms adduRRR(AbstractInstruction * self_in_adduRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms andiRRC(AbstractInstruction * self_in_andiRRC, sqInt destReg, sqInt srcReg, sqInt imm);
static sqInt NoDbgRegParms andRRR(AbstractInstruction * self_in_andRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms beqRRoffset(AbstractInstruction * self_in_beqRRoffset, sqInt leftReg, sqInt rightReg, sqInt offset);
static sqInt NoDbgRegParms bgezRoffset(AbstractInstruction * self_in_bgezRoffset, sqInt cmpReg, sqInt offset);
static sqInt NoDbgRegParms bgtzRoffset(AbstractInstruction * self_in_bgtzRoffset, sqInt cmpReg, sqInt offset);
static sqInt NoDbgRegParms blezRoffset(AbstractInstruction * self_in_blezRoffset, sqInt cmpReg, sqInt offset);
static sqInt NoDbgRegParms bltzRoffset(AbstractInstruction * self_in_bltzRoffset, sqInt cmpReg, sqInt offset);
static sqInt NoDbgRegParms bneRRoffset(AbstractInstruction * self_in_bneRRoffset, sqInt leftReg, sqInt rightReg, sqInt offset);
static sqInt NoDbgRegParms callerSavedRegisterMask(AbstractInstruction * self_in_callerSavedRegisterMask);
static sqInt NoDbgRegParms callInstructionByteSize(AbstractInstruction * self_in_callInstructionByteSize);
static sqInt NoDbgRegParms callTargetFromReturnAddress(AbstractInstruction * self_in_callTargetFromReturnAddress, sqInt callSiteReturnAddress);
static sqInt NoDbgRegParms cmpC32RTempByteSize(AbstractInstruction * self_in_cmpC32RTempByteSize);
static sqInt NoDbgRegParms computeMaximumSize(AbstractInstruction * self_in_computeMaximumSize);
static usqInt NoDbgRegParms concretizeAddCheckOverflowCqR(AbstractInstruction * self_in_concretizeAddCheckOverflowCqR);
static usqInt NoDbgRegParms concretizeAddCheckOverflowRR(AbstractInstruction * self_in_concretizeAddCheckOverflowRR);
static usqInt NoDbgRegParms concretizeAddCqR(AbstractInstruction * self_in_concretizeAddCqR);
static usqInt NoDbgRegParms concretizeAddCwR(AbstractInstruction * self_in_concretizeAddCwR);
static usqInt NoDbgRegParms concretizeAddRR(AbstractInstruction * self_in_concretizeAddRR);
static AbstractInstruction * NoDbgRegParms concretizeAlignmentNops(AbstractInstruction * self_in_concretizeAlignmentNops);
static usqInt NoDbgRegParms concretizeAndCqR(AbstractInstruction * self_in_concretizeAndCqR);
static usqInt NoDbgRegParms concretizeAndCqRR(AbstractInstruction * self_in_concretizeAndCqRR);
static usqInt NoDbgRegParms concretizeAndCwR(AbstractInstruction * self_in_concretizeAndCwR);
static usqInt NoDbgRegParms concretizeAndRR(AbstractInstruction * self_in_concretizeAndRR);
static usqInt NoDbgRegParms concretizeArithmeticShiftRightCqR(AbstractInstruction * self_in_concretizeArithmeticShiftRightCqR);
static usqInt NoDbgRegParms concretizeArithmeticShiftRightRR(AbstractInstruction * self_in_concretizeArithmeticShiftRightRR);
static sqInt NoDbgRegParms concretizeAt(AbstractInstruction * self_in_concretizeAt, sqInt actualAddress);
static usqInt NoDbgRegParms concretizeBrEqualRR(AbstractInstruction * self_in_concretizeBrEqualRR);
static usqInt NoDbgRegParms concretizeBrLongEqualRR(AbstractInstruction * self_in_concretizeBrLongEqualRR);
static usqInt NoDbgRegParms concretizeBrLongNotEqualRR(AbstractInstruction * self_in_concretizeBrLongNotEqualRR);
static usqInt NoDbgRegParms concretizeBrNotEqualRR(AbstractInstruction * self_in_concretizeBrNotEqualRR);
static usqInt NoDbgRegParms concretizeBrSignedGreaterEqualRR(AbstractInstruction * self_in_concretizeBrSignedGreaterEqualRR);
static usqInt NoDbgRegParms concretizeBrSignedGreaterRR(AbstractInstruction * self_in_concretizeBrSignedGreaterRR);
static usqInt NoDbgRegParms concretizeBrSignedLessEqualRR(AbstractInstruction * self_in_concretizeBrSignedLessEqualRR);
static usqInt NoDbgRegParms concretizeBrSignedLessRR(AbstractInstruction * self_in_concretizeBrSignedLessRR);
static usqInt NoDbgRegParms concretizeBrUnsignedGreaterEqualRR(AbstractInstruction * self_in_concretizeBrUnsignedGreaterEqualRR);
static usqInt NoDbgRegParms concretizeBrUnsignedGreaterRR(AbstractInstruction * self_in_concretizeBrUnsignedGreaterRR);
static usqInt NoDbgRegParms concretizeBrUnsignedLessEqualRR(AbstractInstruction * self_in_concretizeBrUnsignedLessEqualRR);
static usqInt NoDbgRegParms concretizeBrUnsignedLessRR(AbstractInstruction * self_in_concretizeBrUnsignedLessRR);
static usqInt NoDbgRegParms concretizeCall(AbstractInstruction * self_in_concretizeCall);
static usqInt NoDbgRegParms concretizeCallFull(AbstractInstruction * self_in_concretizeCallFull);
static sqInt NoDbgRegParms concretizeCmpCqR(AbstractInstruction * self_in_concretizeCmpCqR);
static sqInt NoDbgRegParms concretizeCmpCwR(AbstractInstruction * self_in_concretizeCmpCwR);
static sqInt NoDbgRegParms concretizeCmpRR(AbstractInstruction * self_in_concretizeCmpRR);
static usqInt NoDbgRegParms concretizeDivRR(AbstractInstruction * self_in_concretizeDivRR);
static usqInt NoDbgRegParms concretizeFill32(AbstractInstruction * self_in_concretizeFill32);
static usqInt NoDbgRegParms concretizeJump(AbstractInstruction * self_in_concretizeJump);
static usqInt NoDbgRegParms concretizeJumpFull(AbstractInstruction * self_in_concretizeJumpFull);
static usqInt NoDbgRegParms concretizeJumpLong(AbstractInstruction * self_in_concretizeJumpLong);
static sqInt NoDbgRegParms concretizeJumpLongNonZero(AbstractInstruction * self_in_concretizeJumpLongNonZero);
static sqInt NoDbgRegParms concretizeJumpLongZero(AbstractInstruction * self_in_concretizeJumpLongZero);
static sqInt NoDbgRegParms concretizeJumpNonZero(AbstractInstruction * self_in_concretizeJumpNonZero);
static sqInt NoDbgRegParms concretizeJumpNoOverflow(AbstractInstruction * self_in_concretizeJumpNoOverflow);
static sqInt NoDbgRegParms concretizeJumpOverflow(AbstractInstruction * self_in_concretizeJumpOverflow);
static usqInt NoDbgRegParms concretizeJumpR(AbstractInstruction * self_in_concretizeJumpR);
static sqInt NoDbgRegParms concretizeJumpSignedGreaterEqual(AbstractInstruction * self_in_concretizeJumpSignedGreaterEqual);
static sqInt NoDbgRegParms concretizeJumpSignedGreaterThan(AbstractInstruction * self_in_concretizeJumpSignedGreaterThan);
static sqInt NoDbgRegParms concretizeJumpSignedLessEqual(AbstractInstruction * self_in_concretizeJumpSignedLessEqual);
static sqInt NoDbgRegParms concretizeJumpSignedLessThan(AbstractInstruction * self_in_concretizeJumpSignedLessThan);
static sqInt NoDbgRegParms concretizeJumpUnsignedGreaterEqual(AbstractInstruction * self_in_concretizeJumpUnsignedGreaterEqual);
static sqInt NoDbgRegParms concretizeJumpUnsignedGreaterThan(AbstractInstruction * self_in_concretizeJumpUnsignedGreaterThan);
static sqInt NoDbgRegParms concretizeJumpUnsignedLessEqual(AbstractInstruction * self_in_concretizeJumpUnsignedLessEqual);
static sqInt NoDbgRegParms concretizeJumpUnsignedLessThan(AbstractInstruction * self_in_concretizeJumpUnsignedLessThan);
static sqInt NoDbgRegParms concretizeJumpZero(AbstractInstruction * self_in_concretizeJumpZero);
static usqInt NoDbgRegParms concretizeLoadEffectiveAddressMwrR(AbstractInstruction * self_in_concretizeLoadEffectiveAddressMwrR);
static usqInt NoDbgRegParms concretizeLogicalShiftLeftCqR(AbstractInstruction * self_in_concretizeLogicalShiftLeftCqR);
static usqInt NoDbgRegParms concretizeLogicalShiftLeftRR(AbstractInstruction * self_in_concretizeLogicalShiftLeftRR);
static usqInt NoDbgRegParms concretizeLogicalShiftRightCqR(AbstractInstruction * self_in_concretizeLogicalShiftRightCqR);
static usqInt NoDbgRegParms concretizeLogicalShiftRightRR(AbstractInstruction * self_in_concretizeLogicalShiftRightRR);
static usqInt NoDbgRegParms concretizeMoveAbR(AbstractInstruction * self_in_concretizeMoveAbR);
static usqInt NoDbgRegParms concretizeMoveAwR(AbstractInstruction * self_in_concretizeMoveAwR);
static usqInt NoDbgRegParms concretizeMoveCqR(AbstractInstruction * self_in_concretizeMoveCqR);
static usqInt NoDbgRegParms concretizeMoveCwR(AbstractInstruction * self_in_concretizeMoveCwR);
static usqInt NoDbgRegParms concretizeMoveHighR(AbstractInstruction * self_in_concretizeMoveHighR);
static usqInt NoDbgRegParms concretizeMoveLowR(AbstractInstruction * self_in_concretizeMoveLowR);
static usqInt NoDbgRegParms concretizeMoveM16rR(AbstractInstruction * self_in_concretizeMoveM16rR);
static usqInt NoDbgRegParms concretizeMoveMbrR(AbstractInstruction * self_in_concretizeMoveMbrR);
static usqInt NoDbgRegParms concretizeMoveMwrR(AbstractInstruction * self_in_concretizeMoveMwrR);
static usqInt NoDbgRegParms concretizeMoveRAb(AbstractInstruction * self_in_concretizeMoveRAb);
static usqInt NoDbgRegParms concretizeMoveRAw(AbstractInstruction * self_in_concretizeMoveRAw);
static usqInt NoDbgRegParms concretizeMoveRM16r(AbstractInstruction * self_in_concretizeMoveRM16r);
static usqInt NoDbgRegParms concretizeMoveRMbr(AbstractInstruction * self_in_concretizeMoveRMbr);
static usqInt NoDbgRegParms concretizeMoveRMwr(AbstractInstruction * self_in_concretizeMoveRMwr);
static usqInt NoDbgRegParms concretizeMoveRR(AbstractInstruction * self_in_concretizeMoveRR);
static usqInt NoDbgRegParms concretizeMoveRXbrR(AbstractInstruction * self_in_concretizeMoveRXbrR);
static usqInt NoDbgRegParms concretizeMoveRXwrR(AbstractInstruction * self_in_concretizeMoveRXwrR);
static usqInt NoDbgRegParms concretizeMoveXbrRR(AbstractInstruction * self_in_concretizeMoveXbrRR);
static usqInt NoDbgRegParms concretizeMoveXwrRR(AbstractInstruction * self_in_concretizeMoveXwrRR);
static usqInt NoDbgRegParms concretizeMulCheckOverflowRR(AbstractInstruction * self_in_concretizeMulCheckOverflowRR);
static usqInt NoDbgRegParms concretizeNegateR(AbstractInstruction * self_in_concretizeNegateR);
static usqInt NoDbgRegParms concretizeNop(AbstractInstruction * self_in_concretizeNop);
static usqInt NoDbgRegParms concretizeOrCqR(AbstractInstruction * self_in_concretizeOrCqR);
static usqInt NoDbgRegParms concretizeOrCwR(AbstractInstruction * self_in_concretizeOrCwR);
static usqInt NoDbgRegParms concretizeOrRR(AbstractInstruction * self_in_concretizeOrRR);
static usqInt NoDbgRegParms concretizePopR(AbstractInstruction * self_in_concretizePopR);
static usqInt NoDbgRegParms concretizePrefetchAw(AbstractInstruction * self_in_concretizePrefetchAw);
static usqInt NoDbgRegParms concretizePushCq(AbstractInstruction * self_in_concretizePushCq);
static usqInt NoDbgRegParms concretizePushCw(AbstractInstruction * self_in_concretizePushCw);
static usqInt NoDbgRegParms concretizePushR(AbstractInstruction * self_in_concretizePushR);
static usqInt NoDbgRegParms concretizeRetN(AbstractInstruction * self_in_concretizeRetN);
static usqInt NoDbgRegParms concretizeStop(AbstractInstruction * self_in_concretizeStop);
static usqInt NoDbgRegParms concretizeSubCheckOverflowCqR(AbstractInstruction * self_in_concretizeSubCheckOverflowCqR);
static usqInt NoDbgRegParms concretizeSubCheckOverflowRR(AbstractInstruction * self_in_concretizeSubCheckOverflowRR);
static usqInt NoDbgRegParms concretizeSubCqR(AbstractInstruction * self_in_concretizeSubCqR);
static usqInt NoDbgRegParms concretizeSubCwR(AbstractInstruction * self_in_concretizeSubCwR);
static usqInt NoDbgRegParms concretizeSubRR(AbstractInstruction * self_in_concretizeSubRR);
static usqInt NoDbgRegParms concretizeTstCqR(AbstractInstruction * self_in_concretizeTstCqR);
static usqInt NoDbgRegParms concretizeTstCwR(AbstractInstruction * self_in_concretizeTstCwR);
static sqInt NoDbgRegParms concretizeUnimplemented(AbstractInstruction * self_in_concretizeUnimplemented);
static usqInt NoDbgRegParms concretizeXorCwR(AbstractInstruction * self_in_concretizeXorCwR);
static usqInt NoDbgRegParms concretizeXorRR(AbstractInstruction * self_in_concretizeXorRR);
static void NoDbgRegParms dispatchConcretize(AbstractInstruction * self_in_dispatchConcretize);
static sqInt NoDbgRegParms divRR(AbstractInstruction * self_in_divRR, sqInt dividendReg, sqInt divisorReg);
static sqInt NoDbgRegParms fullCallsAreRelative(AbstractInstruction * self_in_fullCallsAreRelative);
static sqInt NoDbgRegParms functionAtAddress(AbstractInstruction * self_in_functionAtAddress, sqInt mcpc);
static sqInt NoDbgRegParms genDivRRQuoRem(AbstractInstruction * self_in_genDivRRQuoRem, sqInt abstractRegDivisor, sqInt abstractRegDividend, sqInt abstractRegQuotient, sqInt abstractRegRemainder);
static sqInt NoDbgRegParms genLoadCStackPointer(AbstractInstruction * self_in_genLoadCStackPointer);
static sqInt NoDbgRegParms genLoadCStackPointers(AbstractInstruction * self_in_genLoadCStackPointers);
static sqInt NoDbgRegParms genLoadStackPointers(AbstractInstruction * self_in_genLoadStackPointers);
static AbstractInstruction * NoDbgRegParms genMulRR(AbstractInstruction * self_in_genMulRR, sqInt regSource, sqInt regDest);
static AbstractInstruction * NoDbgRegParms genPushRegisterArgsForAbortMissNumArgs(AbstractInstruction * self_in_genPushRegisterArgsForAbortMissNumArgs, sqInt numArgs);
static AbstractInstruction * NoDbgRegParms genPushRegisterArgsForNumArgsscratchReg(AbstractInstruction * self_in_genPushRegisterArgsForNumArgsscratchReg, sqInt numArgs, sqInt ignored);
static sqInt NoDbgRegParms genRemoveNArgsFromStack(AbstractInstruction * self_in_genRemoveNArgsFromStack, sqInt n);
static AbstractInstruction * NoDbgRegParms genRestoreRegs(AbstractInstruction * self_in_genRestoreRegs);
static AbstractInstruction * NoDbgRegParms genRestoreRegsExcept(AbstractInstruction * self_in_genRestoreRegsExcept, sqInt abstractReg);
static AbstractInstruction * NoDbgRegParms genSaveRegsForCCall(AbstractInstruction * self_in_genSaveRegsForCCall);
static sqInt NoDbgRegParms genSaveStackPointers(AbstractInstruction * self_in_genSaveStackPointers);
static AbstractInstruction * NoDbgRegParms genSubstituteReturnAddress(AbstractInstruction * self_in_genSubstituteReturnAddress, sqInt retpc);
static sqInt NoDbgRegParms high16BitsOf(AbstractInstruction * self_in_high16BitsOf, usqInt word);
static sqInt NoDbgRegParms inlineCacheTagAt(AbstractInstruction * self_in_inlineCacheTagAt, usqInt callSiteReturnAddress);
static sqInt NoDbgRegParms instructionSizeAt(AbstractInstruction * self_in_instructionSizeAt, sqInt pc);
static sqInt NoDbgRegParms isAddressRelativeToVarBase(AbstractInstruction * self_in_isAddressRelativeToVarBase, usqInt varAddress);
static sqInt NoDbgRegParms isCallPrecedingReturnPC(AbstractInstruction * self_in_isCallPrecedingReturnPC, sqInt mcpc);
static sqInt NoDbgRegParms isJump(AbstractInstruction * self_in_isJump);
static sqInt NoDbgRegParms isJumpAt(AbstractInstruction * self_in_isJumpAt, sqInt pc);
static sqInt NoDbgRegParms isPCDependent(AbstractInstruction * self_in_isPCDependent);
static sqInt NoDbgRegParms isShortOffset(AbstractInstruction * self_in_isShortOffset, sqInt offset);
static sqInt NoDbgRegParms itypersrteitherImmediate(AbstractInstruction * self_in_itypersrteitherImmediate, sqInt op, sqInt rs, sqInt rt, sqInt immediate);
static sqInt NoDbgRegParms itypersrtsignedImmediate(AbstractInstruction * self_in_itypersrtsignedImmediate, sqInt op, sqInt rs, sqInt rt, sqInt immediate);
static sqInt NoDbgRegParms itypersrtunsignedImmediate(AbstractInstruction * self_in_itypersrtunsignedImmediate, sqInt op, sqInt rs, sqInt rt, sqInt immediate);
static sqInt NoDbgRegParms jA(AbstractInstruction * self_in_jA, sqInt target);
static sqInt NoDbgRegParms jalA(AbstractInstruction * self_in_jalA, sqInt target);
static sqInt NoDbgRegParms jalR(AbstractInstruction * self_in_jalR, sqInt targetReg);
static sqInt NoDbgRegParms jR(AbstractInstruction * self_in_jR, sqInt targetReg);
static sqInt NoDbgRegParms jtypetarget(AbstractInstruction * self_in_jtypetarget, sqInt op, sqInt target);
static sqInt NoDbgRegParms jumpLongByteSize(AbstractInstruction * self_in_jumpLongByteSize);
static sqInt NoDbgRegParms jumpLongConditionalByteSize(AbstractInstruction * self_in_jumpLongConditionalByteSize);
static usqInt NoDbgRegParms jumpLongConditionalTargetBeforeFollowingAddress(AbstractInstruction * self_in_jumpLongConditionalTargetBeforeFollowingAddress, sqInt mcpc);
static sqInt NoDbgRegParms jumpLongTargetBeforeFollowingAddress(AbstractInstruction * self_in_jumpLongTargetBeforeFollowingAddress, sqInt mcpc);
static sqInt NoDbgRegParms jumpShortByteSize(AbstractInstruction * self_in_jumpShortByteSize);
static usqInt NoDbgRegParms jumpTargetPCAt(AbstractInstruction * self_in_jumpTargetPCAt, sqInt pc);
static sqInt NoDbgRegParms lbRbaseoffset(AbstractInstruction * self_in_lbRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset);
static sqInt NoDbgRegParms lbuRbaseoffset(AbstractInstruction * self_in_lbuRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset);
static sqInt NoDbgRegParms lhRbaseoffset(AbstractInstruction * self_in_lhRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset);
static sqInt NoDbgRegParms lhuRbaseoffset(AbstractInstruction * self_in_lhuRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset);
static sqInt NoDbgRegParms literalAtAddress(AbstractInstruction * self_in_literalAtAddress, sqInt mcpc);
static sqInt NoDbgRegParms literalAtAddressput(AbstractInstruction * self_in_literalAtAddressput, sqInt mcpc, sqInt newLiteral);
static sqInt NoDbgRegParms literalBeforeFollowingAddress(AbstractInstruction * self_in_literalBeforeFollowingAddress, sqInt followingAddress);
static sqInt NoDbgRegParms loadLiteralByteSize(AbstractInstruction * self_in_loadLiteralByteSize);
static sqInt NoDbgRegParms loadPICLiteralByteSize(AbstractInstruction * self_in_loadPICLiteralByteSize);
static sqInt NoDbgRegParms low16BitsOf(AbstractInstruction * self_in_low16BitsOf, usqInt word);
static sqInt NoDbgRegParms luiRC(AbstractInstruction * self_in_luiRC, sqInt destReg, sqInt imm);
static sqInt NoDbgRegParms lwRbaseoffset(AbstractInstruction * self_in_lwRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset);
static sqInt NoDbgRegParms machineCodeBytes(AbstractInstruction * self_in_machineCodeBytes);
static sqInt NoDbgRegParms machineCodeWords(AbstractInstruction * self_in_machineCodeWords);
static sqInt NoDbgRegParms mfhiR(AbstractInstruction * self_in_mfhiR, sqInt destReg);
static sqInt NoDbgRegParms mfloR(AbstractInstruction * self_in_mfloR, sqInt destReg);
static sqInt NoDbgRegParms mipsbreak(AbstractInstruction * self_in_mipsbreak, sqInt code);
static sqInt NoDbgRegParms multRR(AbstractInstruction * self_in_multRR, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms nop(AbstractInstruction * self_in_nop);
static AbstractInstruction * NoDbgRegParms noteFollowingConditionalBranch(AbstractInstruction * self_in_noteFollowingConditionalBranch, AbstractInstruction *branch);
static AbstractInstruction * NoDbgRegParms noteFollowingOverflowBranch(AbstractInstruction * self_in_noteFollowingOverflowBranch, AbstractInstruction *branch);
static sqInt NoDbgRegParms numIntRegArgs(AbstractInstruction * self_in_numIntRegArgs);
static sqInt NoDbgRegParms opcodeAtAddress(AbstractInstruction * self_in_opcodeAtAddress, sqInt mcpc);
static sqInt NoDbgRegParms oriRRC(AbstractInstruction * self_in_oriRRC, sqInt destReg, sqInt srcReg, sqInt imm);
static sqInt NoDbgRegParms orRRR(AbstractInstruction * self_in_orRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static AbstractInstruction * NoDbgRegParms padIfPossibleWithStopsFromto(AbstractInstruction * self_in_padIfPossibleWithStopsFromto, sqInt startAddr, sqInt endAddr);
static sqInt NoDbgRegParms prefRoffsethint(AbstractInstruction * self_in_prefRoffsethint, sqInt baseReg, sqInt offset, sqInt hint);
static sqInt NoDbgRegParms pushLinkRegisterByteSize(AbstractInstruction * self_in_pushLinkRegisterByteSize);
static AbstractInstruction * NoDbgRegParms relocateCallBeforeReturnPCby(AbstractInstruction * self_in_relocateCallBeforeReturnPCby, sqInt retpc, sqInt delta);
static AbstractInstruction * NoDbgRegParms relocateJumpLongBeforeFollowingAddressby(AbstractInstruction * self_in_relocateJumpLongBeforeFollowingAddressby, sqInt pc, sqInt delta);
static AbstractInstruction * NoDbgRegParms relocateJumpLongConditionalBeforeFollowingAddressby(AbstractInstruction * self_in_relocateJumpLongConditionalBeforeFollowingAddressby, sqInt pc, sqInt delta);
static AbstractInstruction * NoDbgRegParms relocateMethodReferenceBeforeAddressby(AbstractInstruction * self_in_relocateMethodReferenceBeforeAddressby, sqInt pc, sqInt delta);
static sqInt NoDbgRegParms rewriteCallAttarget(AbstractInstruction * self_in_rewriteCallAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress);
static AbstractInstruction * NoDbgRegParms rewriteConditionalJumpLongAttarget(AbstractInstruction * self_in_rewriteConditionalJumpLongAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress);
static AbstractInstruction * NoDbgRegParms rewriteCPICJumpAttarget(AbstractInstruction * self_in_rewriteCPICJumpAttarget, usqInt addressFollowingJump, usqInt jumpTargetAddress);
static sqInt NoDbgRegParms rewriteInlineCacheAttagtarget(AbstractInstruction * self_in_rewriteInlineCacheAttagtarget, usqInt callSiteReturnAddress, sqInt cacheTag, usqInt callTargetAddress);
static AbstractInstruction * NoDbgRegParms rewriteInlineCacheTagat(AbstractInstruction * self_in_rewriteInlineCacheTagat, sqInt cacheTag, usqInt callSiteReturnAddress);
static AbstractInstruction * NoDbgRegParms rewriteITypeBranchAtAddresstarget(AbstractInstruction * self_in_rewriteITypeBranchAtAddresstarget, sqInt mcpc, sqInt newTarget);
static AbstractInstruction * NoDbgRegParms rewriteJTypeAtAddressdelta(AbstractInstruction * self_in_rewriteJTypeAtAddressdelta, sqInt mcpc, sqInt delta);
static AbstractInstruction * NoDbgRegParms rewriteJTypeAtAddresstarget(AbstractInstruction * self_in_rewriteJTypeAtAddresstarget, sqInt mcpc, sqInt newTarget);
static sqInt NoDbgRegParms rewriteJumpLongAttarget(AbstractInstruction * self_in_rewriteJumpLongAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress);
static sqInt NoDbgRegParms rtAtAddress(AbstractInstruction * self_in_rtAtAddress, sqInt mcpc);
static sqInt NoDbgRegParms rtypersrtrdsafunct(AbstractInstruction * self_in_rtypersrtrdsafunct, sqInt op, sqInt rs, sqInt rt, sqInt rd, sqInt sa, sqInt funct);
static sqInt NoDbgRegParms sbRbaseoffset(AbstractInstruction * self_in_sbRbaseoffset, sqInt srcReg, sqInt baseReg, sqInt offset);
static sqInt NoDbgRegParms setsConditionCodesFor(AbstractInstruction * self_in_setsConditionCodesFor, sqInt aConditionalJumpOpcode);
static sqInt NoDbgRegParms shRbaseoffset(AbstractInstruction * self_in_shRbaseoffset, sqInt srcReg, sqInt baseReg, sqInt offset);
static usqInt NoDbgRegParms sizePCDependentInstructionAt(AbstractInstruction * self_in_sizePCDependentInstructionAt, sqInt eventualAbsoluteAddress);
static sqInt NoDbgRegParms sllRRC(AbstractInstruction * self_in_sllRRC, sqInt destReg, sqInt sourceReg, sqInt shiftAmount);
static sqInt NoDbgRegParms sllvRRR(AbstractInstruction * self_in_sllvRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms sltiRRC(AbstractInstruction * self_in_sltiRRC, sqInt destReg, sqInt leftReg, sqInt imm);
static sqInt NoDbgRegParms sltiuRRC(AbstractInstruction * self_in_sltiuRRC, sqInt destReg, sqInt leftReg, sqInt imm);
static sqInt NoDbgRegParms sltRRR(AbstractInstruction * self_in_sltRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms sltuRRR(AbstractInstruction * self_in_sltuRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms sraRRC(AbstractInstruction * self_in_sraRRC, sqInt destReg, sqInt sourceReg, sqInt shiftAmount);
static sqInt NoDbgRegParms sravRRR(AbstractInstruction * self_in_sravRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms srlRRC(AbstractInstruction * self_in_srlRRC, sqInt destReg, sqInt sourceReg, sqInt shiftAmount);
static sqInt NoDbgRegParms srlvRRR(AbstractInstruction * self_in_srlvRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms stop(AbstractInstruction * self_in_stop);
static AbstractInstruction * NoDbgRegParms stopsFromto(AbstractInstruction * self_in_stopsFromto, sqInt startAddr, sqInt endAddr);
static sqInt NoDbgRegParms storeLiteralbeforeFollowingAddress(AbstractInstruction * self_in_storeLiteralbeforeFollowingAddress, sqInt literal, sqInt followingAddress);
static sqInt NoDbgRegParms subuRRR(AbstractInstruction * self_in_subuRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms swRbaseoffset(AbstractInstruction * self_in_swRbaseoffset, sqInt srcReg, sqInt baseReg, sqInt offset);
static usqInt NoDbgRegParms targetFromITypeAtAddress(AbstractInstruction * self_in_targetFromITypeAtAddress, usqInt mcpc);
static usqInt NoDbgRegParms targetFromJTypeAtAddress(AbstractInstruction * self_in_targetFromJTypeAtAddress, usqInt mcpc);
static sqInt NoDbgRegParms xoriRRC(AbstractInstruction * self_in_xoriRRC, sqInt destReg, sqInt srcReg, sqInt imm);
static sqInt NoDbgRegParms xorRRR(AbstractInstruction * self_in_xorRRR, sqInt destReg, sqInt leftReg, sqInt rightReg);
static sqInt NoDbgRegParms zoneCallsAreRelative(AbstractInstruction * self_in_zoneCallsAreRelative);
static sqInt NoDbgRegParms checkValidObjectReference(sqInt anOop);
static AbstractInstruction * NoDbgRegParms genCmpClassFloatCompactIndexR(sqInt reg);
static AbstractInstruction * NoDbgRegParms genCmpClassMethodContextCompactIndexR(sqInt reg);
static AbstractInstruction * NoDbgRegParms genJumpSmallIntegerscratchReg(sqInt aRegister, sqInt scratch);
static sqInt NoDbgRegParms genLoadSlotsourceRegdestReg(sqInt index, sqInt sourceReg, sqInt destReg);
static sqInt genPrimitiveAdd(void);
static sqInt genPrimitiveBitAnd(void);
static sqInt genPrimitiveBitOr(void);
static sqInt genPrimitiveBitShift(void);
static sqInt genPrimitiveBitXor(void);
static sqInt genPrimitiveClass(void);
static sqInt genPrimitiveDiv(void);
static sqInt genPrimitiveDivide(void);
static sqInt genPrimitiveEqual(void);
static sqInt genPrimitiveGreaterOrEqual(void);
static sqInt genPrimitiveGreaterThan(void);
static sqInt genPrimitiveIdentical(void);
static sqInt genPrimitiveLessOrEqual(void);
static sqInt genPrimitiveLessThan(void);
static sqInt genPrimitiveMod(void);
static sqInt genPrimitiveMultiply(void);
static sqInt genPrimitiveNewMethod(void);
static sqInt genPrimitiveNotEqual(void);
static sqInt genPrimitiveNotIdentical(void);
static sqInt genPrimitiveQuo(void);
static sqInt genPrimitiveSubtract(void);
static sqInt NoDbgRegParms genSmallIntegerComparison(sqInt jumpOpcode);
static sqInt NoDbgRegParms genSmallIntegerComparisonorDoubleComparisoninvert(sqInt jumpOpcode, AbstractInstruction *(*jumpFPOpcodeGenerator)(void *), sqInt invertComparison);
static sqInt NoDbgRegParms isUnannotatableConstant(CogSimStackEntry *simStackEntry);
static sqInt NoDbgRegParms genAddSmallIntegerTagsTo(sqInt aRegister);
static sqInt NoDbgRegParms genClearAndSetSmallIntegerTagsIn(sqInt scratchReg);
static void NoDbgRegParms genConvertCharacterToSmallIntegerInReg(sqInt reg);
static sqInt NoDbgRegParms genConvertIntegerToSmallIntegerInReg(sqInt reg);
static void NoDbgRegParms genConvertSmallIntegerToCharacterInReg(sqInt reg);
static sqInt NoDbgRegParms genConvertSmallIntegerToIntegerInReg(sqInt reg);
static sqInt NoDbgRegParms genFetchIndexRegisterfrominto(sqInt indexReg, sqInt tableObj, sqInt destReg);
static sqInt NoDbgRegParms genGetHashFieldNonImmOfasSmallIntegerInto(sqInt instReg, sqInt destReg);
static sqInt NoDbgRegParms genGetHashFieldNonImmOfinto(sqInt instReg, sqInt destReg);
static AbstractInstruction * NoDbgRegParms genGetInlineCacheClassTagFromintoforEntry(sqInt sourceReg, sqInt destReg, sqInt forEntry);
static sqInt NoDbgRegParms genGetOverflowSlotsOfinto(sqInt srcReg, sqInt destReg);
static AbstractInstruction * NoDbgRegParms genJumpIsSmallIntegerValuescratch(sqInt aRegister, sqInt scratchReg);
static AbstractInstruction * NoDbgRegParms genJumpNotSmallIntegerInScratchReg(sqInt aRegister);
static AbstractInstruction * NoDbgRegParms genJumpNotSmallIntegerValuescratch(sqInt aRegister, sqInt scratchReg);
static AbstractInstruction * NoDbgRegParms genJumpNotSmallInteger(sqInt aRegister);
static AbstractInstruction * NoDbgRegParms genJumpSmallInteger(sqInt aRegister);
static sqInt genPrimitiveAt(void);
static sqInt genPrimitiveAtPut(void);
static sqInt genPrimitiveIdentityHash(void);
static sqInt genPrimitiveNew(void);
static sqInt genPrimitiveNewWithArg(void);
static sqInt genPrimitiveStringAt(void);
static sqInt genPrimitiveStringAtPut(void);
static sqInt NoDbgRegParms genRemoveSmallIntegerTagsInScratchReg(sqInt scratchReg);
static sqInt NoDbgRegParms genShiftAwaySmallIntegerTagsInScratchReg(sqInt scratchReg);
static sqInt NoDbgRegParms inlineCacheTagForInstance(sqInt oop);
static AbstractInstruction * NoDbgRegParms jumpNotSmallIntegerUnsignedValueInRegister(sqInt reg);
static sqInt NoDbgRegParms markAndTraceCacheTagLiteralinatpc(sqInt literal, CogMethod *cogMethodOrNil, usqInt address);
static sqInt numSmallIntegerBits(void);
static sqInt NoDbgRegParms validInlineCacheTag(usqInt classIndexOrTagPattern);
static sqInt NoDbgRegParms cacheTagIsMarked(sqInt cacheTag);
static sqInt NoDbgRegParms checkValidOopReference(sqInt anOop);
static sqInt NoDbgRegParms couldBeObject(sqInt literal);
static sqInt NoDbgRegParms genActiveContextTrampolineLargeinBlockcalled(sqInt isLarge, sqInt isInBlock, char *aString);
static sqInt NoDbgRegParms genConvertCharacterToCodeInReg(sqInt reg);
static sqInt NoDbgRegParms genConvertIntegerToCharacterInReg(sqInt reg);
static sqInt NoDbgRegParms genCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock);
static sqInt NoDbgRegParms genEnsureObjInRegNotForwardedscratchReg(sqInt reg, sqInt scratch);
static sqInt NoDbgRegParms genEnsureOopInRegNotForwardedscratchReg(sqInt reg, sqInt scratch);
static sqInt NoDbgRegParms genEnsureOopInRegNotForwardedscratchRegjumpBackTo(sqInt reg, sqInt scratch, AbstractInstruction *instruction);
static sqInt NoDbgRegParms genEnsureOopInRegNotForwardedscratchRegupdatingSlotin(sqInt reg, sqInt scratch, sqInt index, sqInt objReg);
static void generateObjectRepresentationTrampolines(void);
static sqInt NoDbgRegParms genGetActiveContextLargeinBlock(sqInt isLarge, sqInt isInBlock);
static sqInt NoDbgRegParms genGetActiveContextNumArgslargeinBlock(sqInt numArgs, sqInt isLargeContext, sqInt isInBlock);
static sqInt NoDbgRegParms genGetBitsofFormatByteOfinto(sqInt mask, sqInt sourceReg, sqInt destReg);
static sqInt NoDbgRegParms genGetClassIndexOfNonImminto(sqInt sourceReg, sqInt destReg);
static sqInt NoDbgRegParms genGetClassObjectOfClassIndexintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg);
static sqInt NoDbgRegParms genGetClassObjectOfintoscratchReginstRegIsReceiver(sqInt instReg, sqInt destReg, sqInt scratchReg, sqInt instRegIsReceiver);
static AbstractInstruction * NoDbgRegParms genGetClassTagOfintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg);
static sqInt NoDbgRegParms genGetCompactClassIndexNonImmOfinto(sqInt instReg, sqInt destReg);
static sqInt NoDbgRegParms genGetDoubleValueOfinto(sqInt srcReg, sqInt destFPReg);
static sqInt NoDbgRegParms genGetFormatOfinto(sqInt srcReg, sqInt destReg);
static sqInt NoDbgRegParms genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(sqInt sourceReg, sqInt destReg, sqInt scratchRegOrNone);
static sqInt NoDbgRegParms genGetNumSlotsOfinto(sqInt srcReg, sqInt destReg);
static sqInt NoDbgRegParms genGetRawSlotSizeOfNonImminto(sqInt sourceReg, sqInt destReg);
static AbstractInstruction * NoDbgRegParms genJumpImmediate(sqInt aRegister);
static AbstractInstruction * NoDbgRegParms genJumpNotCharacterInScratchReg(sqInt reg);
static sqInt NoDbgRegParms genNewArrayOfSizeinitialized(sqInt size, sqInt initialized);
static sqInt NoDbgRegParms genNoPopCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock);
static sqInt genPrimitiveAsCharacter(void);
static sqInt genPrimitiveCharacterValue(void);
static sqInt NoDbgRegParms genPrimitiveIdenticalOrNotIf(sqInt orNot);
static sqInt genPrimitiveObjectAt(void);
static sqInt genPrimitiveSize(void);
static sqInt NoDbgRegParms genSetSmallIntegerTagsIn(sqInt scratchReg);
static sqInt genStoreCheckContextReceiverTrampoline(void);
static sqInt NoDbgRegParms genStoreCheckReceiverRegvalueRegscratchReginFrame(sqInt destReg, sqInt valueReg, sqInt scratchReg, sqInt inFrame);
static sqInt NoDbgRegParms genStoreSourceRegslotIndexdestRegscratchReginFrameneedsStoreCheck(sqInt sourceReg, sqInt index, sqInt destReg, sqInt scratchReg, sqInt inFrame, sqInt needsStoreCheck);
static sqInt NoDbgRegParms genStoreSourceRegslotIndexintoNewObjectInDestReg(sqInt sourceReg, sqInt index, sqInt destReg);
static sqInt getActiveContextAllocatesInMachineCode(void);
static sqInt NoDbgRegParms inlineCacheTagIsYoung(sqInt cacheTag);
static AbstractInstruction * NoDbgRegParms jumpNotCharacterUnsignedValueInRegister(sqInt reg);
static sqInt NoDbgRegParms markAndTraceLiteralinatpc(sqInt literal, CogMethod *cogMethodOrNil, usqInt address);
static void NoDbgRegParms markAndTraceLiteralinat(sqInt literal, CogMethod *cogMethod, sqInt *address);
static void NoDbgRegParms markAndTraceUpdatedLiteralin(sqInt objOop, CogMethod *cogMethodOrNil);
static sqInt NoDbgRegParms maybeCompileRetryonPrimitiveFail(AbstractInstruction *retryInst, sqInt primIndex);
static sqInt numCharacterBits(void);
extern sqInt numRegArgs(void);
static sqInt NoDbgRegParms remapObject(sqInt objOop);
static sqInt NoDbgRegParms remapOop(sqInt objOop);
static sqInt NoDbgRegParms shouldAnnotateObjectReference(sqInt anOop);
static sqInt NoDbgRegParms slotOffsetOfInstVarIndex(sqInt index);
static CogSimStackEntry * NoDbgRegParms ensureSpilledAtfrom(CogSimStackEntry * self_in_ensureSpilledAtfrom, sqInt baseOffset, sqInt baseRegister);
static CogSimStackEntry * NoDbgRegParms mergeAtfrom(CogSimStackEntry * self_in_mergeAtfrom, sqInt baseOffset, sqInt baseRegister);
static CogSimStackEntry * NoDbgRegParms popToReg(CogSimStackEntry * self_in_popToReg, sqInt reg);
static sqInt NoDbgRegParms registerMask(CogSimStackEntry * self_in_registerMask);
static sqInt NoDbgRegParms registerOrNone(CogSimStackEntry * self_in_registerOrNone);
static CogSimStackEntry * NoDbgRegParms storeToReg(CogSimStackEntry * self_in_storeToReg, sqInt reg);
static sqInt compileBlockDispatch(void);
static void compileGetErrorCode(void);
static sqInt NoDbgRegParms compileInterpreterPrimitive(void (*primitiveRoutine)(void));
static AbstractInstruction * NoDbgRegParms compileOpenPICMethodCacheProbeForwithShiftbaseRegOrNone(sqInt selector, sqInt shift, sqInt baseRegOrNone);
static void NoDbgRegParms compileOpenPICnumArgs(sqInt selector, sqInt numArgs);
static AbstractInstruction * NoDbgRegParms compilePerformMethodCacheProbeForwithShiftbaseRegOrNone(sqInt selectorReg, sqInt shift, sqInt baseRegOrNone);
static sqInt compilePrimitive(void);
static sqInt extendedPushBytecode(void);
static sqInt extendedStoreAndPopBytecode(void);
static sqInt extendedStoreBytecode(void);
static sqInt NoDbgRegParms frameOffsetOfTemporary(sqInt index);
static sqInt genBlockReturn(void);
static sqInt genExtendedSendBytecode(void);
static sqInt genExtendedSuperBytecode(void);
static sqInt genFastPrimFail(void);
static void NoDbgRegParms genFastPrimTraceUsingand(sqInt r1, sqInt r2);
static sqInt genLongJumpIfFalse(void);
static sqInt genLongJumpIfTrue(void);
static sqInt genLongStoreAndPopTemporaryVariableBytecode(void);
static sqInt genLongUnconditionalBackwardJump(void);
static sqInt genLongUnconditionalForwardJump(void);
static sqInt NoDbgRegParms genLookupForPerformNumArgs(sqInt numArgs);
static AbstractInstruction * NoDbgRegParms genMoveFalseR(sqInt reg);
static AbstractInstruction * NoDbgRegParms genMoveTrueR(sqInt reg);
static sqInt NoDbgRegParms genMustBeBooleanTrampolineForcalled(sqInt boolean, char *trampolineName);
static void NoDbgRegParms genPrimReturnEnterCogCodeEnilopmart(sqInt profiling);
static sqInt genPushClosureTempsBytecode(void);
static sqInt genPushConstantFalseBytecode(void);
static sqInt genPushConstantNilBytecode(void);
static sqInt genPushConstantTrueBytecode(void);
static sqInt genPushLiteralConstantBytecode(void);
static sqInt NoDbgRegParms genPushLiteralIndex(sqInt literalIndex);
static sqInt genPushLiteralVariableBytecode(void);
static sqInt genPushQuickIntegerConstantBytecode(void);
static sqInt genPushReceiverVariableBytecode(void);
static sqInt genPushTemporaryVariableBytecode(void);
extern sqInt genQuickReturnConst(void);
extern sqInt genQuickReturnInstVar(void);
extern sqInt genQuickReturnSelf(void);
static sqInt genReturnFalse(void);
static sqInt genReturnNil(void);
static sqInt genReturnTrue(void);
static sqInt genSecondExtendedSendBytecode(void);
static sqInt genSendLiteralSelector0ArgsBytecode(void);
static sqInt genSendLiteralSelector1ArgBytecode(void);
static sqInt genSendLiteralSelector2ArgsBytecode(void);
static sqInt genShortJumpIfFalse(void);
static sqInt genShortUnconditionalJump(void);
static sqInt genSpecialSelectorSend(void);
static sqInt genStoreAndPopReceiverVariableBytecode(void);
static sqInt genStoreAndPopRemoteTempLongBytecode(void);
static sqInt genStoreAndPopTemporaryVariableBytecode(void);
static sqInt genStoreRemoteTempLongBytecode(void);
static void maybeCompileAllocFillerCheck(void);
static sqInt numSpecialSelectors(void);
static PrimitiveDescriptor * primitiveGeneratorOrNil(void);
extern void recordCallOffsetIn(CogMethod *cogMethod);
static sqInt NoDbgRegParms registerisInMask(sqInt reg, sqInt mask);
static sqInt returnRegForStoreCheck(void);
extern void rewritePrimInvocationInto(CogMethod *cogMethod, void (*primFunctionPointer)(void));
static sqInt NoDbgRegParms v3BlockCodeSize(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj);
static sqInt NoDbgRegParms v3LongForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj);
static sqInt NoDbgRegParms v3LongBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj);
static sqInt NoDbgRegParms v3ShortForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj);
extern void voidCogCompiledCode(void);
static BlockStart * NoDbgRegParms addBlockStartAtnumArgsnumCopiedspan(sqInt bytecodepc, sqInt numArgs, sqInt numCopied, sqInt span);
static void NoDbgRegParms adjustArgumentsForPerform(sqInt numArgs);
static sqInt NoDbgRegParms allocateRegForStackEntryAtnotConflictingWith(sqInt index, sqInt regMask);
static sqInt NoDbgRegParms allocateRegNotConflictingWith(sqInt regMask);
static void NoDbgRegParms annotateBytecodeIfAnnotated(CogSimStackEntry *aSimStackEntry);
static sqInt NoDbgRegParms anyReferencesToRegisterinTopNItems(sqInt reg, sqInt n);
extern void callCogCodePopReceiverArg0Regs(void);
extern void callCogCodePopReceiverArg1Arg0Regs(void);
static sqInt NoDbgRegParms compileAbstractInstructionsFromthrough(sqInt start, sqInt end);
static sqInt compileBlockBodies(void);
static void NoDbgRegParms compileBlockFrameBuild(BlockStart *blockStart);
static void NoDbgRegParms compileBlockFramelessEntry(BlockStart *blockStart);
static CogMethod * NoDbgRegParms compileCogMethod(sqInt selector);
static sqInt compileEntireMethod(void);
static void compileFrameBuild(void);
static sqInt NoDbgRegParms cPICMissTrampolineFor(sqInt numArgs);
static sqInt doubleExtendedDoAnythingBytecode(void);
static sqInt duplicateTopBytecode(void);
static BytecodeFixup * NoDbgRegParms ensureFixupAt(sqInt targetIndex);
static BytecodeFixup * NoDbgRegParms ensureNonMergeFixupAt(sqInt targetIndex);
static void ensureReceiverResultRegContainsSelf(void);
static void NoDbgRegParms evaluateat(BytecodeDescriptor *descriptor, sqInt pc);
static sqInt NoDbgRegParms freeAnyRegNotConflictingWith(sqInt regMask);
static void (*genCallPICEnilopmartNumArgs(sqInt numArgs))(void) ;
static sqInt genCallPrimitiveBytecode(void);
static sqInt NoDbgRegParms genEqualsEqualsNoBranchArgIsConstantrcvrIsConstantargRegrcvrReg(sqInt argIsConstant, sqInt rcvrIsConstant, sqInt argReg, sqInt rcvrRegOrNone);
static sqInt genExternalizePointersForPrimitiveCall(void);
static void generateEnilopmarts(void);
static void generateMissAbortTrampolines(void);
static void generateSendTrampolines(void);
static void generateTracingTrampolines(void);
static sqInt NoDbgRegParms genJumpBackTo(sqInt targetBytecodePC);
static sqInt NoDbgRegParms genJumpIfto(sqInt boolean, sqInt targetBytecodePC);
static sqInt NoDbgRegParms genJumpTo(sqInt targetBytecodePC);
static sqInt NoDbgRegParms genMarshalledSendnumArgssendTable(sqInt selectorIndex, sqInt numArgs, sqInt *sendTable);
static sqInt NoDbgRegParms genMethodAbortTrampolineFor(sqInt numArgs);
static sqInt NoDbgRegParms genPICAbortTrampolineFor(sqInt numArgs);
static sqInt NoDbgRegParms genPICMissTrampolineFor(sqInt numArgs);
static sqInt genPopStackBytecode(void);
static sqInt genPrimitiveClosureValue(void);
static sqInt genPrimitivePerform(void);
static sqInt genPushActiveContextBytecode(void);
static sqInt genPushClosureCopyCopiedValuesBytecode(void);
static sqInt NoDbgRegParms genPushLiteralVariable(sqInt literalIndex);
static sqInt NoDbgRegParms genPushLiteral(sqInt literal);
static sqInt NoDbgRegParms genPushMaybeContextReceiverVariable(sqInt slotIndex);
static sqInt genPushNewArrayBytecode(void);
static sqInt genPushReceiverBytecode(void);
static sqInt NoDbgRegParms genPushReceiverVariable(sqInt index);
static void genPushRegisterArgs(void);
static sqInt genPushRemoteTempLongBytecode(void);
static sqInt NoDbgRegParms genPushTemporaryVariable(sqInt index);
static sqInt genReturnReceiver(void);
static sqInt genReturnTopFromBlock(void);
static sqInt genReturnTopFromMethod(void);
static sqInt NoDbgRegParms genSendSupernumArgs(sqInt selectorIndex, sqInt numArgs);
static sqInt NoDbgRegParms genSendTrampolineFornumArgscalledargargargarg(void *aRoutine, sqInt numArgs, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3);
static sqInt NoDbgRegParms genSendnumArgs(sqInt selectorIndex, sqInt numArgs);
static sqInt genSpecialSelectorArithmetic(void);
static sqInt genSpecialSelectorClass(void);
static sqInt genSpecialSelectorComparison(void);
static sqInt genSpecialSelectorEqualsEquals(void);
static sqInt genSpecialSelectorEqualsEqualsWithForwarders(void);
static sqInt genStaticallyResolvedSpecialSelectorComparison(void);
static sqInt NoDbgRegParms genStorePopLiteralVariable(sqInt popBoolean, sqInt litVarIndex);
static sqInt NoDbgRegParms genStorePopMaybeContextReceiverVariable(sqInt popBoolean, sqInt slotIndex);
static sqInt NoDbgRegParms genStorePopReceiverVariable(sqInt popBoolean, sqInt slotIndex);
static sqInt NoDbgRegParms genStorePopRemoteTempAt(sqInt popBoolean, sqInt slotIndex, sqInt remoteTempIndex);
static sqInt NoDbgRegParms genStorePopTemporaryVariable(sqInt popBoolean, sqInt tempIndex);
static sqInt genUpArrowReturn(void);
static BytecodeFixup * NoDbgRegParms initializeFixupAt(sqInt targetIndex);
static void NoDbgRegParms initSimStackForFramefulMethod(sqInt startpc);
static void NoDbgRegParms initSimStackForFramelessBlock(sqInt startpc);
static void NoDbgRegParms initSimStackForFramelessMethod(sqInt startpc);
static sqInt liveRegisters(void);
static void NoDbgRegParms marshallSendArguments(sqInt numArgs);
static void NoDbgRegParms mergeafterContinuation(BytecodeFixup *fixup, sqInt mergeWithContinuation);
static sqInt NoDbgRegParms methodAbortTrampolineFor(sqInt numArgs);
static sqInt NoDbgRegParms needsFrameIfMod16GENumArgs(sqInt stackDelta);
static sqInt NoDbgRegParms needsFrameIfStackGreaterThanOne(sqInt stackDelta);
static sqInt NoDbgRegParms numberOfSpillsInTopNItems(sqInt n);
static sqInt NoDbgRegParms picAbortTrampolineFor(sqInt numArgs);
static sqInt prevInstIsPCAnnotated(void);
static sqInt NoDbgRegParms pushNilSizenumInitialNils(sqInt aMethodObj, sqInt numInitialNils);
static void NoDbgRegParms reinitializeFixupsFromthrough(sqInt start, sqInt end);
static void NoDbgRegParms scanBlock(BlockStart *blockStart);
static sqInt scanMethod(void);
static void NoDbgRegParms ssAllocateCallReg(sqInt requiredReg);
static void NoDbgRegParms ssAllocateCallRegand(sqInt requiredReg1, sqInt requiredReg2);
static void NoDbgRegParms ssAllocateCallRegandand(sqInt requiredReg1, sqInt requiredReg2, sqInt requiredReg3);
static void NoDbgRegParms ssAllocateRequiredRegMaskupThrough(sqInt requiredRegsMask, sqInt stackPtr);
static void NoDbgRegParms ssAllocateRequiredReg(sqInt requiredReg);
static void NoDbgRegParms ssAllocateRequiredRegand(sqInt requiredReg1, sqInt requiredReg2);
static void NoDbgRegParms ssAllocateRequiredRegupThrough(sqInt requiredReg, sqInt stackPtr);
static void NoDbgRegParms ssFlushTo(sqInt index);
static void NoDbgRegParms ssFlushUpThroughReceiverVariable(sqInt slotIndex);
static void NoDbgRegParms ssFlushUpThroughTemporaryVariable(sqInt tempIndex);
static void NoDbgRegParms ssPop(sqInt n);
static sqInt NoDbgRegParms ssPushAnnotatedConstant(sqInt literal);
static sqInt NoDbgRegParms ssPushBaseoffset(sqInt reg, sqInt offset);
static sqInt NoDbgRegParms ssPushConstant(sqInt literal);
static sqInt NoDbgRegParms ssPushDesc(CogSimStackEntry simStackEntry);
static sqInt NoDbgRegParms ssPushRegister(sqInt reg);
static void NoDbgRegParms ssPush(sqInt n);
static void NoDbgRegParms ssStoreAndReplacePoptoReg(sqInt popBoolean, sqInt reg);
static sqInt NoDbgRegParms ssStorePoptoPreferredReg(sqInt popBoolean, sqInt preferredReg);
static void NoDbgRegParms ssStorePoptoReg(sqInt popBoolean, sqInt reg);
static CogSimStackEntry * ssTop(void);
static CogSimStackEntry ssTopDescriptor(void);
static CogSimStackEntry * NoDbgRegParms ssValue(sqInt n);
static sqInt NoDbgRegParms tryCollapseTempVectorInitializationOfSize(sqInt slots);
static void updateSimSpillBase(void);
static sqInt NoDbgRegParms v3PushNilSizenumInitialNils(sqInt aMethodObj, sqInt numInitialNils);
static sqInt NoDbgRegParms v3NumPushNils(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj);


/*** Variables ***/
static AbstractInstruction * abstractOpcodes;
static AbstractInstruction aMethodLabel;
static AbstractInstruction * const backEnd = &aMethodLabel;
static usqInt baseAddress;
static sqInt blockCount;
static AbstractInstruction * blockEntryLabel;
static AbstractInstruction * blockEntryNoContextSwitch;
sqInt blockNoContextSwitchOffset;
static BlockStart * blockStarts;
static sqInt breakBlock;
static sqInt breakMethod;
sqInt breakPC;
static sqInt byte0;
static sqInt byte1;
static sqInt byte2;
static sqInt byte3;
static sqInt bytecodePC;
static sqInt bytecodeSetOffset;
void * CFramePointer;
void * CStackPointer;
static sqInt callerSavedRegMask;
sqInt ceBaseFrameReturnTrampoline;
void (*ceCall0ArgsPIC)(void);
void (*ceCall1ArgsPIC)(void);
void (*ceCall2ArgsPIC)(void);
void (*ceCallCogCodePopReceiverAndClassRegs)(void);
void (*ceCallCogCodePopReceiverArg0Regs)(void);
void (*ceCallCogCodePopReceiverArg1Arg0Regs)(void);
void (*ceCallCogCodePopReceiverReg)(void);
sqInt ceCannotResumeTrampoline;
void (*ceCaptureCStackPointers)(void);
static unsigned long (*ceCheckFeaturesFunction)(void);
sqInt ceCheckForInterruptTrampoline;
static sqInt ceCPICMissTrampoline;
void (*ceEnterCogCodePopReceiverReg)(void);
static sqInt ceFetchContextInstVarTrampoline;
unsigned long (*ceGetFP)(void);
unsigned long (*ceGetSP)(void);
static sqInt ceLargeActiveContextInBlockTrampoline;
static sqInt ceLargeActiveContextInMethodTrampoline;
static sqInt ceMethodAbortTrampoline;
static sqInt ceNonLocalReturnTrampoline;
static sqInt cePICAbortTrampoline;
static sqInt cePrimReturnEnterCogCode;
static sqInt cePrimReturnEnterCogCodeProfiling;
sqInt ceReturnToInterpreterTrampoline;
static sqInt ceScheduleScavengeTrampoline;
static sqInt ceSendMustBeBooleanAddFalseTrampoline;
static sqInt ceSendMustBeBooleanAddTrueTrampoline;
static sqInt ceSmallActiveContextInBlockTrampoline;
static sqInt ceSmallActiveContextInMethodTrampoline;
static sqInt ceStoreCheckContextReceiverTrampoline;
static sqInt ceStoreCheckTrampoline;
static sqInt ceStoreContextInstVarTrampoline;
static sqInt ceTraceBlockActivationTrampoline;
static sqInt ceTraceLinkedSendTrampoline;
static sqInt ceTraceStoreTrampoline;
unsigned long (*ceTryLockVMOwner)(void);
void (*ceUnlockVMOwner)(void);
sqInt cFramePointerInUse;
static sqInt checkedEntryAlignment;
static sqInt closedPICSize;
sqInt cmEntryOffset;
sqInt cmNoCheckEntryOffset;
static sqInt codeBase;
static sqInt codeModified;
static sqInt compilationTrace;
static sqInt cPICCaseSize;
static sqInt cPICEndOfCodeOffset;
static sqInt cPICEndSize;
static sqInt cPICPrototype;
static sqInt deadCode;
static sqInt debugFixupBreaks;
static sqInt debugOpcodeIndices;
unsigned long debugPrimCallStackOffset;
static sqInt directedSuperSendTrampolines[NumSendTrampolines];
static sqInt disassemblingMethod;
static AbstractInstruction * endCPICCase0;
static sqInt endPC;
static AbstractInstruction * entry;
static sqInt entryPointMask;
static sqInt enumeratingCogMethod;
static sqInt expectedFPAlignment;
static sqInt expectedSPAlignment;
static sqInt extA;
static sqInt extB;
static sqInt externalPrimCallOffsets[MaxNumArgs + 1];
static sqInt externalPrimJumpOffsets[MaxNumArgs + 1];
static sqInt externalSetPrimOffsets[MaxNumArgs + 1];
static sqInt firstCPICCaseOffset;
static sqInt firstSend;
static BytecodeFixup * fixups;
static BytecodeDescriptor generatorTable[256] = {
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushReceiverVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushTemporaryVariableBytecode, 0, needsFrameIfMod16GENumArgs, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushLiteralVariableBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameIfImmutability, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameIfImmutability, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameIfImmutability, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameIfImmutability, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameIfImmutability, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameIfImmutability, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameIfImmutability, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopReceiverVariableBytecode, 0, needsFrameIfImmutability, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopTemporaryVariableBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushReceiverBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushConstantTrueBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushConstantFalseBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushConstantNilBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushQuickIntegerConstantBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genReturnReceiver, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnTrue, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnFalse, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnNil, 0, needsFrameIfInBlock, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnTopFromMethod, 0, needsFrameIfInBlock, -1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0 },
	{ genReturnTopFromBlock, 0, needsFrameNever, -1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0 },
	{ unknownBytecode, 0, 0, 0, Nop, 1, 0, 0, 0, 0, 0, 0, 1, 0 },
	{ unknownBytecode, 0, 0, 0, Nop, 1, 0, 0, 0, 0, 0, 0, 1, 0 },
	{ extendedPushBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ extendedStoreBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ extendedStoreAndPopBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1 },
	{ genExtendedSendBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ doubleExtendedDoAnythingBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genExtendedSuperBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1 },
	{ genSecondExtendedSendBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genPopStackBytecode, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ duplicateTopBytecode, 0, needsFrameNever, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushActiveContextBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushNewArrayBytecode, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genCallPrimitiveBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushRemoteTempLongBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreRemoteTempLongBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genStoreAndPopRemoteTempLongBytecode, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genPushClosureCopyCopiedValuesBytecode, v3BlockCodeSize, 0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortUnconditionalJump, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genShortJumpIfFalse, v3ShortForwardBranchDistance, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalBackwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongUnconditionalForwardJump, v3LongBranchDistance, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfTrue, v3LongForwardBranchDistance, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genLongJumpIfFalse, v3LongForwardBranchDistance, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, AddRR, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, SubRR, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpLess, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpGreater, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpLessOrEqual, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpGreaterOrEqual, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpZero, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorComparison, 0, 0, 0, JumpNonZero, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, AndRR, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorArithmetic, 0, 0, 0, OrRR, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorEqualsEquals, 0, needsFrameNever, -1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genSpecialSelectorClass, 0, needsFrameIfStackGreaterThanOne, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSpecialSelectorSend, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector0ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector1ArgBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 },
	{ genSendLiteralSelector2ArgsBytecode, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0 }
};
static sqInt guardPageSize;
static sqInt hasYoungReferent;
static sqInt inBlock;
static sqInt initialPC;
static int labelCounter;
static sqInt lastSend;
static usqInt limitAddress;
static sqInt maxCPICCases;
static sqInt maxLitIndex;
static sqInt methodAbortTrampolines[4];
static sqInt methodBytesFreedSinceLastCompaction;
static sqInt methodCount;
static sqInt methodHeader;
static AbstractInstruction * const methodLabel = &aMethodLabel;
static sqInt methodObj;
static sqInt methodOrBlockNumArgs;
static sqInt methodOrBlockNumTemps;
static sqInt methodZoneBase;
static unsigned long minValidCallAddress;
sqInt missOffset;
static usqInt mzFreeStart;
static sqInt needsFrame;
static AbstractInstruction * noCheckEntry;
static sqInt numAbstractOpcodes;
static usqInt objectReferencesInRuntime[NumObjRefsInRuntime];
static sqInt opcodeIndex;
static CogMethod *openPICList = 0;
static sqInt openPICSize;
static CogSSOptStatus optStatus;
static sqInt ordinarySendTrampolines[NumSendTrampolines];
static sqInt picAbortTrampolines[4];
static AbstractInstruction * picInterpretAbort;
static sqInt picMissTrampolines[4];
static void (*postCompileHook)(CogMethod *);
static BytecodeDescriptor * prevBCDescriptor;
static AbstractInstruction * primInvokeInstruction;
static sqInt primitiveIndex;
static AbstractInstruction * primSetFunctionLabel;
void (*realCECallCogCodePopReceiverAndClassRegs)(void);
void (*realCECallCogCodePopReceiverArg0Regs)(void);
void (*realCECallCogCodePopReceiverArg1Arg0Regs)(void);
void (*realCECallCogCodePopReceiverReg)(void);
void (*realCEEnterCogCodePopReceiverReg)(void);
static sqInt regArgsHaveBeenPushed;
static sqInt runtimeObjectRefIndex;
static AbstractInstruction * sendMiss;
static CogSimStackEntry simSelf;
static sqInt simSpillBase;
static CogSimStackEntry simStack[77];
static sqInt simStackPtr;
static AbstractInstruction * stackCheckLabel;
static AbstractInstruction * stackOverflowCall;
static sqInt superSendTrampolines[NumSendTrampolines];
int traceFlags = 8 /* prim trace log on by default */;
sqInt traceStores;
static char *trampolineAddresses[NumTrampolines*2];
static sqInt trampolineTableIndex;
static sqInt uncheckedEntryAlignment;
static usqInt unpairedMethodList;
static usqInt youngReferrers;


/*** Macros ***/
#define cPICNumCases stackCheckOffset
#define cPICNumCasesHack hack hack hack i.e. the getter macro does all the work
#define abstractInstructionAt(index) (&abstractOpcodes[index])
#define allocateBlockStarts(numBlocks) do { \
		blockStarts = (numBlocks) ? alloca(sizeof(BlockStart) * (numBlocks)) : 0; \
} while (0)
#define backEnd() backEnd
#define blockAlignment(self) 8
#define blockStartAt(index) (&blockStarts[index])
#define breakOnImplicitReceiver() (traceFlags & 64)
#define callerSavedRegMask() callerSavedRegMask
#define ceBaseFrameReturnPC() ceBaseFrameReturnTrampoline
#define ceCannotResumePC() ((usqInt)ceCannotResumeTrampoline)
#define ceCheckFeatures() ceCheckFeaturesFunction()
#define ceReturnToInterpreterPC() ((usqInt)ceReturnToInterpreterTrampoline)
#define cFramePointerAddress() ((unsigned long)&CFramePointer)
#define compileSendTrace() (traceFlags & 2)
#define cr() putchar('\n')
#define cStackPointerAddress() ((unsigned long)&CStackPointer)
#define entryOffset() cmEntryOffset
#define generatorAt(index) (&generatorTable[index])
#define getCFramePointer() CFramePointer
#define getCStackPointer() CStackPointer
#define getIsObjectReference() 2
#define halt() warning("halt")
#define haltmsg(msg) warning("halt: " msg)
#define interpretOffset() missOffset
#define methodLabel() methodLabel
#define methodZoneBase() methodZoneBase
#define minCallAddress() minValidCallAddress
#define noCheckEntryOffset() cmNoCheckEntryOffset
#define noContextSwitchBlockEntryOffset() blockNoContextSwitchOffset
#define notYetImplemented() warning("not yet implemented")
#define printNum(n) printf("%ld", (long) n)
#define printOnTrace() (traceFlags & 1)
#define print(aString) printf(aString)
#define recordBlockTrace() (traceFlags & 4)
#define recordEventTrace() (traceFlags & 16)
#define recordOverflowTrace() (traceFlags & 32)
#define recordPrimTrace() (traceFlags & 8)
#define recordSendTrace() (traceFlags & 2)
#define reportError(n) warning("compilation error")
#define setCFramePointer(theFP) (CFramePointer = (void *)(theFP))
#define setCStackPointer(theSP) (CStackPointer = (void *)(theSP))
#define tryLockVMOwner() (ceTryLockVMOwner() != 0)
#define unlockVMOwner() ceUnlockVMOwner()
#define nextOpenPIC methodObject
#define nextOpenPICHack hack hack hack i.e. the getter macro does all the work
#define freeStart() mzFreeStart
#define limitZony() ((CogMethod *)mzFreeStart)
#define methodBytesFreedSinceLastCompaction() methodBytesFreedSinceLastCompaction
#define roundUpLength(numBytes) ((numBytes) + 7 & -8)
#define youngReferrers() youngReferrers
#define flushICacheFromto(me,startAddress,endAddress) cacheflush((char*) startAddress, endAddress - startAddress, ICACHE)
#define numberOfSaveableRegisters(self) 0
#define maybeConstant(sse) ((sse)->constant)
#define fixupAt(index) (&fixups[index])
#define simStackAt(index) (simStack + (index))
#define traceDescriptor(ign) 0
#define traceFixup(ign) 0
#define traceMerge(ign) 0
#define traceSimStack() 0
#define traceSpill(ign) 0
#define allocatype(numElements, elementType) alloca((numElements)*sizeof(elementType))
#define numElementsIn(anArray) (sizeof(anArray)/sizeof(anArray[0]))
#define oopisGreaterThanOrEqualTo(anOop,otherOop) ((usqInt)(anOop) >= (usqInt)(otherOop))
#define oopisGreaterThanOrEqualToandLessThanOrEqualTo(anOop,baseOop,limitOop) ((usqInt)(anOop) >= (usqInt)(baseOop) && (usqInt)(anOop) <= (usqInt)(limitOop))
#define oopisGreaterThanOrEqualToandLessThan(anOop,baseOop,limitOop) ((usqInt)(anOop) >= (usqInt)(baseOop) && (usqInt)(anOop) < (usqInt)(limitOop))
#define oopisGreaterThan(anOop,otherOop) ((usqInt)(anOop) > (usqInt)(otherOop))
#define oopisGreaterThanandLessThan(anOop,baseOop,limitOop) ((usqInt)(anOop) > (usqInt)(baseOop) && (usqInt)(anOop) < (usqInt)(limitOop))
#define oopisLessThanOrEqualTo(anOop,otherOop) ((usqInt)(anOop) <= (usqInt)(otherOop))
#define oopisLessThan(anOop,otherOop) ((usqInt)(anOop) < (usqInt)(otherOop))


	/* CogAbstractInstruction>>#addDependent: */
static AbstractInstruction * NoDbgRegParms
addDependent(AbstractInstruction * self_in_addDependent, AbstractInstruction *anInstruction)
{
	if (!(((self_in_addDependent->dependent)) == null)) {
		(anInstruction->dependent = (self_in_addDependent->dependent));
	}
	return ((self_in_addDependent->dependent) = anInstruction);
}


/*	Answer an unused abstract register in the liveRegMask.
	Subclasses with more registers can override to answer them. */

	/* CogAbstractInstruction>>#availableRegisterOrNoneFor: */
static sqInt NoDbgRegParms
availableRegisterOrNoneFor(AbstractInstruction * self_in_availableRegisterOrNoneFor, sqInt liveRegsMask)
{
	flag("searching physical registers that are not assigned to abstract registers first will do a better job and allocate with fewer conflicts.  But this will be much easier if we use the same range for concrete and abstract registers (0-N) and simply number abstract registers the same as their corresponding concrete registers.");
	if (!(liveRegsMask & (registerMaskFor(Arg1Reg)))) {
		return Arg1Reg;
	}
	if (!(liveRegsMask & (registerMaskFor(Arg0Reg)))) {
		return Arg0Reg;
	}
	if (!(liveRegsMask & (registerMaskFor(SendNumArgsReg)))) {
		return SendNumArgsReg;
	}
	if (!(liveRegsMask & (registerMaskFor(ClassReg)))) {
		return ClassReg;
	}
	if (!(liveRegsMask & (registerMaskFor(ReceiverResultReg)))) {
		return ReceiverResultReg;
	}
	return NoReg;
}


/*	For out-of-line literal support, clone a literal from a literal. */

	/* CogAbstractInstruction>>#cloneLiteralFrom: */
static AbstractInstruction * NoDbgRegParms
cloneLiteralFrom(AbstractInstruction * self_in_cloneLiteralFrom, AbstractInstruction *existingLiteral)
{
	assert((((existingLiteral->opcode)) == Literal)
	 && ((((self_in_cloneLiteralFrom->dependent)) == null)
	 && (((self_in_cloneLiteralFrom->address)) == null)));
	(self_in_cloneLiteralFrom->opcode) = Literal;
	(self_in_cloneLiteralFrom->annotation) = (existingLiteral->annotation);
	((self_in_cloneLiteralFrom->operands))[0] = (((existingLiteral->operands))[0]);
	((self_in_cloneLiteralFrom->operands))[1] = (((existingLiteral->operands))[1]);
	((self_in_cloneLiteralFrom->operands))[2] = (((existingLiteral->operands))[2]);
	return self_in_cloneLiteralFrom;
}

	/* CogAbstractInstruction>>#genAlignCStackSavingRegisters:numArgs:wordAlignment: */
static sqInt NoDbgRegParms
genAlignCStackSavingRegistersnumArgswordAlignment(AbstractInstruction * self_in_genAlignCStackSavingRegistersnumArgswordAlignment, sqInt saveRegs, sqInt numArgs, sqInt alignment)
{
    AbstractInstruction *anInstruction;
    sqInt delta;
    sqInt wordsPushedModAlignment;

	if ((numIntRegArgs(self_in_genAlignCStackSavingRegistersnumArgswordAlignment)) >= ((saveRegs
		? (numberOfSaveableRegisters(self_in_genAlignCStackSavingRegistersnumArgswordAlignment)) + numArgs
		: numArgs))) {
		return 0;
	}
	wordsPushedModAlignment = (((saveRegs
	? numberOfSaveableRegisters(self_in_genAlignCStackSavingRegistersnumArgswordAlignment)
	: 0)) + numArgs) % alignment;
	if (wordsPushedModAlignment != 0) {
		delta = alignment - wordsPushedModAlignment;
		/* begin SubCq:R: */
		anInstruction = genoperandoperand(SubCqR, delta * BytesPerWord, SPReg);
	}
	return 0;
}

	/* CogAbstractInstruction>>#genWriteCResultIntoReg: */
static AbstractInstruction * NoDbgRegParms
genWriteCResultIntoReg(AbstractInstruction * self_in_genWriteCResultIntoReg, sqInt abstractRegister)
{
    sqInt cResultReg;

	cResultReg = V0;
	if (abstractRegister != cResultReg) {
		genoperandoperand(MoveRR, cResultReg, abstractRegister);
	}
	return self_in_genWriteCResultIntoReg;
}


/*	Get the target of a jump instruction. Jumps have the target in the first
	operand. 
 */

	/* CogAbstractInstruction>>#getJmpTarget */
static AbstractInstruction * NoDbgRegParms
getJmpTarget(AbstractInstruction * self_in_getJmpTarget)
{
	return ((AbstractInstruction *) (((self_in_getJmpTarget->operands))[0]));
}


/*	For out-of-line literal support, initialize a sharable literal. */

	/* CogAbstractInstruction>>#initializeSharableLiteral: */
static AbstractInstruction * NoDbgRegParms
initializeSharableLiteral(AbstractInstruction * self_in_initializeSharableLiteral, sqInt literal)
{
	(self_in_initializeSharableLiteral->opcode) = Literal;

	/* separate := nil for Slang */
	(self_in_initializeSharableLiteral->annotation) = null;
	(self_in_initializeSharableLiteral->address) = null;
	(self_in_initializeSharableLiteral->dependent) = null;
	((self_in_initializeSharableLiteral->operands))[0] = literal;
	((self_in_initializeSharableLiteral->operands))[1] = 1;
	((self_in_initializeSharableLiteral->operands))[2] = -1;
	return self_in_initializeSharableLiteral;
}


/*	For out-of-line literal support, initialize an unsharable literal. */

	/* CogAbstractInstruction>>#initializeUniqueLiteral: */
static AbstractInstruction * NoDbgRegParms
initializeUniqueLiteral(AbstractInstruction * self_in_initializeUniqueLiteral, sqInt literal)
{
	(self_in_initializeUniqueLiteral->opcode) = Literal;

	/* separate := nil for Slang */
	(self_in_initializeUniqueLiteral->annotation) = null;
	(self_in_initializeUniqueLiteral->address) = null;
	(self_in_initializeUniqueLiteral->dependent) = null;
	((self_in_initializeUniqueLiteral->operands))[0] = literal;
	((self_in_initializeUniqueLiteral->operands))[1] = 0;
	((self_in_initializeUniqueLiteral->operands))[2] = -1;
	return self_in_initializeUniqueLiteral;
}

	/* CogAbstractInstruction>>#isAFixup: */
static sqInt NoDbgRegParms
isAFixup(AbstractInstruction * self_in_isAFixup, void *fixupOrAddress)
{
	return addressIsInFixups(fixupOrAddress);
}


/*	Answer if an address can be accessed using the offset in a MoveMw:r:R: or
	similar instruction.
	We assume this is true for 32-bit processors and expect 64-bit processors
	to answer false
	for values in the interpreter or the object memory. */

	/* CogAbstractInstruction>>#isWithinMwOffsetRange: */
static sqInt NoDbgRegParms
isWithinMwOffsetRange(AbstractInstruction * self_in_isWithinMwOffsetRange, sqInt anAddress)
{
	return 1;
}


/*	Set the target of a jump instruction. These all have the target in the
	first operand. */

	/* CogAbstractInstruction>>#jmpTarget: */
static AbstractInstruction * NoDbgRegParms
jmpTarget(AbstractInstruction * self_in_jmpTarget, AbstractInstruction *anAbstractInstruction)
{
	((self_in_jmpTarget->operands))[0] = (((usqInt)anAbstractInstruction));
	return anAbstractInstruction;
}


/*	Hack: To arrange that the block method field pushed in a block entry has
	its MFMethodFlagIsBlockFlag bit set we provide labels with an offset. The
	offset for the fakeHeader reference is MFMethodFlagIsBlockFlag. See
	compileBlockFrameBuild: */

	/* CogAbstractInstruction>>#labelOffset */
static usqInt NoDbgRegParms
labelOffset(AbstractInstruction * self_in_labelOffset)
{
	return ((self_in_labelOffset->operands))[1];
}


/*	Answer the constant loaded by the instruction sequence just before this
	address: 
 */

	/* CogAbstractInstruction>>#literal32BeforeFollowingAddress: */
static sqInt NoDbgRegParms
literal32BeforeFollowingAddress(AbstractInstruction * self_in_literal32BeforeFollowingAddress, sqInt followingAddress)
{
	return literalBeforeFollowingAddress(self_in_literal32BeforeFollowingAddress, followingAddress);
}

	/* CogAbstractInstruction>>#resolveJumpTarget */
static AbstractInstruction * NoDbgRegParms
resolveJumpTarget(AbstractInstruction * self_in_resolveJumpTarget)
{
    BytecodeFixup *fixup;

	assert(isJump(self_in_resolveJumpTarget));
	fixup = ((BytecodeFixup *) (((self_in_resolveJumpTarget->operands))[0]));
	if (isAFixup(self_in_resolveJumpTarget, fixup)) {
		assert(addressIsInInstructions((fixup->targetInstruction)));
		jmpTarget(self_in_resolveJumpTarget, (fixup->targetInstruction));
	}
	return self_in_resolveJumpTarget;
}


/*	Rewrite a CallFull instruction to call a different target. This variant is
	used to rewrite cached primitive calls.
	Answer the extent of the code change which is used to compute the range of
	the icache to flush.
	This defaults to rewriteCallAt:target:; processors that differentiate
	between Call and CallFull will override. */

	/* CogAbstractInstruction>>#rewriteCallFullAt:target: */
static sqInt NoDbgRegParms
rewriteCallFullAttarget(AbstractInstruction * self_in_rewriteCallFullAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress)
{
	return rewriteCallAttarget(self_in_rewriteCallFullAttarget, callSiteReturnAddress, callTargetAddress);
}


/*	Rewrite a JumpFull instruction to jump to a different target. This variant
	is used to rewrite cached primitive calls.
	Answer the extent of the code change which is used to compute the range of
	the icache to flush.
	This defaults to rewriteJumpLongAt:target:; processors that differentiate
	between Jump and JumpFull will override. */

	/* CogAbstractInstruction>>#rewriteJumpFullAt:target: */
static sqInt NoDbgRegParms
rewriteJumpFullAttarget(AbstractInstruction * self_in_rewriteJumpFullAttarget, sqInt callSiteReturnAddress, sqInt callTargetAddress)
{
	return rewriteJumpLongAttarget(self_in_rewriteJumpFullAttarget, callSiteReturnAddress, callTargetAddress);
}


/*	Hack: To arrange that the block method field pushed in a block entry has
	its MFMethodFlagIsBlockFlag bit set we provide labels with an offset. The
	offset for the fakeHeader reference is MFMethodFlagIsBlockFlag. See
	compileBlockFrameBuild: */

	/* CogAbstractInstruction>>#setLabelOffset: */
static sqInt NoDbgRegParms
setLabelOffset(AbstractInstruction * self_in_setLabelOffset, sqInt aValue)
{
	return ((self_in_setLabelOffset->operands))[1] = aValue;
}


/*	Update an instruction that depends on a label outside
	of generated code (e.g. a method or block header). */

	/* CogAbstractInstruction>>#updateLabel: */
static AbstractInstruction * NoDbgRegParms
updateLabel(AbstractInstruction * self_in_updateLabel, AbstractInstruction *labelInstruction)
{
	assert((((self_in_updateLabel->opcode)) == MoveCwR)
	 || (((self_in_updateLabel->opcode)) == PushCw));
	((self_in_updateLabel->operands))[0] = (((labelInstruction->address)) + (labelOffset(labelInstruction)));
	return self_in_updateLabel;
}


/*	A hack hook to allow ARM to override the simulated address for the
	short-cut trampolines,
	and to allow x64 to address CStackPointer and CFramePointer relative to
	VarBaseReg. 
 */

	/* CogAbstractInstruction>>#wantsNearAddressFor: */
static sqInt NoDbgRegParms
wantsNearAddressFor(AbstractInstruction * self_in_wantsNearAddressFor, sqInt anObject)
{
	return 0;
}

	/* CogBlockMethod>>#cmHomeMethod */
static CogMethod * NoDbgRegParms
cmHomeMethod(CogBlockMethod * self_in_cmHomeMethod)
{
	return ((CogMethod *) ((((usqInt)self_in_cmHomeMethod)) - ((self_in_cmHomeMethod->homeOffset))));
}

	/* CogBytecodeDescriptor>>#isBranch */
static sqInt NoDbgRegParms
isBranch(BytecodeDescriptor * self_in_isBranch)
{
	return (((self_in_isBranch->spanFunction)) != null)
	 && (!((self_in_isBranch->isBlockCreation)));
}

	/* CogBytecodeDescriptor>>#isUnconditionalBranch */
static sqInt NoDbgRegParms
isUnconditionalBranch(BytecodeDescriptor * self_in_isUnconditionalBranch)
{
	return (isBranch(self_in_isUnconditionalBranch))
	 && (!(((self_in_isUnconditionalBranch->isBranchTrue))
 || ((self_in_isUnconditionalBranch->isBranchFalse))));
}

	/* Cogit>>#AddCq:R: */
static AbstractInstruction * NoDbgRegParms
gAddCqR(sqInt quickConstant, sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AddCqR, quickConstant, reg);
	return anInstruction;
}

	/* Cogit>>#AndCq:R: */
static AbstractInstruction * NoDbgRegParms
gAndCqR(sqInt quickConstant, sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AndCqR, quickConstant, reg);
	return anInstruction;
}

	/* Cogit>>#AndCq:R:R: */
static AbstractInstruction * NoDbgRegParms
gAndCqRR(sqInt quickConstant, sqInt srcReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *first;

	/* begin gen:quickConstant:operand:operand: */
	anInstruction = genoperandoperandoperand(AndCqRR, quickConstant, srcReg, destReg);
	return anInstruction;

	if (srcReg == destReg) {
		/* begin gen:quickConstant:operand: */
		anInstruction1 = genoperandoperand(AndCqR, quickConstant, destReg);
		return anInstruction1;
	}
	first = genoperandoperand(MoveRR, srcReg, destReg);
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(AndCqR, quickConstant, destReg);
	return first;
}

	/* Cogit>>#ArithmeticShiftRightR:R: */
static AbstractInstruction * NoDbgRegParms
gArithmeticShiftRightRR(sqInt reg1, sqInt reg2)
{
	return genoperandoperand(ArithmeticShiftRightRR, reg1, reg2);
}

	/* Cogit>>#abortOffset */
sqInt
abortOffset(void)
{
	return missOffset;
}

	/* Cogit>>#addCleanBlockStarts */
static void
addCleanBlockStarts(void)
{
    sqInt i;
    sqInt iLimiT;
    sqInt lit;
    sqInt startPCOrNil;

	for (i = 1, iLimiT = (literalCountOf(methodObj)); i <= iLimiT; i += 1) {
		lit = fetchPointerofObject(i, methodObj);
		startPCOrNil = startPCOrNilOfLiteralin(lit, methodObj);
		if (!(startPCOrNil == null)) {
			maxLitIndex = ((maxLitIndex < i) ? i : maxLitIndex);
			addBlockStartAtnumArgsnumCopiedspan(startPCOrNil - 1, argumentCountOfClosure(lit), copiedValueCountOfClosure(lit), spanForCleanBlockStartingAt(startPCOrNil - 1));
		}
	}
}


/*	Perform an integrity/leak check using the heapMap.
	Set a bit at each cog method's header. */

	/* Cogit>>#addCogMethodsToHeapMap */
void
addCogMethodsToHeapMap(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			heapMapAtWordPut(cogMethod, 1);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* Cogit>>#addressIsInFixups: */
static sqInt NoDbgRegParms
addressIsInFixups(AbstractInstruction *address)
{
	return address >= (AbstractInstruction *)&fixups[0] && address < (AbstractInstruction *)&fixups[numAbstractOpcodes];
}

	/* Cogit>>#addressIsInInstructions: */
static sqInt NoDbgRegParms
addressIsInInstructions(AbstractInstruction *address)
{
	return !((unsigned)(address) & BytesPerWord-1) \
				&& (address) >= &abstractOpcodes[0] \
				&& (address) < &abstractOpcodes[opcodeIndex];
}


/*	calculate the end of the n'th case statement - which is complicated
	because we have case 1 right at the top of our CPIC and then build up from
	the last one. Yes I know this sounds strange, but trust me - I'm an
	Engineer, we do things backwards all the emit
 */

	/* Cogit>>#addressOfEndOfCase:inCPIC: */
static sqInt NoDbgRegParms
addressOfEndOfCaseinCPIC(sqInt n, CogMethod *cPIC)
{
	assert((n >= 1)
	 && (n <= maxCPICCases));
	return (n == 1
		? (((sqInt)cPIC)) + firstCPICCaseOffset
		: ((((sqInt)cPIC)) + firstCPICCaseOffset) + (((maxCPICCases + 1) - n) * cPICCaseSize));
}

	/* Cogit>>#alignUptoRoutineBoundary: */
static sqInt NoDbgRegParms
alignUptoRoutineBoundary(sqInt anAddress)
{
	return (((anAddress + 7) | 7) - 7);
}


/*	Check that all methods have valid selectors, and that all linked sends are
	to valid targets and have valid cache tags
 */

	/* Cogit>>#allMachineCodeObjectReferencesValid */
static sqInt
allMachineCodeObjectReferencesValid(void)
{
    CogMethod *cogMethod;
    sqInt ok;

	ok = 1;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			if (!(asserta(checkValidOopReference((cogMethod->selector))))) {
				ok = 0;
			}
			if (!(asserta((cogMethodDoesntLookKosher(cogMethod)) == 0))) {
				ok = 0;
			}
		}
		if ((((cogMethod->cmType)) == CMMethod)
		 || (((cogMethod->cmType)) == CMOpenPIC)) {
			if (!(asserta((mapForperformUntilarg(cogMethod, checkIfValidOopRefAndTargetpccogMethod, ((sqInt)cogMethod))) == 0))) {
				ok = 0;
			}
		}
		if (((cogMethod->cmType)) == CMClosedPIC) {
			if (!(asserta(noTargetsFreeInClosedPIC(cogMethod)))) {
				ok = 0;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return ok;
}

	/* Cogit>>#allMethodsHaveCorrectHeader */
static sqInt
allMethodsHaveCorrectHeader(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			if (!(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()))) {
				return 0;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return 1;
}

	/* Cogit>>#annotateAbsolutePCRef: */
static AbstractInstruction * NoDbgRegParms
annotateAbsolutePCRef(AbstractInstruction *abstractInstruction)
{
	(abstractInstruction->annotation = IsAbsPCReference);
	return abstractInstruction;
}

	/* Cogit>>#annotateBytecode: */
static AbstractInstruction * NoDbgRegParms
annotateBytecode(AbstractInstruction *abstractInstruction)
{
	(abstractInstruction->annotation = HasBytecodePC);
	return abstractInstruction;
}

	/* Cogit>>#annotate:objRef: */
static AbstractInstruction * NoDbgRegParms
annotateobjRef(AbstractInstruction *abstractInstruction, sqInt anOop)
{
	if (shouldAnnotateObjectReference(anOop)) {
		if (isYoungObject(anOop)) {
			hasYoungReferent = 1;
		}
		(abstractInstruction->annotation = IsObjectReference);
	}
	return abstractInstruction;
}

	/* Cogit>>#assertSaneJumpTarget: */
static void NoDbgRegParms
assertSaneJumpTarget(AbstractInstruction *jumpTarget)
{
	assert((closedPICSize == null)
	 || ((openPICSize == null)
	 || ((addressIsInInstructions(jumpTarget))
	 || ((((((usqInt)jumpTarget)) >= codeBase) && ((((usqInt)jumpTarget)) <= ((((sqInt)(limitZony()))) + (((closedPICSize < openPICSize) ? openPICSize : closedPICSize)))))))));
}

	/* Cogit>>#blockCreationBytecodeSizeForHeader: */
static sqInt NoDbgRegParms
blockCreationBytecodeSizeForHeader(sqInt aMethodHeader)
{
	return 
#  if MULTIPLEBYTECODESETS
		(headerIndicatesAlternateBytecodeSet(aMethodHeader)
				? AltBlockCreationBytecodeSize
				: BlockCreationBytecodeSize)
#  else /* MULTIPLEBYTECODESETS */
		BlockCreationBytecodeSize
#  endif /* MULTIPLEBYTECODESETS */
		;
}


/*	Evaluate binaryFunction with the block start mcpc and supplied arg for
	each entry in the block dispatch. If the function answers non-zero answer
	the value
	it answered. Used to update back-references to the home method in
	compaction.  */

	/* Cogit>>#blockDispatchTargetsFor:perform:arg: */
static sqInt NoDbgRegParms
blockDispatchTargetsForperformarg(CogMethod *cogMethod, usqInt (*binaryFunction)(sqInt mcpc, sqInt arg), sqInt arg)
{
    sqInt blockEntry;
    sqInt end;
    sqInt pc;
    sqInt result;
    usqInt targetpc;

	if (((cogMethod->blockEntryOffset)) == 0) {
		return null;
	}
	blockEntry = ((cogMethod->blockEntryOffset)) + (((sqInt)cogMethod));
	pc = blockEntry;
	end = (mapEndFor(cogMethod)) - 1;
	while (pc < end) {
		if (isJumpAt(backEnd, pc)) {
			targetpc = jumpTargetPCAt(backEnd, pc);
			if (targetpc < blockEntry) {
				result = binaryFunction(targetpc, arg);
				if (result != 0) {
					return result;
				}
			}
		}
		pc += instructionSizeAt(backEnd, pc);
	}
	return 0;
}


/*	Answer the zero-relative bytecode pc matching the machine code pc argument
	in cogMethod, given the start of the bytecodes for cogMethod's block or
	method object. */

	/* Cogit>>#bytecodePCFor:startBcpc:in: */
sqInt
bytecodePCForstartBcpcin(sqInt mcpc, sqInt startbcpc, CogBlockMethod *cogMethod)
{
    sqInt aMethodHeader;
    sqInt aMethodHeader1;
    sqInt aMethodObj;
    sqInt annotation;
    sqInt bcpc;
    sqInt bsOffset;
    sqInt byte;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt endbcpc;
    CogMethod *homeMethod;
    sqInt isBackwardBranch;
    sqInt isInBlock;
    sqInt latestContinuation;
    sqInt map;
    sqInt mapByte;
    usqInt mcpc1;
    sqInt nExts;
    sqInt nextBcpc;
    sqInt result;
    sqInt targetPC;

	latestContinuation = 0;
	/* begin mapFor:bcpc:performUntil:arg: */
	assert(((cogMethod->stackCheckOffset)) > 0);

	/* The stack check maps to the start of the first bytecode,
	   the first bytecode being effectively after frame build. */
	mcpc1 = (((usqInt)cogMethod)) + ((cogMethod->stackCheckOffset));
	result = findIsBackwardBranchMcpcBcpcMatchingMcpc(null, 0, (((char *) mcpc1)), startbcpc, (((void *)mcpc)));
	if (result != 0) {
		return result;
	}

	/* In both CMMethod and CMBlock cases find the start of the map and
	   skip forward to the bytecode pc map entry for the stack check. */
	bcpc = startbcpc;
	if (((cogMethod->cmType)) == CMMethod) {
		isInBlock = 0;
		homeMethod = ((CogMethod *) cogMethod);
		assert(startbcpc == (startPCOfMethodHeader((homeMethod->methodHeader))));
		map = ((((usqInt)homeMethod)) + ((homeMethod->blockSize))) - 1;
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == IsAbsPCReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsObjectReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsRelativeCall)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N))));
		latestContinuation = startbcpc;
		aMethodObj = (homeMethod->methodObject);
		endbcpc = (numBytesOf(aMethodObj)) - 1;
		/* begin bytecodeSetOffsetForHeader: */
		aMethodHeader = (homeMethod->methodHeader);
		bsOffset = 
#    if MULTIPLEBYTECODESETS
			(headerIndicatesAlternateBytecodeSet(aMethodHeader)
						? 256
						: 0)
#    else /* MULTIPLEBYTECODESETS */
			0
#    endif /* MULTIPLEBYTECODESETS */
			;
		bcpc += deltaToSkipPrimAndErrorStoreInheader(aMethodObj, (homeMethod->methodHeader));
	}
	else {
		isInBlock = 1;
		assert(bcpc == ((cogMethod->startpc)));
		homeMethod = cmHomeMethod(cogMethod);
		map = findMapLocationForMcpcinMethod((((usqInt)cogMethod)) + (sizeof(CogBlockMethod)), homeMethod);
		assert(map != 0);
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == HasBytecodePC)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N));
		while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
			map -= 1;
		}

		/* skip fiducial; i.e. the map entry for the pc immediately following the method header. */
		map -= 1;
		aMethodObj = (homeMethod->methodObject);
		bcpc = startbcpc - (blockCreationBytecodeSizeForHeader((homeMethod->methodHeader)));
		/* begin bytecodeSetOffsetForHeader: */
		aMethodHeader1 = (homeMethod->methodHeader);
		bsOffset = 
#    if MULTIPLEBYTECODESETS
			(headerIndicatesAlternateBytecodeSet(aMethodHeader1)
						? 256
						: 0)
#    else /* MULTIPLEBYTECODESETS */
			0
#    endif /* MULTIPLEBYTECODESETS */
			;
		byte = (fetchByteofObject(bcpc, aMethodObj)) + bsOffset;
		descriptor = generatorAt(byte);
		endbcpc = (bcpc + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc, -1, aMethodObj)
	: 0));
		bcpc = startbcpc;
	}

	/* Now skip up through the bytecode pc map entry for the stack check. */
	nExts = 0;
	while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
		map -= 1;
	}
	map -= 1;
	while (((mapByte = byteAt(map))) != MapEnd) {

		/* defensive; we exit on bcpc */
		if (mapByte >= FirstAnnotation) {
			annotation = ((usqInt) mapByte) >> AnnotationShift;
			mcpc1 += (mapByte & DisplacementMask) * 4;
			if ((annotation >= IsSendCall)
			 || ((annotation == HasBytecodePC)
			 || (0))) {
				while (1) {
					byte = (fetchByteofObject(bcpc, aMethodObj)) + bsOffset;
					descriptor = generatorAt(byte);
					if (isInBlock) {
						if (bcpc >= endbcpc) {
							return 0;
						}
					}
					else {
						if (((descriptor->isReturn))
						 && (bcpc >= latestContinuation)) {
							return 0;
						}
						if ((isBranch(descriptor))
						 || ((descriptor->isBlockCreation))) {
							/* begin latestContinuationPCFor:at:exts:in: */
							distance = ((descriptor->spanFunction))(descriptor, bcpc, nExts, aMethodObj);
							targetPC = (bcpc + ((descriptor->numBytes))) + (((distance < 0) ? 0 : distance));
							latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
						}
					}
					nextBcpc = (bcpc + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc, nExts, aMethodObj)
	: 0));
					if (((descriptor->isMapped))
					 || (isInBlock
					 && ((descriptor->isMappedInBlock)))) break;
					bcpc = nextBcpc;
					nExts = ((descriptor->isExtension)
						? nExts + 1
						: 0);
				}
				isBackwardBranch = (isBranch(descriptor))
				 && (isBackwardBranchatextsin(descriptor, bcpc, nExts, aMethodObj));
				result = findIsBackwardBranchMcpcBcpcMatchingMcpc(descriptor, isBackwardBranch, (((char *) mcpc1)), bcpc, (((void *)mcpc)));
				if (result != 0) {
					return result;
				}
				bcpc = nextBcpc;
				nExts = ((descriptor->isExtension)
					? nExts + 1
					: 0);
			}
		}
		else {
			assert(((((usqInt) mapByte) >> AnnotationShift) == IsDisplacementX2N)
			 || ((((usqInt) mapByte) >> AnnotationShift) == IsAnnotationExtension));
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc1 += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
	return 0;
}

	/* Cogit>>#CallRT:registersToBeSavedMask: */
static AbstractInstruction * NoDbgRegParms
CallRTregistersToBeSavedMask(sqInt callTarget, sqInt registersToBeSaved)
{
    AbstractInstruction *abstractInstruction;
    sqInt callerSavedRegsToBeSaved;
    AbstractInstruction *lastInst;
    sqInt reg;
    sqInt registersToBePushed;

	callerSavedRegsToBeSaved = callerSavedRegMask & registersToBeSaved;
	registersToBePushed = callerSavedRegsToBeSaved;
	reg = 0;
	while (registersToBePushed != 0) {
		if (registersToBePushed & 1) {
			/* begin PushR: */
			genoperand(PushR, reg);
		}
		reg += 1;
		registersToBePushed = ((sqInt) registersToBePushed) >> 1;
	}
	/* begin CallRT: */
	abstractInstruction = genoperand(Call, callTarget);
	(abstractInstruction->annotation = IsRelativeCall);
	lastInst = abstractInstruction;
	while (reg >= 0) {
		if (callerSavedRegsToBeSaved & (1 << reg)) {
			/* begin PopR: */
			lastInst = genoperand(PopR, reg);
		}
		reg -= 1;
	}
	return lastInst;
}

	/* Cogit>>#Call: */
static AbstractInstruction * NoDbgRegParms
gCall(sqInt callTarget)
{
	return genoperand(Call, callTarget);
}

	/* Cogit>>#CmpCq:R: */
static AbstractInstruction * NoDbgRegParms
gCmpCqR(sqInt quickConstant, sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(CmpCqR, quickConstant, reg);
	return anInstruction;
}

	/* Cogit>>#CmpCw:R: */
static AbstractInstruction * NoDbgRegParms
gCmpCwR(sqInt wordConstant, sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(CmpCwR, wordConstant, reg);
	return anInstruction;
}

	/* Cogit>>#CmpR:R: */
static AbstractInstruction * NoDbgRegParms
gCmpRR(sqInt reg1, sqInt reg2)
{
	return genoperandoperand(CmpRR, reg1, reg2);
}


/*	This is a static version of ceCallCogCodePopReceiverReg
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* Cogit>>#callCogCodePopReceiver */
void
callCogCodePopReceiver(void)
{
	realCECallCogCodePopReceiverReg();
	error("what??");

}


/*	This is a static version of ceCallCogCodePopReceiverAndClassRegs
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* Cogit>>#callCogCodePopReceiverAndClassRegs */
void
callCogCodePopReceiverAndClassRegs(void)
{
	realCECallCogCodePopReceiverAndClassRegs();
}


/*	Code entry closed PIC miss. A send has fallen
	through a closed (finite) polymorphic inline cache.
	Either extend it or patch the send site to an open PIC.
	The stack looks like:
	receiver
	args
	sp=>	sender return address */

	/* Cogit>>#ceCPICMiss:receiver: */
void
ceCPICMissreceiver(CogMethod *cPIC, sqInt receiver)
{
    sqInt cacheTag;
    sqInt errorSelectorOrNil;
    sqInt errsel;
    sqInt method;
    sqInt methodOrSelectorIndex;
    sqInt newTargetMethodOrNil;
    sqInt outerReturn;
    sqInt result;
    sqInt selector;

	if (isOopForwarded(receiver)) {
		ceSendFromInLineCacheMiss(cPIC);
		return;
	}
	outerReturn = stackTop();
	assert(!(((inlineCacheTagAt(backEnd, outerReturn)) == (picAbortDiscriminatorValue()))));
	if (((cPIC->cPICNumCases)) < maxCPICCases) {
		/* begin lookup:for:methodAndErrorSelectorInto: */
		selector = (cPIC->selector);
		methodOrSelectorIndex = lookupOrdinaryreceiver(selector, receiver);
		if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
			if (!(isOopCompiledMethod(methodOrSelectorIndex))) {
				newTargetMethodOrNil = methodOrSelectorIndex;
				errorSelectorOrNil = SelectorCannotInterpret;

				goto l1;
			}
			if ((!(methodHasCogMethod(methodOrSelectorIndex)))
			 && (methodShouldBeCogged(methodOrSelectorIndex))) {

				/* We assume cog:selector: will *not* reclaim the method zone */
				cogselector(methodOrSelectorIndex, selector);
			}
			newTargetMethodOrNil = methodOrSelectorIndex;
			errorSelectorOrNil = null;

			goto l1;
		}
		if (methodOrSelectorIndex == SelectorDoesNotUnderstand) {
			methodOrSelectorIndex = lookupMNUreceiver(splObj(SelectorDoesNotUnderstand), receiver);
			if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
				assert(isOopCompiledMethod(methodOrSelectorIndex));
				if ((!(methodHasCogMethod(methodOrSelectorIndex)))
				 && (methodShouldBeCogged(methodOrSelectorIndex))) {

					/* We assume cog:selector: will *not* reclaim the method zone */
					cogselector(methodOrSelectorIndex, splObj(SelectorDoesNotUnderstand));
				}
				newTargetMethodOrNil = methodOrSelectorIndex;
				errorSelectorOrNil = SelectorDoesNotUnderstand;

				goto l1;
			}
			newTargetMethodOrNil = null;
			errorSelectorOrNil = SelectorDoesNotUnderstand;

			goto l1;
		}
		newTargetMethodOrNil = null;
		errorSelectorOrNil = methodOrSelectorIndex;

	l1:	/* end lookup:for:methodAndErrorSelectorInto: */;
	}
	else {
		newTargetMethodOrNil = (errorSelectorOrNil = null);
	}
	assert(outerReturn == (stackTop()));
	cacheTag = inlineCacheTagForInstance(receiver);
	if ((((cPIC->cPICNumCases)) >= maxCPICCases)
	 || (((errorSelectorOrNil != null)
	 && (errorSelectorOrNil != SelectorDoesNotUnderstand))
	 || ((newTargetMethodOrNil == null)
	 || (isYoung(newTargetMethodOrNil))))) {
		result = patchToOpenPICFornumArgsreceiver((cPIC->selector), (cPIC->cmNumArgs), receiver);
		assert(!result);
		ceSendFromInLineCacheMiss(cPIC);
		return;
	}
	cogExtendPICCaseNMethodtagisMNUCase(cPIC, newTargetMethodOrNil, cacheTag, errorSelectorOrNil == SelectorDoesNotUnderstand);
	executeCogPICfromLinkedSendWithReceiverandCacheTag(cPIC, receiver, inlineCacheTagAt(backEnd, outerReturn));
	return;
}


/*	An in-line cache check in a method has failed. The failing entry check has
	jumped to the ceMethodAbort abort call at the start of the method which
	has called this routine.
	If possible allocate a closed PIC for the current and existing classes.
	The stack looks like:
	receiver
	args
	sender return address
	sp=>	ceMethodAbort call return address
	So we can find the method that did the failing entry check at
	ceMethodAbort call return address - missOffset
	and we can find the send site from the outer return address. */

	/* Cogit>>#ceSICMiss: */
sqInt
ceSICMiss(sqInt receiver)
{
    sqInt cacheTag;
    sqInt entryPoint;
    sqInt errorSelectorOrNil;
    sqInt errsel;
    sqInt extent;
    usqInt innerReturn;
    sqInt method;
    sqInt methodOrSelectorIndex;
    sqInt newTargetMethodOrNil;
    usqInt outerReturn;
    CogMethod *pic;
    sqInt result;
    sqInt selector;
    CogMethod *targetMethod;


	/* Whether we can relink to a PIC or not we need to pop off the inner return and identify the target method. */
	innerReturn = ((usqInt)(popStack()));
	targetMethod = ((CogMethod *) (innerReturn - missOffset));
	if (isOopForwarded(receiver)) {
		return ceSendFromInLineCacheMiss(targetMethod);
	}
	outerReturn = ((usqInt)(stackTop()));
	assert(((outerReturn >= methodZoneBase) && (outerReturn <= (freeStart()))));
	entryPoint = callTargetFromReturnAddress(backEnd, outerReturn);
	assert(((targetMethod->selector)) != (nilObject()));
	assert(((((sqInt)targetMethod)) + cmEntryOffset) == entryPoint);
	/* begin lookup:for:methodAndErrorSelectorInto: */
	selector = (targetMethod->selector);
	methodOrSelectorIndex = lookupOrdinaryreceiver(selector, receiver);
	if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
		if (!(isOopCompiledMethod(methodOrSelectorIndex))) {
			newTargetMethodOrNil = methodOrSelectorIndex;
			errorSelectorOrNil = SelectorCannotInterpret;

			goto l1;
		}
		if ((!(methodHasCogMethod(methodOrSelectorIndex)))
		 && (methodShouldBeCogged(methodOrSelectorIndex))) {

			/* We assume cog:selector: will *not* reclaim the method zone */
			cogselector(methodOrSelectorIndex, selector);
		}
		newTargetMethodOrNil = methodOrSelectorIndex;
		errorSelectorOrNil = null;

		goto l1;
	}
	if (methodOrSelectorIndex == SelectorDoesNotUnderstand) {
		methodOrSelectorIndex = lookupMNUreceiver(splObj(SelectorDoesNotUnderstand), receiver);
		if ((((usqInt)methodOrSelectorIndex)) > (maxLookupNoMNUErrorCode())) {
			assert(isOopCompiledMethod(methodOrSelectorIndex));
			if ((!(methodHasCogMethod(methodOrSelectorIndex)))
			 && (methodShouldBeCogged(methodOrSelectorIndex))) {

				/* We assume cog:selector: will *not* reclaim the method zone */
				cogselector(methodOrSelectorIndex, splObj(SelectorDoesNotUnderstand));
			}
			newTargetMethodOrNil = methodOrSelectorIndex;
			errorSelectorOrNil = SelectorDoesNotUnderstand;

			goto l1;
		}
		newTargetMethodOrNil = null;
		errorSelectorOrNil = SelectorDoesNotUnderstand;

		goto l1;
	}
	newTargetMethodOrNil = null;
	errorSelectorOrNil = methodOrSelectorIndex;

l1:	/* end lookup:for:methodAndErrorSelectorInto: */;
	assert(outerReturn == (stackTop()));
	cacheTag = inlineCacheTagForInstance(receiver);
	if (((errorSelectorOrNil != null)
	 && (errorSelectorOrNil != SelectorDoesNotUnderstand))
	 || (((inlineCacheTagAt(backEnd, outerReturn)) == 0)
	 || ((newTargetMethodOrNil == null)
	 || (isYoung(newTargetMethodOrNil))))) {
		result = patchToOpenPICFornumArgsreceiver((targetMethod->selector), (targetMethod->cmNumArgs), receiver);
		assert(!result);
		return ceSendFromInLineCacheMiss(targetMethod);
	}
	pic = openPICWithSelector((targetMethod->selector));
	if (!(pic)) {

		/* otherwise attempt to create a closed PIC for the two cases. */
		pic = cogPICSelectornumArgsCase0MethodCase1MethodtagisMNUCase((targetMethod->selector), (targetMethod->cmNumArgs), targetMethod, newTargetMethodOrNil, cacheTag, errorSelectorOrNil == SelectorDoesNotUnderstand);
		if ((((((sqInt)pic)) >= MaxNegativeErrorCode) && ((((sqInt)pic)) <= -1))) {

			/* For some reason the PIC couldn't be generated, most likely a lack of code memory.
			   Continue as if this is an unlinked send. */
			if ((((sqInt)pic)) == InsufficientCodeSpace) {
				callForCogCompiledCodeCompaction();
			}
			return ceSendFromInLineCacheMiss(targetMethod);
		}
		flushICacheFromto(processor, ((usqInt)pic), (((usqInt)pic)) + closedPICSize);
	}
	extent = (((pic->cmType)) == CMOpenPIC
		? rewriteInlineCacheAttagtarget(backEnd, outerReturn, inlineCacheValueForSelectorinat((targetMethod->selector), mframeHomeMethodExport(), outerReturn), (((sqInt)pic)) + cmEntryOffset)
		: rewriteCallAttarget(backEnd, outerReturn, (((sqInt)pic)) + cmEntryOffset));
	flushICacheFromto(processor, (((usqInt)outerReturn)) - extent, ((usqInt)outerReturn));
	executeCogPICfromLinkedSendWithReceiverandCacheTag(pic, receiver, inlineCacheTagAt(backEnd, outerReturn));
	return null;
}

	/* Cogit>>#checkAssertsEnabledInCogit */
void
checkAssertsEnabledInCogit(void)
{
    sqInt assertsAreEnabledInCogit;

	assertsAreEnabledInCogit = 0;
	assert(assertsAreEnabledInCogit);
}


/*	Check for a valid object reference, if any, at a map entry. Answer a code
	unique to each error for debugging. */

	/* Cogit>>#checkIfValidOopRefAndTarget:pc:cogMethod: */
static sqInt NoDbgRegParms
checkIfValidOopRefAndTargetpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt offset;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObject;
    sqInt targetMethod;
    CogMethod *targetMethod1;

	if (annotation == IsObjectReference) {
		literal = literalBeforeFollowingAddress(backEnd, ((usqInt)mcpc));
		if (!(asserta(checkValidOopReference(literal)))) {
			return 1;
		}
		if ((couldBeObject(literal))
		 && (isReallyYoungObject(literal))) {
			if (!(asserta(((((CogMethod *) cogMethod))->cmRefersToYoung)))) {
				return 2;
			}
		}
	}
	if (annotation >= IsSendCall) {
		if (!(asserta((((((CogMethod *) cogMethod))->cmType)) == CMMethod))) {
			return 3;
		}
		/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */
		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj = (entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC)));
		if (tagCouldBeObj) {
			if (couldBeObject(cacheTag1)) {
				if (!(asserta(checkValidOopReference(cacheTag1)))) {
					return 4;
				}
			}
			else {
				if (!(asserta(validInlineCacheTag(cacheTag1)))) {
					return 5;
				}
			}
			if ((couldBeObject(cacheTag1))
			 && (isReallyYoungObject(cacheTag1))) {
				if (!(asserta(((((CogMethod *) cogMethod))->cmRefersToYoung)))) {
					return 6;
				}
			}
		}
		else {
			if (!(asserta(validInlineCacheTag(cacheTag1)))) {
				return 7;
			}
		}

		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send; find which kind. */
			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if (!(asserta((((targetMethod1->cmType)) == CMMethod)
				 || ((((targetMethod1->cmType)) == CMClosedPIC)
				 || (((targetMethod1->cmType)) == CMOpenPIC))))) {
				return 8;
			}

		}
	}
	return 0;
}


/*	Check for a valid object reference, if any, at a map entry. Answer a code
	unique to each error for debugging. */

	/* Cogit>>#checkIfValidOopRef:pc:cogMethod: */
static sqInt NoDbgRegParms
checkIfValidOopRefpccogMethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
    sqInt entryPoint;
    sqInt literal;
    sqInt off;
    sqInt offset;
    sqInt offset1;
    sqInt selectorOrCacheTag;
    sqInt *sendTable;
    sqInt table;

	if (annotation == IsObjectReference) {
		literal = literalBeforeFollowingAddress(backEnd, ((usqInt)mcpc));
		if (!(checkValidOopReference(literal))) {
			print("object ref leak in CM ");
			printHex(((sqInt)cogMethod));
			print(" @ ");
			printHex(((sqInt)mcpc));
			cr();
			return 1;
		}
	}
	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint <= methodZoneBase) {
			offset = entryPoint;
		}
		else {
			/* begin offsetAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				offset1 = cmEntryOffset;
				sendTable = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				offset1 = cmNoCheckEntryOffset;
				sendTable = superSendTrampolines;



			}
			offset = offset1;

		}
		selectorOrCacheTag = inlineCacheTagAt(backEnd, ((sqInt)mcpc));
		if ((entryPoint > methodZoneBase)
		 && ((offset != cmNoCheckEntryOffset)
		 && ((((((CogMethod *) (entryPoint - offset)))->cmType)) != CMOpenPIC))) {

			/* linked non-super send, cacheTag is a cacheTag */
			if (!(validInlineCacheTag(selectorOrCacheTag))) {
				print("cache tag leak in CM ");
				printHex(((sqInt)cogMethod));
				print(" @ ");
				printHex(((sqInt)mcpc));
				cr();
				return 1;
			}
		}
		else {

			/* unlinked send or super send; cacheTag is a selector unless 64-bit, in which case it is an index. */
			if (!(checkValidOopReference(selectorOrCacheTag))) {
				print("selector leak in CM ");
				printHex(((sqInt)cogMethod));
				print(" @ ");
				printHex(((sqInt)mcpc));
				cr();
				return 1;
			}
		}
	}
	return 0;
}


/*	Answer if all references to objects in machine-code are valid. */

	/* Cogit>>#checkIntegrityOfObjectReferencesInCode: */
sqInt
checkIntegrityOfObjectReferencesInCode(sqInt gcModes)
{
    CogMethod *cogMethod;
    sqInt count;
    sqInt ok;

	cogMethod = ((CogMethod *) methodZoneBase);
	ok = 1;
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			if ((cogMethod->cmRefersToYoung)) {
				if (((count = occurrencesInYoungReferrers(cogMethod))) != 1) {
					print("young referrer CM ");
					printHex(((sqInt)cogMethod));
					if (count == 0) {
						print(" is not in youngReferrers");
						cr();
					}
					else {
						print(" is in youngReferrers ");
						printNum(count);
						print(" times!");
						cr();
					}
					ok = 0;
				}
			}
			if (!(checkValidOopReference((cogMethod->selector)))) {
				print("object leak in CM ");
				printHex(((sqInt)cogMethod));
				print(" selector");
				cr();
				ok = 0;
			}
			if (((cogMethod->cmType)) == CMMethod) {
				assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
				if (!(checkValidObjectReference((cogMethod->methodObject)))) {
					print("object leak in CM ");
					printHex(((sqInt)cogMethod));
					print(" methodObject");
					cr();
					ok = 0;
				}
				if (!(isOopCompiledMethod((cogMethod->methodObject)))) {
					print("non-method in CM ");
					printHex(((sqInt)cogMethod));
					print(" methodObject");
					cr();
					ok = 0;
				}
				if ((mapForperformUntilarg(cogMethod, checkIfValidOopRefpccogMethod, ((sqInt)cogMethod))) != 0) {
					ok = 0;
				}
				if (((isYoungObject((cogMethod->methodObject)))
				 || (isYoung((cogMethod->selector))))
				 && (!((cogMethod->cmRefersToYoung)))) {
					print("CM ");
					printHex(((sqInt)cogMethod));
					print(" refers to young but not marked as such");
					cr();
					ok = 0;
				}

			}
			else {
				if (((cogMethod->cmType)) == CMClosedPIC) {
					if (!(checkValidObjectReferencesInClosedPIC(cogMethod))) {
						ok = 0;
					}
				}
				else {
					if (((cogMethod->cmType)) == CMOpenPIC) {
						if ((mapForperformUntilarg(cogMethod, checkIfValidOopRefpccogMethod, ((sqInt)cogMethod))) != 0) {
							ok = 0;
						}
					}
				}
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return ok;
}

	/* Cogit>>#checkMaybeObjRefInClosedPIC: */
static sqInt NoDbgRegParms
checkMaybeObjRefInClosedPIC(sqInt maybeObject)
{
	if (maybeObject == 0) {
		return 1;
	}
	if (!(couldBeObject(maybeObject))) {
		return 1;
	}
	return checkValidObjectReference(maybeObject);
}

	/* Cogit>>#checkValidObjectReferencesInClosedPIC: */
static sqInt NoDbgRegParms
checkValidObjectReferencesInClosedPIC(CogMethod *cPIC)
{
    sqInt i;
    sqInt ok;
    sqInt pc;

	ok = 1;

	/* first we check the obj ref at the beginning of the CPIC */
	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	if (!(checkMaybeObjRefInClosedPIC(literalBeforeFollowingAddress(backEnd, pc - (jumpLongByteSize(backEnd)))))) {
		print("object leak in CPIC ");
		printHex(((sqInt)cPIC));
		print(" @ ");
		printHex(pc - (jumpLongByteSize(backEnd)));
		cr();
		ok = 0;
	}

	/* For each case we check any object reference at the end address - sizeof(conditional instruction) and then increment the end address by case size */
	pc = addressOfEndOfCaseinCPIC((cPIC->cPICNumCases), cPIC);
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		if (!(checkMaybeObjRefInClosedPIC(literalBeforeFollowingAddress(backEnd, (pc - (jumpLongConditionalByteSize(backEnd))) - (cmpC32RTempByteSize(backEnd)))))) {
			print("object leak in CPIC ");
			printHex(((sqInt)cPIC));
			print(" @ ");
			printHex(pc - (jumpLongConditionalByteSize(backEnd)));
			cr();
			ok = 0;
		}
		pc += cPICCaseSize;
	}
	return ok;
}


/*	Answer if the ClosedPIC refers to any unmarked objects or freed/freeable
	target methods,
	applying markAndTraceOrFreeCogMethod:firstVisit: to those targets to
	determine if freed/freeable.
 */

	/* Cogit>>#closedPICRefersToUnmarkedObject: */
static sqInt NoDbgRegParms
closedPICRefersToUnmarkedObject(CogMethod *cPIC)
{
    sqInt i;
    sqInt object;
    sqInt pc;

	if (!((isImmediate((cPIC->selector)))
		 || (isMarked((cPIC->selector))))) {
		return 1;
	}
	pc = addressOfEndOfCaseinCPIC(1, cPIC);
	if (couldBeObject((object = literalBeforeFollowingAddress(backEnd, pc - (jumpLongByteSize(backEnd)))))) {
		if (!(isMarked(object))) {
			return 1;
		}
	}
	if (markAndTraceOrFreePICTargetin(jumpLongTargetBeforeFollowingAddress(backEnd, pc), cPIC)) {
		return 1;
	}
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		pc = addressOfEndOfCaseinCPIC(i, cPIC);
		if (couldBeObject((object = literalBeforeFollowingAddress(backEnd, (pc - (jumpLongConditionalByteSize(backEnd))) - (cmpC32RTempByteSize(backEnd)))))) {
			if (!(isMarked(object))) {
				return 1;
			}
		}
		if (markAndTraceOrFreePICTargetin(jumpLongConditionalTargetBeforeFollowingAddress(backEnd, pc), cPIC)) {
			return 1;
		}
	}
	return 0;
}

	/* Cogit>>#codeEntryFor: */
char *
codeEntryFor(char *address)
{
    sqInt i;

	for (i = 0; i <= (trampolineTableIndex - 3); i += 2) {
		if (((address >= (trampolineAddresses[i + 1])) && (address <= ((trampolineAddresses[i + 3]) - 1)))) {
			return trampolineAddresses[i + 1];
		}
	}
	return null;
}

	/* Cogit>>#codeEntryNameFor: */
char *
codeEntryNameFor(char *address)
{
    sqInt i;

	for (i = 0; i <= (trampolineTableIndex - 3); i += 2) {
		if (((address >= (trampolineAddresses[i + 1])) && (address <= ((trampolineAddresses[i + 3]) - 1)))) {
			return trampolineAddresses[i];
		}
	}
	return null;
}

	/* Cogit>>#cogCodeBase */
sqInt
cogCodeBase(void)
{
	return codeBase;
}


/*	Answer the contents of the code zone as an array of pair-wise element,
	address in ascending address order.
	Answer a string for a runtime routine or abstract label (beginning, end,
	etc), a CompiledMethod for a CMMethod,
	or a selector (presumably a Symbol) for a PIC. */

	/* Cogit>>#cogCodeConstituents */
sqInt
cogCodeConstituents(void)
{
    CogMethod *cogMethod;
    sqInt constituents;
    sqInt count;
    sqInt i;
    sqInt label;
    sqInt value;


	/* + 3 for start, freeStart and end */
	count = (trampolineTableIndex / 2) + 3;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			count += 1;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	constituents = instantiateClassindexableSize(classArray(), count * 2);
	if (!(constituents)) {
		return constituents;
	}
	pushRemappableOop(constituents);
	if ((((label = stringForCString("CogCode"))) == null)
	 || (((value = positive32BitIntegerFor(codeBase))) == null)) {
		return null;
	}
	storePointerUncheckedofObjectwithValue(0, topRemappableOop(), label);
	storePointerUncheckedofObjectwithValue(1, topRemappableOop(), value);
	for (i = 0; i < trampolineTableIndex; i += 2) {
		if ((((label = stringForCString(trampolineAddresses[i]))) == null)
		 || (((value = positive32BitIntegerFor(((usqInt)(trampolineAddresses[i + 1]))))) == null)) {
			popRemappableOop();
			return null;
		}
		storePointerUncheckedofObjectwithValue(2 + i, topRemappableOop(), label);
		storePointerUncheckedofObjectwithValue(3 + i, topRemappableOop(), value);
	}
	count = trampolineTableIndex + 2;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			storePointerUncheckedofObjectwithValue(count, topRemappableOop(), (((cogMethod->cmType)) == CMMethod
				? (cogMethod->methodObject)
				: (cogMethod->selector)));
			if (!((value = positive32BitIntegerFor(((usqInt)cogMethod))))) {
				popRemappableOop();
				return null;
			}
			storePointerUncheckedofObjectwithValue(count + 1, topRemappableOop(), value);
			count += 2;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if ((((label = stringForCString("CCFree"))) == null)
	 || (((value = positive32BitIntegerFor(mzFreeStart))) == null)) {
		popRemappableOop();
		return null;
	}
	storePointerUncheckedofObjectwithValue(count, topRemappableOop(), label);
	storePointerUncheckedofObjectwithValue(count + 1, topRemappableOop(), value);
	if ((((label = stringForCString("CCEnd"))) == null)
	 || (((value = positive32BitIntegerFor(limitAddress))) == null)) {
		popRemappableOop();
		return null;
	}
	storePointerUncheckedofObjectwithValue(count + 2, topRemappableOop(), label);
	storePointerUncheckedofObjectwithValue(count + 3, topRemappableOop(), value);
	constituents = popRemappableOop();
	beRootIfOld(constituents);
	return constituents;
}


/*	Extend the cPIC with the supplied case. If caseNMethod is cogged dispatch
	direct to
	its unchecked entry-point. If caseNMethod is not cogged, jump to the fast
	interpreter dispatch, and if isMNUCase then dispatch to fast MNU
	invocation and mark the cPIC as
	having the MNU case for cache flushing. */

	/* Cogit>>#cogExtendPIC:CaseNMethod:tag:isMNUCase: */
static sqInt NoDbgRegParms
cogExtendPICCaseNMethodtagisMNUCase(CogMethod *cPIC, sqInt caseNMethod, sqInt caseNTag, sqInt isMNUCase)
{
    sqInt address;
    sqInt operand;
    sqInt target;

	compilationBreakpointisMNUCase((cPIC->selector), numBytesOf((cPIC->selector)), isMNUCase);
	assert(!(inlineCacheTagIsYoung(caseNTag)));
	assert((caseNMethod != null)
	 && (!(isYoung(caseNMethod))));
	if ((!isMNUCase)
	 && (methodHasCogMethod(caseNMethod))) {

		/* this isn't an MNU and we have an already cogged method to jump to */
		operand = 0;
		target = (((sqInt)(cogMethodOf(caseNMethod)))) + cmNoCheckEntryOffset;
	}
	else {
		operand = caseNMethod;
		if (isMNUCase) {

			/* this is an MNU so tag the CPIC header and setup a jump to the MNUAbort */
			(cPIC->cpicHasMNUCase = 1);
			target = (((sqInt)cPIC)) + (sizeof(CogMethod));
		}
		else {

			/* setup a jump to the interpretAborth so we can cog the target method */
			target = (((sqInt)cPIC)) + (picInterpretAbortOffset());
		}
	}
	address = addressOfEndOfCaseinCPIC(((cPIC->cPICNumCases)) + 1, cPIC);
	rewriteCPICCaseAttagobjReftarget(address, caseNTag, operand, target);
	/* begin rewriteCPIC:caseJumpTo: */
	rewriteCPICJumpAttarget(backEnd, (((((sqInt)cPIC)) + firstCPICCaseOffset) - (jumpLongByteSize(backEnd))) - (loadLiteralByteSize(backEnd)), address - cPICCaseSize);
	flushICacheFromto(processor, ((usqInt)cPIC), (((usqInt)cPIC)) + closedPICSize);
	(cPIC->cPICNumCases = ((cPIC->cPICNumCases)) + 1);
	return 0;
}

	/* Cogit>>#cogitPostGCAction: */
void
cogitPostGCAction(sqInt gcMode)
{
	assert(allMethodsHaveCorrectHeader());
	assert(((gcMode & (GCModeFull + GCModeNewSpace)) == 0)
	 || (kosherYoungReferrers()));
}


/*	Check that the header fields onf a non-free method are consistent with
	the type. Answer 0 if it is ok, otherwise answer a code for the error. */

	/* Cogit>>#cogMethodDoesntLookKosher: */
sqInt
cogMethodDoesntLookKosher(CogMethod *cogMethod)
{
	if (((((cogMethod->blockSize)) & (BytesPerWord - 1)) != 0)
	 || ((((cogMethod->blockSize)) < (sizeof(CogMethod)))
	 || (((cogMethod->blockSize)) >= 32768))) {
		return 1;
	}
	if (((cogMethod->cmType)) == CMFree) {
		return 2;
	}
	if (((cogMethod->cmType)) == CMMethod) {
		if (!((((cogMethod->methodHeader)) & 1))) {
			return 11;
		}
		if (!(couldBeObject((cogMethod->methodObject)))) {
			return 12;
		}
		if ((((cogMethod->stackCheckOffset)) > 0)
		 && (((cogMethod->stackCheckOffset)) < cmNoCheckEntryOffset)) {
			return 13;
		}
		return 0;
	}
	if (((cogMethod->cmType)) == CMOpenPIC) {
		if (((cogMethod->blockSize)) != openPICSize) {
			return 21;
		}
		if (((cogMethod->methodHeader)) != 0) {
			return 22;
		}
		if (((cogMethod->objectHeader)) >= 0) {
			if ((((cogMethod->methodObject)) != 0)
			 && ((((cogMethod->methodObject)) < methodZoneBase)
			 || ((((cogMethod->methodObject)) > ((freeStart()) - openPICSize))
			 || (((((cogMethod->methodObject)) & (BytesPerWord - 1)) != 0)
			 || ((((((CogMethod *) ((cogMethod->methodObject))))->cmType)) != CMOpenPIC))))) {
				return 23;
			}
		}
		if (((cogMethod->stackCheckOffset)) != 0) {
			return 24;
		}
		return 0;
	}
	if (((cogMethod->cmType)) == CMClosedPIC) {
		if (((cogMethod->blockSize)) != closedPICSize) {
			return 0x1F;
		}
		if (!(((((cogMethod->cPICNumCases)) >= 1) && (((cogMethod->cPICNumCases)) <= maxCPICCases)))) {
			return 32;
		}
		if (((cogMethod->methodHeader)) != 0) {
			return 33;
		}
		if (((cogMethod->methodObject)) != 0) {
			return 34;
		}
		return 0;
	}
	return 9;
}


/*	Attempt to create a one-case PIC for an MNU.
	The tag for the case is at the send site and so doesn't need to be
	generated. 
 */

	/* Cogit>>#cogMNUPICSelector:receiver:methodOperand:numArgs: */
CogMethod *
cogMNUPICSelectorreceivermethodOperandnumArgs(sqInt selector, sqInt rcvr, sqInt methodOperand, sqInt numArgs)
{
    CogMethod *pic;
    sqInt startAddress;

	if ((isYoung(selector))
	 || ((inlineCacheTagForInstance(rcvr)) == 0)) {
		return 0;
	}
	compilationBreakpointisMNUCase(selector, numBytesOf(selector), 1);
	assert(endCPICCase0 != null);
	startAddress = allocate(closedPICSize);
	if (startAddress == 0) {
		callForCogCompiledCodeCompaction();
		return 0;
	}
	memcpy(startAddress, cPICPrototype, closedPICSize);
	configureMNUCPICmethodOperandnumArgsdelta(((CogMethod *) startAddress), methodOperand, numArgs, startAddress - cPICPrototype);
	/* begin fillInCPICHeader:numArgs:numCases:hasMNUCase:selector: */
	pic = ((CogMethod *) startAddress);
	assert(!(isYoung(selector)));
	(pic->cmType = CMClosedPIC);
	(pic->objectHeader = 0);
	(pic->blockSize = closedPICSize);
	(pic->methodObject = 0);
	(pic->methodHeader = 0);
	(pic->selector = selector);
	(pic->cmNumArgs = numArgs);
	(pic->cmRefersToYoung = 0);
	(pic->cmUsageCount = initialClosedPICUsageCount());
	(pic->cpicHasMNUCase = 1);
	(pic->cPICNumCases = 1);
	(pic->blockEntryOffset = 0);
	assert(((pic->cmType)) == CMClosedPIC);
	assert(((pic->selector)) == selector);
	assert(((pic->cmNumArgs)) == numArgs);
	assert(((pic->cPICNumCases)) == 1);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)pic)) + missOffset)) == (picAbortTrampolineFor(numArgs)));
	assert(closedPICSize == (roundUpLength(closedPICSize)));
	flushICacheFromto(processor, ((usqInt)pic), (((usqInt)pic)) + closedPICSize);
	/* begin maybeEnableSingleStep */
	return pic;
}


/*	Create an Open PIC. Temporarily create a direct call of
	ceSendFromOpenPIC:. Should become a probe of the first-level method lookup
	cache followed by a
	call of ceSendFromOpenPIC: if the probe fails. */

	/* Cogit>>#cogOpenPICSelector:numArgs: */
static CogMethod * NoDbgRegParms
cogOpenPICSelectornumArgs(sqInt selector, sqInt numArgs)
{
    sqInt codeSize;
    sqInt end;
    sqInt fixupSize;
    sqInt mapSize;
    sqInt opcodeSize;
    CogMethod *pic;
    sqInt startAddress;

	compilationBreakpointisMNUCase(selector, numBytesOf(selector), 0);
	startAddress = allocate(openPICSize);
	if (startAddress == 0) {
		return ((CogMethod *) InsufficientCodeSpace);
	}
	(methodLabel->address = startAddress);
	(methodLabel->dependent = null);
	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 100;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	compileOpenPICnumArgs(selector, numArgs);
	computeMaximumSizes();
	concretizeAt(methodLabel, startAddress);
	codeSize = generateInstructionsAt(startAddress + (sizeof(CogMethod)));
	mapSize = generateMapAtstart((startAddress + openPICSize) - 1, startAddress + cmNoCheckEntryOffset);
	assert((((entry->address)) - startAddress) == cmEntryOffset);
	assert(((roundUpLength((sizeof(CogMethod)) + codeSize)) + (roundUpLength(mapSize))) <= openPICSize);
	end = outputInstructionsAt(startAddress + (sizeof(CogMethod)));
	/* begin fillInOPICHeader:numArgs:selector: */
	pic = ((CogMethod *) startAddress);
	(pic->cmType = CMOpenPIC);
	(pic->objectHeader = 0);
	(pic->blockSize = openPICSize);
	addToOpenPICList(pic);
	(pic->methodHeader = 0);
	(pic->selector = selector);
	(pic->cmNumArgs = numArgs);
	if ((pic->cmRefersToYoung = isYoung(selector))) {
		addToYoungReferrers(pic);
	}
	(pic->cmUsageCount = initialOpenPICUsageCount());
	(pic->cpicHasMNUCase = 0);
	(pic->cPICNumCases = 0);
	(pic->blockEntryOffset = 0);
	assert(((pic->cmType)) == CMOpenPIC);
	assert(((pic->selector)) == selector);
	assert(((pic->cmNumArgs)) == numArgs);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)pic)) + missOffset)) == (picAbortTrampolineFor(numArgs)));
	assert(openPICSize == (roundUpLength(openPICSize)));
	flushICacheFromto(processor, ((usqInt)pic), (((usqInt)pic)) + openPICSize);
	/* begin maybeEnableSingleStep */
	return pic;
}


/*	Attempt to create a two-case PIC for case0CogMethod and
	case1Method,case1Tag. The tag for case0CogMethod is at the send site and
	so doesn't need to be generated.
	case1Method may be any of
	- a Cog method; link to its unchecked entry-point
	- a CompiledMethod; link to ceInterpretMethodFromPIC:
	- a CompiledMethod; link to ceMNUFromPICMNUMethod:receiver: */

	/* Cogit>>#cogPICSelector:numArgs:Case0Method:Case1Method:tag:isMNUCase: */
static CogMethod * NoDbgRegParms
cogPICSelectornumArgsCase0MethodCase1MethodtagisMNUCase(sqInt selector, sqInt numArgs, CogMethod *case0CogMethod, sqInt case1MethodOrNil, sqInt case1Tag, sqInt isMNUCase)
{
    CogMethod *pic;
    sqInt startAddress;

	if (isYoung(selector)) {
		return ((CogMethod *) YoungSelectorInPIC);
	}
	compilationBreakpointisMNUCase(selector, numBytesOf(selector), isMNUCase);
	startAddress = allocate(closedPICSize);
	if (startAddress == 0) {
		return ((CogMethod *) InsufficientCodeSpace);
	}
	memcpy(startAddress, cPICPrototype, closedPICSize);
	configureCPICCase0Case1MethodtagisMNUCasenumArgsdelta(((CogMethod *) startAddress), case0CogMethod, case1MethodOrNil, case1Tag, isMNUCase, numArgs, startAddress - cPICPrototype);
	/* begin fillInCPICHeader:numArgs:numCases:hasMNUCase:selector: */
	pic = ((CogMethod *) startAddress);
	assert(!(isYoung(selector)));
	(pic->cmType = CMClosedPIC);
	(pic->objectHeader = 0);
	(pic->blockSize = closedPICSize);
	(pic->methodObject = 0);
	(pic->methodHeader = 0);
	(pic->selector = selector);
	(pic->cmNumArgs = numArgs);
	(pic->cmRefersToYoung = 0);
	(pic->cmUsageCount = initialClosedPICUsageCount());
	(pic->cpicHasMNUCase = isMNUCase);
	(pic->cPICNumCases = 2);
	(pic->blockEntryOffset = 0);
	assert(((pic->cmType)) == CMClosedPIC);
	assert(((pic->selector)) == selector);
	assert(((pic->cmNumArgs)) == numArgs);
	assert(((pic->cPICNumCases)) == 2);
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)pic)) + missOffset)) == (picAbortTrampolineFor(numArgs)));
	assert(closedPICSize == (roundUpLength(closedPICSize)));
	flushICacheFromto(processor, ((usqInt)pic), (((usqInt)pic)) + closedPICSize);
	/* begin maybeEnableSingleStep */
	return pic;
}


/*	Attempt to produce a machine code method for the bytecode method
	object aMethodObj. N.B. If there is no code memory available do *NOT*
	attempt to reclaim the method zone. Certain clients (e.g. ceSICMiss:)
	depend on the zone remaining constant across method generation. */

	/* Cogit>>#cog:selector: */
CogMethod *
cogselector(sqInt aMethodObj, sqInt aSelectorOop)
{
    CogMethod *cogMethod;

	assert(!((methodHasCogMethod(aMethodObj))));

	compilationBreakpointisMNUCase(aSelectorOop, lengthOf(aSelectorOop), 0);
	if (aMethodObj == breakMethod) {
		haltmsg("Compilation of breakMethod");
	}
	if (methodUsesAlternateBytecodeSet(aMethodObj)) {
		if ((numElementsIn(generatorTable)) <= 256) {
			return null;
		}
		bytecodeSetOffset = 256;
	}
	else {
		bytecodeSetOffset = 0;
	}
	ensureNoForwardedLiteralsIn(aMethodObj);
	methodObj = aMethodObj;
	methodHeader = methodHeaderOf(aMethodObj);
	cogMethod = compileCogMethod(aSelectorOop);
	if ((((((sqInt)cogMethod)) >= MaxNegativeErrorCode) && ((((sqInt)cogMethod)) <= -1))) {
		if ((((sqInt)cogMethod)) == InsufficientCodeSpace) {
			callForCogCompiledCodeCompaction();
		}
		/* begin maybeFreeCounters */
		return null;
	}
	return cogMethod;
}

	/* Cogit>>#compactCogCompiledCode */
void
compactCogCompiledCode(void)
{
	assert(noCogMethodsMaximallyMarked());
	markActiveMethodsAndReferents();
	freeOlderMethodsForCompaction();
	freePICsWithFreedTargets();
	planCompaction();
	updateStackZoneReferencesToCompiledCodePreCompaction();
	relocateMethodsPreCompaction();
	compactCompiledCode();
	assert(allMethodsHaveCorrectHeader());
	assert(kosherYoungReferrers());
	stopsFromto(backEnd, freeStart(), (youngReferrers()) - 1);
	flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(youngReferrers())));
}


/*	The start of a CogMethod has a call to a run-time abort routine that
	either handles an in-line cache failure or a stack overflow. The routine
	selects the
	path depending on ReceiverResultReg; if zero it takes the stack overflow
	path; if nonzero the in-line cache miss path. Neither of these paths
	returns. The abort routine must be called; In the callee the method is
	located by
	adding the relevant offset to the return address of the call.
	
	N.B. This code must match that in compilePICAbort: so that the offset of
	the return address of the call is the same in methods and closed PICs. */

	/* Cogit>>#compileAbort */
static AbstractInstruction *
compileAbort(void)
{
    AbstractInstruction *anInstruction;
    sqInt callTarget;

	/* begin MoveCq:R: */
	anInstruction = genoperandoperand(MoveCqR, 0, ReceiverResultReg);
	stackOverflowCall = anInstruction;
	
	/* If there is a link register it must be saved (pushed onto the stack) before it
	   is smashed by the abort call, and hence needs to be manually handled here */
	/* begin PushR: */
	sendMiss = genoperand(PushR, LinkReg);
	/* begin Call: */
	callTarget = methodAbortTrampolineFor(methodOrBlockNumArgs);
	return genoperand(Call, callTarget);

}

	/* Cogit>>#compileBlockDispatchFrom:to: */
static void NoDbgRegParms
compileBlockDispatchFromto(sqInt lowBlockStartIndex, sqInt highBlockStartIndex)
{
    AbstractInstruction *anInstruction;
    BlockStart *blockStart;
    sqInt halfWay;
    AbstractInstruction *jmp;
    void *jumpTarget;
    void *jumpTarget1;
    void *jumpTarget2;
    sqInt quickConstant;

	if (lowBlockStartIndex == highBlockStartIndex) {
		blockStart = blockStartAt(lowBlockStartIndex);
		/* begin Jump: */
		jumpTarget = (blockStart->entryLabel);
		genoperand(Jump, ((sqInt)jumpTarget));
		return;
	}
	halfWay = (highBlockStartIndex + lowBlockStartIndex) / 2;
	assert(((halfWay >= lowBlockStartIndex) && (halfWay <= highBlockStartIndex)));

	/* N.B. FLAGS := TempReg - startpc */
	blockStart = blockStartAt(halfWay);
	/* begin CmpCq:R: */
	quickConstant = (((((blockStart->startpc)) + 1) << 1) | 1);
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(CmpCqR, quickConstant, TempReg);
	if (lowBlockStartIndex == halfWay) {
		/* begin JumpLessOrEqual: */
		jumpTarget1 = (blockStart->entryLabel);
		genConditionalBranchoperand(JumpLessOrEqual, ((sqInt)jumpTarget1));
		compileBlockDispatchFromto(halfWay + 1, highBlockStartIndex);
		return;
	}
	if ((halfWay + 1) == highBlockStartIndex) {
		blockStart = blockStartAt(highBlockStartIndex);
		/* begin JumpGreater: */
		jumpTarget2 = (blockStart->entryLabel);
		genConditionalBranchoperand(JumpGreater, ((sqInt)jumpTarget2));
		compileBlockDispatchFromto(lowBlockStartIndex, halfWay);
		return;
	}
	/* begin JumpGreater: */
	jmp = genConditionalBranchoperand(JumpGreater, ((sqInt)0));
	compileBlockDispatchFromto(lowBlockStartIndex, halfWay);
	if (halfWay == highBlockStartIndex) {
		blockStart = blockStartAt(highBlockStartIndex);
		jmpTarget(jmp, (blockStart->entryLabel));
	}
	else {
		jmpTarget(jmp, gLabel());
		compileBlockDispatchFromto(halfWay + 1, highBlockStartIndex);
	}
}


/*	Compile a block's entry. This looks like a dummy CogBlockMethod header
	(for frame parsing)
	followed by either a frame build, if a frame is required, or nothing. The
	CogMethodHeader's objectHeader field is a back pointer to the method, but
	this can't be filled in until code generation. */

	/* Cogit>>#compileBlockEntry: */
static void NoDbgRegParms
compileBlockEntry(BlockStart *blockStart)
{
    AbstractInstruction *abstractInstruction;
    sqInt alignment;

	/* begin AlignmentNops: */
	alignment = blockAlignment();
	genoperand(AlignmentNops, alignment);
	(blockStart->fakeHeader = gLabel());
	
	switch (sizeof(CogBlockMethod)) {
	case 8:
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		break;
	case 12:
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		break;
	case 16:
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		/* begin Fill32: */
		genoperand(Fill32, 0);
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	(blockStart->entryLabel = gLabel());
	if (needsFrame) {
		compileBlockFrameBuild(blockStart);
		if (recordBlockTrace()) {
			/* begin CallRT: */
			abstractInstruction = genoperand(Call, ceTraceBlockActivationTrampoline);
			(abstractInstruction->annotation = IsRelativeCall);
		}
	}
	else {
		compileBlockFramelessEntry(blockStart);
	}
}


/*	Generate a call to aRoutine with up to 4 arguments. If resultRegOrNone is
	not NoReg assign the C result to resultRegOrNone. If saveRegs, save all
	registers. Hack: a negative arg value indicates an abstract register, a
	non-negative value
	indicates a constant. */

	/* Cogit>>#compileCallFor:numArgs:arg:arg:arg:arg:resultReg:saveRegs: */
static void NoDbgRegParms
compileCallFornumArgsargargargargresultRegsaveRegs(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt resultRegOrNone, sqInt saveRegs)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    sqInt callTarget;
    const int cStackAlignment = STACK_ALIGN_BYTES;

	if (cStackAlignment > BytesPerWord) {
		genAlignCStackSavingRegistersnumArgswordAlignment(backEnd, saveRegs, numArgs, cStackAlignment / BytesPerWord);
	}
	if (saveRegs) {
		genSaveRegsForCCall(backEnd);
	}
	/* begin genMarshallNArgs:arg:arg:arg:arg: */
	flag("OABI");
	if (numArgs == 0) {
		((AbstractInstruction *) backEnd);
		goto l1;
	}
	if (regOrConst0 < NoReg) {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, -2 - regOrConst0, A0);
	}
	else {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, regOrConst0, A0);
	}
	if (numArgs == 1) {
		((AbstractInstruction *) backEnd);
		goto l1;
	}
	if (regOrConst1 < NoReg) {
		/* begin MoveCq:R: */
		anInstruction1 = genoperandoperand(MoveCqR, -2 - regOrConst1, A1);
	}
	else {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, regOrConst1, A1);
	}
	if (numArgs == 2) {
		((AbstractInstruction *) backEnd);
		goto l1;
	}
	if (regOrConst2 < NoReg) {
		/* begin MoveCq:R: */
		anInstruction2 = genoperandoperand(MoveCqR, -2 - regOrConst2, A2);
	}
	else {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, regOrConst2, A2);
	}
	if (numArgs == 3) {
		((AbstractInstruction *) backEnd);
		goto l1;
	}
	if (regOrConst3 < NoReg) {
		/* begin MoveCq:R: */
		anInstruction3 = genoperandoperand(MoveCqR, -2 - regOrConst3, A3);
	}
	else {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, regOrConst3, A3);
	}
	((AbstractInstruction *) backEnd);
l1:	/* end genMarshallNArgs:arg:arg:arg:arg: */;
	/* begin CallFullRT: */
	callTarget = ((usqInt)aRoutine);
	/* begin CallFull: */
	anInstruction4 = genoperand(CallFull, callTarget);

	if (resultRegOrNone != NoReg) {
		genWriteCResultIntoReg(backEnd, resultRegOrNone);
	}
	if (saveRegs) {
		if (numArgs > 0) {
			genRemoveNArgsFromStack(backEnd, numArgs);
		}
		if (resultRegOrNone != NoReg) {
			genRestoreRegsExcept(backEnd, resultRegOrNone);
		}
		else {
			genRestoreRegs(backEnd);
		}
	}
}


/*	Compile the cache tag computation and the first comparison. Answer the
	address of that comparison. */

	/* Cogit>>#compileCPICEntry */
static AbstractInstruction *
compileCPICEntry(void)
{
	entry = genGetInlineCacheClassTagFromintoforEntry(ReceiverResultReg, TempReg, 1);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, ClassReg, TempReg);
	/* begin JumpNonZero: */
	return genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
}


/*	The entry code to a method checks that the class of the current receiver
	matches that in the inline cache. Other non-obvious elements are that its
	alignment must be
	different from the alignment of the noCheckEntry so that the method map
	machinery can distinguish normal and super sends (super sends bind to the
	noCheckEntry).  */

	/* Cogit>>#compileEntry */
static void
compileEntry(void)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction * inst;

	entry = genGetInlineCacheClassTagFromintoforEntry(ReceiverResultReg, TempReg, 1);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, ClassReg, TempReg);
	/* begin JumpNonZero: */
	genConditionalBranchoperand(JumpNonZero, ((sqInt)sendMiss));
	/* begin Label */
	noCheckEntry = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	if (compileSendTrace()) {
		/* begin saveAndRestoreLinkRegAround: */
		inst = genoperand(PushR, LinkReg);
		/* begin CallRT: */
		abstractInstruction = genoperand(Call, ceTraceLinkedSendTrampoline);
		(abstractInstruction->annotation = IsRelativeCall);

		/* begin PopR: */
		genoperand(PopR, LinkReg);
	}
}


/*	Compile the top-level method body. */

	/* Cogit>>#compileMethodBody */
static sqInt
compileMethodBody(void)
{
	if (endPC < initialPC) {
		return 0;
	}
	return compileAbstractInstructionsFromthrough(initialPC + (deltaToSkipPrimAndErrorStoreInheader(methodObj, methodHeader)), endPC);
}


/*	The start of a PIC has a call to a run-time abort routine that either
	handles a dispatch to an
	interpreted method or a dispatch of an MNU case. The routine selects the
	path by testing
	ClassReg, which holds the inline cache tag; if equal to the
	picAbortDiscriminatorValue (zero)
	it takes the MNU path; if nonzero the dispatch to interpreter path.
	Neither of these paths
	returns. The abort routine must be called; In the callee the PIC is
	located by adding the
	relevant offset to the return address of the call.
	
	N.B. This code must match that in compileAbort so that the offset of the
	return address of
	the call is the same in methods and closed PICs. */

	/* Cogit>>#compilePICAbort: */
static sqInt NoDbgRegParms
compilePICAbort(sqInt numArgs)
{
    AbstractInstruction *anInstruction;
    sqInt callTarget;
    sqInt callTarget1;
    AbstractInstruction * picMNUAbort;

	/* begin MoveCq:R: */
	anInstruction = genoperandoperand(MoveCqR, 0, ClassReg);
	picMNUAbort = anInstruction;
	
	/* If there is a link register it must be saved (pushed onto the stack) before it
	   is smashed by the abort call, and hence needs to be manually handled here */
	/* begin PushR: */
	picInterpretAbort = genoperand(PushR, LinkReg);
	/* begin Call: */
	callTarget = picAbortTrampolineFor(numArgs);
	genoperand(Call, callTarget);

	return 0;
}


/*	Generate a trampoline with up to four arguments. Generate either a call or
	a jump to aRoutine
	as requested by callJumpBar. If generating a call and resultRegOrNone is
	not NoReg pass the C
	result back in resultRegOrNone.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#compileTrampolineFor:numArgs:arg:arg:arg:arg:saveRegs:pushLinkReg:resultReg: */
static void NoDbgRegParms
compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(void *aRoutine, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNone)
{
	genSmalltalkToCStackSwitch(pushLinkReg);
	compileCallFornumArgsargargargargresultRegsaveRegs(aRoutine, numArgs, regOrConst0, regOrConst1, regOrConst2, regOrConst3, resultRegOrNone, saveRegs);
	genLoadStackPointers(backEnd);
	if (pushLinkReg
	 && (1)) {
		/* begin PopR: */
		genoperand(PopR, LinkReg);
		/* begin RetN: */
		genoperand(RetN, 0);

	}
	else {
		/* begin RetN: */
		genoperand(RetN, 0);
	}
}


/*	Generate the entry code for a method to determine cmEntryOffset and
	cmNoCheckEntryOffset. We
	need cmNoCheckEntryOffset up front to be able to generate the map starting
	from cmNoCheckEntryOffset */
/*	stack allocate the various collections so that they
	are effectively garbage collected on return. */

	/* Cogit>>#computeEntryOffsets */
static void
computeEntryOffsets(void)
{
    sqInt fixupSize;
    sqInt opcodeSize;
    AbstractInstruction *sendMissCall;

	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 24;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	methodOrBlockNumArgs = 0;
	sendMissCall = compileAbort();
	compileEntry();
	computeMaximumSizes();
	generateInstructionsAt(methodZoneBase + (sizeof(CogMethod)));
	cmEntryOffset = ((entry->address)) - methodZoneBase;
	cmNoCheckEntryOffset = ((noCheckEntry->address)) - methodZoneBase;
	missOffset = (((sendMissCall->address)) + ((sendMissCall->machineCodeSize))) - methodZoneBase;
	entryPointMask = BytesPerWord - 1;
	while ((cmEntryOffset & entryPointMask) == (cmNoCheckEntryOffset & entryPointMask)) {
		entryPointMask = (entryPointMask + entryPointMask) + 1;
	}
	if (entryPointMask >= (roundUpLength(1))) {
		error("cannot differentiate checked and unchecked entry-points with current cog method alignment");
	}
	checkedEntryAlignment = cmEntryOffset & entryPointMask;
	uncheckedEntryAlignment = cmNoCheckEntryOffset & entryPointMask;
	assert(checkedEntryAlignment != uncheckedEntryAlignment);
}


/*	This pass assigns maximum sizes to all abstract instructions and
	eliminates jump fixups.
	It hence assigns the maximum address an instruction will occur at which
	allows the next
	pass to conservatively size jumps. */

	/* Cogit>>#computeMaximumSizes */
static void
computeMaximumSizes(void)
{
    AbstractInstruction *abstractInstruction;
    sqInt i;
    sqInt relativeAddress;

	/* begin dumpLiterals: */
	relativeAddress = 0;
	for (i = 0; i < opcodeIndex; i += 1) {
		abstractInstruction = abstractInstructionAt(i);
		(abstractInstruction->address = relativeAddress);
		(abstractInstruction->maxSize = computeMaximumSize(abstractInstruction));
		relativeAddress += (abstractInstruction->maxSize);
	}
}


/*	Configure a copy of the prototype CPIC for a two-case PIC for 
	case0CogMethod and
	case1Method
	case1Tag.
	The tag for case0CogMethod is at the send site and so doesn't need to be
	generated. case1Method may be any of
	- a Cog method; jump to its unchecked entry-point
	- a CompiledMethod; jump to the ceInterpretFromPIC trampoline
	- nil; call ceMNUFromPIC
	addDelta is the address change from the prototype to the new CPIC
	location, needed
	because the loading of the CPIC label at the end may use a literal instead
	of a pc relative load. */
/*	self disassembleFrom: cPIC asInteger + (self sizeof: CogMethod) to: cPIC
	asInteger + closedPICSize
 */

	/* Cogit>>#configureCPIC:Case0:Case1Method:tag:isMNUCase:numArgs:delta: */
static sqInt NoDbgRegParms
configureCPICCase0Case1MethodtagisMNUCasenumArgsdelta(CogMethod *cPIC, CogMethod *case0CogMethod, sqInt case1Method, sqInt case1Tag, sqInt isMNUCase, sqInt numArgs, sqInt addrDelta)
{
    sqInt caseEndAddress;
    sqInt operand;
    sqInt targetEntry;

	assert(case1Method != null);
	rewriteCallAttarget(backEnd, (((sqInt)cPIC)) + missOffset, picAbortTrampolineFor(numArgs));
	assert(!(inlineCacheTagIsYoung(case1Tag)));
	if ((!isMNUCase)
	 && (methodHasCogMethod(case1Method))) {
		operand = 0;
		targetEntry = (((sqInt)(cogMethodOf(case1Method)))) + cmNoCheckEntryOffset;
	}
	else {

		/* We do not scavenge PICs, hence we cannot cache the MNU method if it is in new space. */
		operand = ((case1Method == null)
		 || (isYoungObject(case1Method))
			? 0
			: case1Method);
		targetEntry = (case1Method == null
			? (((sqInt)cPIC)) + (sizeof(CogMethod))
			: (((sqInt)cPIC)) + (picInterpretAbortOffset()));
	}
	rewriteJumpLongAttarget(backEnd, (((sqInt)cPIC)) + firstCPICCaseOffset, (((sqInt)case0CogMethod)) + cmNoCheckEntryOffset);

	/* update the cpic case */
	caseEndAddress = addressOfEndOfCaseinCPIC(2, cPIC);
	rewriteCPICCaseAttagobjReftarget(caseEndAddress, case1Tag, operand, ((sqInt)((isMNUCase
	? (((sqInt)cPIC)) + (sizeof(CogMethod))
	: targetEntry))));
	relocateMethodReferenceBeforeAddressby(backEnd, ((((sqInt)cPIC)) + cPICEndOfCodeOffset) - (jumpLongByteSize(backEnd)), addrDelta);
	rewriteJumpLongAttarget(backEnd, (((sqInt)cPIC)) + cPICEndOfCodeOffset, cPICMissTrampolineFor(numArgs));
	return 0;
}


/*	Configure a copy of the prototype CPIC for a one-case MNU CPIC that calls
	ceMNUFromPIC for
	case0Tag The tag for case0 is at the send site and so doesn't need to be
	generated. addDelta is the address change from the prototype to the new
	CPIC location, needed
	because the loading of the CPIC label at the end may be a literal instead
	of a pc-relative load. */
/*	adjust the jump at missOffset, the ceAbortXArgs */

	/* Cogit>>#configureMNUCPIC:methodOperand:numArgs:delta: */
static sqInt NoDbgRegParms
configureMNUCPICmethodOperandnumArgsdelta(CogMethod *cPIC, sqInt methodOperand, sqInt numArgs, sqInt addrDelta)
{
    sqInt operand;
    sqInt target;

	rewriteCallAttarget(backEnd, (((sqInt)cPIC)) + missOffset, picAbortTrampolineFor(numArgs));

	/* set the jump to the case0 method */
	operand = ((methodOperand == null)
	 || (isYoungObject(methodOperand))
		? 0
		: methodOperand);
	rewriteJumpLongAttarget(backEnd, (((sqInt)cPIC)) + firstCPICCaseOffset, (((sqInt)cPIC)) + (sizeof(CogMethod)));
	storeLiteralbeforeFollowingAddress(backEnd, operand, ((((sqInt)cPIC)) + firstCPICCaseOffset) - (jumpLongByteSize(backEnd)));
	rewriteJumpLongAttarget(backEnd, (((sqInt)cPIC)) + cPICEndOfCodeOffset, cPICMissTrampolineFor(numArgs));
	relocateMethodReferenceBeforeAddressby(backEnd, ((((sqInt)cPIC)) + cPICEndOfCodeOffset) - (jumpLongByteSize(backEnd)), addrDelta);
	/* begin rewriteCPIC:caseJumpTo: */
	target = addressOfEndOfCaseinCPIC(2, cPIC);
	rewriteCPICJumpAttarget(backEnd, (((((sqInt)cPIC)) + firstCPICCaseOffset) - (jumpLongByteSize(backEnd))) - (loadLiteralByteSize(backEnd)), target);
	return 0;
}


/*	The first case in a CPIC doesn't have a class reference so we need only
	step over actually usd subsequent cases.
 */

	/* Cogit>>#cPICHasForwardedClass: */
static sqInt NoDbgRegParms
cPICHasForwardedClass(CogMethod *cPIC)
{
    sqInt classIndex;
    sqInt i;
    sqInt pc;


	/* start by finding the address of the topmost case, the cPICNumCases'th one */
	pc = (addressOfEndOfCaseinCPIC((cPIC->cPICNumCases), cPIC)) - (jumpLongConditionalByteSize(backEnd));
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		classIndex = literalBeforeFollowingAddress(backEnd, pc);
		if (isForwardedClassIndex(classIndex)) {
			return 1;
		}
		pc += cPICCaseSize;
	}
	return 0;
}


/*	scan the CPIC for target methods that have been freed. */

	/* Cogit>>#cPICHasFreedTargets: */
static sqInt NoDbgRegParms
cPICHasFreedTargets(CogMethod *cPIC)
{
    usqInt entryPoint;
    sqInt i;
    sqInt pc;
    CogMethod *targetMethod;

	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {
		pc = addressOfEndOfCaseinCPIC(i, cPIC);

		/* Find target from jump.  Ignore jumps to the interpret and MNU calls within this PIC */
		entryPoint = (i == 1
			? jumpLongTargetBeforeFollowingAddress(backEnd, pc)
			: jumpLongConditionalTargetBeforeFollowingAddress(backEnd, pc));
		if (!(((((usqInt)cPIC)) <= (((usqInt)entryPoint)))
			 && (((((usqInt)cPIC)) + ((cPIC->blockSize))) >= (((usqInt)entryPoint))))) {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			assert((((targetMethod->cmType)) == CMMethod)
			 || (((targetMethod->cmType)) == CMFree));
			if (((targetMethod->cmType)) == CMFree) {
				return 1;
			}
		}
	}
	return 0;
}


/*	Whimsey; we want 16rCA5E10 + cPICPrototypeCaseOffset to be somewhere in
	the middle of the zone.
 */

	/* Cogit>>#cPICPrototypeCaseOffset */
static sqInt
cPICPrototypeCaseOffset(void)
{
	return ((methodZoneBase + (youngReferrers())) / 2) - 13262352;
}


/*	Are any of the jumps from this CPIC to targetMethod? */

	/* Cogit>>#cPIC:HasTarget: */
static sqInt NoDbgRegParms
cPICHasTarget(CogMethod *cPIC, CogMethod *targetMethod)
{
    sqInt i;
    sqInt pc;
    usqInt target;

	target = (((usqInt)targetMethod)) + cmNoCheckEntryOffset;

	/* Since this is a fast test doing simple compares we don't need to care that some
	   cases have nonsense addresses in there. Just zip on through. */
	/* First jump is unconditional; subsequent ones are conditional */
	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	if (target == (jumpLongTargetBeforeFollowingAddress(backEnd, pc))) {
		return 1;
	}
	for (i = 2; i <= maxCPICCases; i += 1) {
		pc += cPICCaseSize;
		if (target == (jumpLongConditionalTargetBeforeFollowingAddress(backEnd, pc))) {
			return 1;
		}
	}
	return 0;
}


/*	Division is a little weird on some processors. Defer to the backEnd
	to allow it to generate any special code it may need to. */

	/* Cogit>>#DivR:R:Quo:Rem: */
static AbstractInstruction * NoDbgRegParms
gDivRRQuoRem(sqInt rDivisor, sqInt rDividend, sqInt rQuotient, sqInt rRemainder)
{
	genDivRRQuoRem(backEnd, rDivisor, rDividend, rQuotient, rRemainder);
	return abstractInstructionAt(opcodeIndex - 1);
}


/*	Return the default number of bytes to allocate for native code at startup.
	The actual value can be set via vmParameterAt: and/or a preference in the
	ini file. */

	/* Cogit>>#defaultCogCodeSize */
sqInt
defaultCogCodeSize(void)
{
	return 1024 * 1536;
}


/*	Answer the number of bytecodes to skip to get to the first bytecode
	past the primitive call and any store of the error code. */

	/* Cogit>>#deltaToSkipPrimAndErrorStoreIn:header: */
static sqInt NoDbgRegParms
deltaToSkipPrimAndErrorStoreInheader(sqInt aMethodObj, sqInt aMethodHeader)
{
	return (((primitiveIndexOfMethodheader(aMethodObj, aMethodHeader)) > 0)
	 && ((longStoreBytecodeForHeader(aMethodHeader)) == (fetchByteofObject(initialPC + (sizeOfCallPrimitiveBytecode(aMethodHeader)), aMethodObj)))
		? (sizeOfCallPrimitiveBytecode(aMethodHeader)) + (sizeOfLongStoreTempBytecode(aMethodHeader))
		: 0);
}

	/* Cogit>>#endPCOf: */
static sqInt NoDbgRegParms
endPCOf(sqInt aMethod)
{
    sqInt bsOffset;
    sqInt byte;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt end;
    sqInt latestContinuation;
    sqInt nExts;
    sqInt pc;
    sqInt prim;
    sqInt targetPC;

	pc = (latestContinuation = startPCOfMethod(aMethod));
	if (((prim = primitiveIndexOf(aMethod))) > 0) {
		if (isQuickPrimitiveIndex(prim)) {
			return pc - 1;
		}
	}
	bsOffset = 
#  if MULTIPLEBYTECODESETS
		(methodUsesAlternateBytecodeSet(aMethod)
				? 256
				: 0)
#  else /* MULTIPLEBYTECODESETS */
		0
#  endif /* MULTIPLEBYTECODESETS */
		;
	nExts = 0;
	end = numBytesOf(aMethod);
	while (pc <= end) {
		byte = fetchByteofObject(pc, aMethod);
		descriptor = generatorAt(byte + bsOffset);
		if (((descriptor->isReturn))
		 && (pc >= latestContinuation)) {
			end = pc;
		}
		if ((isBranch(descriptor))
		 || ((descriptor->isBlockCreation))) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, aMethod);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
			if ((descriptor->isBlockCreation)) {
				pc += distance;
			}
		}
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
		pc += (descriptor->numBytes);
	}
	return end;
}


/*	This is a static version of ceEnterCogCodePopReceiverReg
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* Cogit>>#enterCogCodePopReceiver */
void
enterCogCodePopReceiver(void)
{
	realCEEnterCogCodePopReceiverReg();
	error("what??");

}


/*	Use asserts to check if the ClosedPICPrototype is as expected from
	compileClosedPICPrototype, and can be updated as required via
	rewriteCPICCaseAt:tag:objRef:target:. If all asserts pass, answer
	0, otherwise answer a bit mask identifying all the errors. */
/*	self disassembleFrom: methodZoneBase + (self sizeof: CogMethod) to:
	methodZoneBase + closedPICSize
 */

	/* Cogit>>#expectedClosedPICPrototype: */
static sqInt NoDbgRegParms
expectedClosedPICPrototype(CogMethod *cPIC)
{
    sqInt classTag;
    usqInt classTagPC;
    usqInt entryPoint;
    sqInt errors;
    sqInt i;
    usqInt methodObjPC;
    sqInt object;
    usqInt pc;

	errors = 0;

	/* First jump is unconditional; subsequent ones are conditional */
	pc = (((usqInt)cPIC)) + firstCPICCaseOffset;
	object = literalBeforeFollowingAddress(backEnd, pc - (jumpLongByteSize(backEnd)));
	if (!(asserta(object == 99282957))) {
		errors = 1;
	}
	entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd, pc);
	if (!(asserta(entryPoint == ((cPICPrototypeCaseOffset()) + 13262352)))) {
		errors += 2;
	}
	for (i = 1; i < maxCPICCases; i += 1) {

		/* verify information in case is as expected. */
		pc += cPICCaseSize;
		methodObjPC = (pc - (jumpLongConditionalByteSize(backEnd))) - (cmpC32RTempByteSize(backEnd));
		object = literalBeforeFollowingAddress(backEnd, methodObjPC);
		if (!(asserta(object == (195929424 + i)))) {
			errors = errors | 4;
		}
		classTagPC = pc - (jumpLongConditionalByteSize(backEnd));
		classTag = literalBeforeFollowingAddress(backEnd, classTagPC);
		if (!(asserta(classTag == (3133021973UL + i)))) {
			errors = errors | 8;
		}
		entryPoint = jumpLongConditionalTargetBeforeFollowingAddress(backEnd, pc);
		if (!(asserta(entryPoint == (((cPICPrototypeCaseOffset()) + 13262352) + (i * 16))))) {
			errors = errors | 16;
		}
		rewriteCPICCaseAttagobjReftarget(pc, classTag ^ 1515870810, object ^ 2779096485UL, entryPoint ^ 5614160);
		object = literalBeforeFollowingAddress(backEnd, methodObjPC);
		if (!(asserta(object == ((195929424 + i) ^ 2779096485UL)))) {
			errors = errors | 32;
		}
		classTag = literalBeforeFollowingAddress(backEnd, classTagPC);
		if (!(asserta(classTag == ((3133021973UL + i) ^ 1515870810)))) {
			errors = errors | 64;
		}
		entryPoint = jumpLongConditionalTargetBeforeFollowingAddress(backEnd, pc);
		if (!(asserta(entryPoint == ((((cPICPrototypeCaseOffset()) + 13262352) + (i * 16)) ^ 5614160)))) {
			errors = errors | 128;
		}
		rewriteCPICCaseAttagobjReftarget(pc, classTag ^ 1515870810, object ^ 2779096485UL, entryPoint ^ 5614160);
	}
	entryPoint = jumpLongTargetBeforeFollowingAddress(backEnd, (pc + cPICEndSize));
	if (!(asserta(entryPoint == (cPICMissTrampolineFor(0))))) {
		errors += 256;
	}
	return errors;
}


/*	Fill in the block headers now we know the exact layout of the code. */

	/* Cogit>>#fillInBlockHeadersAt: */
static sqInt NoDbgRegParms
fillInBlockHeadersAt(sqInt startAddress)
{
    CogBlockMethod *blockHeader;
    BlockStart *blockStart;
    sqInt i;

	if (!(needsFrame
		 && (blockCount > 0))) {
		return null;
	}
	if (blockNoContextSwitchOffset == null) {
		blockNoContextSwitchOffset = ((blockEntryLabel->address)) - ((blockEntryNoContextSwitch->address));
	}
	else {
		assert(blockNoContextSwitchOffset == (((blockEntryLabel->address)) - ((blockEntryNoContextSwitch->address))));
	}
	for (i = 0; i < blockCount; i += 1) {
		blockStart = blockStartAt(i);
		blockHeader = ((CogBlockMethod *) ((((blockStart->fakeHeader))->address)));
		(blockHeader->homeOffset = ((((blockStart->fakeHeader))->address)) - startAddress);
		(blockHeader->startpc = (blockStart->startpc));
		(blockHeader->cmType = CMBlock);
		(blockHeader->cmNumArgs = (blockStart->numArgs));
		(blockHeader->cbUsesInstVars = (blockStart->hasInstVarRef));
		(blockHeader->stackCheckOffset = (((blockStart->stackCheckLabel)) == null
			? 0
			: ((((blockStart->stackCheckLabel))->address)) - ((((blockStart->fakeHeader))->address))));
	}
}

	/* Cogit>>#fillInMethodHeader:size:selector: */
static CogMethod * NoDbgRegParms
fillInMethodHeadersizeselector(CogMethod *method, sqInt size, sqInt selector)
{
    CogMethod *originalMethod;
    sqInt rawHeader;

	(method->cmType = CMMethod);
	(method->objectHeader = nullHeaderForMachineCodeMethod());
	(method->blockSize = size);
	(method->methodObject = methodObj);

	/* If the method has already been cogged (e.g. Newspeak accessors) then
	   leave the original method attached to its cog method, but get the right header. */
	rawHeader = rawHeaderOf(methodObj);
	if (isCogMethodReference(rawHeader)) {
		originalMethod = ((CogMethod *) rawHeader);
		assert(((originalMethod->blockSize)) == size);
		assert(methodHeader == ((originalMethod->methodHeader)));
			}
	else {
		rawHeaderOfput(methodObj, ((sqInt)method));
			}
	(method->methodHeader = methodHeader);
	(method->selector = selector);
	(method->cmNumArgs = argumentCountOfMethodHeader(methodHeader));
	if ((method->cmRefersToYoung = hasYoungReferent)) {
		addToYoungReferrers(method);
	}
	(method->cmUsageCount = initialMethodUsageCount());
	(method->cpicHasMNUCase = 0);
	(method->cmUsesPenultimateLit = maxLitIndex >= ((literalCountOfMethodHeader(methodHeader)) - 2));
	(method->blockEntryOffset = (blockEntryLabel != null
		? ((blockEntryLabel->address)) - (((sqInt)method))
		: 0));
	if (needsFrame) {
		if (!((((stackCheckLabel->address)) - (((sqInt)method))) <= MaxStackCheckOffset)) {
			error("too much code for stack check offset");
		}
	}
	(method->stackCheckOffset = (needsFrame
		? ((stackCheckLabel->address)) - (((sqInt)method))
		: 0));
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)method)) + missOffset)) == (methodAbortTrampolineFor((method->cmNumArgs))));
	assert(size == (roundUpLength(size)));
	flushICacheFromto(processor, ((usqInt)method), (((usqInt)method)) + size);
	/* begin maybeEnableSingleStep */
	return method;
}

	/* Cogit>>#findBlockMethodWithEntry:startBcpc: */
static usqInt NoDbgRegParms
findBlockMethodWithEntrystartBcpc(sqInt blockEntryMcpc, sqInt startBcpc)
{
    CogBlockMethod *cogBlockMethod;

	cogBlockMethod = ((CogBlockMethod *) (blockEntryMcpc - (sizeof(CogBlockMethod))));
	if (((cogBlockMethod->startpc)) == startBcpc) {
		return ((usqInt)cogBlockMethod);
	}
	return 0;
}

	/* Cogit>>#findMapLocationForMcpc:inMethod: */
static sqInt NoDbgRegParms
findMapLocationForMcpcinMethod(sqInt targetMcpc, CogMethod *cogMethod)
{
    sqInt annotation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;

	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	if (mcpc == targetMcpc) {
		return map;
	}
	while (((mapByte = byteAt(map))) != MapEnd) {
		annotation = ((usqInt) mapByte) >> AnnotationShift;
		if (annotation != IsAnnotationExtension) {
			mcpc += 4 * ((annotation == IsDisplacementX2N
	? (mapByte - DisplacementX2N) << AnnotationShift
	: mapByte & DisplacementMask));
		}
		if (mcpc >= targetMcpc) {
			assert(mcpc == targetMcpc);
			if (annotation == IsDisplacementX2N) {
				map -= 1;
				mapByte = byteAt(map);
				annotation = ((usqInt) mapByte) >> AnnotationShift;
				assert(annotation > IsAnnotationExtension);
			}
			return map;
		}
		map -= 1;
	}
	return 0;
}


/*	Find the CMMethod or CMBlock that has zero-relative startbcpc as its first
	bytecode pc.
	As this is for cannot resume processing and/or conversion to machine-code
	on backward
	branch, it doesn't have to be fast. Enumerate block returns and map to
	bytecode pcs. */

	/* Cogit>>#findMethodForStartBcpc:inHomeMethod: */
CogBlockMethod *
findMethodForStartBcpcinHomeMethod(sqInt startbcpc, CogMethod *cogMethod)
{
	assert(((cogMethod->cmType)) == CMMethod);
	if (startbcpc == (startPCOfMethodHeader((cogMethod->methodHeader)))) {
		return ((CogBlockMethod *) cogMethod);
	}
	assert(((cogMethod->blockEntryOffset)) != 0);
	return ((CogBlockMethod *) (blockDispatchTargetsForperformarg(cogMethod, findBlockMethodWithEntrystartBcpc, startbcpc)));
}


/*	Machine code addresses map to the following bytecode for all bytecodes
	except backward branches, where they map to the backward branch itself.
	This is so that loops continue, rather than terminate prematurely. */

	/* Cogit>>#find:IsBackwardBranch:Mcpc:Bcpc:MatchingMcpc: */
static sqInt NoDbgRegParms
findIsBackwardBranchMcpcBcpcMatchingMcpc(BytecodeDescriptor *descriptor, sqInt isBackwardBranch, char *mcpc, sqInt bcpc, void *targetMcpc)
{
	return (targetMcpc == mcpc
		? ((descriptor == null)
			 || (isBackwardBranch)
				? bcpc
				: bcpc + ((descriptor->numBytes)))
		: 0);
}

	/* Cogit>>#followForwardedLiteralsIn: */
void
followForwardedLiteralsIn(CogMethod *cogMethod)
{
    sqInt annotation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	assert(!(isForwarded((cogMethod->methodObject))));
	if (shouldRemapOop((cogMethod->selector))) {
		(cogMethod->selector = remapObj((cogMethod->selector)));
		if (isYoung((cogMethod->selector))) {
			ensureInYoungReferrers(cogMethod);
		}
	}
	/* begin mapFor:performUntil:arg: */
	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {

			/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
			mcpc += (mapByte & DisplacementMask) * 4;
			if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
			 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
				annotation += mapByte & DisplacementMask;
				map -= 1;
			}
			result = remapIfObjectRefpchasYoung(annotation, (((char *) mcpc)), 0);
			if (result != 0) {
				goto l1;
			}
		}
		else {
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
l1:	/* end mapFor:performUntil:arg: */;
}

	/* Cogit>>#followForwardedMethods */
void
followForwardedMethods(void)
{
    CogMethod *cogMethod;
    sqInt freedPIC;

	freedPIC = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			if (isForwarded((cogMethod->methodObject))) {
				(cogMethod->methodObject = followForwarded((cogMethod->methodObject)));
				if (isYoungObject((cogMethod->methodObject))) {
					ensureInYoungReferrers(cogMethod);
				}
			}
		}
		if (((cogMethod->cmType)) == CMClosedPIC) {
			if (followMethodReferencesInClosedPIC(cogMethod)) {
				freedPIC = 1;
				freeMethod(cogMethod);
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freedPIC) {
		unlinkSendsToFree();
	}
}


/*	Follow a potential object reference from a closed PIC.
	This may be a method reference or null.
	Answer if the followed literal is young.
	'mcpc' refers to the jump/branch instruction at the end of
	each cpic case */

	/* Cogit>>#followMaybeObjRefInClosedPICAt: */
static sqInt NoDbgRegParms
followMaybeObjRefInClosedPICAt(sqInt mcpc)
{
    sqInt object;
    sqInt subject;

	object = literalBeforeFollowingAddress(backEnd, mcpc);
	if (!(couldBeObject(object))) {
		return 0;
	}
	if (!(isForwarded(object))) {
		return isYoungObject(object);
	}
	subject = followForwarded(object);
	storeLiteralbeforeFollowingAddress(backEnd, subject, mcpc);
	codeModified = 1;
	return isYoungObject(subject);
}


/*	Remap all object references in the closed PIC. Answer if any references
	are young.
	Set codeModified if any modifications are made. */

	/* Cogit>>#followMethodReferencesInClosedPIC: */
static sqInt NoDbgRegParms
followMethodReferencesInClosedPIC(CogMethod *cPIC)
{
    sqInt i;
    sqInt pc;
    sqInt refersToYoung;


	/* first we check the potential method oop load at the beginning of the CPIC */
	pc = addressOfEndOfCaseinCPIC(1, cPIC);

	/* We find the end address of the cPICNumCases'th case and can then just step forward by the case size thereafter */
	refersToYoung = followMaybeObjRefInClosedPICAt(pc - (jumpLongByteSize(backEnd)));

	/* Next we check the potential potential method oop load for each case. */
	pc = addressOfEndOfCaseinCPIC((cPIC->cPICNumCases), cPIC);
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		if (followMaybeObjRefInClosedPICAt((pc - (jumpLongConditionalByteSize(backEnd))) - (cmpC32RTempByteSize(backEnd)))) {
			refersToYoung = 1;
		}
		pc += cPICCaseSize;
	}
	return refersToYoung;
}

	/* Cogit>>#freePICsWithFreedTargets */
static void
freePICsWithFreedTargets(void)
{
    CogMethod *cogMethod;
    sqInt count;

	cogMethod = ((CogMethod *) methodZoneBase);
	count = 0;
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMClosedPIC)
		 && (cPICHasFreedTargets(cogMethod))) {
			(cogMethod->cmType = CMFree);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		count += 1;
	}
	assert(count == (numMethods()));
}


/*	Free machine-code methods whose compiled methods are unmarked
	and open PICs whose selectors are not marked, and closed PICs that
	refer to unmarked objects. */

	/* Cogit>>#freeUnmarkedMachineCode */
void
freeUnmarkedMachineCode(void)
{
    CogMethod *cogMethod;
    sqInt freedMethod;

	freedMethod = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMMethod)
		 && (!(isMarked((cogMethod->methodObject))))) {
			freedMethod = 1;
			freeMethod(cogMethod);
		}
		if ((((cogMethod->cmType)) == CMOpenPIC)
		 && ((!(isImmediate((cogMethod->selector))))
		 && (!(isMarked((cogMethod->selector)))))) {
			freedMethod = 1;
			freeMethod(cogMethod);
		}
		if ((((cogMethod->cmType)) == CMClosedPIC)
		 && (closedPICRefersToUnmarkedObject(cogMethod))) {
			freedMethod = 1;
			freeMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freedMethod) {
		unlinkSendsToFree();
	}
}

	/* Cogit>>#genCheckForInterruptsTrampoline */
static sqInt
genCheckForInterruptsTrampoline(void)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;

	zeroOpcodeIndex();
	/* begin MoveR:Aw: */
	address = instructionPointerAddress();
	/* begin gen:operand:literal: */
	anInstruction = genoperandoperand(MoveRAw, LinkReg, address);

	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceCheckForInterrupts, "ceCheckForInterruptsTrampoline", 0, null, null, null, null, 0, 0, NoReg, 1);
}

	/* Cogit>>#genConditionalBranch:operand: */
static AbstractInstruction * NoDbgRegParms
genConditionalBranchoperand(sqInt opcode, sqInt operandOne)
{
	return noteFollowingConditionalBranch(previousInstruction(), genoperand(opcode, operandOne));
}


/*	An enilopmart (the reverse of a trampoline) is a piece of code that makes
	the system-call-like transition from the C runtime into generated machine
	code. The desired arguments and entry-point are pushed on a stackPage's
	stack. The enilopmart pops off the values to be loaded into registers and
	then executes a return instruction to pop off the entry-point and jump to
	it. 
	BEFORE				AFTER			(stacks grow down)
	whatever			stackPointer ->	whatever
	target address =>	reg1 = reg1val, etc
	reg1val				pc = target address
	reg2val
	stackPointer ->	reg3val */

	/* Cogit>>#genEnilopmartFor:and:and:forCall:called: */
static void (*genEnilopmartForandandforCallcalled(sqInt regArg1, sqInt regArg2OrNone, sqInt regArg3OrNone, sqInt forCall, char *trampolineName))(void)

{
    AbstractInstruction *anInstruction;
    sqInt endAddress;
    sqInt enilopmart;
    sqInt quickConstant;
    sqInt size;

	zeroOpcodeIndex();
	/* begin MoveCq:R: */
	quickConstant = varBaseAddress();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(MoveCqR, quickConstant, VarBaseReg);

	genLoadStackPointers(backEnd);
	if (regArg3OrNone != NoReg) {
		/* begin PopR: */
		genoperand(PopR, regArg3OrNone);
	}
	if (regArg2OrNone != NoReg) {
		/* begin PopR: */
		genoperand(PopR, regArg2OrNone);
	}
	/* begin PopR: */
	genoperand(PopR, regArg1);
	genEnilopmartReturn(forCall);
	computeMaximumSizes();
	size = generateInstructionsAt(methodZoneBase);
	endAddress = outputInstructionsAt(methodZoneBase);
	assert((methodZoneBase + size) == endAddress);
	enilopmart = methodZoneBase;
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	stopsFromto(backEnd, endAddress, methodZoneBase - 1);
	recordGeneratedRunTimeaddress(trampolineName, enilopmart);
	return ((void (*)(void)) enilopmart);
}


/*	An enilopmart (the reverse of a trampoline) is a piece of code that makes
	the system-call-like transition from the C runtime into generated machine
	code. At the point the enilopmart enters machine code via a return
	instruction, any argument registers have been loaded with their values and
	the stack, if
	for call, looks like
	ret pc
	stackPointer ->	target address
	
	and if not for call, looks like
	whatever
	stackPointer ->	target address
	
	If forCall and running on a CISC, ret pc must be left on the stack. If
	forCall and
	running on a RISC, ret pc must be popped into LinkReg. In either case,
	target address must be removed from the stack and jumped/returned to. */

	/* Cogit>>#genEnilopmartReturn: */
static void NoDbgRegParms
genEnilopmartReturn(sqInt forCall)
{
	if (forCall) {
		/* begin PopR: */
		genoperand(PopR, RISCTempReg);
		/* begin PopR: */
		genoperand(PopR, LinkReg);
		/* begin JumpR: */
		genoperand(JumpR, RISCTempReg);
	}
	else {
		/* begin PopR: */
		genoperand(PopR, RISCTempReg);
		/* begin JumpR: */
		genoperand(JumpR, RISCTempReg);

	}

}


/*	Generate the routine that writes the current values of the C frame and
	stack pointers into
	variables. These are used to establish the C stack in trampolines back
	into the C run-time.
	
	This is a presumptuous quick hack for x86. It is presumptuous for two
	reasons. Firstly
	the system's frame and stack pointers may differ from those we use in
	generated code,
	e.g. on register-rich RISCs. Secondly the ABI may not support a simple
	frameless call
	as written here (for example 128-bit stack alignment on Mac OS X). */

	/* Cogit>>#generateCaptureCStackPointers: */
static void NoDbgRegParms
generateCaptureCStackPointers(sqInt captureFramePointer)
{
    sqInt address;
    sqInt address1;
    sqInt address2;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    sqInt fixupSize;
    sqInt opcodeSize;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt startAddress;

	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 32;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;

	/* Must happen first; value may be used in accessing any of the following addresses */
	startAddress = methodZoneBase;
	/* begin PushR: */
	genoperand(PushR, VarBaseReg);
	/* begin MoveCq:R: */
	quickConstant1 = varBaseAddress();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(MoveCqR, quickConstant1, VarBaseReg);

	if (captureFramePointer) {
		/* begin MoveR:Aw: */
		address = cFramePointerAddress();
		/* begin gen:operand:literal: */
		anInstruction2 = genoperandoperand(MoveRAw, FPReg, address);
	}
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SPReg, TempReg);
	/* begin AddCq:R: */
	quickConstant = 0 + BytesPerWord;
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AddCqR, quickConstant, TempReg);
	/* begin MoveR:Aw: */
	address1 = cStackPointerAddress();
	/* begin gen:operand:literal: */
	anInstruction3 = genoperandoperand(MoveRAw, TempReg, address1);

	/* begin PopR: */
	genoperand(PopR, VarBaseReg);

	/* begin RetN: */
	genoperand(RetN, 0);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	flushICacheFromto(processor, ((usqInt)startAddress), ((usqInt)methodZoneBase));
	recordGeneratedRunTimeaddress("ceCaptureCStackPointers", startAddress);
	ceCaptureCStackPointers = ((void (*)(void)) startAddress);
}


/*	Generate the prototype ClosedPIC to determine how much space as full PIC
	takes. When we first allocate a closed PIC it only has one or two cases
	and we want to grow it.
	So we have to determine how big a full one is before hand. */

	/* Cogit>>#generateClosedPICPrototype */
static void
generateClosedPICPrototype(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    CogMethod *cPIC;
    AbstractInstruction * cPICEndOfCodeLabel;
    sqInt endAddress;
    AbstractInstruction * endCPICCase1;
    sqInt fixupSize;
    sqInt h;
    AbstractInstruction *jumpNext;
    sqInt jumpTarget;
    sqInt jumpTarget1;
    sqInt jumpTarget2;
    sqInt literal;
    sqInt numArgs;
    sqInt opcode;
    sqInt opcodeSize;
    sqInt wordConstant;


	/* stack allocate the various collections so that they
	   are effectively garbage collected on return. */
	maxCPICCases = 6;
	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = maxCPICCases * 9;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	(methodLabel->address = methodZoneBase);
	(methodLabel->dependent = null);
	/* begin compileClosedPICPrototype */
	compilePICAbort((numArgs = 0));

	/* At the end of the entry code we need to jump to the first case code, which is actually the last chunk.
	   On each entension we must update this jump to move back one case. */
	/* 16r5EAF00D is the method oop, or 0, for the 1st case. */
	jumpNext = compileCPICEntry();
	/* begin MoveUniqueCw:R: */
	anInstruction2 = genoperandoperand(MoveCwR, 99282957, SendNumArgsReg);
	/* begin JumpLong: */
	jumpTarget1 = (cPICPrototypeCaseOffset()) + 13262352;
	genoperand(JumpLong, jumpTarget1);
	/* begin Label */
	endCPICCase0 = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	for (h = 1; h < maxCPICCases; h += 1) {
		if (h == (maxCPICCases - 1)) {
			jmpTarget(jumpNext, gLabel());
		}
		/* begin MoveUniqueCw:R: */
		anInstruction1 = genoperandoperand(MoveCwR, 195929424 + h, SendNumArgsReg);
		/* begin CmpC32:R: */
		opcode = CmpCwR;
		/* begin checkLiteral:forInstruction: */
		literal = 3133021973UL + h;
		anInstruction = genoperandoperand(opcode, 3133021973UL + h, TempReg);
		/* begin JumpLongZero: */
		jumpTarget = ((cPICPrototypeCaseOffset()) + 13262352) + (h * 16);
		genConditionalBranchoperand(JumpLongZero, ((sqInt)jumpTarget));
		if (h == 1) {
			/* begin Label */
			endCPICCase1 = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
	}
	/* begin MoveCw:R: */
	wordConstant = (methodLabel->address);
	/* begin gen:literal:operand: */
	anInstruction3 = genoperandoperand(MoveCwR, wordConstant, ClassReg);
	/* begin JumpLong: */
	jumpTarget2 = cPICMissTrampolineFor(numArgs);
	genoperand(JumpLong, jumpTarget2);
	/* begin Label */
	cPICEndOfCodeLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin dumpLiterals: */
	computeMaximumSizes();
	cPIC = ((CogMethod *) methodZoneBase);
	closedPICSize = (sizeof(CogMethod)) + (generateInstructionsAt(methodZoneBase + (sizeof(CogMethod))));
	endAddress = outputInstructionsAt(methodZoneBase + (sizeof(CogMethod)));
	assert((methodZoneBase + closedPICSize) == endAddress);
	firstCPICCaseOffset = ((endCPICCase0->address)) - methodZoneBase;
	cPICEndOfCodeOffset = ((cPICEndOfCodeLabel->address)) - methodZoneBase;
	cPICCaseSize = ((endCPICCase1->address)) - ((endCPICCase0->address));
	cPICEndSize = closedPICSize - (((maxCPICCases - 1) * cPICCaseSize) + firstCPICCaseOffset);
	closedPICSize = roundUpLength(closedPICSize);
	assert(((picInterpretAbort->address)) == (((methodLabel->address)) + (picInterpretAbortOffset())));
	assert((expectedClosedPICPrototype(cPIC)) == 0);
	storeLiteralbeforeFollowingAddress(backEnd, 0, ((endCPICCase0->address)) - (jumpLongByteSize(backEnd)));
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	cPICPrototype = cPIC;
}


/*	We handle jump sizing simply. First we make a pass that asks each
	instruction to compute its maximum size. Then we make a pass that
	sizes jumps based on the maxmimum sizes. Then we make a pass
	that fixes up jumps. When fixing up a jump the jump is not allowed to
	choose a smaller offset but must stick to the size set in the second pass. */

	/* Cogit>>#generateCogMethod: */
static CogMethod * NoDbgRegParms
generateCogMethod(sqInt selector)
{
    sqInt codeSize;
    sqInt headerSize;
    sqInt mapSize;
    CogMethod *method;
    sqInt result;
    sqInt startAddress;
    sqInt totalSize;

	headerSize = sizeof(CogMethod);
	(methodLabel->address = freeStart());
	computeMaximumSizes();
	concretizeAt(methodLabel, freeStart());
	codeSize = generateInstructionsAt(((methodLabel->address)) + headerSize);
	mapSize = generateMapAtstart(null, ((methodLabel->address)) + cmNoCheckEntryOffset);
	totalSize = roundUpLength((headerSize + codeSize) + mapSize);
	if (totalSize > MaxMethodSize) {
		return ((CogMethod *) MethodTooBig);
	}
	startAddress = allocate(totalSize);
	if (startAddress == 0) {
		return ((CogMethod *) InsufficientCodeSpace);
	}
	assert((startAddress + cmEntryOffset) == ((entry->address)));
	assert((startAddress + cmNoCheckEntryOffset) == ((noCheckEntry->address)));
	result = outputInstructionsAt(startAddress + headerSize);
	assert(((startAddress + headerSize) + codeSize) == result);
	padIfPossibleWithStopsFromto(backEnd, result, (startAddress + totalSize) - mapSize);
	generateMapAtstart((startAddress + totalSize) - 1, startAddress + cmNoCheckEntryOffset);
	fillInBlockHeadersAt(startAddress);
	method = fillInMethodHeadersizeselector(((CogMethod *) startAddress), totalSize, selector);
	if (!(postCompileHook == null)) {
		postCompileHook(method);
		postCompileHook = null;
	}
	return method;
}


/*	Size pc-dependent instructions and assign eventual addresses to all
	instructions. Answer the size of the code.
	Compute forward branches based on virtual address (abstract code starts at
	0), assuming that any branches branched over are long.
	Compute backward branches based on actual address.
	Reuse the fixups array to record the pc-dependent instructions that need
	to have
	their code generation postponed until after the others. */

	/* Cogit>>#generateInstructionsAt: */
static sqInt NoDbgRegParms
generateInstructionsAt(sqInt eventualAbsoluteAddress)
{
    sqInt absoluteAddress;
    AbstractInstruction *abstractInstruction;
    BytecodeFixup *fixup;
    sqInt i;
    sqInt j;
    sqInt pcDependentIndex;

	absoluteAddress = eventualAbsoluteAddress;
	pcDependentIndex = 0;
	for (i = 0; i < opcodeIndex; i += 1) {
		abstractInstruction = abstractInstructionAt(i);
		if (isPCDependent(abstractInstruction)) {
			sizePCDependentInstructionAt(abstractInstruction, absoluteAddress);
			fixup = fixupAt(pcDependentIndex);
			pcDependentIndex += 1;
			(fixup->instructionIndex = i);
			absoluteAddress += (abstractInstruction->machineCodeSize);
		}
		else {
			absoluteAddress = concretizeAt(abstractInstruction, absoluteAddress);
		}
	}
	for (j = 0; j < pcDependentIndex; j += 1) {
		fixup = fixupAt(j);
		abstractInstruction = abstractInstructionAt((fixup->instructionIndex));
		concretizeAt(abstractInstruction, (abstractInstruction->address));
	}
	return absoluteAddress - eventualAbsoluteAddress;
}


/*	Generate the method map at addressrNull (or compute it if addressOrNull is
	null). Answer the length of the map in byes. Each entry in the map is in
	two parts. In the
	least signficant bits are a displacement of how far from the start or
	previous entry,
	unless it is an IsAnnotationExtension byte, in which case those bits are
	the extension.
	In the most signficant bits are the type of annotation at the point
	reached. A null
	byte ends the map. */

	/* Cogit>>#generateMapAt:start: */
static sqInt NoDbgRegParms
generateMapAtstart(sqInt addressOrNull, sqInt startAddress)
{
    unsigned char annotation;
    sqInt delta;
    sqInt i;
    AbstractInstruction *instruction;
    sqInt length;
    sqInt location;
    sqInt mapEntry;
    sqInt maxDelta;
    usqInt mcpc;

	length = 0;
	location = startAddress;
	for (i = 0; i < opcodeIndex; i += 1) {
		instruction = abstractInstructionAt(i);
		annotation = (instruction->annotation);
		if (!(annotation == null)) {
			/* begin assertValidAnnotation:for: */
			mcpc = ((instruction->address)) + ((instruction->machineCodeSize));
			while (((delta = (mcpc - location) / 4)) > DisplacementMask) {
				maxDelta = (((((delta < MaxX2NDisplacement) ? delta : MaxX2NDisplacement)) | DisplacementMask) - DisplacementMask);
				assert((((usqInt) maxDelta) >> AnnotationShift) <= DisplacementMask);
				if (!(addressOrNull == null)) {
					/* begin addToMap:instruction:byte:at:for: */
					byteAtput(addressOrNull - length, (((usqInt) maxDelta) >> AnnotationShift) + DisplacementX2N);
				}
				location += maxDelta * 4;
				length += 1;
			}
			if (!(addressOrNull == null)) {
				mapEntry = delta + ((((annotation < IsSendCall) ? annotation : IsSendCall)) << AnnotationShift);
				/* begin addToMap:instruction:byte:at:for: */
				byteAtput(addressOrNull - length, mapEntry);
			}
			location += delta * 4;
			length += 1;
			if (annotation > IsSendCall) {

				/* Add the necessary IsAnnotationExtension */
				if (!(addressOrNull == null)) {
					mapEntry = (IsAnnotationExtension << AnnotationShift) + (annotation - IsSendCall);
					/* begin addToMap:instruction:byte:at:for: */
					byteAtput(addressOrNull - length, mapEntry);
				}
				length += 1;
			}
		}
	}
	if (!(addressOrNull == null)) {
		/* begin addToMap:instruction:byte:at:for: */
		byteAtput(addressOrNull - length, MapEnd);
	}
	return length + 1;
}


/*	Generate the prototype ClosedPIC to determine how much space as full PIC
	takes. When we first allocate a closed PIC it only has one or two cases
	and we want to grow it.
	So we have to determine how big a full one is before hand. */
/*	stack allocate the various collections so that they
	are effectively garbage collected on return. */

	/* Cogit>>#generateOpenPICPrototype */
static void
generateOpenPICPrototype(void)
{
    sqInt codeSize;
    sqInt fixupSize;
    sqInt mapSize;
    sqInt opcodeSize;

	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 100;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	(methodLabel->address = methodZoneBase);
	(methodLabel->dependent = null);
	compileOpenPICnumArgs(specialSelector(0), 2);
	computeMaximumSizes();
	concretizeAt(methodLabel, methodZoneBase);
	codeSize = generateInstructionsAt(methodZoneBase + (sizeof(CogMethod)));
	mapSize = generateMapAtstart(null, methodZoneBase + cmNoCheckEntryOffset);
	openPICSize = (roundUpLength((sizeof(CogMethod)) + codeSize)) + (roundUpLength(mapSize));
}


/*	Generate the run-time entries at the base of the native code zone and
	update the base.
 */

	/* Cogit>>#generateRunTimeTrampolines */
static void
generateRunTimeTrampolines(void)
{
	ceSendMustBeBooleanAddFalseTrampoline = genMustBeBooleanTrampolineForcalled(falseObject(), "ceSendMustBeBooleanAddFalseTrampoline");
	ceSendMustBeBooleanAddTrueTrampoline = genMustBeBooleanTrampolineForcalled(trueObject(), "ceSendMustBeBooleanAddTrueTrampoline");
	ceNonLocalReturnTrampoline = genNonLocalReturnTrampoline();
	ceCheckForInterruptTrampoline = genCheckForInterruptsTrampoline();
	ceFetchContextInstVarTrampoline = genTrampolineForcalledargargresult(ceContextinstVar, "ceFetchContextInstVarTrampoline", ReceiverResultReg, SendNumArgsReg, SendNumArgsReg);
	ceStoreContextInstVarTrampoline = genTrampolineForcalledargargargresult(ceContextinstVarvalue, "ceStoreContextInstVarTrampoline", ReceiverResultReg, SendNumArgsReg, ClassReg, ReceiverResultReg);

	/* These two are unusual; they are reached by return instructions. */
	ceCannotResumeTrampoline = genTrampolineForcalled(ceCannotResume, "ceCannotResumeTrampoline");
	ceBaseFrameReturnTrampoline = genReturnTrampolineForcalledarg(ceBaseFrameReturn, "ceBaseFrameReturnTrampoline", ReceiverResultReg);
	ceReturnToInterpreterTrampoline = genReturnTrampolineForcalledarg(ceReturnToInterpreter, "ceReturnToInterpreterTrampoline", ReceiverResultReg);
}


/*	Generate a routine ceCaptureCStackPointers that will capture the C stack
	pointer, and, if it is in use, the C frame pointer. These are used in
	trampolines to call
	run-time routines in the interpreter from machine-code. */

	/* Cogit>>#generateStackPointerCapture */
static void
generateStackPointerCapture(void)
{
    sqInt oldMethodZoneBase;
    sqInt oldTrampolineTableIndex;


	/* For the benefit of the following assert, assume the minimum at first. */
	cFramePointerInUse = 0;
	assertCStackWellAligned();
	oldMethodZoneBase = methodZoneBase;
	oldTrampolineTableIndex = trampolineTableIndex;
	generateCaptureCStackPointers(1);
	ceCaptureCStackPointers();
	if (!((cFramePointerInUse = isCFramePointerInUse()))) {
		methodZoneBase = oldMethodZoneBase;
		trampolineTableIndex = oldTrampolineTableIndex;
		generateCaptureCStackPointers(0);
	}
	assertCStackWellAligned();
}


/*	Generate the run-time entries and exits at the base of the native code
	zone and update the base.
	Read the class-side method trampolines for documentation on the various
	trampolines 
 */

	/* Cogit>>#generateTrampolines */
static void
generateTrampolines(void)
{
    sqInt fixupSize;
    sqInt methodZoneStart;
    sqInt opcodeSize;

	methodZoneStart = methodZoneBase;
	(methodLabel->address = methodZoneStart);
	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 80;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	hasYoungReferent = 0;
	/* begin maybeGenerateSelectorIndexDereferenceRoutine */
	generateSendTrampolines();
	generateMissAbortTrampolines();
	generateObjectRepresentationTrampolines();
	generateRunTimeTrampolines();
	generateEnilopmarts();
	generateTracingTrampolines();
	recordGeneratedRunTimeaddress("methodZoneBase", methodZoneBase);
	flushICacheFromto(processor, ((usqInt)methodZoneStart), ((usqInt)methodZoneBase));
}


/*	Generate a routine that answers the stack pointer immedately
	after a leaf call, used for checking stack pointer alignment. */

	/* Cogit>>#genGetLeafCallStackPointer */
static void
genGetLeafCallStackPointer(void)
{
    AbstractInstruction *anInstruction;
    sqInt fixupSize;
    sqInt opcodeSize;
    sqInt startAddress;

	/* begin allocateOpcodes:bytecodes: */
	numAbstractOpcodes = 4;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	startAddress = methodZoneBase;
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, FPReg, V0);
	/* begin RetN: */
	genoperand(RetN, 0);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceGetFP", startAddress);
	ceGetFP = ((unsigned long (*)(void)) startAddress);
	startAddress = methodZoneBase;
	zeroOpcodeIndex();
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SPReg, V0);
	/* begin RetN: */
	genoperand(RetN, 0);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceGetSP", startAddress);
	ceGetSP = ((unsigned long (*)(void)) startAddress);
}


/*	Generate the abort for a PIC. This abort performs either a call of
	ceInterpretMethodFromPIC:receiver: to handle invoking an uncogged target
	or a call of ceMNUFromPICMNUMethod:receiver: to handle an MNU dispatch
	in a closed PIC. It distinguishes the two by testing ClassReg. If the
	register is zero then this is an MNU.
	
	This poses a problem in 32-bit Spur, where zero is the cache tag for
	immediate characters (tag pattern 2r10) because SmallIntegers have tag
	patterns 2r11
	and 2r01, so anding with 1 reduces these to 0 & 1. We solve the ambiguity
	by patching send sites with a 0 cache tag to open PICs instead of closed
	PICs.  */

	/* Cogit>>#genInnerPICAbortTrampoline: */
static sqInt NoDbgRegParms
genInnerPICAbortTrampoline(char *name)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *jumpMNUCase;

	/* begin CmpCq:R: */
	anInstruction = genoperandoperand(CmpCqR, 0, ClassReg);
	/* begin JumpZero: */
	jumpMNUCase = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(ceInterpretMethodFromPICreceiver, 2, SendNumArgsReg, ReceiverResultReg, null, null, 0, 0, NoReg);
	jmpTarget(jumpMNUCase, gLabel());
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceMNUFromPICMNUMethodreceiver, name, 2, SendNumArgsReg, ReceiverResultReg, null, null, 0, 0, NoReg, 1);
}

	/* Cogit>>#genLoadCStackPointersForPrimCall */
static sqInt
genLoadCStackPointersForPrimCall(void)
{
    sqInt address;
    sqInt address1;
    sqInt address2;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;

	if (debugPrimCallStackOffset == 0) {
		/* begin MoveAw:R: */
		address = cStackPointerAddress();
		/* begin gen:literal:operand: */
		anInstruction = genoperandoperand(MoveAwR, address, SPReg);
	}
	else {
		/* begin MoveAw:R: */
		address1 = cStackPointerAddress();
		/* begin gen:literal:operand: */
		anInstruction1 = genoperandoperand(MoveAwR, address1, TempReg);
		/* begin SubCq:R: */
		anInstruction2 = genoperandoperand(SubCqR, debugPrimCallStackOffset, TempReg);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, TempReg, SPReg);
	}
	if (cFramePointerInUse) {
		/* begin MoveAw:R: */
		address2 = cFramePointerAddress();
		/* begin gen:literal:operand: */
		anInstruction3 = genoperandoperand(MoveAwR, address2, FPReg);
	}
	return 0;
}


/*	The in-line cache for a send is implemented as a constant load into
	ClassReg. We always use a 32-bit load, even in 64-bits.
	
	In the initial (unlinked) state the in-line cache is notionally loaded
	with the selector.
	But since in 64-bits an arbitrary selector oop won't fit in a 32-bit
	constant load, we
	instead load the cache with the selector's index, either into the literal
	frame of the
	current method, or into the special selector array. Negative values are
	1-relative indices into the special selector array.
	
	When a send is linked, the load of the selector, or selector index, is
	overwritten with a
	load of the receiver's class, or class tag. Hence, the 64-bit VM is
	currently constrained
	to use class indices as cache tags. If out-of-line literals are used,
	distinct caches /must
	not/ share acche locations, for if they do, send cacheing will be confused
	by the sharing.
	Hence we use the MoveUniqueC32:R: instruction that will not share literal
	locations.  */

	/* Cogit>>#genLoadInlineCacheWithSelector: */
static void NoDbgRegParms
genLoadInlineCacheWithSelector(sqInt selectorIndex)
{
    AbstractInstruction *anInstruction;
    sqInt cacheValue;
    sqInt opcode;
    sqInt selector;

	assert((selectorIndex < 0
		? (((-selectorIndex) >= 1) && ((-selectorIndex) <= (numSpecialSelectors())))
		: ((selectorIndex >= 0) && (selectorIndex <= ((literalCountOf(methodObj)) - 1)))));
	selector = (selectorIndex < 0
		? specialSelector(-1 - selectorIndex)
		: getLiteral(selectorIndex));
	assert(addressCouldBeOop(selector));
	if (isYoung(selector)) {
		hasYoungReferent = 1;
	}
	cacheValue = selector;

	/* begin MoveUniqueC32:R: */
	opcode = MoveCwR;
	/* begin uniqueLiteral:forInstruction: */
	anInstruction = genoperandoperand(opcode, cacheValue, ClassReg);
}

	/* Cogit>>#genNonLocalReturnTrampoline */
static sqInt
genNonLocalReturnTrampoline(void)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;

	zeroOpcodeIndex();
	/* begin MoveR:Aw: */
	address = instructionPointerAddress();
	/* begin gen:operand:literal: */
	anInstruction = genoperandoperand(MoveRAw, LinkReg, address);

	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceNonLocalReturn, "ceNonLocalReturnTrampoline", 1, ReceiverResultReg, null, null, null, 0, 0, NoReg, 1);
}


/*	Generate a trampoline for a routine used as a return address, that has one
	argument. Hack: a negative value indicates an abstract register, a
	non-negative value indicates a constant. */

	/* Cogit>>#genReturnTrampolineFor:called:arg: */
static sqInt NoDbgRegParms
genReturnTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 1, regOrConst0, null, null, null, 0, 0, NoReg, 0);
}


/*	Generate a trampoline with no arguments that will
	save and restore all registers around the call */

	/* Cogit>>#genSafeTrampolineFor:called: */
static sqInt NoDbgRegParms
genSafeTrampolineForcalled(void *aRoutine, char *aString)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 0, null, null, null, null, 1, 1, NoReg, 0);
}


/*	Generate a trampoline with one argument that will
	save and restore all registers around the call */

	/* Cogit>>#genSafeTrampolineFor:called:arg: */
static sqInt NoDbgRegParms
genSafeTrampolineForcalledarg(void *aRoutine, char *aString, sqInt regOrConst0)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 1, regOrConst0, null, null, null, 1, 1, NoReg, 0);
}


/*	Generate a trampoline with two arguments that
	will save and restore all registers around the call */

	/* Cogit>>#genSafeTrampolineFor:called:arg:arg: */
static sqInt NoDbgRegParms
genSafeTrampolineForcalledargarg(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 2, regOrConst0, regOrConst1, null, null, 1, 1, NoReg, 0);
}


/*	If the client requires, then on an ARM-like RISC processor, the return
	address needs to
	be pushed to the stack so that the interpreter sees the same stack layout
	as on CISC.
 */

	/* Cogit>>#genSmalltalkToCStackSwitch: */
static sqInt NoDbgRegParms
genSmalltalkToCStackSwitch(sqInt pushLinkReg)
{
	if (pushLinkReg) {
		/* begin PushR: */
		genoperand(PushR, LinkReg);
	}
	genSaveStackPointers(backEnd);
	if (cFramePointerInUse) {
		genLoadCStackPointers(backEnd);
	}
	else {
		genLoadCStackPointer(backEnd);
	}
	return 0;
}


/*	Generate a trampoline with no arguments */

	/* Cogit>>#genTrampolineFor:called: */
static sqInt NoDbgRegParms
genTrampolineForcalled(void *aRoutine, char *aString)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 0, null, null, null, null, 0, 1, NoReg, 0);
}


/*	Generate a trampoline with three arguments.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#genTrampolineFor:called:arg:arg:arg: */
static sqInt NoDbgRegParms
genTrampolineForcalledargargarg(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 3, regOrConst0, regOrConst1, regOrConst2, null, 0, 1, NoReg, 0);
}


/*	Generate a trampoline with two arguments that answers a result.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#genTrampolineFor:called:arg:arg:arg:result: */
static sqInt NoDbgRegParms
genTrampolineForcalledargargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt resultReg)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 3, regOrConst0, regOrConst1, regOrConst2, null, 0, 1, resultReg, 0);
}


/*	Generate a trampoline with two arguments that answers a result.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#genTrampolineFor:called:arg:arg:result: */
static sqInt NoDbgRegParms
genTrampolineForcalledargargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt resultReg)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 2, regOrConst0, regOrConst1, null, null, 0, 1, resultReg, 0);
}


/*	Generate a trampoline with one argument that answers a result.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#genTrampolineFor:called:arg:result: */
static sqInt NoDbgRegParms
genTrampolineForcalledargresult(void *aRoutine, char *aString, sqInt regOrConst0, sqInt resultReg)
{
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 1, regOrConst0, null, null, null, 0, 1, resultReg, 0);
}


/*	Generate a trampoline with up to four arguments. Generate either a call or
	a jump to aRoutineOrNil
	as requested by callJumpBar. If generating a call and resultRegOrNone is
	not NoReg pass the C result
	back in resultRegOrNone.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* Cogit>>#genTrampolineFor:called:numArgs:arg:arg:arg:arg:saveRegs:pushLinkReg:resultReg:appendOpcodes: */
static sqInt NoDbgRegParms
genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(void *aRoutine, char *trampolineName, sqInt numArgs, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3, sqInt saveRegs, sqInt pushLinkReg, sqInt resultRegOrNone, sqInt appendBoolean)
{
    sqInt startAddress;

	startAddress = methodZoneBase;
	if (!appendBoolean) {
		zeroOpcodeIndex();
	}
	compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(aRoutine, numArgs, regOrConst0, regOrConst1, regOrConst2, regOrConst3, saveRegs, pushLinkReg, resultRegOrNone);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress(trampolineName, startAddress);
	recordRunTimeObjectReferences();
	return startAddress;
}


/*	<Integer> */

	/* Cogit>>#gen: */
static AbstractInstruction * NoDbgRegParms
gen(sqInt opcode)
{
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	return abstractInstruction;
}


/*	<Integer> */
/*	<Integer|CogAbstractInstruction> */

	/* Cogit>>#gen:operand: */
static AbstractInstruction * NoDbgRegParms
genoperand(sqInt opcode, sqInt operand)
{
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	((abstractInstruction->operands))[0] = operand;
	return abstractInstruction;
}


/*	<Integer> */
/*	<Integer|CogAbstractInstruction> */
/*	<Integer|CogAbstractInstruction> */

	/* Cogit>>#gen:operand:operand: */
static AbstractInstruction * NoDbgRegParms
genoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo)
{
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	((abstractInstruction->operands))[0] = operandOne;
	((abstractInstruction->operands))[1] = operandTwo;
	return abstractInstruction;
}


/*	<Integer> */
/*	<Integer|CogAbstractInstruction> */
/*	<Integer|CogAbstractInstruction> */
/*	<Integer|CogAbstractInstruction> */

	/* Cogit>>#gen:operand:operand:operand: */
static AbstractInstruction * NoDbgRegParms
genoperandoperandoperand(sqInt opcode, sqInt operandOne, sqInt operandTwo, sqInt operandThree)
{
    AbstractInstruction *abstractInstruction;

	assert(opcodeIndex < numAbstractOpcodes);
	abstractInstruction = abstractInstructionAt(opcodeIndex);
	opcodeIndex += 1;
	(abstractInstruction->opcode = opcode);
	((abstractInstruction->operands))[0] = operandOne;
	((abstractInstruction->operands))[1] = operandTwo;
	((abstractInstruction->operands))[2] = operandThree;
	return abstractInstruction;
}

	/* Cogit>>#getLiteral: */
static sqInt NoDbgRegParms
getLiteral(sqInt litIndex)
{
	if (maxLitIndex < litIndex) {
		maxLitIndex = litIndex;
	}
	return literalofMethod(litIndex, methodObj);
}

	/* Cogit>>#incrementUsageOfTargetIfLinkedSend:mcpc:ignored: */
static sqInt NoDbgRegParms
incrementUsageOfTargetIfLinkedSendmcpcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    CogMethod * targetMethod;
    CogMethod *targetMethod1;

	if (annotation >= IsSendCall) {
		assert(annotation != IsNSSendCall);
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */
			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if (((targetMethod1->cmUsageCount)) < (CMMaxUsageCount / 2)) {
				(targetMethod1->cmUsageCount = ((targetMethod1->cmUsageCount)) + 1);
			}

		}
	}
	return 0;
}


/*	Answer the value to put in an inline-cache that is being loaded with the
	selector. Usually this is simply the selector, but in 64-bits the cache is
	only 32-bits wide
	and so the cache is loaded with the index of the selector. */

	/* Cogit>>#indexForSelector:in:at: */
static sqInt NoDbgRegParms
indexForSelectorinat(sqInt selector, CogMethod *cogMethod, sqInt mcpc)
{
    sqInt i;
    sqInt iLimiT;
    sqInt methodOop;

	assert(((((usqInt)mcpc)) > (((usqInt)cogMethod)))
	 && (mcpc < ((((usqInt)cogMethod)) + ((cogMethod->blockSize)))));
	for (i = 0; i < NumSpecialSelectors; i += 1) {
		if (selector == (specialSelector(i))) {
			return -1 - i;
		}
	}

	/* Then search the method's literal frame... open code fetchPointer:ofObject: for speed... */
	methodOop = (cogMethod->methodObject);
	for (i = LiteralStart, iLimiT = (literalCountOfMethodHeader((cogMethod->methodHeader))); i <= iLimiT; i += 1) {
		if ((longAt(((i * BytesPerOop) + BaseHeaderSize) + methodOop)) == selector) {
			assert(selector == (literalofMethod(i - 1, methodOop)));
			return i - 1;
		}
	}
	error("could not find selector in method when unlinking send site");
	return 0;
}


/*	Answer a usage count that reflects likely long-term usage. */

	/* Cogit>>#initialClosedPICUsageCount */
static sqInt
initialClosedPICUsageCount(void)
{
	return CMMaxUsageCount / 2;
}

	/* Cogit>>#initializeBackend */
static void
initializeBackend(void)
{
	(methodLabel->machineCodeSize = 0);
	(methodLabel->opcode = Label);
	((methodLabel->operands))[0] = 0;
	((methodLabel->operands))[1] = 0;
	callerSavedRegMask = callerSavedRegisterMask(backEnd);
	assert(((registerMaskFor(VarBaseReg)) & callerSavedRegMask) == 0);

	/* begin allocateLiterals: */
	}

	/* Cogit>>#initializeCodeZoneFrom:upTo: */
void
initializeCodeZoneFromupTo(sqInt startAddress, sqInt endAddress)
{
    static void (*ceFlushICache)(unsigned long from, unsigned long to);
    sqInt fixupSize;
    sqInt fixupSize1;
    sqInt fixupSize2;
    sqInt numberOfAbstractOpcodes;
    sqInt opcodeSize;
    sqInt opcodeSize1;
    sqInt opcodeSize2;
    sqInt startAddress1;
    sqInt startAddress2;
    sqInt startAddress3;

	initializeBackend();
	stopsFromto(backEnd, startAddress, endAddress - 1);
	sqMakeMemoryExecutableFromTo(startAddress, endAddress);
	codeBase = (methodZoneBase = startAddress);
	minValidCallAddress = (((((codeBase < (interpretAddress())) ? codeBase : (interpretAddress()))) < (primitiveFailAddress())) ? (((codeBase < (interpretAddress())) ? codeBase : (interpretAddress()))) : (primitiveFailAddress()));
	manageFromto(methodZoneBase, endAddress);
	/* begin maybeGenerateCheckFeatures */
	/* begin maybeGenerateICacheFlush */
	/* begin generateVMOwnerLockFunctions */
	
#  if COGMTVM
	/* begin allocateOpcodes:bytecodes: */
	numberOfAbstractOpcodes = numLowLevelLockOpcodes(backEnd);
	numAbstractOpcodes = numberOfAbstractOpcodes;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	abstractOpcodes = alloca(opcodeSize + fixupSize);
	bzero(abstractOpcodes, opcodeSize + fixupSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
	zeroOpcodeIndex();
	startAddress1 = methodZoneBase;
	generateLowLevelTryLock(backEnd, vmOwnerLockAddress());
	outputInstructionsForGeneratedRuntimeAt(startAddress1);
	recordGeneratedRunTimeaddress("ceTryLockVMOwner", startAddress1);
	ceTryLockVMOwner = ((unsigned long (*)(void)) startAddress1);
	zeroOpcodeIndex();
	initialPC = 0;
	endPC = numAbstractOpcodes - 1;
	startAddress1 = methodZoneBase;
	generateLowLevelUnlock(backEnd, vmOwnerLockAddress());
	outputInstructionsForGeneratedRuntimeAt(startAddress1);
	recordGeneratedRunTimeaddress("ceUnlockVMOwner", startAddress1);
	ceUnlockVMOwner = ((void (*)(void)) startAddress1);

#  endif /* COGMTVM */

	genGetLeafCallStackPointer();
	generateStackPointerCapture();
	generateTrampolines();
	computeEntryOffsets();
	generateClosedPICPrototype();
	manageFromto(methodZoneBase, endAddress);
	generateOpenPICPrototype();
}


/*	Answer a usage count that reflects likely long-term usage.
	Answer 1 for non-primitives or quick primitives (inst var accessors),
	2 for methods with interpreter primitives, and 3 for compiled primitives. */

	/* Cogit>>#initialMethodUsageCount */
static sqInt
initialMethodUsageCount(void)
{
	if ((primitiveIndex == 1)
	 || (isQuickPrimitiveIndex(primitiveIndex))) {
		return 1;
	}
	if (!(primitiveGeneratorOrNil())) {
		return 2;
	}
	return 3;
}


/*	Answer a usage count that reflects likely long-term usage. */

	/* Cogit>>#initialOpenPICUsageCount */
static sqInt
initialOpenPICUsageCount(void)
{
	return CMMaxUsageCount - 1;
}


/*	Answer the value to put in an inline-cache that is being loaded with the
	selector. Usually this is simply the selector, but in 64-bits the cache is
	only 32-bits wide
	and so the cache is loaded with the index of the selector. */

	/* Cogit>>#inlineCacheValueForSelector:in:at: */
static sqInt NoDbgRegParms
inlineCacheValueForSelectorinat(sqInt selector, sqInt aCogMethod, sqInt mcpc)
{
	return selector;
}

	/* Cogit>>#inverseBranchFor: */
static sqInt NoDbgRegParms
inverseBranchFor(sqInt opcode)
{
	
	switch (opcode) {
	case JumpLongZero:
		return JumpLongNonZero;

	case JumpLongNonZero:
		return JumpLongZero;

	case JumpZero:
		return JumpNonZero;

	case JumpNonZero:
		return JumpZero;

	case JumpNegative:
		return JumpNonNegative;

	case JumpNonNegative:
		return JumpNegative;

	case JumpOverflow:
		return JumpNoOverflow;

	case JumpNoOverflow:
		return JumpOverflow;

	case JumpCarry:
		return JumpNoCarry;

	case JumpNoCarry:
		return JumpCarry;

	case JumpLess:
		return JumpGreaterOrEqual;

	case JumpGreaterOrEqual:
		return JumpLess;

	case JumpGreater:
		return JumpLessOrEqual;

	case JumpLessOrEqual:
		return JumpGreater;

	case JumpBelow:
		return JumpAboveOrEqual;

	case JumpAboveOrEqual:
		return JumpBelow;

	case JumpAbove:
		return JumpBelowOrEqual;

	case JumpBelowOrEqual:
		return JumpAbove;

	default:
		error("Case not found and no otherwise clause");
	}
	error("invalid opcode for inverse");
	return 0;
}


/*	Answer if the branch bytecode with the given descriptor is a backward
	branch. 
 */

	/* Cogit>>#isBackwardBranch:at:exts:in: */
static sqInt NoDbgRegParms
isBackwardBranchatextsin(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(((descriptor->spanFunction)) != null);
	return (((descriptor->spanFunction))(descriptor, pc, nExts, aMethodObj)) < 0;
}

	/* Cogit>>#isPCMappedAnnotation: */
static sqInt NoDbgRegParms
isPCMappedAnnotation(sqInt annotation)
{
	return (annotation >= IsSendCall)
	 || ((annotation == HasBytecodePC)
	 || (0));
}

	/* Cogit>>#isPCWithinMethodZone: */
sqInt
isPCWithinMethodZone(void *address)
{
	return (((((usqInt)address)) >= methodZoneBase) && ((((usqInt)address)) <= (freeStart())));
}


/*	Answer if the instruction preceding retpc is a call instruction. */

	/* Cogit>>#isSendReturnPC: */
sqInt
isSendReturnPC(sqInt retpc)
{
    sqInt target;

	if (!(isCallPrecedingReturnPC(backEnd, retpc))) {
		return 0;
	}
	target = callTargetFromReturnAddress(backEnd, retpc);
	return (((target >= firstSend) && (target <= lastSend)))
	 || (((target >= methodZoneBase) && (target <= (freeStart()))));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPEqual: */
static AbstractInstruction * NoDbgRegParms
gJumpFPEqual(void *jumpTarget)
{
	/* begin genJumpFPEqual: */
	return genoperand(JumpFPEqual, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPGreaterOrEqual: */
static AbstractInstruction * NoDbgRegParms
gJumpFPGreaterOrEqual(void *jumpTarget)
{
	/* begin genJumpFPGreaterOrEqual: */
	return genoperand(JumpFPGreaterOrEqual, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPGreater: */
static AbstractInstruction * NoDbgRegParms
gJumpFPGreater(void *jumpTarget)
{
	/* begin genJumpFPGreater: */
	return genoperand(JumpFPGreater, ((sqInt)jumpTarget));
}


/*	Floating-point jumps are a little weird on some processors. Defer to
	the backEnd to allow it to generate any special code it may need to. */

	/* Cogit>>#JumpFPNotEqual: */
static AbstractInstruction * NoDbgRegParms
gJumpFPNotEqual(void *jumpTarget)
{
	/* begin genJumpFPNotEqual: */
	return genoperand(JumpFPNotEqual, ((sqInt)jumpTarget));
}

	/* Cogit>>#Label */
static AbstractInstruction *
gLabel(void)
{
	return genoperandoperand(Label, (labelCounter += 1), bytecodePC);
}

	/* Cogit>>#LogicalShiftLeftCq:R: */
static AbstractInstruction * NoDbgRegParms
gLogicalShiftLeftCqR(sqInt quickConstant, sqInt reg)
{
	return genoperandoperand(LogicalShiftLeftCqR, quickConstant, reg);
}

	/* Cogit>>#lastOpcode */
static AbstractInstruction *
lastOpcode(void)
{
	assert(opcodeIndex > 0);
	return abstractInstructionAt(opcodeIndex - 1);
}

	/* Cogit>>#linkSendAt:in:to:offset:receiver: */
void
linkSendAtintooffsetreceiver(sqInt callSiteReturnAddress, CogMethod *sendingMethod, CogMethod *targetMethod, sqInt theEntryOffset, sqInt receiver)
{
    sqInt address;
    sqInt extent;
    sqInt inlineCacheTag;

	assert((theEntryOffset == cmEntryOffset)
	 || (theEntryOffset == cmNoCheckEntryOffset));
	assert(((callSiteReturnAddress >= methodZoneBase) && (callSiteReturnAddress <= (freeStart()))));
	inlineCacheTag = (theEntryOffset == cmNoCheckEntryOffset
		? (targetMethod->selector)
		: inlineCacheTagForInstance(receiver));
	address = (((sqInt)targetMethod)) + theEntryOffset;
	extent = rewriteInlineCacheAttagtarget(backEnd, callSiteReturnAddress, inlineCacheTag, address);
	flushICacheFromto(processor, (((usqInt)callSiteReturnAddress)) - extent, ((usqInt)callSiteReturnAddress));
}

	/* Cogit>>#loadSubsequentBytesForDescriptor:at: */
static void NoDbgRegParms
loadSubsequentBytesForDescriptorat(BytecodeDescriptor *descriptor, sqInt pc)
{
	if (((descriptor->numBytes)) > 1) {
		byte1 = fetchByteofObject(pc + 1, methodObj);
		if (((descriptor->numBytes)) > 2) {
			byte2 = fetchByteofObject(pc + 2, methodObj);
			if (((descriptor->numBytes)) > 3) {
				byte3 = fetchByteofObject(pc + 3, methodObj);
				if (((descriptor->numBytes)) > 4) {
					notYetImplemented();
				}
			}
		}
	}
}

	/* Cogit>>#MoveAw:R: */
static AbstractInstruction * NoDbgRegParms
gMoveAwR(sqInt address, sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(MoveAwR, address, reg);
	return anInstruction;
}

	/* Cogit>>#MoveCw:R: */
static AbstractInstruction * NoDbgRegParms
gMoveCwR(sqInt wordConstant, sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(MoveCwR, wordConstant, reg);
	return anInstruction;
}

	/* Cogit>>#MoveMw:r:R: */
static AbstractInstruction * NoDbgRegParms
gMoveMwrR(sqInt offset, sqInt baseReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:quickConstant:operand:operand: */
	anInstruction = genoperandoperandoperand(MoveMwrR, offset, baseReg, destReg);
	return anInstruction;
}

	/* Cogit>>#MoveR:Mw:r: */
static AbstractInstruction * NoDbgRegParms
gMoveRMwr(sqInt sourceReg, sqInt offset, sqInt baseReg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:operand:quickConstant:operand: */
	anInstruction = genoperandoperandoperand(MoveRMwr, sourceReg, offset, baseReg);
	return anInstruction;
}

	/* Cogit>>#MoveR:R: */
static AbstractInstruction * NoDbgRegParms
gMoveRR(sqInt reg1, sqInt reg2)
{
	return genoperandoperand(MoveRR, reg1, reg2);
}


/*	Answer the address of the null byte at the end of the method map. */

	/* Cogit>>#mapEndFor: */
static sqInt NoDbgRegParms
mapEndFor(CogMethod *cogMethod)
{
    sqInt end;

	end = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while ((byteAt(end)) != MapEnd) {
		end -= 1;
		assert(end > ((((sqInt)cogMethod)) + cmNoCheckEntryOffset));
	}
	return end;
}


/*	Unlinking/GC/Disassembly support */

	/* Cogit>>#mapFor:performUntil:arg: */
static sqInt NoDbgRegParms
mapForperformUntilarg(CogMethod *cogMethod, sqInt (*functionSymbol)(sqInt annotation, char *mcpc, sqInt arg), sqInt arg)
{
    sqInt annotation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {

			/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
			mcpc += (mapByte & DisplacementMask) * 4;
			if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
			 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
				annotation += mapByte & DisplacementMask;
				map -= 1;
			}
			result = functionSymbol(annotation, (((char *) mcpc)), arg);
			if (result != 0) {
				return result;
			}
		}
		else {
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
	return 0;
}


/*	Remap all object references in the closed PIC. Answer if any references
	are young.
	Set codeModified if any modifications are made. */

	/* Cogit>>#mapObjectReferencesInClosedPIC: */
static sqInt NoDbgRegParms
mapObjectReferencesInClosedPIC(CogMethod *cPIC)
{
    sqInt i;
    sqInt pc;
    sqInt refersToYoung;


	/* first we check the potential method oop load at the beginning of the CPIC */
	pc = addressOfEndOfCaseinCPIC(1, cPIC);

	/* We find the end address of the cPICNumCases'th case and can then just step forward by the case size thereafter */
	refersToYoung = remapMaybeObjRefInClosedPICAt(pc - (jumpLongByteSize(backEnd)));

	/* Next we check the potential class ref in the compare instruction, and the potential method oop load for each case. */
	pc = addressOfEndOfCaseinCPIC((cPIC->cPICNumCases), cPIC);
	for (i = 2; i <= ((cPIC->cPICNumCases)); i += 1) {
		if (remapMaybeObjRefInClosedPICAt((pc - (jumpLongConditionalByteSize(backEnd))) - (cmpC32RTempByteSize(backEnd)))) {
			refersToYoung = 1;
		}
		pc += cPICCaseSize;
	}
	return refersToYoung;
}


/*	Update all references to objects in the generated runtime. */

	/* Cogit>>#mapObjectReferencesInGeneratedRuntime */
static void
mapObjectReferencesInGeneratedRuntime(void)
{
    sqInt i;
    sqInt literal;
    sqInt mappedLiteral;
    usqInt mcpc;

	for (i = 0; i < runtimeObjectRefIndex; i += 1) {
		mcpc = objectReferencesInRuntime[i];
		literal = literalBeforeFollowingAddress(backEnd, mcpc);
		mappedLiteral = remapObject(literal);
		if (mappedLiteral != literal) {
			storeLiteralbeforeFollowingAddress(backEnd, mappedLiteral, mcpc);
			codeModified = 1;
		}
	}
}


/*	Update all references to objects in machine code for a become.
	Unlike incrementalGC or fullGC a method that does not refer to young may
	refer to young as a result of the become operation. Unlike incrementalGC
	or fullGC the reference from a Cog method to its methodObject *must not*
	change since the two are two halves of the same object. */

	/* Cogit>>#mapObjectReferencesInMachineCodeForBecome */
static void
mapObjectReferencesInMachineCodeForBecome(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt freedPIC;
    sqInt hasYoungObj;
    sqInt hasYoungObjPtr;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt remappedMethod;
    sqInt result;
    sqInt val;

	val = 0;
	hasYoungObj = 0;
	hasYoungObjPtr = ((sqInt)((&hasYoungObj)));
	codeModified = (freedPIC = 0);
	mapObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		assert(!hasYoungObj);
		if (((cogMethod->cmType)) != CMFree) {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			(cogMethod->selector = remapOop((cogMethod->selector)));
			if (((cogMethod->cmType)) == CMClosedPIC) {
				if ((isYoung((cogMethod->selector)))
				 || (mapObjectReferencesInClosedPIC(cogMethod))) {
					freedPIC = 1;
					freeMethod(cogMethod);
				}
			}
			else {
				if (isYoung((cogMethod->selector))) {
					hasYoungObj = 1;
				}
				if (((cogMethod->cmType)) == CMMethod) {
					assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
					remappedMethod = remapOop((cogMethod->methodObject));
					if (remappedMethod != ((cogMethod->methodObject))) {
						if (methodHasCogMethod(remappedMethod)) {
							error("attempt to become two cogged methods");
						}
						if (!(withoutForwardingOnandwithsendToCogit((cogMethod->methodObject), remappedMethod, (cogMethod->cmUsesPenultimateLit), methodhasSameCodeAscheckPenultimate))) {
							error("attempt to become cogged method into different method");
						}
						if ((rawHeaderOf((cogMethod->methodObject))) == (((sqInt)cogMethod))) {
							rawHeaderOfput((cogMethod->methodObject), (cogMethod->methodHeader));
							(cogMethod->methodHeader = rawHeaderOf(remappedMethod));
							(cogMethod->methodObject = remappedMethod);
							rawHeaderOfput(remappedMethod, ((sqInt)cogMethod));
						}
						else {
							assert((noAssertMethodClassAssociationOf((cogMethod->methodObject))) == (nilObject()));
							(cogMethod->methodHeader = rawHeaderOf(remappedMethod));
							(cogMethod->methodObject = remappedMethod);
						}
					}
					if (isYoung((cogMethod->methodObject))) {
						hasYoungObj = 1;
					}
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {

						/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
						mcpc += (mapByte & DisplacementMask) * 4;
						if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
						 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
							annotation += mapByte & DisplacementMask;
							map -= 1;
						}
						result = remapIfObjectRefpchasYoung(annotation, (((char *) mcpc)), hasYoungObjPtr);
						if (result != 0) {
							goto l1;
						}
					}
					else {
						if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
							mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
						}
					}
					map -= 1;
				}
			l1:	/* end mapFor:performUntil:arg: */;
				if (hasYoungObj) {
					ensureInYoungReferrers(cogMethod);
					hasYoungObj = 0;
				}
				else {
					(cogMethod->cmRefersToYoung = 0);
				}
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	pruneYoungReferrers();
	if (freedPIC) {
		unlinkSendsToFree();
	}
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */
		flushICacheFromto(processor, ((usqInt)codeBase), ((usqInt)(limitZony())));
	}
}


/*	Update all references to objects in machine code for a full gc. Since
	the current (New)ObjectMemory GC makes everything old in a full GC
	a method not referring to young will not refer to young afterwards */

	/* Cogit>>#mapObjectReferencesInMachineCodeForFullGC */
static void
mapObjectReferencesInMachineCodeForFullGC(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	codeModified = 0;
	mapObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) != CMFree) {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			(cogMethod->selector = remapOop((cogMethod->selector)));
			if (((cogMethod->cmType)) == CMClosedPIC) {
				assert(!((cogMethod->cmRefersToYoung)));
				mapObjectReferencesInClosedPIC(cogMethod);
			}
			else {
				if (((cogMethod->cmType)) == CMMethod) {
					assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
					(cogMethod->methodObject = remapOop((cogMethod->methodObject)));
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {

						/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
						mcpc += (mapByte & DisplacementMask) * 4;
						if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
						 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
							annotation += mapByte & DisplacementMask;
							map -= 1;
						}
						result = remapIfObjectRefpchasYoung(annotation, (((char *) mcpc)), 0);
						if (result != 0) {
							goto l1;
						}
					}
					else {
						if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
							mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
						}
					}
					map -= 1;
				}
			l1:	/* end mapFor:performUntil:arg: */;
							}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	pruneYoungReferrers();
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */
		flushICacheFromto(processor, ((usqInt)codeBase), ((usqInt)(limitZony())));
	}
}


/*	Update all references to objects in machine code for either a Spur
	scavenging gc
	or a Squeak V3 incremental GC. Avoid scanning all code by using the
	youngReferrers list. In a young gc a method referring to young may no
	longer refer to young, but a
	method not referring to young cannot and will not refer to young
	afterwards.  */

	/* Cogit>>#mapObjectReferencesInMachineCodeForYoungGC */
static void
mapObjectReferencesInMachineCodeForYoungGC(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt hasYoungObj;
    sqInt hasYoungObjPtr;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    usqInt pointer;
    sqInt result;
    sqInt val;

	val = 0;
	hasYoungObj = 0;
	hasYoungObjPtr = ((sqInt)((&hasYoungObj)));
	codeModified = 0;
	pointer = youngReferrers();
	while (pointer < limitAddress) {
		assert(!hasYoungObj);
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (((cogMethod->cmType)) == CMFree) {
			assert(!((cogMethod->cmRefersToYoung)));
		}
		else {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			if ((cogMethod->cmRefersToYoung)) {
				assert((((cogMethod->cmType)) == CMMethod)
				 || (((cogMethod->cmType)) == CMOpenPIC));
				(cogMethod->selector = remapOop((cogMethod->selector)));
				if (isYoung((cogMethod->selector))) {
					hasYoungObj = 1;
				}
				if (((cogMethod->cmType)) == CMMethod) {
					assert(((cogMethod->objectHeader)) == (nullHeaderForMachineCodeMethod()));
					(cogMethod->methodObject = remapOop((cogMethod->methodObject)));
					if (isYoung((cogMethod->methodObject))) {
						hasYoungObj = 1;
					}
				}
				/* begin mapFor:performUntil:arg: */
				mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
				map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
				while (((mapByte = byteAt(map))) != MapEnd) {
					if (mapByte >= FirstAnnotation) {

						/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
						mcpc += (mapByte & DisplacementMask) * 4;
						if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
						 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
							annotation += mapByte & DisplacementMask;
							map -= 1;
						}
						result = remapIfObjectRefpchasYoung(annotation, (((char *) mcpc)), hasYoungObjPtr);
						if (result != 0) {
							goto l1;
						}
					}
					else {
						if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
							mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
						}
					}
					map -= 1;
				}
			l1:	/* end mapFor:performUntil:arg: */;
				if (hasYoungObj) {
					hasYoungObj = 0;
				}
				else {
					(cogMethod->cmRefersToYoung = 0);
				}
			}
		}
		pointer += BytesPerWord;
	}
	pruneYoungReferrers();
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */
		flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
	}
}


/*	Update all references to objects in machine code. */

	/* Cogit>>#mapObjectReferencesInMachineCode: */
void
mapObjectReferencesInMachineCode(sqInt gcMode)
{
	
	switch (gcMode) {
	case GCModeNewSpace:
		mapObjectReferencesInMachineCodeForYoungGC();
		break;
	case GCModeFull:
		mapObjectReferencesInMachineCodeForFullGC();
		break;
	case GCModeBecome:
		mapObjectReferencesInMachineCodeForBecome();
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	if (!(asserta((freeStart()) <= (youngReferrers())))) {
		error("youngReferrers list overflowed");
	}
}


/*	Mark objects in machine-code of marked methods (or open PICs with marked
	selectors). 
 */

	/* Cogit>>#markAndTraceMachineCodeOfMarkedMethods */
void
markAndTraceMachineCodeOfMarkedMethods(void)
{
    sqInt annotation;
    sqInt annotation1;
    CogMethod *cogMethod;
    sqInt map;
    sqInt map1;
    sqInt mapByte;
    sqInt mapByte1;
    sqInt mcpc;
    sqInt mcpc1;
    sqInt result;
    sqInt result1;
    sqInt val;
    sqInt val1;

	val = 0;
	val1 = 0;
	if (leakCheckFullGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	codeModified = 0;
	markAndTraceObjectReferencesInGeneratedRuntime();
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMMethod)
		 && (isMarked((cogMethod->methodObject)))) {
			/* begin markAndTraceLiteralsIn: */
			assert(((((cogMethod->cmType)) == CMMethod)
			 && (isMarked((cogMethod->methodObject))))
			 || ((((cogMethod->cmType)) == CMOpenPIC)
			 && ((isImmediate((cogMethod->selector)))
			 || (isMarked((cogMethod->selector))))));
			markAndTraceLiteralinat((cogMethod->selector), cogMethod, (&((cogMethod->selector))));
			maybeMarkCountersIn(cogMethod);
			/* begin maybeMarkIRCsIn: */
			
#      if NewspeakVM
			markIfIRC(nextMethodOrIRCs(cogMethod));


#      endif /* NewspeakVM */

			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = markLiteralspcmethod(annotation, (((char *) mcpc)), (((sqInt)cogMethod)));
					if (result != 0) {
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
		l1:	/* end mapFor:performUntil:arg: */;
		}
		if ((((cogMethod->cmType)) == CMOpenPIC)
		 && ((isImmediate((cogMethod->selector)))
		 || (isMarked((cogMethod->selector))))) {
			/* begin markAndTraceLiteralsIn: */
			assert(((((cogMethod->cmType)) == CMMethod)
			 && (isMarked((cogMethod->methodObject))))
			 || ((((cogMethod->cmType)) == CMOpenPIC)
			 && ((isImmediate((cogMethod->selector)))
			 || (isMarked((cogMethod->selector))))));
			markAndTraceLiteralinat((cogMethod->selector), cogMethod, (&((cogMethod->selector))));
			maybeMarkCountersIn(cogMethod);
			/* begin maybeMarkIRCsIn: */
			
#      if NewspeakVM
			markIfIRC(nextMethodOrIRCs(cogMethod));


#      endif /* NewspeakVM */

			/* begin mapFor:performUntil:arg: */
			mcpc1 = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map1 = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte1 = byteAt(map1))) != MapEnd) {
				if (mapByte1 >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
					mcpc1 += (mapByte1 & DisplacementMask) * 4;
					if ((((annotation1 = ((usqInt) mapByte1) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte1 = byteAt(map1 - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation1 += mapByte1 & DisplacementMask;
						map1 -= 1;
					}
					result1 = markLiteralspcmethod(annotation1, (((char *) mcpc1)), (((sqInt)cogMethod)));
					if (result1 != 0) {
						goto l2;
					}
				}
				else {
					if (mapByte1 < (IsAnnotationExtension << AnnotationShift)) {
						mcpc1 += ((mapByte1 - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map1 -= 1;
			}
		l2:	/* end mapFor:performUntil:arg: */;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (leakCheckFullGC()) {
		assert(allMachineCodeObjectReferencesValid());
	}
	if (codeModified) {

		/* After updating oops in inline caches we need to flush the icache. */
		flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
	}
}


/*	Mark and trace any object references in the generated run-time. */

	/* Cogit>>#markAndTraceObjectReferencesInGeneratedRuntime */
static void
markAndTraceObjectReferencesInGeneratedRuntime(void)
{
    sqInt i;
    sqInt literal;
    usqInt mcpc;

	for (i = 0; i < runtimeObjectRefIndex; i += 1) {
		mcpc = objectReferencesInRuntime[i];
		literal = literalBeforeFollowingAddress(backEnd, mcpc);
		markAndTraceLiteralinatpc(literal, ((CogMethod *) null), ((usqInt)mcpc));
	}
}


/*	Mark and trace objects in the argument and free if it is appropriate.
	Answer if the method has been freed. firstVisit is a hint used to avoid
	scanning methods we've already seen. False positives are fine.
	For a CMMethod this
	frees if the bytecode method isnt marked,
	marks and traces object literals and selectors,
	unlinks sends to targets that should be freed.
	For a CMClosedPIC this
	frees if it refers to anything that should be freed or isn't marked.
	For a CMOpenPIC this
	frees if the selector isn't marked. */
/*	this recurses at most one level down */

	/* Cogit>>#markAndTraceOrFreeCogMethod:firstVisit: */
static sqInt NoDbgRegParms
markAndTraceOrFreeCogMethodfirstVisit(CogMethod *cogMethod, sqInt firstVisit)
{
    sqInt annotation;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;
    sqInt val;

	val = 0;
	if (((cogMethod->cmType)) == CMFree) {
		return 1;
	}
	assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
	if (((cogMethod->cmType)) == CMMethod) {
		if (!(isMarked((cogMethod->methodObject)))) {
			freeMethod(cogMethod);
			return 1;
		}
		if (firstVisit) {
			/* begin markLiteralsAndUnlinkUnmarkedSendsIn: */
			assert(((cogMethod->cmType)) == CMMethod);
			assert(isMarked((cogMethod->methodObject)));
			markAndTraceLiteralinat((cogMethod->selector), cogMethod, (&((cogMethod->selector))));
			maybeMarkCountersIn(cogMethod);
			/* begin maybeMarkIRCsIn: */
			
#      if NewspeakVM
			markIfIRC(nextMethodOrIRCs(cogMethod));


#      endif /* NewspeakVM */

			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = markLiteralsAndUnlinkIfUnmarkedSendpcmethod(annotation, (((char *) mcpc)), (((sqInt)cogMethod)));
					if (result != 0) {
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
		l1:	/* end mapFor:performUntil:arg: */;
		}
		return 0;
	}
	if (((cogMethod->cmType)) == CMClosedPIC) {
		if (!(closedPICRefersToUnmarkedObject(cogMethod))) {
			return 0;
		}
		freeMethod(cogMethod);
		return 1;
	}
	if (((cogMethod->cmType)) == CMOpenPIC) {
		if (isMarked((cogMethod->selector))) {
			return 0;
		}
		freeMethod(cogMethod);
		return 1;
	}
	assert((((cogMethod->cmType)) == CMMethod)
	 || ((((cogMethod->cmType)) == CMClosedPIC)
	 || (((cogMethod->cmType)) == CMOpenPIC)));
	return 0;
}


/*	If entryPoint is that of some method, then mark and trace objects in it
	and free if it is appropriate.
	Answer if the method has been freed. */

	/* Cogit>>#markAndTraceOrFreePICTarget:in: */
static sqInt NoDbgRegParms
markAndTraceOrFreePICTargetin(sqInt entryPoint, CogMethod *cPIC)
{
    CogMethod *targetMethod;

	assert((entryPoint > methodZoneBase)
	 && (entryPoint < (freeStart())));
	if (((((usqInt)cPIC)) <= (((usqInt)entryPoint)))
	 && (((((usqInt)cPIC)) + ((cPIC->blockSize))) >= (((usqInt)entryPoint)))) {
		return 0;
	}
	targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
	assert((((targetMethod->cmType)) == CMMethod)
	 || (((targetMethod->cmType)) == CMFree));
	return markAndTraceOrFreeCogMethodfirstVisit(targetMethod, (((usqInt)targetMethod)) > (((usqInt)cPIC)));
}


/*	Mark and trace literals. Unlink sends that have unmarked cache tags or
	targets. 
 */

	/* Cogit>>#markLiteralsAndUnlinkIfUnmarkedSend:pc:method: */
static sqInt NoDbgRegParms
markLiteralsAndUnlinkIfUnmarkedSendpcmethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt cacheTagMarked;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;
    CogMethod * targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;
    sqInt val;

	literal = 0;
	val = 0;
	if (annotation == IsObjectReference) {
		literal = literalBeforeFollowingAddress(backEnd, ((usqInt)mcpc));
		if (markAndTraceLiteralinatpc(literal, ((CogMethod *) cogMethod), ((usqInt)mcpc))) {
			codeModified = 1;
		}
	}
	if (annotation >= IsSendCall) {
		/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */
		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC)));
		cacheTagMarked = tagCouldBeObj1
		 && (cacheTagIsMarked(cacheTag1));
		if (entryPoint1 > methodZoneBase) {

			/* It's a linked send. */
			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint1 - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint1 - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if ((!cacheTagMarked)
			 || (markAndTraceOrFreeCogMethodfirstVisit(targetMethod1, (((usqInt)targetMethod1)) > (((usqInt)mcpc))))) {

				/* Either the cacheTag is unmarked (e.g. new class) or the target
				   has been freed (because it is unmarked), so unlink the send. */
				/* begin unlinkSendAt:targetMethod:sendTable: */
				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), inlineCacheValueForSelectorinat((targetMethod1->selector), enumeratingCogMethod, mcpc), unlinkedRoutine);
				codeModified = 1;
				markAndTraceLiteralinat((targetMethod1->selector), targetMethod1, (&((targetMethod1->selector))));
			}

		}
		else {

			/* cacheTag is selector */
			if (markAndTraceCacheTagLiteralinatpc(cacheTag1, ((CogMethod *) cogMethod), ((usqInt)mcpc))) {
				codeModified = 1;
			}
		}

	}
	return 0;
}


/*	Mark and trace literals.
	Additionally in Newspeak, void push implicits that have unmarked classes. */

	/* Cogit>>#markLiterals:pc:method: */
static sqInt NoDbgRegParms
markLiteralspcmethod(sqInt annotation, char *mcpc, sqInt cogMethod)
{
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt literal;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;

	literal = 0;
	if (annotation == IsObjectReference) {
		literal = literalBeforeFollowingAddress(backEnd, ((usqInt)mcpc));
		if (markAndTraceLiteralinatpc(literal, ((CogMethod *) cogMethod), ((usqInt)mcpc))) {
			codeModified = 1;
		}
	}
	if (annotation >= IsSendCall) {
		/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */
		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC)));
		if (tagCouldBeObj1) {
			if (markAndTraceCacheTagLiteralinatpc(cacheTag1, ((CogMethod *) cogMethod), ((usqInt)mcpc))) {

				/* cacheTag is selector */
				codeModified = 1;
			}
		}

	}
	return 0;
}

	/* Cogit>>#markMethodAndReferents: */
void
markMethodAndReferents(CogBlockMethod *aCogMethod)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	assert((((aCogMethod->cmType)) == CMMethod)
	 || (((aCogMethod->cmType)) == CMBlock));
	cogMethod = (((aCogMethod->cmType)) == CMMethod
		? ((CogMethod *) aCogMethod)
		: cmHomeMethod(aCogMethod));
	(cogMethod->cmUsageCount = CMMaxUsageCount);
	/* begin mapFor:performUntil:arg: */
	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {

			/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
			mcpc += (mapByte & DisplacementMask) * 4;
			if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
			 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
				annotation += mapByte & DisplacementMask;
				map -= 1;
			}
			result = incrementUsageOfTargetIfLinkedSendmcpcignored(annotation, (((char *) mcpc)), 0);
			if (result != 0) {
				goto l1;
			}
		}
		else {
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
l1:	/* end mapFor:performUntil:arg: */;
}

	/* Cogit>>#maxCogMethodAddress */
usqInt
maxCogMethodAddress(void)
{
	return ((usqInt)(limitZony()));
}


/*	If this is the Newspeak VM and the objectRepresentation supports pinning
	then allocate space for the implicit receiver caches on the heap. */

	/* Cogit>>#maybeAllocAndInitIRCs */
static sqInt
maybeAllocAndInitIRCs(void)
{
	
#  if NewspeakVM
	indexOfIRC = (theIRCs = 0);
	if (numIRCs > 0) {
		assert((noAssertMethodClassAssociationOf(methodObj)) != (nilObject()));
		theIRCs = allocateNPinnedSlots(numIRCs * NumOopsPerNSC);
		return theIRCs != 0;
	}
	return 1;

#  else /* NewspeakVM */
	return 1;

#  endif /* NewspeakVM */

}


/*	Check that the header fields are consistent with the type.
	Answer 0 if it is ok, otherwise answer a code for the error. */

	/* Cogit>>#maybeFreeCogMethodDoesntLookKosher: */
static sqInt NoDbgRegParms
maybeFreeCogMethodDoesntLookKosher(CogMethod *cogMethod)
{
    sqInt result;

	result = cogMethodDoesntLookKosher(cogMethod);
	return (result == 2
		? 0
		: result);
}


/*	In SIsta Spur counters are held on the heap in pinned objects which must
	be marked
	to avoid them being garbage collected. This is the hook through which that
	happens. 
 */

	/* Cogit>>#maybeMarkCountersIn: */
static void NoDbgRegParms
maybeMarkCountersIn(CogMethod *cogMethod)
{
}

	/* Cogit>>#mclassIsSmallInteger */
static sqInt
mclassIsSmallInteger(void)
{
	return (methodClassOf(methodObj)) == (classSmallInteger());
}


/*	Answer the absolute machine code pc matching the zero-relative
	bytecode pc of a backward branch in cogMethod, given the start
	of the bytecodes for cogMethod's block or method object. */

	/* Cogit>>#mcPCForBackwardBranch:startBcpc:in: */
usqInt
mcPCForBackwardBranchstartBcpcin(sqInt bcpc, sqInt startbcpc, CogBlockMethod *cogMethod)
{
    sqInt aMethodHeader;
    sqInt aMethodHeader1;
    sqInt aMethodObj;
    sqInt annotation;
    sqInt bcpc1;
    sqInt bsOffset;
    sqInt byte;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt endbcpc;
    CogMethod *homeMethod;
    sqInt isBackwardBranch;
    sqInt isInBlock;
    sqInt latestContinuation;
    sqInt map;
    sqInt mapByte;
    usqInt mcpc;
    sqInt nExts;
    sqInt nextBcpc;
    sqInt result;
    sqInt targetPC;

	latestContinuation = 0;
	/* begin mapFor:bcpc:performUntil:arg: */
	assert(((cogMethod->stackCheckOffset)) > 0);

	/* The stack check maps to the start of the first bytecode,
	   the first bytecode being effectively after frame build. */
	mcpc = (((usqInt)cogMethod)) + ((cogMethod->stackCheckOffset));
	result = 0;
	if (result != 0) {
		return result;
	}

	/* In both CMMethod and CMBlock cases find the start of the map and
	   skip forward to the bytecode pc map entry for the stack check. */
	bcpc1 = startbcpc;
	if (((cogMethod->cmType)) == CMMethod) {
		isInBlock = 0;
		homeMethod = ((CogMethod *) cogMethod);
		assert(startbcpc == (startPCOfMethodHeader((homeMethod->methodHeader))));
		map = ((((usqInt)homeMethod)) + ((homeMethod->blockSize))) - 1;
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == IsAbsPCReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsObjectReference)
		 || (((((usqInt) (byteAt(map))) >> AnnotationShift) == IsRelativeCall)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N))));
		latestContinuation = startbcpc;
		aMethodObj = (homeMethod->methodObject);
		endbcpc = (numBytesOf(aMethodObj)) - 1;
		/* begin bytecodeSetOffsetForHeader: */
		aMethodHeader = (homeMethod->methodHeader);
		bsOffset = 
#    if MULTIPLEBYTECODESETS
			(headerIndicatesAlternateBytecodeSet(aMethodHeader)
						? 256
						: 0)
#    else /* MULTIPLEBYTECODESETS */
			0
#    endif /* MULTIPLEBYTECODESETS */
			;
		bcpc1 += deltaToSkipPrimAndErrorStoreInheader(aMethodObj, (homeMethod->methodHeader));
	}
	else {
		isInBlock = 1;
		assert(bcpc1 == ((cogMethod->startpc)));
		homeMethod = cmHomeMethod(cogMethod);
		map = findMapLocationForMcpcinMethod((((usqInt)cogMethod)) + (sizeof(CogBlockMethod)), homeMethod);
		assert(map != 0);
		assert(((((usqInt) (byteAt(map))) >> AnnotationShift) == HasBytecodePC)
		 || ((((usqInt) (byteAt(map))) >> AnnotationShift) == IsDisplacementX2N));
		while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
			map -= 1;
		}

		/* skip fiducial; i.e. the map entry for the pc immediately following the method header. */
		map -= 1;
		aMethodObj = (homeMethod->methodObject);
		bcpc1 = startbcpc - (blockCreationBytecodeSizeForHeader((homeMethod->methodHeader)));
		/* begin bytecodeSetOffsetForHeader: */
		aMethodHeader1 = (homeMethod->methodHeader);
		bsOffset = 
#    if MULTIPLEBYTECODESETS
			(headerIndicatesAlternateBytecodeSet(aMethodHeader1)
						? 256
						: 0)
#    else /* MULTIPLEBYTECODESETS */
			0
#    endif /* MULTIPLEBYTECODESETS */
			;
		byte = (fetchByteofObject(bcpc1, aMethodObj)) + bsOffset;
		descriptor = generatorAt(byte);
		endbcpc = (bcpc1 + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc1, -1, aMethodObj)
	: 0));
		bcpc1 = startbcpc;
	}

	/* Now skip up through the bytecode pc map entry for the stack check. */
	nExts = 0;
	while ((((usqInt) (byteAt(map))) >> AnnotationShift) != HasBytecodePC) {
		map -= 1;
	}
	map -= 1;
	while (((mapByte = byteAt(map))) != MapEnd) {

		/* defensive; we exit on bcpc */
		if (mapByte >= FirstAnnotation) {
			annotation = ((usqInt) mapByte) >> AnnotationShift;
			mcpc += (mapByte & DisplacementMask) * 4;
			if ((annotation >= IsSendCall)
			 || ((annotation == HasBytecodePC)
			 || (0))) {
				while (1) {
					byte = (fetchByteofObject(bcpc1, aMethodObj)) + bsOffset;
					descriptor = generatorAt(byte);
					if (isInBlock) {
						if (bcpc1 >= endbcpc) {
							return 0;
						}
					}
					else {
						if (((descriptor->isReturn))
						 && (bcpc1 >= latestContinuation)) {
							return 0;
						}
						if ((isBranch(descriptor))
						 || ((descriptor->isBlockCreation))) {
							/* begin latestContinuationPCFor:at:exts:in: */
							distance = ((descriptor->spanFunction))(descriptor, bcpc1, nExts, aMethodObj);
							targetPC = (bcpc1 + ((descriptor->numBytes))) + (((distance < 0) ? 0 : distance));
							latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
						}
					}
					nextBcpc = (bcpc1 + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bcpc1, nExts, aMethodObj)
	: 0));
					if (((descriptor->isMapped))
					 || (isInBlock
					 && ((descriptor->isMappedInBlock)))) break;
					bcpc1 = nextBcpc;
					nExts = ((descriptor->isExtension)
						? nExts + 1
						: 0);
				}
				isBackwardBranch = (isBranch(descriptor))
				 && (isBackwardBranchatextsin(descriptor, bcpc1, nExts, aMethodObj));
				result = (isBackwardBranch
				 && ((((sqInt)(((void *)bcpc)))) == bcpc1)
					? ((sqInt)(((char *) mcpc)))
					: 0);
				if (result != 0) {
					return result;
				}
				bcpc1 = nextBcpc;
				nExts = ((descriptor->isExtension)
					? nExts + 1
					: 0);
			}
		}
		else {
			assert(((((usqInt) mapByte) >> AnnotationShift) == IsDisplacementX2N)
			 || ((((usqInt) mapByte) >> AnnotationShift) == IsAnnotationExtension));
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
	return 0;
}


/*	For the purposes of become: see if the two methods are similar, i.e. can
	be safely becommed.
	This is pretty strict. All literals and bytecodes must be identical. Only
	trailer bytes and header
	flags can differ. */

	/* Cogit>>#method:hasSameCodeAs:checkPenultimate: */
static sqInt NoDbgRegParms
methodhasSameCodeAscheckPenultimate(sqInt methodA, sqInt methodB, sqInt comparePenultimateLiteral)
{
    sqInt bi;
    sqInt endPCA;
    sqInt headerA;
    sqInt headerB;
    sqInt li;
    sqInt numLitsA;

	headerA = methodHeaderOf(methodA);
	headerB = methodHeaderOf(methodB);
	numLitsA = literalCountOfMethodHeader(headerA);
	endPCA = endPCOf(methodA);
	if (((argumentCountOfMethodHeader(headerA)) != (argumentCountOfMethodHeader(headerB)))
	 || (((temporaryCountOfMethodHeader(headerA)) != (temporaryCountOfMethodHeader(headerB)))
	 || (((primitiveIndexOfMethodheader(methodA, headerA)) != (primitiveIndexOfMethodheader(methodB, headerB)))
	 || ((numLitsA != (literalCountOfMethodHeader(headerB)))
	 || (endPCA > (numBytesOf(methodB))))))) {
		return 0;
	}
	for (li = 1; li < numLitsA; li += 1) {
		if ((fetchPointerofObject(li, methodA)) != (fetchPointerofObject(li, methodB))) {
			if ((li < (numLitsA - 1))
			 || (comparePenultimateLiteral)) {
				return 0;
			}
		}
	}
	for (bi = (startPCOfMethod(methodA)); bi <= endPCA; bi += 1) {
		if ((fetchByteofObject(bi, methodA)) != (fetchByteofObject(bi, methodB))) {
			return 0;
		}
	}
	return 1;
}

	/* Cogit>>#minCogMethodAddress */
sqInt
minCogMethodAddress(void)
{
	return methodZoneBase;
}

	/* Cogit>>#mnuOffset */
sqInt
mnuOffset(void)
{
	return missOffset;
}

	/* Cogit>>#NegateR: */
static AbstractInstruction * NoDbgRegParms
gNegateR(sqInt reg)
{
	return genoperand(NegateR, reg);
}

	/* Cogit>>#needsFrameIfImmutability: */
static sqInt NoDbgRegParms
needsFrameIfImmutability(sqInt stackDelta)
{
	return IMMUTABILITY;
}

	/* Cogit>>#needsFrameIfInBlock: */
static sqInt NoDbgRegParms
needsFrameIfInBlock(sqInt stackDelta)
{
	return inBlock;
}

	/* Cogit>>#needsFrameNever: */
static sqInt NoDbgRegParms
needsFrameNever(sqInt stackDelta)
{
	return 0;
}

	/* Cogit>>#noAssertMethodClassAssociationOf: */
static sqInt NoDbgRegParms
noAssertMethodClassAssociationOf(sqInt methodPointer)
{
	return literalofMethod((literalCountOfMethodHeader(noAssertHeaderOf(methodPointer))) - 1, methodPointer);
}


/*	Check that no method is maximally marked. A maximal mark is an indication
	the method has been scanned to increase the usage count of its referent
	methods.  */

	/* Cogit>>#noCogMethodsMaximallyMarked */
static sqInt
noCogMethodsMaximallyMarked(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (((cogMethod->cmUsageCount)) == CMMaxUsageCount)) {
			return 0;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return 1;
}


/*	Answer if all targets in the PIC are in-use methods. */

	/* Cogit>>#noTargetsFreeInClosedPIC: */
static sqInt NoDbgRegParms
noTargetsFreeInClosedPIC(sqInt cPIC)
{
	return !(cPICHasFreedTargets(cPIC));
}


/*	Store the generated machine code, answering the last address */

	/* Cogit>>#outputInstructionsAt: */
static sqInt NoDbgRegParms
outputInstructionsAt(sqInt startAddress)
{
    sqInt absoluteAddress;
    AbstractInstruction *abstractInstruction;
    sqInt i;
    sqInt j;

	absoluteAddress = startAddress;
	for (i = 0; i < opcodeIndex; i += 1) {
		abstractInstruction = abstractInstructionAt(i);
		assert(((abstractInstruction->address)) == absoluteAddress);
		/* begin outputMachineCodeAt: */
		for (j = 0; j < ((abstractInstruction->machineCodeSize)); j += 4) {
			longAtput(absoluteAddress + j, ((abstractInstruction->machineCode))[j / 4]);
		}
		absoluteAddress += (abstractInstruction->machineCodeSize);
	}
	return absoluteAddress;
}


/*	Output instructions generated for one of the generated run-time routines,
	a trampoline, etc
 */

	/* Cogit>>#outputInstructionsForGeneratedRuntimeAt: */
static sqInt NoDbgRegParms
outputInstructionsForGeneratedRuntimeAt(sqInt startAddress)
{
    sqInt endAddress;
    sqInt size;

	computeMaximumSizes();
	(methodLabel->address = startAddress);
	size = generateInstructionsAt(startAddress);
	endAddress = outputInstructionsAt(startAddress);
	assert((startAddress + size) == endAddress);
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	stopsFromto(backEnd, endAddress, methodZoneBase - 1);
	return startAddress;
}

	/* Cogit>>#PopR: */
static AbstractInstruction * NoDbgRegParms
gPopR(sqInt reg)
{
	return genoperand(PopR, reg);
}

	/* Cogit>>#PushCw: */
static AbstractInstruction * NoDbgRegParms
gPushCw(sqInt wordConstant)
{
    AbstractInstruction *anInstruction;

	/* begin gen:literal: */
	anInstruction = genoperand(PushCw, wordConstant);
	return anInstruction;
}


/*	Code entry closed PIC full or miss to an instance of a young class or to a
	young target method.
	Attempt to patch the send site to an open PIC. Answer if the attempt
	succeeded; in fact it will
	only return if the attempt failed.
	The stack looks like:
	receiver
	args
	sp=>	sender return address */

	/* Cogit>>#patchToOpenPICFor:numArgs:receiver: */
sqInt
patchToOpenPICFornumArgsreceiver(sqInt selector, sqInt numArgs, sqInt receiver)
{
    sqInt extent;
    CogMethod *oPIC;
    sqInt outerReturn;


	/* See if an Open PIC is already available. */
	outerReturn = stackTop();
	oPIC = openPICWithSelector(selector);
	if (!(oPIC)) {

		/* otherwise attempt to create an Open PIC. */
		oPIC = cogOpenPICSelectornumArgs(selector, numArgs);
		if ((((((sqInt)oPIC)) >= MaxNegativeErrorCode) && ((((sqInt)oPIC)) <= -1))) {

			/* For some reason the PIC couldn't be generated, most likely a lack of code memory. */
			if ((((sqInt)oPIC)) == InsufficientCodeSpace) {
				callForCogCompiledCodeCompaction();
			}
			return 0;
		}
	}
	extent = rewriteInlineCacheAttagtarget(backEnd, outerReturn, inlineCacheValueForSelectorinat(selector, mframeHomeMethodExport(), outerReturn), (((sqInt)oPIC)) + cmEntryOffset);
	flushICacheFromto(processor, (((usqInt)outerReturn)) - extent, ((usqInt)outerReturn));
	flushICacheFromto(processor, ((usqInt)oPIC), (((usqInt)oPIC)) + openPICSize);
	executeCogMethodfromLinkedSendWithReceiver(oPIC, receiver);
	return 1;
}


/*	This value is used to decide between MNU processing
	or interpretation in the closed PIC aborts. */

	/* Cogit>>#picAbortDiscriminatorValue */
static sqInt
picAbortDiscriminatorValue(void)
{
	return 0;
}


/*	Answer the start of the abort sequence for invoking the interpreter in a
	closed PIC.
 */

	/* Cogit>>#picInterpretAbortOffset */
static sqInt
picInterpretAbortOffset(void)
{
	return (interpretOffset()) - ((pushLinkRegisterByteSize(backEnd)) + (callInstructionByteSize(backEnd)));
}

	/* Cogit>>#previousInstruction */
static AbstractInstruction *
previousInstruction(void)
{
	assert(opcodeIndex > 0);
	return abstractInstructionAt(opcodeIndex - 1);
}

	/* Cogit>>#printCogMethodFor: */
void
printCogMethodFor(void *address)
{
    CogMethod *cogMethod;

	cogMethod = methodFor(address);
	if (cogMethod == 0) {
		print("not a method");
		cr();
	}
	else {
		printCogMethod(cogMethod);
	}
}

	/* Cogit>>#printTrampolineTable */
void
printTrampolineTable(void)
{
    sqInt i;

	for (i = 0; i < trampolineTableIndex; i += 2) {
		printHex(((sqInt)(trampolineAddresses[i + 1])));
		print(": ");
		print(((char *) (trampolineAddresses[i])));
		cr();
	}
}

	/* Cogit>>#processorHasDivQuoRemAndMClassIsSmallInteger */
static sqInt
processorHasDivQuoRemAndMClassIsSmallInteger(void)
{
	return mclassIsSmallInteger();
}

	/* Cogit>>#processorHasMultiplyAndMClassIsSmallInteger */
static sqInt
processorHasMultiplyAndMClassIsSmallInteger(void)
{
	return mclassIsSmallInteger();
}

	/* Cogit>>#recordGeneratedRunTime:address: */
static void NoDbgRegParms
recordGeneratedRunTimeaddress(char *aString, sqInt address)
{
	trampolineAddresses[trampolineTableIndex] = aString;
	trampolineAddresses[trampolineTableIndex + 1] = (((char *) address));
	trampolineTableIndex += 2;
}


/*	This one for C support code. */

	/* Cogit>>#recordPrimTraceFunc */
sqInt
recordPrimTraceFunc(void)
{
	return recordPrimTrace();
}

	/* Cogit>>#recordRunTimeObjectReferences */
static void
recordRunTimeObjectReferences(void)
{
    sqInt i;
    AbstractInstruction *instruction;

	for (i = 0; i < opcodeIndex; i += 1) {
		instruction = abstractInstructionAt(i);
		if (((instruction->annotation)) == IsObjectReference) {
			assert(runtimeObjectRefIndex < NumObjRefsInRuntime);
			assert(!hasYoungReferent);
			if (hasYoungReferent) {
				error("attempt to generate run-time routine containing young object reference.  Cannot initialize Cogit run-time.");
			}
			objectReferencesInRuntime[runtimeObjectRefIndex] = (((usqInt)(((instruction->address)) + ((instruction->machineCodeSize)))));
			runtimeObjectRefIndex += 1;
		}
	}
}

	/* Cogit>>#registerMaskFor: */
static sqInt NoDbgRegParms
registerMaskFor(sqInt reg)
{
	return 1 << reg;
}

	/* Cogit>>#registerMaskFor:and: */
static sqInt NoDbgRegParms
registerMaskForand(sqInt reg1, sqInt reg2)
{
	return (1 << reg1) | (1 << reg2);
}

	/* Cogit>>#registerMaskFor:and:and:and:and:and:and:and:and:and: */
static sqInt NoDbgRegParms
registerMaskForandandandandandandandandand(sqInt reg1, sqInt reg2, sqInt reg3, sqInt reg4, sqInt reg5, sqInt reg6, sqInt reg7, sqInt reg8, sqInt reg9, sqInt reg10)
{
	return (((((((((1 << reg1) | (1 << reg2)) | (1 << reg3)) | (1 << reg4)) | (1 << reg5)) | (1 << reg6)) | (1 << reg7)) | (1 << reg8)) | (1 << reg9)) | (1 << reg10);
}

	/* Cogit>>#relocateCallsAndSelfReferencesInMethod: */
static void NoDbgRegParms
relocateCallsAndSelfReferencesInMethod(CogMethod *cogMethod)
{
    sqInt annotation;
    sqLong callDelta;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqLong refDelta;
    sqInt result;

	refDelta = (cogMethod->objectHeader);
	callDelta = 0;
	assert((((cogMethod->cmType)) == CMMethod)
	 || (((cogMethod->cmType)) == CMOpenPIC));
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)cogMethod)) + missOffset)) == ((((cogMethod->cmType)) == CMMethod
		? methodAbortTrampolineFor((cogMethod->cmNumArgs))
		: picAbortTrampolineFor((cogMethod->cmNumArgs)))));
	relocateCallBeforeReturnPCby(backEnd, (((sqInt)cogMethod)) + missOffset, -callDelta);
	/* begin mapFor:performUntil:arg: */
	mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
	map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
	while (((mapByte = byteAt(map))) != MapEnd) {
		if (mapByte >= FirstAnnotation) {

			/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
			mcpc += (mapByte & DisplacementMask) * 4;
			if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
			 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
				annotation += mapByte & DisplacementMask;
				map -= 1;
			}
			result = relocateIfCallOrMethodReferencemcpcdelta(annotation, (((char *) mcpc)), refDelta);
			if (result != 0) {
				goto l1;
			}
		}
		else {
			if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
				mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
			}
		}
		map -= 1;
	}
l1:	/* end mapFor:performUntil:arg: */;
}

	/* Cogit>>#relocateCallsInClosedPIC: */
static void NoDbgRegParms
relocateCallsInClosedPIC(CogMethod *cPIC)
{
    sqLong callDelta;
    usqInt entryPoint;
    sqInt i;
    sqInt pc;
    sqLong refDelta;
    CogMethod *targetMethod;

	refDelta = (cPIC->objectHeader);
	callDelta = 0;
	assert((callTargetFromReturnAddress(backEnd, (((sqInt)cPIC)) + missOffset)) == (picAbortTrampolineFor((cPIC->cmNumArgs))));
	relocateCallBeforeReturnPCby(backEnd, (((sqInt)cPIC)) + missOffset, -callDelta);
	pc = (((sqInt)cPIC)) + firstCPICCaseOffset;
	for (i = 1; i <= ((cPIC->cPICNumCases)); i += 1) {
		pc = addressOfEndOfCaseinCPIC(i, cPIC);
		entryPoint = (i == 1
			? jumpLongTargetBeforeFollowingAddress(backEnd, pc)
			: jumpLongConditionalTargetBeforeFollowingAddress(backEnd, pc));
		if (((((usqInt)cPIC)) <= (((usqInt)entryPoint)))
		 && (((((usqInt)cPIC)) + ((cPIC->blockSize))) >= (((usqInt)entryPoint)))) {

			/* Interpret/MNU */
			if (i == 1) {
				relocateJumpLongBeforeFollowingAddressby(backEnd, pc, refDelta);
			}
			else {
				relocateJumpLongConditionalBeforeFollowingAddressby(backEnd, pc, refDelta);
			}

		}
		else {
			targetMethod = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
			assert(((targetMethod->cmType)) == CMMethod);
			if (i == 1) {
				relocateJumpLongBeforeFollowingAddressby(backEnd, pc, -(callDelta - ((targetMethod->objectHeader))));
			}
			else {
				relocateJumpLongConditionalBeforeFollowingAddressby(backEnd, pc, -(callDelta - ((targetMethod->objectHeader))));
			}
		}
	}
	assert(((cPIC->cPICNumCases)) > 0);
	relocateMethodReferenceBeforeAddressby(backEnd, (addressOfEndOfCaseinCPIC(2, cPIC)) + (loadLiteralByteSize(backEnd)), refDelta);
	relocateJumpLongBeforeFollowingAddressby(backEnd, (((sqInt)cPIC)) + cPICEndOfCodeOffset, -callDelta);
}

	/* Cogit>>#relocateIfCallOrMethodReference:mcpc:delta: */
static sqInt NoDbgRegParms
relocateIfCallOrMethodReferencemcpcdelta(sqInt annotation, char *mcpc, sqInt refDelta)
{
    sqInt callDelta;
    sqInt entryPoint;
    sqInt offset;
    sqInt offset1;
    sqInt sendTable;
    sqInt *sendTable1;
    CogMethod *targetMethod;
    sqInt unlinkedRoutine;

	callDelta = 0;
	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint <= methodZoneBase) {

			/* send is not linked; just relocate */
			relocateCallBeforeReturnPCby(backEnd, ((sqInt)mcpc), -callDelta);
			return 0;
		}
		/* begin offsetAndSendTableFor:annotation:into: */
		if (annotation == IsSendCall) {
			offset1 = cmEntryOffset;
			sendTable1 = ordinarySendTrampolines;
		}
		else {
			assert(annotation == IsSuperSend);
			offset1 = cmNoCheckEntryOffset;
			sendTable1 = superSendTrampolines;



		}
		targetMethod = ((CogMethod *) (entryPoint - offset1));
		if (((targetMethod->cmType)) != CMFree) {

			/* send target not freed; just relocate. */
			relocateCallBeforeReturnPCby(backEnd, ((sqInt)mcpc), -(callDelta - ((targetMethod->objectHeader))));
			return 0;
		}
		unlinkedRoutine = sendTable1[((((targetMethod->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod->cmNumArgs)) : (NumSendTrampolines - 1))];
		unlinkedRoutine -= callDelta;
		rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), inlineCacheValueForSelectorinat((targetMethod->selector), enumeratingCogMethod, mcpc), unlinkedRoutine);
		return 0;

	}
	if (annotation == IsRelativeCall) {
		relocateCallBeforeReturnPCby(backEnd, ((sqInt)mcpc), -callDelta);
		return 0;
	}
	if (annotation == IsAbsPCReference) {
		relocateMethodReferenceBeforeAddressby(backEnd, ((sqInt)mcpc), refDelta);
	}
	return 0;
}

	/* Cogit>>#remapIfObjectRef:pc:hasYoung: */
static sqInt NoDbgRegParms
remapIfObjectRefpchasYoung(sqInt annotation, char *mcpc, sqInt hasYoungPtr)
{
    sqInt cacheTag;
    sqInt cacheTag1;
    sqInt entryPoint;
    sqInt entryPoint1;
    sqInt ignored;
    sqInt literal;
    sqInt mappedCacheTag;
    sqInt mappedLiteral;
    sqInt *sendTable;
    sqInt tagCouldBeObj;
    sqInt tagCouldBeObj1;
    CogMethod *targetMethod;
    CogMethod *targetMethod1;

	if (annotation == IsObjectReference) {
		literal = literalBeforeFollowingAddress(backEnd, ((usqInt)mcpc));
		if (couldBeObject(literal)) {
			mappedLiteral = remapObject(literal);
			if (literal != mappedLiteral) {
				storeLiteralbeforeFollowingAddress(backEnd, mappedLiteral, ((usqInt)mcpc));
				codeModified = 1;
			}
			if ((hasYoungPtr != 0)
			 && (isYoung(mappedLiteral))) {
				(((sqInt *) hasYoungPtr))[0] = 1;
			}
		}
	}
	if (annotation >= IsSendCall) {
		/* begin offsetCacheTagAndCouldBeObjectAt:annotation:into: */
		cacheTag1 = inlineCacheTagAt(backEnd, ((sqInt)mcpc));

		/* in-line cache tags are the selectors of sends if sends are unlinked,
		   the selectors of super sends (entry offset = cmNoCheckEntryOffset),
		   the selectors of open PIC sends (entry offset = cmEntryOffset, target is an Open PIC)
		   or in-line cache tags (classes, class indices, immediate bit patterns, etc).
		   Note that selectors can be immediate so there is no guarantee that they
		   are markable/remappable objects. */
		entryPoint1 = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		tagCouldBeObj1 = (entryPoint1 < methodZoneBase)
		 || (((entryPoint1 & entryPointMask) == uncheckedEntryAlignment)
		 || (((entryPoint1 & entryPointMask) == checkedEntryAlignment)
		 && ((((((CogMethod *) (entryPoint1 - cmEntryOffset)))->cmType)) == CMOpenPIC)));
		if (tagCouldBeObj1
		 && (couldBeObject(cacheTag1))) {
			mappedCacheTag = remapObject(cacheTag1);
			if (cacheTag1 != mappedCacheTag) {
				rewriteInlineCacheTagat(backEnd, mappedCacheTag, ((usqInt)mcpc));
				codeModified = 1;
			}
			if ((hasYoungPtr != 0)
			 && (isYoung(mappedCacheTag))) {
				(((sqInt *) hasYoungPtr))[0] = 1;
			}
		}
		if (hasYoungPtr != 0) {

			/* Since the unlinking routines may rewrite the cacheTag to the send's selector, and
			   since they don't have the cogMethod to hand and can't add it to youngReferrers,
			   the method must remain in youngReferrers if the targetMethod's selector is young. */
			if (entryPoint1 > methodZoneBase) {

				/* It's a linked send. */
				/* begin targetMethodAndSendTableFor:annotation:into: */
				if (annotation == IsSendCall) {
					targetMethod1 = ((CogMethod *) (entryPoint1 - cmEntryOffset));
					sendTable = ordinarySendTrampolines;
				}
				else {
					assert(annotation == IsSuperSend);
					targetMethod1 = ((CogMethod *) (entryPoint1 - cmNoCheckEntryOffset));
					sendTable = superSendTrampolines;



				}
				if (isYoung((targetMethod1->selector))) {
					(((sqInt *) hasYoungPtr))[0] = 1;
				}

			}
		}

	}
	return 0;
}


/*	Remap a potential object reference from a closed PIC.
	This may be an object reference, an inline cache tag or null.
	Answer if the updated literal is young.
	mcpc is the address of the next instruction following either
	the load of the method literal or the compare of the class tag. */

	/* Cogit>>#remapMaybeObjRefInClosedPICAt: */
static sqInt NoDbgRegParms
remapMaybeObjRefInClosedPICAt(sqInt mcpc)
{
    sqInt object;
    sqInt subject;

	object = literalBeforeFollowingAddress(backEnd, mcpc);
	if (!(couldBeObject(object))) {
		return 0;
	}
	subject = remapOop(object);
	if (object != subject) {
		storeLiteralbeforeFollowingAddress(backEnd, subject, mcpc);
		codeModified = 1;
	}
	return isYoungObject(subject);
}


/*	Rewrite the three values involved in a CPIC case. Used by the initialize &
	extend CPICs.
	c.f. expectedClosedPICPrototype: */
/*	write the obj ref/operand via the second ldr */

	/* Cogit>>#rewriteCPICCaseAt:tag:objRef:target: */
static void NoDbgRegParms
rewriteCPICCaseAttagobjReftarget(sqInt followingAddress, sqInt newTag, sqInt newObjRef, sqInt newTarget)
{
    sqInt classTagPC;
    sqInt methodObjPC;

	methodObjPC = (followingAddress - (jumpLongConditionalByteSize(backEnd))) - (cmpC32RTempByteSize(backEnd));
	storeLiteralbeforeFollowingAddress(backEnd, newObjRef, methodObjPC);

	/* rewite the tag via the first ldr */
	classTagPC = followingAddress - (jumpLongConditionalByteSize(backEnd));
	/* begin storeLiteral32:beforeFollowingAddress: */
	storeLiteralbeforeFollowingAddress(((AbstractInstruction *) backEnd), newTag, classTagPC);

	((AbstractInstruction *) backEnd);
	rewriteConditionalJumpLongAttarget(backEnd, followingAddress, newTarget);
}

	/* Cogit>>#SubCq:R: */
static AbstractInstruction * NoDbgRegParms
gSubCqR(sqInt quickConstant, sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(SubCqR, quickConstant, reg);
	return anInstruction;
}

	/* Cogit>>#SubCw:R: */
static AbstractInstruction * NoDbgRegParms
gSubCwR(sqInt wordConstant, sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(SubCwR, wordConstant, reg);
	return anInstruction;
}


/*	Answer the number of clean blocks found in the literal frame */

	/* Cogit>>#scanForCleanBlocks */
static sqInt
scanForCleanBlocks(void)
{
    sqInt i;
    sqInt iLimiT;
    sqInt lit;
    sqInt numCleanBlocks;
    sqInt startPCOrNil;

	numCleanBlocks = 0;
	for (i = 1, iLimiT = (literalCountOf(methodObj)); i <= iLimiT; i += 1) {
		lit = fetchPointerofObject(i, methodObj);
		startPCOrNil = startPCOrNilOfLiteralin(lit, methodObj);
		if (!(startPCOrNil == null)) {
			numCleanBlocks += 1;
		}
	}
	return numCleanBlocks;
}

	/* Cogit>>#setBreakMethod: */
void
setBreakMethod(sqInt anObj)
{
	breakMethod = anObj;
}

	/* Cogit>>#setPostCompileHook: */
void
setPostCompileHook(void (*aFunction)(CogMethod *))
{
	postCompileHook = aFunction;
}


/*	If a method is compiled to machine code via a block entry it won't have a
	selector. A subsequent send can find the method and hence fill in the
	selector. 
 */
/*	self disassembleMethod: cogMethod */

	/* Cogit>>#setSelectorOf:to: */
void
setSelectorOfto(CogMethod *cogMethod, sqInt aSelectorOop)
{
	compilationBreakpointisMNUCase(aSelectorOop, numBytesOf(aSelectorOop), 0);
	assert(((cogMethod->cmType)) == CMMethod);
	(cogMethod->selector = aSelectorOop);
	if (isYoung(aSelectorOop)) {
		ensureInYoungReferrers(cogMethod);
	}
}

	/* Cogit>>#spanForCleanBlockStartingAt: */
static sqInt NoDbgRegParms
spanForCleanBlockStartingAt(sqInt startPC)
{
    BytecodeDescriptor *descriptor;
    sqInt end;
    sqInt pc;

	pc = startPC;
	end = numBytesOf(methodObj);
	while (pc <= end) {
		descriptor = generatorAt((fetchByteofObject(pc, methodObj)) + bytecodeSetOffset);
		pc += (descriptor->numBytes);
		if ((descriptor->isReturn)) {
			return pc - startPC;
		}
	}
	error("couldn't locate end of clean block");
	return 0;
}

	/* Cogit>>#traceLinkedSendOffset */
sqInt
traceLinkedSendOffset(void)
{
	return (cmNoCheckEntryOffset + (callInstructionByteSize(backEnd))) + (pushLinkRegisterByteSize(backEnd));
}


/*	Encode true and false and 0 to N such that they can't be confused for
	register numbers (including NoReg)
	and can be tested for by isTrampolineArgConstant: and decoded by
	trampolineArgValue: 
 */

	/* Cogit>>#trampolineArgConstant: */
static sqInt NoDbgRegParms
trampolineArgConstant(sqInt booleanOrInteger)
{
	assert(booleanOrInteger >= 0);
	return -2 - booleanOrInteger;
}

	/* Cogit>>#trampolineName:numArgs: */
static char * NoDbgRegParms
trampolineNamenumArgs(char *routinePrefix, sqInt numArgs)
{
    char *theString;

	/* begin trampolineName:numArgs:limit: */
	theString = malloc((strlen(routinePrefix)) + 6);
	sprintf(theString, "%s%cArgs", routinePrefix, (numArgs <= (NumSendTrampolines - 2)
		? '0' + numArgs
		: 'N'));
	return theString;
}

	/* Cogit>>#trampolineName:numRegArgs: */
static char * NoDbgRegParms
trampolineNamenumRegArgs(char *routinePrefix, sqInt numArgs)
{
    char *theString;

	/* begin trampolineName:numArgs:limit: */
	theString = malloc((strlen(routinePrefix)) + 6);
	sprintf(theString, "%s%cArgs", routinePrefix, (numArgs <= 2
		? '0' + numArgs
		: 'N'));
	return theString;
}

	/* Cogit>>#unknownBytecode */
static sqInt
unknownBytecode(void)
{
	return EncounteredUnknownBytecode;
}


/*	Unlink all sends in cog methods. */

	/* Cogit>>#unlinkAllSends */
void
unlinkAllSends(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	if (!(methodZoneBase)) {
		return;
	}
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfLinkedSendpcignored(annotation, (((char *) mcpc)), 0);
					if (result != 0) {
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
			if (((cogMethod->cmType)) != CMFree) {
				freeMethod(cogMethod);
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
}

	/* Cogit>>#unlinkIfFreeOrLinkedSend:pc:of: */
static sqInt NoDbgRegParms
unlinkIfFreeOrLinkedSendpcof(sqInt annotation, char *mcpc, sqInt theSelector)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    CogMethod * targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */
			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if ((((targetMethod1->cmType)) == CMFree)
			 || (((targetMethod1->selector)) == theSelector)) {
				/* begin unlinkSendAt:targetMethod:sendTable: */
				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), inlineCacheValueForSelectorinat((targetMethod1->selector), enumeratingCogMethod, mcpc), unlinkedRoutine);
				codeModified = 1;
			}

		}
	}
	return 0;
}

	/* Cogit>>#unlinkIfInvalidClassSend:pc:ignored: */
static sqInt NoDbgRegParms
unlinkIfInvalidClassSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send, but maybe a super send or linked to an OpenPIC, in which case the cache tag will be a selector.... */
			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if (!(((annotation == IsSuperSend)
				 || (0))
				 || (((targetMethod1->cmType)) == CMOpenPIC))) {
				if (!(isValidClassTag(inlineCacheTagAt(backEnd, ((sqInt)mcpc))))) {
					/* begin unlinkSendAt:targetMethod:sendTable: */
					unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
					rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), inlineCacheValueForSelectorinat((targetMethod1->selector), enumeratingCogMethod, mcpc), unlinkedRoutine);
					codeModified = 1;
				}
			}

		}
	}
	return 0;
}

	/* Cogit>>#unlinkIfLinkedSendToFree:pc:ignored: */
static sqInt NoDbgRegParms
unlinkIfLinkedSendToFreepcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */
			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if (((targetMethod1->cmType)) == CMFree) {
				/* begin unlinkSendAt:targetMethod:sendTable: */
				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), inlineCacheValueForSelectorinat((targetMethod1->selector), enumeratingCogMethod, mcpc), unlinkedRoutine);
				codeModified = 1;
			}

		}
	}
	return 0;
}

	/* Cogit>>#unlinkIfLinkedSend:pc:ignored: */
static sqInt NoDbgRegParms
unlinkIfLinkedSendpcignored(sqInt annotation, char *mcpc, sqInt superfluity)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */
			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			/* begin unlinkSendAt:targetMethod:sendTable: */
			unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
			rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), inlineCacheValueForSelectorinat((targetMethod1->selector), enumeratingCogMethod, mcpc), unlinkedRoutine);
			codeModified = 1;

		}
	}
	return 0;
}

	/* Cogit>>#unlinkIfLinkedSend:pc:to: */
static sqInt NoDbgRegParms
unlinkIfLinkedSendpcto(sqInt annotation, char *mcpc, sqInt theCogMethod)
{
    sqInt entryPoint;
    sqInt sendTable;
    sqInt *sendTable1;
    sqInt targetMethod;
    CogMethod *targetMethod1;
    sqInt unlinkedRoutine;

	if (annotation >= IsSendCall) {
		entryPoint = callTargetFromReturnAddress(backEnd, ((sqInt)mcpc));
		if (entryPoint > methodZoneBase) {

			/* It's a linked send. */
			/* begin targetMethodAndSendTableFor:annotation:into: */
			if (annotation == IsSendCall) {
				targetMethod1 = ((CogMethod *) (entryPoint - cmEntryOffset));
				sendTable1 = ordinarySendTrampolines;
			}
			else {
				assert(annotation == IsSuperSend);
				targetMethod1 = ((CogMethod *) (entryPoint - cmNoCheckEntryOffset));
				sendTable1 = superSendTrampolines;



			}
			if ((((sqInt)targetMethod1)) == theCogMethod) {
				/* begin unlinkSendAt:targetMethod:sendTable: */
				unlinkedRoutine = sendTable1[((((targetMethod1->cmNumArgs)) < (NumSendTrampolines - 1)) ? ((targetMethod1->cmNumArgs)) : (NumSendTrampolines - 1))];
				rewriteInlineCacheAttagtarget(backEnd, ((sqInt)mcpc), inlineCacheValueForSelectorinat((targetMethod1->selector), enumeratingCogMethod, mcpc), unlinkedRoutine);
				codeModified = 1;
			}

		}
	}
	return 0;
}


/*	Unlink all sends in cog methods whose class tag is that of a forwarded
	class. 
 */

	/* Cogit>>#unlinkSendsLinkedForInvalidClasses */
void
unlinkSendsLinkedForInvalidClasses(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt freedPIC;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	if (!(methodZoneBase)) {
		return;
	}
	cogMethod = ((CogMethod *) methodZoneBase);
	codeModified = (freedPIC = 0);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfInvalidClassSendpcignored(annotation, (((char *) mcpc)), 0);
					if (result != 0) {
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
			if ((((cogMethod->cmType)) == CMClosedPIC)
			 && (cPICHasForwardedClass(cogMethod))) {
				freeMethod(cogMethod);
				freedPIC = 1;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freedPIC) {
		unlinkSendsToFree();
	}
	else {
		if (codeModified) {

			/* After possibly updating inline caches we need to flush the icache. */
			flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
		}
	}
}


/*	Unlink all sends in cog methods. Free all Closed PICs with the selector,
	or with an MNU case if isMNUSelector. First check if any method actually
	has the selector; if not there can't be any linked send to it. This
	routine (including descendents) is performance critical. It contributes
	perhaps 30% of entire execution time in Compiler recompileAll. */

	/* Cogit>>#unlinkSendsOf:isMNUSelector: */
void
unlinkSendsOfisMNUSelector(sqInt selector, sqInt isMNUSelector)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt mustScanAndUnlink;
    sqInt result;

	if (!(methodZoneBase)) {
		return;
	}
	cogMethod = ((CogMethod *) methodZoneBase);
	mustScanAndUnlink = 0;
	if (isMNUSelector) {
		while (cogMethod < (limitZony())) {
			if (((cogMethod->cmType)) != CMFree) {
				if ((cogMethod->cpicHasMNUCase)) {
					assert(((cogMethod->cmType)) == CMClosedPIC);
					freeMethod(cogMethod);
					mustScanAndUnlink = 1;
				}
				else {
					if (((cogMethod->selector)) == selector) {
						mustScanAndUnlink = 1;
						if (((cogMethod->cmType)) == CMClosedPIC) {
							freeMethod(cogMethod);
						}
					}
				}
			}
			cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		}
	}
	else {
		while (cogMethod < (limitZony())) {
			if ((((cogMethod->cmType)) != CMFree)
			 && (((cogMethod->selector)) == selector)) {
				mustScanAndUnlink = 1;
				if (((cogMethod->cmType)) == CMClosedPIC) {
					freeMethod(cogMethod);
				}
			}
			cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		}
	}
	if (!mustScanAndUnlink) {
		return;
	}
	codeModified = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfFreeOrLinkedSendpcof(annotation, (((char *) mcpc)), selector);
					if (result != 0) {
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
		l1:	/* end mapFor:performUntil:arg: */;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (codeModified) {

		/* After possibly updating inline caches we need to flush the icache. */
		flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
	}
}


/*	Unlink all sends in cog methods to free methods and/or pics. */

	/* Cogit>>#unlinkSendsToFree */
void
unlinkSendsToFree(void)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;

	if (!(methodZoneBase)) {
		return;
	}
	codeModified = 0;
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfLinkedSendToFreepcignored(annotation, (((char *) mcpc)), 0);
					if (result != 0) {
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
			if (((cogMethod->cmType)) == CMClosedPIC) {
				assert(noTargetsFreeInClosedPIC(cogMethod));
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (codeModified) {

		/* After possibly updating inline caches we need to flush the icache. */
		flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
	}
}


/*	Unlink all sends in cog methods to a particular target method.
	If targetMethodObject isn't actually a method (perhaps being
	used via invokeAsMethod) then there's nothing to do. */

	/* Cogit>>#unlinkSendsTo:andFreeIf: */
void
unlinkSendsToandFreeIf(sqInt targetMethodObject, sqInt freeIfTrue)
{
    sqInt annotation;
    CogMethod *cogMethod;
    sqInt freedPIC;
    sqInt map;
    sqInt mapByte;
    sqInt mcpc;
    sqInt result;
    CogMethod *targetMethod;

	if (!((isOopCompiledMethod(targetMethodObject))
		 && (methodHasCogMethod(targetMethodObject)))) {
		return;
	}
	targetMethod = cogMethodOf(targetMethodObject);
	if (!(methodZoneBase)) {
		return;
	}
	codeModified = (freedPIC = 0);
	cogMethod = ((CogMethod *) methodZoneBase);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == CMMethod) {
			/* begin mapFor:performUntil:arg: */
			mcpc = (((sqInt)cogMethod)) + cmNoCheckEntryOffset;
			map = ((((usqInt)cogMethod)) + ((cogMethod->blockSize))) - 1;
			while (((mapByte = byteAt(map))) != MapEnd) {
				if (mapByte >= FirstAnnotation) {

					/* If this is an IsSendCall annotation, peek ahead for an IsAnnotationExtension, and consume it. */
					mcpc += (mapByte & DisplacementMask) * 4;
					if ((((annotation = ((usqInt) mapByte) >> AnnotationShift)) == IsSendCall)
					 && ((((usqInt) ((mapByte = byteAt(map - 1)))) >> AnnotationShift) == IsAnnotationExtension)) {
						annotation += mapByte & DisplacementMask;
						map -= 1;
					}
					result = unlinkIfLinkedSendpcto(annotation, (((char *) mcpc)), (((sqInt)targetMethod)));
					if (result != 0) {
						goto l1;
					}
				}
				else {
					if (mapByte < (IsAnnotationExtension << AnnotationShift)) {
						mcpc += ((mapByte - DisplacementX2N) << AnnotationShift) * 4;
					}
				}
				map -= 1;
			}
		l1:	/* end mapFor:performUntil:arg: */;
		}
		else {
			if ((((cogMethod->cmType)) == CMClosedPIC)
			 && (cPICHasTarget(cogMethod, targetMethod))) {
				freeMethod(cogMethod);
				freedPIC = 1;
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	if (freeIfTrue) {
		freeMethod(targetMethod);
	}
	if (freedPIC) {
		unlinkSendsToFree();
	}
	else {
		if (codeModified) {

			/* After possibly updating inline caches we need to flush the icache. */
			flushICacheFromto(processor, ((usqInt)methodZoneBase), ((usqInt)(limitZony())));
		}
	}
}

	/* Cogit>>#XorCw:R: */
static AbstractInstruction * NoDbgRegParms
gXorCwR(sqInt wordConstant, sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(XorCwR, wordConstant, reg);
	return anInstruction;
}


/*	Access for the object representations when they need to prepend code to
	trampolines. 
 */

	/* Cogit>>#zeroOpcodeIndex */
static void
zeroOpcodeIndex(void)
{
	opcodeIndex = 0;
	/* begin resetLiterals */
}

	/* CogMethodZone>>#addAllToYoungReferrers */
void
addAllToYoungReferrers(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) == CMMethod)
		 || (((cogMethod->cmType)) == CMOpenPIC)) {
			ensureInYoungReferrers(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#addToOpenPICList: */
static void NoDbgRegParms
addToOpenPICList(CogMethod *anOpenPIC)
{
	assert(((anOpenPIC->cmType)) == CMOpenPIC);
	assert((openPICList == null)
	 || (((openPICList->cmType)) == CMOpenPIC));
	(anOpenPIC->nextOpenPIC = ((usqInt)openPICList));
	openPICList = anOpenPIC;
}

	/* CogMethodZone>>#addToYoungReferrers: */
static void NoDbgRegParms
addToYoungReferrers(CogMethod *cogMethod)
{
	assert(youngReferrers <= limitAddress);
	assert((occurrencesInYoungReferrers(cogMethod)) == 0);
	assert((cogMethod->cmRefersToYoung));
	assert((youngReferrers <= limitAddress)
	 && (youngReferrers >= (limitAddress - (methodCount * BytesPerWord))));
	if (!(asserta((limitAddress - (methodCount * BytesPerWord)) >= mzFreeStart))) {
		error("no room on youngReferrers list");
	}
	youngReferrers -= BytesPerWord;
	longAtput(youngReferrers, ((usqInt)cogMethod));
}

	/* CogMethodZone>>#allocate: */
static sqInt NoDbgRegParms
allocate(sqInt numBytes)
{
    usqInt allocation;
    sqInt roundedBytes;

	roundedBytes = (numBytes + 7) & -8;
	if ((mzFreeStart + roundedBytes) >= (limitAddress - (methodCount * BytesPerWord))) {
		return 0;
	}
	allocation = mzFreeStart;
	mzFreeStart += roundedBytes;
	methodCount += 1;
	return allocation;
}


/*	Free all methods */

	/* CogMethodZone>>#clearCogCompiledCode */
static void
clearCogCompiledCode(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while ((((usqInt)cogMethod)) < mzFreeStart) {
		if (((cogMethod->cmType)) == CMMethod) {
			freeMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	manageFromto(baseAddress, limitAddress);
}

	/* CogMethodZone>>#compactCompiledCode */
static void
compactCompiledCode(void)
{
    unsigned short bytes;
    CogMethod *dest;
    sqLong objectHeaderValue;
    CogMethod *source;

	objectHeaderValue = nullHeaderForMachineCodeMethod();
	source = ((CogMethod *) baseAddress);
	openPICList = null;
	methodCount = 0;
	while ((source < (limitZony()))
	 && (((source->cmType)) != CMFree)) {
		assert((cogMethodDoesntLookKosher(source)) == 0);
		(source->objectHeader = objectHeaderValue);
		if (((source->cmUsageCount)) > 0) {
			(source->cmUsageCount = ((source->cmUsageCount)) / 2);
		}
		if (((source->cmType)) == CMOpenPIC) {
			(source->nextOpenPIC = ((usqInt)openPICList));
			openPICList = source;
		}
		methodCount += 1;
		source = ((CogMethod *) (roundUpLength((((sqInt)source)) + ((source->blockSize)))));
	}
	if (source >= (limitZony())) {
		haltmsg("no free methods; cannot compact.");
		return;
	}
	dest = source;
	while (source < (limitZony())) {
		assert((maybeFreeCogMethodDoesntLookKosher(source)) == 0);
		bytes = (source->blockSize);
		if (((source->cmType)) != CMFree) {
			methodCount += 1;
			memmove(dest, source, bytes);
			(dest->objectHeader = objectHeaderValue);
			if (((dest->cmType)) == CMMethod) {

				/* For non-Newspeak there should be a one-to-one mapping between bytecoded and
				   cog methods.  For Newspeak not necessarily, but only for anonymous accessors. */
				/* Only update the original method's header if it is referring to this CogMethod. */
				if ((((sqInt)(rawHeaderOf((dest->methodObject))))) == (((sqInt)source))) {
					rawHeaderOfput((dest->methodObject), ((sqInt)dest));
				}
				else {
					assert((noAssertMethodClassAssociationOf((dest->methodObject))) == (nilObject()));
									}
			}
			else {
				if (((dest->cmType)) == CMOpenPIC) {
					(dest->nextOpenPIC = ((usqInt)openPICList));
					openPICList = dest;
				}
			}
			if (((dest->cmUsageCount)) > 0) {
				(dest->cmUsageCount = ((dest->cmUsageCount)) / 2);
			}
			dest = ((CogMethod *) ((((usqInt)dest)) + bytes));
		}
		source = ((CogMethod *) ((((usqInt)source)) + bytes));
	}
	mzFreeStart = ((usqInt)dest);
	methodBytesFreedSinceLastCompaction = 0;
}

	/* CogMethodZone>>#ensureInYoungReferrers: */
static void NoDbgRegParms
ensureInYoungReferrers(CogMethod *cogMethod)
{
	if (!((cogMethod->cmRefersToYoung))) {
		assert((occurrencesInYoungReferrers(cogMethod)) == 0);
		(cogMethod->cmRefersToYoung = 1);
		addToYoungReferrers(cogMethod);
	}
}

	/* CogMethodZone>>#freeMethod: */
void
freeMethod(CogMethod *cogMethod)
{
	assert(((cogMethod->cmType)) != CMFree);
	assert(((cogMethodDoesntLookKosher(cogMethod)) == 0)
	 || (((cogMethodDoesntLookKosher(cogMethod)) == 23)
	 && ((((((CogMethod *) ((cogMethod->methodObject))))->cmType)) == CMFree)));
	if (((cogMethod->cmType)) == CMMethod) {

		/* For non-Newspeak there should ne a one-to-one mapping between bytecoded and
		   cog methods.  For Newspeak not necessarily, but only for anonymous accessors. */
		/* Only reset the original method's header if it is referring to this CogMethod. */
		if ((((sqInt)(rawHeaderOf((cogMethod->methodObject))))) == (((sqInt)cogMethod))) {
			rawHeaderOfput((cogMethod->methodObject), (cogMethod->methodHeader));
					}
		else {
			assert((noAssertMethodClassAssociationOf((cogMethod->methodObject))) == (nilObject()));
					}
		/* begin maybeFreeCountersOf: */
	}
	if (((cogMethod->cmType)) == CMOpenPIC) {
		removeFromOpenPICList(cogMethod);
	}
	(cogMethod->cmRefersToYoung = 0);
	(cogMethod->cmType = CMFree);
	methodBytesFreedSinceLastCompaction += (cogMethod->blockSize);
}


/*	Free methods, preferring older methods for compaction, up to some
	fraction, currently a quarter.
 */

	/* CogMethodZone>>#freeOlderMethodsForCompaction */
static void
freeOlderMethodsForCompaction(void)
{
    sqInt amountToFree;
    sqInt cascade0;
    sqInt cascade1;
    CogMethod *cogMethod;
    sqInt freeableUsage;
    usqInt freedSoFar;
    usqInt initialFreeSpace;
    usqInt zoneSize;

	zoneSize = limitAddress - baseAddress;
	initialFreeSpace = (limitAddress - mzFreeStart) + methodBytesFreedSinceLastCompaction;
	freedSoFar = initialFreeSpace;

	/* 4 needs to be e.g. a start-up parameter */
	amountToFree = zoneSize / 4;
	freeableUsage = 0;
	do {
		cogMethod = ((CogMethod *) baseAddress);
		while (((((usqInt)cogMethod)) < mzFreeStart)
		 && (freedSoFar < amountToFree)) {
			if ((((cogMethod->cmType)) != CMFree)
			 && (((cogMethod->cmUsageCount)) <= freeableUsage)) {
				freeMethod(cogMethod);
				freedSoFar += (cogMethod->blockSize);
			}
			cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		}
	} while((freedSoFar < amountToFree)
		 && (((freeableUsage += 1)) < CMMaxUsageCount));
	}


/*	Answer that all entries in youngReferrers are in-use and have the
	cmRefersToYoung flag set.
	Used to check that the youngreferrers pruning routines work correctly. */

	/* CogMethodZone>>#kosherYoungReferrers */
static sqInt
kosherYoungReferrers(void)
{
    CogMethod *cogMethod;
    usqInt pointer;

	if ((youngReferrers > limitAddress)
	 || (youngReferrers < mzFreeStart)) {
		return 0;
	}
	pointer = youngReferrers;
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (!((((cogMethod->cmType)) != CMFree)
			 && ((cogMethod->cmRefersToYoung)))) {
			return 0;
		}
		pointer += BytesPerWord;
	}
	return 1;
}

	/* CogMethodZone>>#manageFrom:to: */
static void NoDbgRegParms
manageFromto(sqInt theStartAddress, sqInt theLimitAddress)
{
	mzFreeStart = (baseAddress = theStartAddress);
	youngReferrers = (limitAddress = theLimitAddress);
	openPICList = null;
	methodBytesFreedSinceLastCompaction = 0;
	methodCount = 0;
}

	/* CogMethodZone>>#methodFor: */
CogMethod *
methodFor(void *address)
{
    CogMethod *cogMethod;
    CogMethod *nextMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while ((cogMethod < (limitZony()))
	 && ((((usqInt)cogMethod)) <= (((usqInt)address)))) {
		nextMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
		if (nextMethod == cogMethod) {
			return 0;
		}
		if (((((usqInt)address)) >= (((usqInt)cogMethod)))
		 && ((((usqInt)address)) < (((usqInt)nextMethod)))) {
			return cogMethod;
		}
		cogMethod = nextMethod;
	}
	return 0;
}

	/* CogMethodZone>>#numMethods */
static sqInt
numMethods(void)
{
	return methodCount;
}

	/* CogMethodZone>>#numMethodsOfType: */
sqInt
numMethodsOfType(sqInt cogMethodType)
{
    CogMethod *cogMethod;
    sqInt n;

	n = 0;
	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == cogMethodType) {
			n += 1;
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	return n;
}

	/* CogMethodZone>>#occurrencesInYoungReferrers: */
static sqInt NoDbgRegParms
occurrencesInYoungReferrers(CogMethod *cogMethod)
{
    sqInt count;
    usqInt pointer;

	assert(youngReferrers <= limitAddress);
	count = 0;
	pointer = youngReferrers;
	while (pointer < limitAddress) {
		if ((((sqInt)cogMethod)) == (longAt(pointer))) {
			count += 1;
		}
		pointer += BytesPerWord;
	}
	return count;
}

	/* CogMethodZone>>#openPICWithSelector: */
static CogMethod * NoDbgRegParms
openPICWithSelector(sqInt aSelector)
{
    CogMethod *openPIC;

	openPIC = openPICList;
	do {
		if ((openPIC == null)
		 || (((openPIC->selector)) == aSelector)) {
			return openPIC;
		}
		openPIC = ((CogMethod *) ((openPIC->nextOpenPIC)));
	} while(1);
}


/*	Some methods have been freed. Compute how much each survivor needs to
	move during the ensuing compaction and record it in the objectHeader
	field. 
	For Sista, where we want PICs to last so they can be observed, we need to
	keep PICs unless
	they are definitely unused. So we need to identify unused PICs. So in
	planCompact, zero the
	usage counts of all PICs, saving the actual usage count in
	blockEntryOffset. Then in
	relocateMethodsPreCompaction (actually in
	relocateIfCallOrMethodReference:mcpc:delta:) restore the usage counts of
	used PICs. Finally in compactCompiledCode, clear the blockEntryOffset
	of the unused PICs; they will then have a zero count and be reclaimed in
	the next code compaction. */

	/* CogMethodZone>>#planCompaction */
static void
planCompaction(void)
{
    CogMethod *cogMethod;
    sqInt delta;

	delta = 0;
	cogMethod = ((CogMethod *) baseAddress);
	while ((((usqInt)cogMethod)) < mzFreeStart) {
		if (((cogMethod->cmType)) == CMFree) {
			delta -= (cogMethod->blockSize);
		}
		else {
			assert((cogMethodDoesntLookKosher(cogMethod)) == 0);
			(cogMethod->objectHeader = delta);
					}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethods */
void
printCogMethods(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		printCogMethod(cogMethod);
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethodsOfType: */
void
printCogMethodsOfType(sqInt cmType)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if (((cogMethod->cmType)) == cmType) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethodsWithMethod: */
void
printCogMethodsWithMethod(sqInt methodOop)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (((cogMethod->methodObject)) == methodOop)) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethodsWithPrimitive: */
void
printCogMethodsWithPrimitive(sqInt primIdx)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (primIdx == (primitiveIndexOfMethodheader((cogMethod->methodObject), (cogMethod->methodHeader))))) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogMethodsWithSelector: */
void
printCogMethodsWithSelector(sqInt selectorOop)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while (cogMethod < (limitZony())) {
		if ((((cogMethod->cmType)) != CMFree)
		 && (((cogMethod->selector)) == selectorOop)) {
			printCogMethod(cogMethod);
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
}

	/* CogMethodZone>>#printCogYoungReferrers */
void
printCogYoungReferrers(void)
{
    CogMethod *cogMethod;
    usqInt pointer;

	pointer = youngReferrers;
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (!((cogMethod->cmRefersToYoung))) {
			print("*");
		}
		if (((cogMethod->cmType)) == CMFree) {
			print("!");
		}
		if (!(((cogMethod->cmRefersToYoung))
			 && (((cogMethod->cmType)) != CMFree))) {
			print(" ");
		}
		printCogMethod(cogMethod);
		pointer += BytesPerWord;
	}
}

	/* CogMethodZone>>#printOpenPICList */
void
printOpenPICList(void)
{
    CogMethod *openPIC;

	openPIC = openPICList;
	while (!(openPIC == null)) {
		printCogMethod(openPIC);
		openPIC = ((CogMethod *) ((openPIC->nextOpenPIC)));
	}
}

	/* CogMethodZone>>#pruneYoungReferrers */
static sqInt
pruneYoungReferrers(void)
{
    usqInt dest;
    usqInt next;
    usqInt source;

	assert(youngReferrers <= limitAddress);
	if (youngReferrers == limitAddress) {
		return null;
	}
	dest = limitAddress;
	while (1) {
		next = dest - BytesPerWord;
		if (!((next >= youngReferrers)
		 && (((((CogMethod *) (longAt(next))))->cmRefersToYoung)))) break;
		dest = next;
	}
	assert(dest >= youngReferrers);
	source = dest - BytesPerWord;
	while (source >= youngReferrers) {
		if (((((CogMethod *) (longAt(source))))->cmRefersToYoung)) {
			assert(source < (dest - BytesPerWord));
			longAtput((dest -= BytesPerWord), longAt(source));
		}
		source -= BytesPerWord;
	}
	youngReferrers = dest;
	assert(kosherYoungReferrers());
}

	/* CogMethodZone>>#relocateAndPruneYoungReferrers */
static sqInt
relocateAndPruneYoungReferrers(void)
{
    CogMethod *cogMethod;
    usqInt dest;
    usqInt next;
    usqInt source;

	assert(youngReferrers <= limitAddress);
	if (youngReferrers == limitAddress) {
		return null;
	}
	dest = limitAddress;
	while (1) {
		next = dest - BytesPerWord;
		if (!((next >= youngReferrers)
		 && (((((cogMethod = ((CogMethod *) (longAt(next))))->cmType)) != CMFree)
		 && ((cogMethod->cmRefersToYoung))))) break;
		if (((cogMethod->objectHeader)) != 0) {
			longAtput(next, (((sqInt)cogMethod)) + ((cogMethod->objectHeader)));
		}
		dest = next;
	}
	assert(dest >= youngReferrers);
	source = dest - BytesPerWord;
	while (source >= youngReferrers) {
		cogMethod = ((CogMethod *) (longAt(source)));
		if ((((cogMethod->cmType)) != CMFree)
		 && ((cogMethod->cmRefersToYoung))) {
			assert(source < (dest - BytesPerWord));
			if (((cogMethod->objectHeader)) != 0) {
				cogMethod = ((CogMethod *) ((((sqInt)cogMethod)) + (((sqInt)((cogMethod->objectHeader))))));
			}
			longAtput((dest -= BytesPerWord), ((sqInt)cogMethod));
		}
		source -= BytesPerWord;
	}
	youngReferrers = dest;
}


/*	All surviving methods have had the amount they are going to relocate by
	stored in their objectHeader fields. Relocate all relative calls so that
	after the compaction of both the method containing each call and the call
	target the calls invoke the same target. */

	/* CogMethodZone>>#relocateMethodsPreCompaction */
static sqInt
relocateMethodsPreCompaction(void)
{
    CogMethod *cogMethod;

	cogMethod = ((CogMethod *) baseAddress);
	while ((((usqInt)cogMethod)) < mzFreeStart) {
		if (((cogMethod->cmType)) != CMFree) {
			if (((cogMethod->cmType)) == CMClosedPIC) {
				relocateCallsInClosedPIC(cogMethod);
			}
			else {
				relocateCallsAndSelfReferencesInMethod(cogMethod);
			}
		}
		cogMethod = ((CogMethod *) (roundUpLength((((sqInt)cogMethod)) + ((cogMethod->blockSize)))));
	}
	relocateAndPruneYoungReferrers();
	return 1;
}

	/* CogMethodZone>>#removeFromOpenPICList: */
static sqInt NoDbgRegParms
removeFromOpenPICList(CogMethod *anOpenPIC)
{
    CogMethod *prevPIC;

	assert(((anOpenPIC->cmType)) == CMOpenPIC);
	if (anOpenPIC == openPICList) {

		/* N.B. Use self rather than coInterpreter to avoid attempting to cast nil.
		   Conversion to CogMethod done in the nextOpenPIC accessor. */
		openPICList = ((CogMethod *) ((anOpenPIC->nextOpenPIC)));
		return null;
	}
	prevPIC = openPICList;
	do {
		assert((prevPIC != null)
		 && (((prevPIC->cmType)) == CMOpenPIC));
		if (((prevPIC->nextOpenPIC)) == (((sqInt)anOpenPIC))) {
			(prevPIC->nextOpenPIC = (anOpenPIC->nextOpenPIC));
			return null;
		}
		prevPIC = ((CogMethod *) ((prevPIC->nextOpenPIC)));
	} while(1);
}

	/* CogMethodZone>>#voidYoungReferrersPostTenureAll */
static void
voidYoungReferrersPostTenureAll(void)
{
    CogMethod *cogMethod;
    usqInt pointer;

	assert(youngReferrers <= limitAddress);
	pointer = youngReferrers;
	while (pointer < limitAddress) {
		cogMethod = ((CogMethod *) (longAt(pointer)));
		if (((cogMethod->cmType)) != CMFree) {
			(cogMethod->cmRefersToYoung = 0);
		}
		pointer += BytesPerWord;
	}
	youngReferrers = limitAddress;
}

	/* CogMethodZone>>#whereIsMaybeCodeThing: */
char *
whereIsMaybeCodeThing(sqInt anOop)
{
	if (oopisGreaterThanOrEqualToandLessThan(anOop, codeBase, limitAddress)) {
		if (oopisLessThan(anOop, methodZoneBase)) {
			return " is in generated runtime";
		}
		if (oopisLessThan(anOop, mzFreeStart)) {
			return " is in generated methods";
		}
		if (oopisLessThan(anOop, youngReferrers)) {
			return " is in code zone";
		}
		return " is in young referrers";
	}
	return null;
}

	/* CogMIPSELCompiler>>#addiuR:R:C: */
static sqInt NoDbgRegParms
addiuRRC(AbstractInstruction * self_in_addiuRRC, sqInt destReg, sqInt srcReg, sqInt imm)
{
	return itypersrtsignedImmediate(self_in_addiuRRC, ADDIU, srcReg, destReg, imm);
}

	/* CogMIPSELCompiler>>#adduR:R:R: */
static sqInt NoDbgRegParms
adduRRR(AbstractInstruction * self_in_adduRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_adduRRR, SPECIAL, leftReg, rightReg, destReg, 0, ADDU);
}

	/* CogMIPSELCompiler>>#andiR:R:C: */
static sqInt NoDbgRegParms
andiRRC(AbstractInstruction * self_in_andiRRC, sqInt destReg, sqInt srcReg, sqInt imm)
{
	return itypersrteitherImmediate(self_in_andiRRC, ANDI, srcReg, destReg, imm);
}

	/* CogMIPSELCompiler>>#andR:R:R: */
static sqInt NoDbgRegParms
andRRR(AbstractInstruction * self_in_andRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_andRRR, SPECIAL, leftReg, rightReg, destReg, 0, AND);
}

	/* CogMIPSELCompiler>>#beqR:R:offset: */
static sqInt NoDbgRegParms
beqRRoffset(AbstractInstruction * self_in_beqRRoffset, sqInt leftReg, sqInt rightReg, sqInt offset)
{
	assert((offset & 3) == 0);
	assert(((offset >= -131072) && (offset <= 0x1FFFF)));
	return itypersrtsignedImmediate(self_in_beqRRoffset, BEQ, leftReg, rightReg, ((sqInt) offset) >> 2);
}

	/* CogMIPSELCompiler>>#bgezR:offset: */
static sqInt NoDbgRegParms
bgezRoffset(AbstractInstruction * self_in_bgezRoffset, sqInt cmpReg, sqInt offset)
{
	assert((offset & 3) == 0);
	assert(((offset >= -131072) && (offset <= 0x1FFFF)));
	return itypersrtsignedImmediate(self_in_bgezRoffset, REGIMM, cmpReg, BGEZ, ((sqInt) offset) >> 2);
}

	/* CogMIPSELCompiler>>#bgtzR:offset: */
static sqInt NoDbgRegParms
bgtzRoffset(AbstractInstruction * self_in_bgtzRoffset, sqInt cmpReg, sqInt offset)
{
	assert((offset & 3) == 0);
	assert(((offset >= -131072) && (offset <= 0x1FFFF)));
	return itypersrtsignedImmediate(self_in_bgtzRoffset, BGTZ, cmpReg, 0, ((sqInt) offset) >> 2);
}

	/* CogMIPSELCompiler>>#blezR:offset: */
static sqInt NoDbgRegParms
blezRoffset(AbstractInstruction * self_in_blezRoffset, sqInt cmpReg, sqInt offset)
{
	assert((offset & 3) == 0);
	assert(((offset >= -131072) && (offset <= 0x1FFFF)));
	return itypersrtsignedImmediate(self_in_blezRoffset, BLEZ, cmpReg, 0, ((sqInt) offset) >> 2);
}

	/* CogMIPSELCompiler>>#bltzR:offset: */
static sqInt NoDbgRegParms
bltzRoffset(AbstractInstruction * self_in_bltzRoffset, sqInt cmpReg, sqInt offset)
{
	assert((offset & 3) == 0);
	assert(((offset >= -131072) && (offset <= 0x1FFFF)));
	return itypersrtsignedImmediate(self_in_bltzRoffset, REGIMM, cmpReg, BLTZ, ((sqInt) offset) >> 2);
}

	/* CogMIPSELCompiler>>#bneR:R:offset: */
static sqInt NoDbgRegParms
bneRRoffset(AbstractInstruction * self_in_bneRRoffset, sqInt leftReg, sqInt rightReg, sqInt offset)
{
	assert((offset & 3) == 0);
	assert(((offset >= -131072) && (offset <= 0x1FFFF)));
	return itypersrtsignedImmediate(self_in_bneRRoffset, BNE, leftReg, rightReg, ((sqInt) offset) >> 2);
}


/*	Volatile */
/*	See MIPSConstants initializeRegisters. */

	/* CogMIPSELCompiler>>#callerSavedRegisterMask */
static sqInt NoDbgRegParms
callerSavedRegisterMask(AbstractInstruction * self_in_callerSavedRegisterMask)
{
	flag("OABI");
	return registerMaskForandandandandandandandandand(T0, T1, T2, T3, T4, T5, T6, T7, T8, T9);
}

	/* CogMIPSELCompiler>>#callInstructionByteSize */
static sqInt NoDbgRegParms
callInstructionByteSize(AbstractInstruction * self_in_callInstructionByteSize)
{
	flag("todo");
	return 16;
}


/*	csra - 16:	lui t9, high
	csra - 12:	ori t9, low
	csra - 8:	jalr t9
	csra - 4:	nop (delay slot) */

	/* CogMIPSELCompiler>>#callTargetFromReturnAddress: */
static sqInt NoDbgRegParms
callTargetFromReturnAddress(AbstractInstruction * self_in_callTargetFromReturnAddress, sqInt callSiteReturnAddress)
{
	assert((opcodeAtAddress(self_in_callTargetFromReturnAddress, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_callTargetFromReturnAddress, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_callTargetFromReturnAddress, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_callTargetFromReturnAddress, callSiteReturnAddress - 8)) == JALR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_callTargetFromReturnAddress)));
	return literalAtAddress(self_in_callTargetFromReturnAddress, callSiteReturnAddress - 12);
}

	/* CogMIPSELCompiler>>#cmpC32RTempByteSize */
static sqInt NoDbgRegParms
cmpC32RTempByteSize(AbstractInstruction * self_in_cmpC32RTempByteSize)
{
	return 8;
}


/*	Each MIPS instruction has 4 bytes. Many abstract opcodes need more than
	one instruction. Instructions that refer to constants and/or literals
	depend on literals
	being stored in-line or out-of-line.
	
	N.B. The ^N forms are to get around the bytecode compiler's long branch
	limits which are exceeded when each case jumps around the otherwise. */

	/* CogMIPSELCompiler>>#computeMaximumSize */
static sqInt NoDbgRegParms
computeMaximumSize(AbstractInstruction * self_in_computeMaximumSize)
{
	
	switch ((self_in_computeMaximumSize->opcode)) {
	case BrEqualRR:
	case BrNotEqualRR:
	case JumpR:
	case Jump:
	case JumpZero:
	case JumpNonZero:
	case JumpNegative:
	case JumpNonNegative:
	case JumpOverflow:
	case JumpNoOverflow:
	case JumpCarry:
	case JumpNoCarry:
	case JumpLess:
	case JumpGreaterOrEqual:
	case JumpGreater:
	case JumpLessOrEqual:
	case JumpBelow:
	case JumpAboveOrEqual:
	case JumpAbove:
	case JumpBelowOrEqual:
	case JumpFPEqual:
	case JumpFPNotEqual:
	case JumpFPLess:
	case JumpFPGreaterOrEqual:
	case JumpFPGreater:
	case JumpFPLessOrEqual:
	case JumpFPOrdered:
	case JumpFPUnordered:
	case RetN:
	case MoveCqR:
	case MoveCwR:
	case MoveXbrRR:
	case MoveRXbrR:
	case PopR:
	case PushR:
	case ConvertRRd:
		return 8;

	case BrUnsignedLessRR:
	case BrUnsignedLessEqualRR:
	case BrUnsignedGreaterRR:
	case BrUnsignedGreaterEqualRR:
	case BrSignedLessRR:
	case BrSignedLessEqualRR:
	case BrSignedGreaterRR:
	case BrSignedGreaterEqualRR:
	case AddCqR:
	case AndCqRR:
	case OrCqR:
	case SubCqR:
	case TstCqR:
	case XorCqR:
	case AddCwR:
	case AndCwR:
	case OrCwR:
	case SubCwR:
	case XorCwR:
	case LoadEffectiveAddressMwrR:
	case MoveXwrRR:
	case MoveRXwrR:
	case PrefetchAw:
		return 12;

	case BrLongEqualRR:
	case BrLongNotEqualRR:
	case AndCqR:
	case MoveRMwr:
	case MoveMwrR:
	case PushCw:
	case PushCq:
		return 16;

	case MulRR:
	case DivRR:
	case MoveLowR:
	case MoveHighR:
	case Literal:
	case Fill32:
	case Nop:
	case Stop:
	case AddRR:
	case AndRR:
	case OrRR:
	case XorRR:
	case SubRR:
	case NegateR:
	case LogicalShiftLeftCqR:
	case LogicalShiftRightCqR:
	case ArithmeticShiftRightCqR:
	case LogicalShiftLeftRR:
	case LogicalShiftRightRR:
	case ArithmeticShiftRightRR:
	case AddRdRd:
	case CmpRdRd:
	case SubRdRd:
	case MulRdRd:
	case DivRdRd:
	case SqrtRd:
	case MoveRR:
	case MoveRdRd:
	case MoveMbrR:
	case MoveRMbr:
	case MoveM16rR:
	case MoveRM16r:
		return 4;

	case Label:
		return 0;

	case AlignmentNops:
		return (((self_in_computeMaximumSize->operands))[0]) - 4;

	case Call:
	case CallFull:
	case JumpFull:
	case JumpLong:
	case JumpLongZero:
	case JumpLongNonZero:
		return 8 + 8;

	case CmpCqR:
	case CmpCwR:
	case AddCheckOverflowCqR:
	case SubCheckOverflowCqR:
		return 28;

	case CmpRR:
	case AddCheckOverflowRR:
	case SubCheckOverflowRR:
	case MulCheckOverflowRR:
		return 20;

	case MoveAwR:
	case MoveAbR:
		return (isAddressRelativeToVarBase(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[0])
			? 4
			: 8 + 4);

	case MoveRAw:
	case MoveRAb:
		return (isAddressRelativeToVarBase(self_in_computeMaximumSize, ((self_in_computeMaximumSize->operands))[1])
			? 4
			: 8 + 4);

	case MoveRdM64r:
	case MoveM64rRd:
		return 8 + 4;

	default:
		error("Case not found and no otherwise clause");
	}
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeAddCheckOverflowCqR */
static usqInt NoDbgRegParms
concretizeAddCheckOverflowCqR(AbstractInstruction * self_in_concretizeAddCheckOverflowCqR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    sqInt aWord4;
    sqInt aWord5;
    sqInt aWord6;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeAddCheckOverflowCqR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeAddCheckOverflowCqR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeAddCheckOverflowCqR, AT, high16BitsOf(self_in_concretizeAddCheckOverflowCqR, rightImm));
	((self_in_concretizeAddCheckOverflowCqR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeAddCheckOverflowCqR, AT, AT, low16BitsOf(self_in_concretizeAddCheckOverflowCqR, rightImm));
	((self_in_concretizeAddCheckOverflowCqR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = adduRRR(self_in_concretizeAddCheckOverflowCqR, OverflowTemp1, leftReg, ZR);
	((self_in_concretizeAddCheckOverflowCqR->machineCode))[8 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = adduRRR(self_in_concretizeAddCheckOverflowCqR, destReg, leftReg, AT);
	((self_in_concretizeAddCheckOverflowCqR->machineCode))[12 / 4] = aWord3;
	/* begin machineCodeAt:put: */
	aWord4 = xorRRR(self_in_concretizeAddCheckOverflowCqR, OverflowTemp2, destReg, AT);
	((self_in_concretizeAddCheckOverflowCqR->machineCode))[16 / 4] = aWord4;
	/* begin machineCodeAt:put: */
	aWord5 = xorRRR(self_in_concretizeAddCheckOverflowCqR, OverflowTemp1, destReg, OverflowTemp1);
	((self_in_concretizeAddCheckOverflowCqR->machineCode))[20 / 4] = aWord5;
	/* begin machineCodeAt:put: */
	aWord6 = andRRR(self_in_concretizeAddCheckOverflowCqR, Overflow, OverflowTemp1, OverflowTemp2);
	((self_in_concretizeAddCheckOverflowCqR->machineCode))[24 / 4] = aWord6;
	return ((self_in_concretizeAddCheckOverflowCqR->machineCodeSize) = 28);
}

	/* CogMIPSELCompiler>>#concretizeAddCheckOverflowRR */
static usqInt NoDbgRegParms
concretizeAddCheckOverflowRR(AbstractInstruction * self_in_concretizeAddCheckOverflowRR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    sqInt aWord4;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightReg;

	rightReg = ((self_in_concretizeAddCheckOverflowRR->operands))[0];

	/* Save original LHS */
	destReg = (leftReg = ((self_in_concretizeAddCheckOverflowRR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = adduRRR(self_in_concretizeAddCheckOverflowRR, OverflowTemp1, leftReg, ZR);
	((self_in_concretizeAddCheckOverflowRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = adduRRR(self_in_concretizeAddCheckOverflowRR, destReg, leftReg, rightReg);
	((self_in_concretizeAddCheckOverflowRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = xorRRR(self_in_concretizeAddCheckOverflowRR, OverflowTemp2, destReg, rightReg);
	((self_in_concretizeAddCheckOverflowRR->machineCode))[8 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = xorRRR(self_in_concretizeAddCheckOverflowRR, OverflowTemp1, destReg, OverflowTemp1);
	((self_in_concretizeAddCheckOverflowRR->machineCode))[12 / 4] = aWord3;
	/* begin machineCodeAt:put: */
	aWord4 = andRRR(self_in_concretizeAddCheckOverflowRR, Overflow, OverflowTemp1, OverflowTemp2);
	((self_in_concretizeAddCheckOverflowRR->machineCode))[16 / 4] = aWord4;
	return ((self_in_concretizeAddCheckOverflowRR->machineCodeSize) = 20);
}

	/* CogMIPSELCompiler>>#concretizeAddCqR */
static usqInt NoDbgRegParms
concretizeAddCqR(AbstractInstruction * self_in_concretizeAddCqR)
{
    sqInt aWord;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeAddCqR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeAddCqR->operands))[1]);
	if (!(((rightImm >= -32768) && (rightImm <= 0x7FFF)))) {
		return concretizeAddCwR(self_in_concretizeAddCqR);
	}
	/* begin machineCodeAt:put: */
	aWord = addiuRRC(self_in_concretizeAddCqR, destReg, leftReg, rightImm);
	((self_in_concretizeAddCqR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeAddCqR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeAddCwR */
static usqInt NoDbgRegParms
concretizeAddCwR(AbstractInstruction * self_in_concretizeAddCwR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeAddCwR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeAddCwR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeAddCwR, AT, high16BitsOf(self_in_concretizeAddCwR, rightImm));
	((self_in_concretizeAddCwR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeAddCwR, AT, AT, low16BitsOf(self_in_concretizeAddCwR, rightImm));
	((self_in_concretizeAddCwR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = adduRRR(self_in_concretizeAddCwR, destReg, leftReg, AT);
	((self_in_concretizeAddCwR->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizeAddCwR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeAddRR */
static usqInt NoDbgRegParms
concretizeAddRR(AbstractInstruction * self_in_concretizeAddRR)
{
    sqInt aWord;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightReg;

	rightReg = ((self_in_concretizeAddRR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeAddRR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = adduRRR(self_in_concretizeAddRR, destReg, leftReg, rightReg);
	((self_in_concretizeAddRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeAddRR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeAlignmentNops */
static AbstractInstruction * NoDbgRegParms
concretizeAlignmentNops(AbstractInstruction * self_in_concretizeAlignmentNops)
{
    sqInt p;

	assert((((self_in_concretizeAlignmentNops->machineCodeSize)) % 4) == 0);
	for (p = 0; p < ((self_in_concretizeAlignmentNops->machineCodeSize)); p += 4) {
		/* begin machineCodeAt:put: */
		((self_in_concretizeAlignmentNops->machineCode))[p / 4] = 0;
	}
	return self_in_concretizeAlignmentNops;
}

	/* CogMIPSELCompiler>>#concretizeAndCqR */
static usqInt NoDbgRegParms
concretizeAndCqR(AbstractInstruction * self_in_concretizeAndCqR)
{
    sqInt aWord;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeAndCqR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeAndCqR->operands))[1]);
	if (!(((rightImm >= -32768) && (rightImm <= 0x7FFF)))) {
		return concretizeAndCwR(self_in_concretizeAndCqR);
	}
	/* begin machineCodeAt:put: */
	aWord = andiRRC(self_in_concretizeAndCqR, destReg, leftReg, rightImm);
	((self_in_concretizeAndCqR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeAndCqR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeAndCqRR */
static usqInt NoDbgRegParms
concretizeAndCqRR(AbstractInstruction * self_in_concretizeAndCqRR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    unsigned long dstReg;
    unsigned long srcReg;
    unsigned long value;

	value = ((self_in_concretizeAndCqRR->operands))[0];
	srcReg = ((self_in_concretizeAndCqRR->operands))[1];
	dstReg = ((self_in_concretizeAndCqRR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeAndCqRR, AT, high16BitsOf(self_in_concretizeAndCqRR, value));
	((self_in_concretizeAndCqRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeAndCqRR, AT, AT, low16BitsOf(self_in_concretizeAndCqRR, value));
	((self_in_concretizeAndCqRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = andRRR(self_in_concretizeAndCqRR, dstReg, srcReg, AT);
	((self_in_concretizeAndCqRR->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizeAndCqRR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeAndCwR */
static usqInt NoDbgRegParms
concretizeAndCwR(AbstractInstruction * self_in_concretizeAndCwR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeAndCwR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeAndCwR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeAndCwR, AT, high16BitsOf(self_in_concretizeAndCwR, rightImm));
	((self_in_concretizeAndCwR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeAndCwR, AT, AT, low16BitsOf(self_in_concretizeAndCwR, rightImm));
	((self_in_concretizeAndCwR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = andRRR(self_in_concretizeAndCwR, destReg, leftReg, AT);
	((self_in_concretizeAndCwR->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizeAndCwR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeAndRR */
static usqInt NoDbgRegParms
concretizeAndRR(AbstractInstruction * self_in_concretizeAndRR)
{
    sqInt aWord;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightReg;

	rightReg = ((self_in_concretizeAndRR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeAndRR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = andRRR(self_in_concretizeAndRR, destReg, leftReg, rightReg);
	((self_in_concretizeAndRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeAndRR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeArithmeticShiftRightCqR */
static usqInt NoDbgRegParms
concretizeArithmeticShiftRightCqR(AbstractInstruction * self_in_concretizeArithmeticShiftRightCqR)
{
    sqInt aWord;
    sqInt distance;
    unsigned long reg;

	distance = (((((self_in_concretizeArithmeticShiftRightCqR->operands))[0]) < 0x1F) ? (((self_in_concretizeArithmeticShiftRightCqR->operands))[0]) : 0x1F);
	reg = ((self_in_concretizeArithmeticShiftRightCqR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = sraRRC(self_in_concretizeArithmeticShiftRightCqR, reg, reg, distance);
	((self_in_concretizeArithmeticShiftRightCqR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeArithmeticShiftRightCqR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeArithmeticShiftRightRR */
static usqInt NoDbgRegParms
concretizeArithmeticShiftRightRR(AbstractInstruction * self_in_concretizeArithmeticShiftRightRR)
{
    sqInt aWord;
    unsigned long destReg;
    unsigned long distReg;

	distReg = ((self_in_concretizeArithmeticShiftRightRR->operands))[0];
	destReg = ((self_in_concretizeArithmeticShiftRightRR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = sravRRR(self_in_concretizeArithmeticShiftRightRR, destReg, destReg, distReg);
	((self_in_concretizeArithmeticShiftRightRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeArithmeticShiftRightRR->machineCodeSize) = 4);
}


/*	Generate concrete machine code for the instruction at actualAddress,
	setting machineCodeSize, and answer the following address. */
/*	Generate concrete machine code for the instruction at actualAddress,
	setting machineCodeSize, and answer the following address. */

	/* CogMIPSELCompiler>>#concretizeAt: */
static sqInt NoDbgRegParms
concretizeAt(AbstractInstruction * self_in_concretizeAt, sqInt actualAddress)
{
	assert((actualAddress % 4) == 0);
	(self_in_concretizeAt->address) = actualAddress;
	dispatchConcretize(self_in_concretizeAt);
	assert((((self_in_concretizeAt->maxSize)) == null)
	 || (((self_in_concretizeAt->maxSize)) >= ((self_in_concretizeAt->machineCodeSize))));
	return actualAddress + ((self_in_concretizeAt->machineCodeSize));
}

	/* CogMIPSELCompiler>>#concretizeBrEqualRR */
static usqInt NoDbgRegParms
concretizeBrEqualRR(AbstractInstruction * self_in_concretizeBrEqualRR)
{
    sqInt aWord;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrEqualRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrEqualRR->address)) + 4)));
	leftReg = ((self_in_concretizeBrEqualRR->operands))[1];
	rightReg = ((self_in_concretizeBrEqualRR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = beqRRoffset(self_in_concretizeBrEqualRR, leftReg, rightReg, offset);
	((self_in_concretizeBrEqualRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrEqualRR->machineCode))[4 / 4] = 0;
	return ((self_in_concretizeBrEqualRR->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizeBrLongEqualRR */
static usqInt NoDbgRegParms
concretizeBrLongEqualRR(AbstractInstruction * self_in_concretizeBrLongEqualRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    usqInt jumpTargetAddr;
    AbstractInstruction *jumpTargetInstruction;
    unsigned long leftReg;
    unsigned long rightReg;

	/* begin longJumpTargetAddress */
	jumpTarget = ((AbstractInstruction *) (((self_in_concretizeBrLongEqualRR->operands))[0]));
	if ((addressIsInInstructions(jumpTarget))
	 || (jumpTarget == (methodLabel()))) {
		jumpTarget = ((AbstractInstruction *) ((jumpTarget->address)));
	}
	assert(jumpTarget != 0);
	jumpTargetInstruction = jumpTarget;
	flag("todo");
	jumpTargetAddr = (((usqInt)jumpTargetInstruction)) & 0xFFFFFFF;
	leftReg = ((self_in_concretizeBrLongEqualRR->operands))[1];
	rightReg = ((self_in_concretizeBrLongEqualRR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = bneRRoffset(self_in_concretizeBrLongEqualRR, leftReg, rightReg, 12);
	((self_in_concretizeBrLongEqualRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrLongEqualRR->machineCode))[4 / 4] = 0;
	/* begin machineCodeAt:put: */
	aWord1 = jA(self_in_concretizeBrLongEqualRR, jumpTargetAddr);
	((self_in_concretizeBrLongEqualRR->machineCode))[8 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrLongEqualRR->machineCode))[12 / 4] = 0;
	return ((self_in_concretizeBrLongEqualRR->machineCodeSize) = 16);
}

	/* CogMIPSELCompiler>>#concretizeBrLongNotEqualRR */
static usqInt NoDbgRegParms
concretizeBrLongNotEqualRR(AbstractInstruction * self_in_concretizeBrLongNotEqualRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    usqInt jumpTargetAddr;
    AbstractInstruction *jumpTargetInstruction;
    unsigned long leftReg;
    unsigned long rightReg;

	/* begin longJumpTargetAddress */
	jumpTarget = ((AbstractInstruction *) (((self_in_concretizeBrLongNotEqualRR->operands))[0]));
	if ((addressIsInInstructions(jumpTarget))
	 || (jumpTarget == (methodLabel()))) {
		jumpTarget = ((AbstractInstruction *) ((jumpTarget->address)));
	}
	assert(jumpTarget != 0);
	jumpTargetInstruction = jumpTarget;
	flag("todo");
	jumpTargetAddr = (((usqInt)jumpTargetInstruction)) & 0xFFFFFFF;
	leftReg = ((self_in_concretizeBrLongNotEqualRR->operands))[1];
	rightReg = ((self_in_concretizeBrLongNotEqualRR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = beqRRoffset(self_in_concretizeBrLongNotEqualRR, leftReg, rightReg, 12);
	((self_in_concretizeBrLongNotEqualRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrLongNotEqualRR->machineCode))[4 / 4] = 0;
	/* begin machineCodeAt:put: */
	aWord1 = jA(self_in_concretizeBrLongNotEqualRR, jumpTargetAddr);
	((self_in_concretizeBrLongNotEqualRR->machineCode))[8 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrLongNotEqualRR->machineCode))[12 / 4] = 0;
	return ((self_in_concretizeBrLongNotEqualRR->machineCodeSize) = 16);
}

	/* CogMIPSELCompiler>>#concretizeBrNotEqualRR */
static usqInt NoDbgRegParms
concretizeBrNotEqualRR(AbstractInstruction * self_in_concretizeBrNotEqualRR)
{
    sqInt aWord;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrNotEqualRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrNotEqualRR->address)) + 4)));
	leftReg = ((self_in_concretizeBrNotEqualRR->operands))[1];
	rightReg = ((self_in_concretizeBrNotEqualRR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = bneRRoffset(self_in_concretizeBrNotEqualRR, leftReg, rightReg, offset);
	((self_in_concretizeBrNotEqualRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrNotEqualRR->machineCode))[4 / 4] = 0;
	return ((self_in_concretizeBrNotEqualRR->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizeBrSignedGreaterEqualRR */
static usqInt NoDbgRegParms
concretizeBrSignedGreaterEqualRR(AbstractInstruction * self_in_concretizeBrSignedGreaterEqualRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrSignedGreaterEqualRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrSignedGreaterEqualRR->address)) + 8)));
	leftReg = ((self_in_concretizeBrSignedGreaterEqualRR->operands))[1];
	rightReg = ((self_in_concretizeBrSignedGreaterEqualRR->operands))[2];
	assert(leftReg != BranchTemp);
	assert(rightReg != BranchTemp);
	/* begin machineCodeAt:put: */
	aWord = sltRRR(self_in_concretizeBrSignedGreaterEqualRR, BranchTemp, leftReg, rightReg);
	((self_in_concretizeBrSignedGreaterEqualRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = beqRRoffset(self_in_concretizeBrSignedGreaterEqualRR, BranchTemp, ZR, offset);
	((self_in_concretizeBrSignedGreaterEqualRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrSignedGreaterEqualRR->machineCode))[8 / 4] = 0;
	return ((self_in_concretizeBrSignedGreaterEqualRR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeBrSignedGreaterRR */
static usqInt NoDbgRegParms
concretizeBrSignedGreaterRR(AbstractInstruction * self_in_concretizeBrSignedGreaterRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrSignedGreaterRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrSignedGreaterRR->address)) + 8)));
	leftReg = ((self_in_concretizeBrSignedGreaterRR->operands))[1];
	rightReg = ((self_in_concretizeBrSignedGreaterRR->operands))[2];
	assert(leftReg != BranchTemp);
	assert(rightReg != BranchTemp);
	/* begin machineCodeAt:put: */
	aWord = sltRRR(self_in_concretizeBrSignedGreaterRR, BranchTemp, rightReg, leftReg);
	((self_in_concretizeBrSignedGreaterRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = bneRRoffset(self_in_concretizeBrSignedGreaterRR, BranchTemp, ZR, offset);
	((self_in_concretizeBrSignedGreaterRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrSignedGreaterRR->machineCode))[8 / 4] = 0;
	return ((self_in_concretizeBrSignedGreaterRR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeBrSignedLessEqualRR */
static usqInt NoDbgRegParms
concretizeBrSignedLessEqualRR(AbstractInstruction * self_in_concretizeBrSignedLessEqualRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrSignedLessEqualRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrSignedLessEqualRR->address)) + 8)));
	leftReg = ((self_in_concretizeBrSignedLessEqualRR->operands))[1];
	rightReg = ((self_in_concretizeBrSignedLessEqualRR->operands))[2];
	assert(leftReg != BranchTemp);
	assert(rightReg != BranchTemp);
	/* begin machineCodeAt:put: */
	aWord = sltRRR(self_in_concretizeBrSignedLessEqualRR, BranchTemp, rightReg, leftReg);
	((self_in_concretizeBrSignedLessEqualRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = beqRRoffset(self_in_concretizeBrSignedLessEqualRR, BranchTemp, ZR, offset);
	((self_in_concretizeBrSignedLessEqualRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrSignedLessEqualRR->machineCode))[8 / 4] = 0;
	return ((self_in_concretizeBrSignedLessEqualRR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeBrSignedLessRR */
static usqInt NoDbgRegParms
concretizeBrSignedLessRR(AbstractInstruction * self_in_concretizeBrSignedLessRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrSignedLessRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrSignedLessRR->address)) + 8)));
	leftReg = ((self_in_concretizeBrSignedLessRR->operands))[1];
	rightReg = ((self_in_concretizeBrSignedLessRR->operands))[2];
	assert(leftReg != BranchTemp);
	assert(rightReg != BranchTemp);
	/* begin machineCodeAt:put: */
	aWord = sltRRR(self_in_concretizeBrSignedLessRR, BranchTemp, leftReg, rightReg);
	((self_in_concretizeBrSignedLessRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = bneRRoffset(self_in_concretizeBrSignedLessRR, BranchTemp, ZR, offset);
	((self_in_concretizeBrSignedLessRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrSignedLessRR->machineCode))[8 / 4] = 0;
	return ((self_in_concretizeBrSignedLessRR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeBrUnsignedGreaterEqualRR */
static usqInt NoDbgRegParms
concretizeBrUnsignedGreaterEqualRR(AbstractInstruction * self_in_concretizeBrUnsignedGreaterEqualRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrUnsignedGreaterEqualRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrUnsignedGreaterEqualRR->address)) + 8)));
	leftReg = ((self_in_concretizeBrUnsignedGreaterEqualRR->operands))[1];
	rightReg = ((self_in_concretizeBrUnsignedGreaterEqualRR->operands))[2];
	assert(leftReg != BranchTemp);
	assert(rightReg != BranchTemp);
	/* begin machineCodeAt:put: */
	aWord = sltuRRR(self_in_concretizeBrUnsignedGreaterEqualRR, BranchTemp, leftReg, rightReg);
	((self_in_concretizeBrUnsignedGreaterEqualRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = beqRRoffset(self_in_concretizeBrUnsignedGreaterEqualRR, BranchTemp, ZR, offset);
	((self_in_concretizeBrUnsignedGreaterEqualRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrUnsignedGreaterEqualRR->machineCode))[8 / 4] = 0;
	return ((self_in_concretizeBrUnsignedGreaterEqualRR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeBrUnsignedGreaterRR */
static usqInt NoDbgRegParms
concretizeBrUnsignedGreaterRR(AbstractInstruction * self_in_concretizeBrUnsignedGreaterRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrUnsignedGreaterRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrUnsignedGreaterRR->address)) + 8)));
	leftReg = ((self_in_concretizeBrUnsignedGreaterRR->operands))[1];
	rightReg = ((self_in_concretizeBrUnsignedGreaterRR->operands))[2];
	assert(leftReg != BranchTemp);
	assert(rightReg != BranchTemp);
	/* begin machineCodeAt:put: */
	aWord = sltuRRR(self_in_concretizeBrUnsignedGreaterRR, BranchTemp, rightReg, leftReg);
	((self_in_concretizeBrUnsignedGreaterRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = bneRRoffset(self_in_concretizeBrUnsignedGreaterRR, BranchTemp, ZR, offset);
	((self_in_concretizeBrUnsignedGreaterRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrUnsignedGreaterRR->machineCode))[8 / 4] = 0;
	return ((self_in_concretizeBrUnsignedGreaterRR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeBrUnsignedLessEqualRR */
static usqInt NoDbgRegParms
concretizeBrUnsignedLessEqualRR(AbstractInstruction * self_in_concretizeBrUnsignedLessEqualRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrUnsignedLessEqualRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrUnsignedLessEqualRR->address)) + 8)));
	leftReg = ((self_in_concretizeBrUnsignedLessEqualRR->operands))[1];
	rightReg = ((self_in_concretizeBrUnsignedLessEqualRR->operands))[2];
	assert(leftReg != BranchTemp);
	assert(rightReg != BranchTemp);
	/* begin machineCodeAt:put: */
	aWord = sltuRRR(self_in_concretizeBrUnsignedLessEqualRR, BranchTemp, rightReg, leftReg);
	((self_in_concretizeBrUnsignedLessEqualRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = beqRRoffset(self_in_concretizeBrUnsignedLessEqualRR, BranchTemp, ZR, offset);
	((self_in_concretizeBrUnsignedLessEqualRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrUnsignedLessEqualRR->machineCode))[8 / 4] = 0;
	return ((self_in_concretizeBrUnsignedLessEqualRR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeBrUnsignedLessRR */
static usqInt NoDbgRegParms
concretizeBrUnsignedLessRR(AbstractInstruction * self_in_concretizeBrUnsignedLessRR)
{
    sqInt aWord;
    sqInt aWord1;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    unsigned long leftReg;
    sqInt offset;
    unsigned long rightReg;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeBrUnsignedLessRR->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeBrUnsignedLessRR->address)) + 8)));
	leftReg = ((self_in_concretizeBrUnsignedLessRR->operands))[1];
	rightReg = ((self_in_concretizeBrUnsignedLessRR->operands))[2];
	assert(leftReg != BranchTemp);
	assert(rightReg != BranchTemp);
	/* begin machineCodeAt:put: */
	aWord = sltuRRR(self_in_concretizeBrUnsignedLessRR, BranchTemp, leftReg, rightReg);
	((self_in_concretizeBrUnsignedLessRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = bneRRoffset(self_in_concretizeBrUnsignedLessRR, BranchTemp, ZR, offset);
	((self_in_concretizeBrUnsignedLessRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	((self_in_concretizeBrUnsignedLessRR->machineCode))[8 / 4] = 0;
	return ((self_in_concretizeBrUnsignedLessRR->machineCodeSize) = 12);
}


/*	Call is used only for calls within code-space, See CallFull for general
	anywhere in address space calling
 */
/*	Relative branches in MIPS have a displacement of +/- 131kB (signed 18
	bits), which is too small to cover
	the method zone. */

	/* CogMIPSELCompiler>>#concretizeCall */
static usqInt NoDbgRegParms
concretizeCall(AbstractInstruction * self_in_concretizeCall)
{
	return concretizeCallFull(self_in_concretizeCall);
}

	/* CogMIPSELCompiler>>#concretizeCallFull */
static usqInt NoDbgRegParms
concretizeCallFull(AbstractInstruction * self_in_concretizeCallFull)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    AbstractInstruction *jumpTarget;
    usqInt jumpTargetAddr;
    AbstractInstruction *jumpTargetInstruction;

	/* begin longJumpTargetAddress */
	jumpTarget = ((AbstractInstruction *) (((self_in_concretizeCallFull->operands))[0]));
	if ((addressIsInInstructions(jumpTarget))
	 || (jumpTarget == (methodLabel()))) {
		jumpTarget = ((AbstractInstruction *) ((jumpTarget->address)));
	}
	assert(jumpTarget != 0);
	jumpTargetInstruction = jumpTarget;
	jumpTargetAddr = ((usqInt)jumpTargetInstruction);
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeCallFull, TargetReg, high16BitsOf(self_in_concretizeCallFull, jumpTargetAddr));
	((self_in_concretizeCallFull->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeCallFull, TargetReg, TargetReg, low16BitsOf(self_in_concretizeCallFull, jumpTargetAddr));
	((self_in_concretizeCallFull->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = jalR(self_in_concretizeCallFull, TargetReg);
	((self_in_concretizeCallFull->machineCode))[8 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	((self_in_concretizeCallFull->machineCode))[12 / 4] = 0;
	return ((self_in_concretizeCallFull->machineCodeSize) = 16);
}

	/* CogMIPSELCompiler>>#concretizeCmpCqR */
static sqInt NoDbgRegParms
concretizeCmpCqR(AbstractInstruction * self_in_concretizeCmpCqR)
{
	return concretizeCmpCwR(self_in_concretizeCmpCqR);
}

	/* CogMIPSELCompiler>>#concretizeCmpCwR */
static sqInt NoDbgRegParms
concretizeCmpCwR(AbstractInstruction * self_in_concretizeCmpCwR)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeCmpRR */
static sqInt NoDbgRegParms
concretizeCmpRR(AbstractInstruction * self_in_concretizeCmpRR)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeDivRR */
static usqInt NoDbgRegParms
concretizeDivRR(AbstractInstruction * self_in_concretizeDivRR)
{
    sqInt aWord;
    unsigned long dividendReg;
    unsigned long divisorReg;

	dividendReg = ((self_in_concretizeDivRR->operands))[0];
	divisorReg = ((self_in_concretizeDivRR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = divRR(self_in_concretizeDivRR, dividendReg, divisorReg);
	((self_in_concretizeDivRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeDivRR->machineCodeSize) = 4);
}


/*	fill with operand 0 according to the processor's endianness.
	You might think this is bogus and we should fill with stop instrurctions
	instead, but this is used to leave room for a CMBlock header before the
	code for a block;
	the gaps get filled in by fillInBlockHeadersAt: after code has been
	generated.  */

	/* CogMIPSELCompiler>>#concretizeFill32 */
static usqInt NoDbgRegParms
concretizeFill32(AbstractInstruction * self_in_concretizeFill32)
{
    sqInt aWord;

	/* begin machineCodeAt:put: */
	aWord = ((self_in_concretizeFill32->operands))[0];
	((self_in_concretizeFill32->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeFill32->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeJump */
static usqInt NoDbgRegParms
concretizeJump(AbstractInstruction * self_in_concretizeJump)
{
    sqInt aWord;
    AbstractInstruction *jumpTarget;
    AbstractInstruction *jumpTarget1;
    sqInt offset;

	/* begin computeJumpTargetOffsetPlus: */
	jumpTarget1 = ((AbstractInstruction *) (((self_in_concretizeJump->operands))[0]));
	assertSaneJumpTarget(jumpTarget1);
	if ((addressIsInInstructions(jumpTarget1))
	 || (jumpTarget1 == (methodLabel()))) {
		jumpTarget1 = ((AbstractInstruction *) ((jumpTarget1->address)));
	}
	assert(jumpTarget1 != 0);
	jumpTarget = jumpTarget1;
	offset = (((int) jumpTarget)) - (((int) (((self_in_concretizeJump->address)) + 4)));
	flag("BranchRange");
	/* begin machineCodeAt:put: */
	aWord = beqRRoffset(self_in_concretizeJump, ZR, ZR, offset);
	((self_in_concretizeJump->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	((self_in_concretizeJump->machineCode))[4 / 4] = 0;
	return ((self_in_concretizeJump->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizeJumpFull */
static usqInt NoDbgRegParms
concretizeJumpFull(AbstractInstruction * self_in_concretizeJumpFull)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    AbstractInstruction *jumpTarget;
    usqInt jumpTargetAddr;
    AbstractInstruction *jumpTargetInstruction;

	/* begin longJumpTargetAddress */
	jumpTarget = ((AbstractInstruction *) (((self_in_concretizeJumpFull->operands))[0]));
	if ((addressIsInInstructions(jumpTarget))
	 || (jumpTarget == (methodLabel()))) {
		jumpTarget = ((AbstractInstruction *) ((jumpTarget->address)));
	}
	assert(jumpTarget != 0);
	jumpTargetInstruction = jumpTarget;
	jumpTargetAddr = ((usqInt)jumpTargetInstruction);
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeJumpFull, TargetReg, high16BitsOf(self_in_concretizeJumpFull, jumpTargetAddr));
	((self_in_concretizeJumpFull->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeJumpFull, TargetReg, TargetReg, low16BitsOf(self_in_concretizeJumpFull, jumpTargetAddr));
	((self_in_concretizeJumpFull->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = jR(self_in_concretizeJumpFull, TargetReg);
	((self_in_concretizeJumpFull->machineCode))[8 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	((self_in_concretizeJumpFull->machineCode))[12 / 4] = 0;
	return ((self_in_concretizeJumpFull->machineCodeSize) = 16);
}

	/* CogMIPSELCompiler>>#concretizeJumpLong */
static usqInt NoDbgRegParms
concretizeJumpLong(AbstractInstruction * self_in_concretizeJumpLong)
{
	return concretizeJumpFull(self_in_concretizeJumpLong);
}

	/* CogMIPSELCompiler>>#concretizeJumpLongNonZero */
static sqInt NoDbgRegParms
concretizeJumpLongNonZero(AbstractInstruction * self_in_concretizeJumpLongNonZero)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpLongZero */
static sqInt NoDbgRegParms
concretizeJumpLongZero(AbstractInstruction * self_in_concretizeJumpLongZero)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpNonZero */
static sqInt NoDbgRegParms
concretizeJumpNonZero(AbstractInstruction * self_in_concretizeJumpNonZero)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpNoOverflow */
static sqInt NoDbgRegParms
concretizeJumpNoOverflow(AbstractInstruction * self_in_concretizeJumpNoOverflow)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpOverflow */
static sqInt NoDbgRegParms
concretizeJumpOverflow(AbstractInstruction * self_in_concretizeJumpOverflow)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpR */
static usqInt NoDbgRegParms
concretizeJumpR(AbstractInstruction * self_in_concretizeJumpR)
{
    sqInt aWord;
    unsigned long reg;

	flag("OABI");
	reg = ((self_in_concretizeJumpR->operands))[0];
	/* begin machineCodeAt:put: */
	aWord = jR(self_in_concretizeJumpR, reg);
	((self_in_concretizeJumpR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	((self_in_concretizeJumpR->machineCode))[4 / 4] = 0;
	return ((self_in_concretizeJumpR->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizeJumpSignedGreaterEqual */
static sqInt NoDbgRegParms
concretizeJumpSignedGreaterEqual(AbstractInstruction * self_in_concretizeJumpSignedGreaterEqual)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpSignedGreaterThan */
static sqInt NoDbgRegParms
concretizeJumpSignedGreaterThan(AbstractInstruction * self_in_concretizeJumpSignedGreaterThan)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpSignedLessEqual */
static sqInt NoDbgRegParms
concretizeJumpSignedLessEqual(AbstractInstruction * self_in_concretizeJumpSignedLessEqual)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpSignedLessThan */
static sqInt NoDbgRegParms
concretizeJumpSignedLessThan(AbstractInstruction * self_in_concretizeJumpSignedLessThan)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpUnsignedGreaterEqual */
static sqInt NoDbgRegParms
concretizeJumpUnsignedGreaterEqual(AbstractInstruction * self_in_concretizeJumpUnsignedGreaterEqual)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpUnsignedGreaterThan */
static sqInt NoDbgRegParms
concretizeJumpUnsignedGreaterThan(AbstractInstruction * self_in_concretizeJumpUnsignedGreaterThan)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpUnsignedLessEqual */
static sqInt NoDbgRegParms
concretizeJumpUnsignedLessEqual(AbstractInstruction * self_in_concretizeJumpUnsignedLessEqual)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpUnsignedLessThan */
static sqInt NoDbgRegParms
concretizeJumpUnsignedLessThan(AbstractInstruction * self_in_concretizeJumpUnsignedLessThan)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeJumpZero */
static sqInt NoDbgRegParms
concretizeJumpZero(AbstractInstruction * self_in_concretizeJumpZero)
{
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeLoadEffectiveAddressMwrR */
static usqInt NoDbgRegParms
concretizeLoadEffectiveAddressMwrR(AbstractInstruction * self_in_concretizeLoadEffectiveAddressMwrR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    unsigned long baseReg;
    unsigned long destReg;
    sqInt offset;

	offset = ((self_in_concretizeLoadEffectiveAddressMwrR->operands))[0];
	baseReg = ((self_in_concretizeLoadEffectiveAddressMwrR->operands))[1];
	destReg = ((self_in_concretizeLoadEffectiveAddressMwrR->operands))[2];
	if (isShortOffset(self_in_concretizeLoadEffectiveAddressMwrR, offset)) {
		/* begin machineCodeAt:put: */
		aWord = addiuRRC(self_in_concretizeLoadEffectiveAddressMwrR, destReg, baseReg, offset);
		((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[0 / 4] = aWord;
		return ((self_in_concretizeLoadEffectiveAddressMwrR->machineCodeSize) = 4);
	}
	/* begin machineCodeAt:put: */
	aWord1 = luiRC(self_in_concretizeLoadEffectiveAddressMwrR, AT, high16BitsOf(self_in_concretizeLoadEffectiveAddressMwrR, offset));
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[0 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = oriRRC(self_in_concretizeLoadEffectiveAddressMwrR, AT, AT, low16BitsOf(self_in_concretizeLoadEffectiveAddressMwrR, offset));
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[4 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = adduRRR(self_in_concretizeLoadEffectiveAddressMwrR, destReg, baseReg, AT);
	((self_in_concretizeLoadEffectiveAddressMwrR->machineCode))[8 / 4] = aWord3;
	return ((self_in_concretizeLoadEffectiveAddressMwrR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeLogicalShiftLeftCqR */
static usqInt NoDbgRegParms
concretizeLogicalShiftLeftCqR(AbstractInstruction * self_in_concretizeLogicalShiftLeftCqR)
{
    sqInt aWord;
    sqInt distance;
    unsigned long reg;

	distance = (((((self_in_concretizeLogicalShiftLeftCqR->operands))[0]) < 0x1F) ? (((self_in_concretizeLogicalShiftLeftCqR->operands))[0]) : 0x1F);
	reg = ((self_in_concretizeLogicalShiftLeftCqR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = sllRRC(self_in_concretizeLogicalShiftLeftCqR, reg, reg, distance);
	((self_in_concretizeLogicalShiftLeftCqR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeLogicalShiftLeftCqR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeLogicalShiftLeftRR */
static usqInt NoDbgRegParms
concretizeLogicalShiftLeftRR(AbstractInstruction * self_in_concretizeLogicalShiftLeftRR)
{
    sqInt aWord;
    unsigned long destReg;
    unsigned long distReg;

	distReg = ((self_in_concretizeLogicalShiftLeftRR->operands))[0];
	destReg = ((self_in_concretizeLogicalShiftLeftRR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = sllvRRR(self_in_concretizeLogicalShiftLeftRR, destReg, destReg, distReg);
	((self_in_concretizeLogicalShiftLeftRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeLogicalShiftLeftRR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeLogicalShiftRightCqR */
static usqInt NoDbgRegParms
concretizeLogicalShiftRightCqR(AbstractInstruction * self_in_concretizeLogicalShiftRightCqR)
{
    sqInt aWord;
    sqInt distance;
    unsigned long reg;

	distance = (((((self_in_concretizeLogicalShiftRightCqR->operands))[0]) < 0x1F) ? (((self_in_concretizeLogicalShiftRightCqR->operands))[0]) : 0x1F);
	reg = ((self_in_concretizeLogicalShiftRightCqR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = srlRRC(self_in_concretizeLogicalShiftRightCqR, reg, reg, distance);
	((self_in_concretizeLogicalShiftRightCqR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeLogicalShiftRightCqR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeLogicalShiftRightRR */
static usqInt NoDbgRegParms
concretizeLogicalShiftRightRR(AbstractInstruction * self_in_concretizeLogicalShiftRightRR)
{
    sqInt aWord;
    unsigned long destReg;
    unsigned long distReg;

	distReg = ((self_in_concretizeLogicalShiftRightRR->operands))[0];
	destReg = ((self_in_concretizeLogicalShiftRightRR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = srlvRRR(self_in_concretizeLogicalShiftRightRR, destReg, destReg, distReg);
	((self_in_concretizeLogicalShiftRightRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeLogicalShiftRightRR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveAbR */
static usqInt NoDbgRegParms
concretizeMoveAbR(AbstractInstruction * self_in_concretizeMoveAbR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    unsigned long destReg;
    unsigned long srcAddr;

	srcAddr = ((self_in_concretizeMoveAbR->operands))[0];
	destReg = ((self_in_concretizeMoveAbR->operands))[1];
	if ((srcAddr != null)
	 && ((((varBaseAddress()) - (1 << 15)) < srcAddr)
	 && (srcAddr < ((varBaseAddress()) + (1 << 15))))) {
		/* begin machineCodeAt:put: */
		aWord = lwRbaseoffset(self_in_concretizeMoveAbR, destReg, ConcreteVarBaseReg, srcAddr - (varBaseAddress()));
		((self_in_concretizeMoveAbR->machineCode))[0 / 4] = aWord;
		return ((self_in_concretizeMoveAbR->machineCodeSize) = 4);
	}
	/* begin machineCodeAt:put: */
	aWord1 = luiRC(self_in_concretizeMoveAbR, AT, high16BitsOf(self_in_concretizeMoveAbR, srcAddr));
	((self_in_concretizeMoveAbR->machineCode))[0 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = oriRRC(self_in_concretizeMoveAbR, AT, AT, low16BitsOf(self_in_concretizeMoveAbR, srcAddr));
	((self_in_concretizeMoveAbR->machineCode))[4 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = lbuRbaseoffset(self_in_concretizeMoveAbR, destReg, AT, 0);
	((self_in_concretizeMoveAbR->machineCode))[8 / 4] = aWord3;
	return ((self_in_concretizeMoveAbR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeMoveAwR */
static usqInt NoDbgRegParms
concretizeMoveAwR(AbstractInstruction * self_in_concretizeMoveAwR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    unsigned long destReg;
    unsigned long srcAddr;

	srcAddr = ((self_in_concretizeMoveAwR->operands))[0];
	destReg = ((self_in_concretizeMoveAwR->operands))[1];
	if ((srcAddr != null)
	 && ((((varBaseAddress()) - (1 << 15)) < srcAddr)
	 && (srcAddr < ((varBaseAddress()) + (1 << 15))))) {
		/* begin machineCodeAt:put: */
		aWord = lwRbaseoffset(self_in_concretizeMoveAwR, destReg, ConcreteVarBaseReg, srcAddr - (varBaseAddress()));
		((self_in_concretizeMoveAwR->machineCode))[0 / 4] = aWord;
		return ((self_in_concretizeMoveAwR->machineCodeSize) = 4);
	}
	/* begin machineCodeAt:put: */
	aWord1 = luiRC(self_in_concretizeMoveAwR, AT, high16BitsOf(self_in_concretizeMoveAwR, srcAddr));
	((self_in_concretizeMoveAwR->machineCode))[0 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = oriRRC(self_in_concretizeMoveAwR, AT, AT, low16BitsOf(self_in_concretizeMoveAwR, srcAddr));
	((self_in_concretizeMoveAwR->machineCode))[4 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = lwRbaseoffset(self_in_concretizeMoveAwR, destReg, AT, 0);
	((self_in_concretizeMoveAwR->machineCode))[8 / 4] = aWord3;
	return ((self_in_concretizeMoveAwR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeMoveCqR */
static usqInt NoDbgRegParms
concretizeMoveCqR(AbstractInstruction * self_in_concretizeMoveCqR)
{
    sqInt aWord;
    unsigned long reg;
    sqInt word;

	word = ((self_in_concretizeMoveCqR->operands))[0];
	reg = ((self_in_concretizeMoveCqR->operands))[1];
	if (!(((word >= -32768) && (word <= 0x7FFF)))) {
		return concretizeMoveCwR(self_in_concretizeMoveCqR);
	}
	/* begin machineCodeAt:put: */
	aWord = addiuRRC(self_in_concretizeMoveCqR, reg, ZR, word);
	((self_in_concretizeMoveCqR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeMoveCqR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveCwR */
static usqInt NoDbgRegParms
concretizeMoveCwR(AbstractInstruction * self_in_concretizeMoveCwR)
{
    sqInt aWord;
    sqInt aWord1;
    unsigned long reg;
    sqInt word;

	word = ((self_in_concretizeMoveCwR->operands))[0];
	reg = ((self_in_concretizeMoveCwR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeMoveCwR, reg, high16BitsOf(self_in_concretizeMoveCwR, word));
	((self_in_concretizeMoveCwR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeMoveCwR, reg, reg, low16BitsOf(self_in_concretizeMoveCwR, word));
	((self_in_concretizeMoveCwR->machineCode))[4 / 4] = aWord1;
	return ((self_in_concretizeMoveCwR->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizeMoveHighR */
static usqInt NoDbgRegParms
concretizeMoveHighR(AbstractInstruction * self_in_concretizeMoveHighR)
{
    sqInt aWord;
    unsigned long destReg;

	destReg = ((self_in_concretizeMoveHighR->operands))[0];
	/* begin machineCodeAt:put: */
	aWord = mfhiR(self_in_concretizeMoveHighR, destReg);
	((self_in_concretizeMoveHighR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeMoveHighR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveLowR */
static usqInt NoDbgRegParms
concretizeMoveLowR(AbstractInstruction * self_in_concretizeMoveLowR)
{
    sqInt aWord;
    unsigned long destReg;

	destReg = ((self_in_concretizeMoveLowR->operands))[0];
	/* begin machineCodeAt:put: */
	aWord = mfloR(self_in_concretizeMoveLowR, destReg);
	((self_in_concretizeMoveLowR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeMoveLowR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveM16rR */
static usqInt NoDbgRegParms
concretizeMoveM16rR(AbstractInstruction * self_in_concretizeMoveM16rR)
{
    sqInt aWord;
    unsigned long destReg;
    sqInt offset;
    unsigned long srcReg;

	offset = ((self_in_concretizeMoveM16rR->operands))[0];
	srcReg = ((self_in_concretizeMoveM16rR->operands))[1];
	destReg = ((self_in_concretizeMoveM16rR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = lhuRbaseoffset(self_in_concretizeMoveM16rR, destReg, srcReg, offset);
	((self_in_concretizeMoveM16rR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeMoveM16rR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveMbrR */
static usqInt NoDbgRegParms
concretizeMoveMbrR(AbstractInstruction * self_in_concretizeMoveMbrR)
{
    sqInt aWord;
    unsigned long destReg;
    sqInt offset;
    unsigned long srcReg;

	offset = ((self_in_concretizeMoveMbrR->operands))[0];
	srcReg = ((self_in_concretizeMoveMbrR->operands))[1];
	destReg = ((self_in_concretizeMoveMbrR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = lbuRbaseoffset(self_in_concretizeMoveMbrR, destReg, srcReg, offset);
	((self_in_concretizeMoveMbrR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeMoveMbrR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveMwrR */
static usqInt NoDbgRegParms
concretizeMoveMwrR(AbstractInstruction * self_in_concretizeMoveMwrR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    sqInt aWord4;
    unsigned long baseReg;
    unsigned long destReg;
    sqInt offset;

	offset = ((self_in_concretizeMoveMwrR->operands))[0];
	baseReg = ((self_in_concretizeMoveMwrR->operands))[1];
	destReg = ((self_in_concretizeMoveMwrR->operands))[2];
	if (isShortOffset(self_in_concretizeMoveMwrR, offset)) {
		/* begin machineCodeAt:put: */
		aWord = lwRbaseoffset(self_in_concretizeMoveMwrR, destReg, baseReg, offset);
		((self_in_concretizeMoveMwrR->machineCode))[0 / 4] = aWord;
		return ((self_in_concretizeMoveMwrR->machineCodeSize) = 4);
	}
	/* begin machineCodeAt:put: */
	aWord1 = luiRC(self_in_concretizeMoveMwrR, AT, high16BitsOf(self_in_concretizeMoveMwrR, offset));
	((self_in_concretizeMoveMwrR->machineCode))[0 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = oriRRC(self_in_concretizeMoveMwrR, AT, AT, low16BitsOf(self_in_concretizeMoveMwrR, offset));
	((self_in_concretizeMoveMwrR->machineCode))[4 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = adduRRR(self_in_concretizeMoveMwrR, AT, baseReg, AT);
	((self_in_concretizeMoveMwrR->machineCode))[8 / 4] = aWord3;
	/* begin machineCodeAt:put: */
	aWord4 = lwRbaseoffset(self_in_concretizeMoveMwrR, destReg, AT, 0);
	((self_in_concretizeMoveMwrR->machineCode))[12 / 4] = aWord4;
	return ((self_in_concretizeMoveMwrR->machineCodeSize) = 16);
}

	/* CogMIPSELCompiler>>#concretizeMoveRAb */
static usqInt NoDbgRegParms
concretizeMoveRAb(AbstractInstruction * self_in_concretizeMoveRAb)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    unsigned long destAddr;
    unsigned long srcReg;

	srcReg = ((self_in_concretizeMoveRAb->operands))[0];
	destAddr = ((self_in_concretizeMoveRAb->operands))[1];
	if ((destAddr != null)
	 && ((((varBaseAddress()) - (1 << 15)) < destAddr)
	 && (destAddr < ((varBaseAddress()) + (1 << 15))))) {
		/* begin machineCodeAt:put: */
		aWord = swRbaseoffset(self_in_concretizeMoveRAb, srcReg, ConcreteVarBaseReg, destAddr - (varBaseAddress()));
		((self_in_concretizeMoveRAb->machineCode))[0 / 4] = aWord;
		return ((self_in_concretizeMoveRAb->machineCodeSize) = 4);
	}
	/* begin machineCodeAt:put: */
	aWord1 = luiRC(self_in_concretizeMoveRAb, AT, high16BitsOf(self_in_concretizeMoveRAb, destAddr));
	((self_in_concretizeMoveRAb->machineCode))[0 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = oriRRC(self_in_concretizeMoveRAb, AT, AT, low16BitsOf(self_in_concretizeMoveRAb, destAddr));
	((self_in_concretizeMoveRAb->machineCode))[4 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = sbRbaseoffset(self_in_concretizeMoveRAb, srcReg, AT, 0);
	((self_in_concretizeMoveRAb->machineCode))[8 / 4] = aWord3;
	return ((self_in_concretizeMoveRAb->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeMoveRAw */
static usqInt NoDbgRegParms
concretizeMoveRAw(AbstractInstruction * self_in_concretizeMoveRAw)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    unsigned long destAddr;
    unsigned long srcReg;

	srcReg = ((self_in_concretizeMoveRAw->operands))[0];
	destAddr = ((self_in_concretizeMoveRAw->operands))[1];
	if ((destAddr != null)
	 && ((((varBaseAddress()) - (1 << 15)) < destAddr)
	 && (destAddr < ((varBaseAddress()) + (1 << 15))))) {
		/* begin machineCodeAt:put: */
		aWord = swRbaseoffset(self_in_concretizeMoveRAw, srcReg, ConcreteVarBaseReg, destAddr - (varBaseAddress()));
		((self_in_concretizeMoveRAw->machineCode))[0 / 4] = aWord;
		return ((self_in_concretizeMoveRAw->machineCodeSize) = 4);
	}
	/* begin machineCodeAt:put: */
	aWord1 = luiRC(self_in_concretizeMoveRAw, AT, high16BitsOf(self_in_concretizeMoveRAw, destAddr));
	((self_in_concretizeMoveRAw->machineCode))[0 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = oriRRC(self_in_concretizeMoveRAw, AT, AT, low16BitsOf(self_in_concretizeMoveRAw, destAddr));
	((self_in_concretizeMoveRAw->machineCode))[4 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = swRbaseoffset(self_in_concretizeMoveRAw, srcReg, AT, 0);
	((self_in_concretizeMoveRAw->machineCode))[8 / 4] = aWord3;
	return ((self_in_concretizeMoveRAw->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeMoveRM16r */
static usqInt NoDbgRegParms
concretizeMoveRM16r(AbstractInstruction * self_in_concretizeMoveRM16r)
{
    sqInt aWord;
    unsigned long destReg;
    sqInt offset;
    unsigned long srcReg;

	srcReg = ((self_in_concretizeMoveRM16r->operands))[0];
	offset = ((self_in_concretizeMoveRM16r->operands))[1];
	destReg = ((self_in_concretizeMoveRM16r->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = shRbaseoffset(self_in_concretizeMoveRM16r, srcReg, destReg, offset);
	((self_in_concretizeMoveRM16r->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeMoveRM16r->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveRMbr */
static usqInt NoDbgRegParms
concretizeMoveRMbr(AbstractInstruction * self_in_concretizeMoveRMbr)
{
    sqInt aWord;
    unsigned long destReg;
    sqInt offset;
    unsigned long srcReg;

	srcReg = ((self_in_concretizeMoveRMbr->operands))[0];
	offset = ((self_in_concretizeMoveRMbr->operands))[1];
	destReg = ((self_in_concretizeMoveRMbr->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = sbRbaseoffset(self_in_concretizeMoveRMbr, srcReg, destReg, offset);
	((self_in_concretizeMoveRMbr->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeMoveRMbr->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveRMwr */
static usqInt NoDbgRegParms
concretizeMoveRMwr(AbstractInstruction * self_in_concretizeMoveRMwr)
{
    sqInt aWord;
    unsigned long baseReg;
    sqInt offset;
    unsigned long srcReg;

	srcReg = ((self_in_concretizeMoveRMwr->operands))[0];
	offset = ((self_in_concretizeMoveRMwr->operands))[1];
	baseReg = ((self_in_concretizeMoveRMwr->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = swRbaseoffset(self_in_concretizeMoveRMwr, srcReg, baseReg, offset);
	((self_in_concretizeMoveRMwr->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeMoveRMwr->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveRR */
static usqInt NoDbgRegParms
concretizeMoveRR(AbstractInstruction * self_in_concretizeMoveRR)
{
    sqInt aWord;
    unsigned long destReg;
    unsigned long srcReg;

	srcReg = ((self_in_concretizeMoveRR->operands))[0];
	destReg = ((self_in_concretizeMoveRR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = adduRRR(self_in_concretizeMoveRR, destReg, srcReg, ZR);
	((self_in_concretizeMoveRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeMoveRR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeMoveRXbrR */
static usqInt NoDbgRegParms
concretizeMoveRXbrR(AbstractInstruction * self_in_concretizeMoveRXbrR)
{
    sqInt aWord;
    sqInt aWord1;
    unsigned long baseReg;
    unsigned long indexReg;
    unsigned long srcReg;

	srcReg = ((self_in_concretizeMoveRXbrR->operands))[0];
	indexReg = ((self_in_concretizeMoveRXbrR->operands))[1];
	baseReg = ((self_in_concretizeMoveRXbrR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = adduRRR(self_in_concretizeMoveRXbrR, AT, baseReg, indexReg);
	((self_in_concretizeMoveRXbrR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = sbRbaseoffset(self_in_concretizeMoveRXbrR, srcReg, AT, 0);
	((self_in_concretizeMoveRXbrR->machineCode))[4 / 4] = aWord1;
	return ((self_in_concretizeMoveRXbrR->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizeMoveRXwrR */
static usqInt NoDbgRegParms
concretizeMoveRXwrR(AbstractInstruction * self_in_concretizeMoveRXwrR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    unsigned long baseReg;
    unsigned long indexReg;
    unsigned long srcReg;

	srcReg = ((self_in_concretizeMoveRXwrR->operands))[0];
	indexReg = ((self_in_concretizeMoveRXwrR->operands))[1];
	baseReg = ((self_in_concretizeMoveRXwrR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = sllRRC(self_in_concretizeMoveRXwrR, AT, indexReg, 2);
	((self_in_concretizeMoveRXwrR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = adduRRR(self_in_concretizeMoveRXwrR, AT, baseReg, AT);
	((self_in_concretizeMoveRXwrR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = swRbaseoffset(self_in_concretizeMoveRXwrR, srcReg, AT, 0);
	((self_in_concretizeMoveRXwrR->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizeMoveRXwrR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeMoveXbrRR */
static usqInt NoDbgRegParms
concretizeMoveXbrRR(AbstractInstruction * self_in_concretizeMoveXbrRR)
{
    sqInt aWord;
    sqInt aWord1;
    unsigned long baseReg;
    unsigned long destReg;
    unsigned long indexReg;


	/* index is number of *bytes* */
	indexReg = ((self_in_concretizeMoveXbrRR->operands))[0];
	baseReg = ((self_in_concretizeMoveXbrRR->operands))[1];
	destReg = ((self_in_concretizeMoveXbrRR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = adduRRR(self_in_concretizeMoveXbrRR, AT, baseReg, indexReg);
	((self_in_concretizeMoveXbrRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = lbuRbaseoffset(self_in_concretizeMoveXbrRR, destReg, AT, 0);
	((self_in_concretizeMoveXbrRR->machineCode))[4 / 4] = aWord1;
	return ((self_in_concretizeMoveXbrRR->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizeMoveXwrRR */
static usqInt NoDbgRegParms
concretizeMoveXwrRR(AbstractInstruction * self_in_concretizeMoveXwrRR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    unsigned long baseReg;
    unsigned long destReg;
    unsigned long indexReg;

	indexReg = ((self_in_concretizeMoveXwrRR->operands))[0];
	baseReg = ((self_in_concretizeMoveXwrRR->operands))[1];
	destReg = ((self_in_concretizeMoveXwrRR->operands))[2];
	/* begin machineCodeAt:put: */
	aWord = sllRRC(self_in_concretizeMoveXwrRR, AT, indexReg, 2);
	((self_in_concretizeMoveXwrRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = adduRRR(self_in_concretizeMoveXwrRR, AT, baseReg, AT);
	((self_in_concretizeMoveXwrRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = lwRbaseoffset(self_in_concretizeMoveXwrRR, destReg, AT, 0);
	((self_in_concretizeMoveXwrRR->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizeMoveXwrRR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeMulCheckOverflowRR */
static usqInt NoDbgRegParms
concretizeMulCheckOverflowRR(AbstractInstruction * self_in_concretizeMulCheckOverflowRR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightReg;

	rightReg = ((self_in_concretizeMulCheckOverflowRR->operands))[0];

	/* Overflow occured if the sign bit of the low part is different from the high part. */
	destReg = (leftReg = ((self_in_concretizeMulCheckOverflowRR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = multRR(self_in_concretizeMulCheckOverflowRR, leftReg, rightReg);
	((self_in_concretizeMulCheckOverflowRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = mfloR(self_in_concretizeMulCheckOverflowRR, destReg);
	((self_in_concretizeMulCheckOverflowRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = sraRRC(self_in_concretizeMulCheckOverflowRR, OverflowTemp1, destReg, 0x1F);
	((self_in_concretizeMulCheckOverflowRR->machineCode))[8 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = mfhiR(self_in_concretizeMulCheckOverflowRR, OverflowTemp2);
	((self_in_concretizeMulCheckOverflowRR->machineCode))[12 / 4] = aWord3;
	return ((self_in_concretizeMulCheckOverflowRR->machineCodeSize) = 16);
}

	/* CogMIPSELCompiler>>#concretizeNegateR */
static usqInt NoDbgRegParms
concretizeNegateR(AbstractInstruction * self_in_concretizeNegateR)
{
    sqInt aWord;
    unsigned long reg;

	reg = ((self_in_concretizeNegateR->operands))[0];
	/* begin machineCodeAt:put: */
	aWord = subuRRR(self_in_concretizeNegateR, reg, ZR, reg);
	((self_in_concretizeNegateR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeNegateR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeNop */
static usqInt NoDbgRegParms
concretizeNop(AbstractInstruction * self_in_concretizeNop)
{
	/* begin machineCodeAt:put: */
	((self_in_concretizeNop->machineCode))[0 / 4] = 0;
	return ((self_in_concretizeNop->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeOrCqR */
static usqInt NoDbgRegParms
concretizeOrCqR(AbstractInstruction * self_in_concretizeOrCqR)
{
    sqInt aWord;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeOrCqR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeOrCqR->operands))[1]);
	if (!(((rightImm >= 0) && (rightImm <= 0xFFFF)))) {
		return concretizeOrCwR(self_in_concretizeOrCqR);
	}
	/* begin machineCodeAt:put: */
	aWord = oriRRC(self_in_concretizeOrCqR, destReg, leftReg, rightImm);
	((self_in_concretizeOrCqR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeOrCqR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeOrCwR */
static usqInt NoDbgRegParms
concretizeOrCwR(AbstractInstruction * self_in_concretizeOrCwR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeOrCwR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeOrCwR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeOrCwR, AT, high16BitsOf(self_in_concretizeOrCwR, rightImm));
	((self_in_concretizeOrCwR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeOrCwR, AT, AT, low16BitsOf(self_in_concretizeOrCwR, rightImm));
	((self_in_concretizeOrCwR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = orRRR(self_in_concretizeOrCwR, destReg, leftReg, AT);
	((self_in_concretizeOrCwR->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizeOrCwR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeOrRR */
static usqInt NoDbgRegParms
concretizeOrRR(AbstractInstruction * self_in_concretizeOrRR)
{
    sqInt aWord;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightReg;

	rightReg = ((self_in_concretizeOrRR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeOrRR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = orRRR(self_in_concretizeOrRR, destReg, leftReg, rightReg);
	((self_in_concretizeOrRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeOrRR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizePopR */
static usqInt NoDbgRegParms
concretizePopR(AbstractInstruction * self_in_concretizePopR)
{
    sqInt aWord;
    sqInt aWord1;
    unsigned long destReg;

	destReg = ((self_in_concretizePopR->operands))[0];
	/* begin machineCodeAt:put: */
	aWord = lwRbaseoffset(self_in_concretizePopR, destReg, SP, 0);
	((self_in_concretizePopR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = addiuRRC(self_in_concretizePopR, SP, SP, 4);
	((self_in_concretizePopR->machineCode))[4 / 4] = aWord1;
	return ((self_in_concretizePopR->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizePrefetchAw */
static usqInt NoDbgRegParms
concretizePrefetchAw(AbstractInstruction * self_in_concretizePrefetchAw)
{
    unsigned long addressOperand;
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;

	addressOperand = ((self_in_concretizePrefetchAw->operands))[0];
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizePrefetchAw, AT, high16BitsOf(self_in_concretizePrefetchAw, addressOperand));
	((self_in_concretizePrefetchAw->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizePrefetchAw, AT, AT, low16BitsOf(self_in_concretizePrefetchAw, addressOperand));
	((self_in_concretizePrefetchAw->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = prefRoffsethint(self_in_concretizePrefetchAw, AT, 0, HintLoad);
	((self_in_concretizePrefetchAw->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizePrefetchAw->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizePushCq */
static usqInt NoDbgRegParms
concretizePushCq(AbstractInstruction * self_in_concretizePushCq)
{
	return concretizePushCw(self_in_concretizePushCq);
}

	/* CogMIPSELCompiler>>#concretizePushCw */
static usqInt NoDbgRegParms
concretizePushCw(AbstractInstruction * self_in_concretizePushCw)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    unsigned long value;

	value = ((self_in_concretizePushCw->operands))[0];
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizePushCw, AT, high16BitsOf(self_in_concretizePushCw, value));
	((self_in_concretizePushCw->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizePushCw, AT, AT, low16BitsOf(self_in_concretizePushCw, value));
	((self_in_concretizePushCw->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = addiuRRC(self_in_concretizePushCw, SP, SP, -4);
	((self_in_concretizePushCw->machineCode))[8 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = swRbaseoffset(self_in_concretizePushCw, AT, SP, 0);
	((self_in_concretizePushCw->machineCode))[12 / 4] = aWord3;
	return ((self_in_concretizePushCw->machineCodeSize) = 16);
}

	/* CogMIPSELCompiler>>#concretizePushR */
static usqInt NoDbgRegParms
concretizePushR(AbstractInstruction * self_in_concretizePushR)
{
    sqInt aWord;
    sqInt aWord1;
    unsigned long srcReg;

	srcReg = ((self_in_concretizePushR->operands))[0];
	/* begin machineCodeAt:put: */
	aWord = addiuRRC(self_in_concretizePushR, SP, SP, -4);
	((self_in_concretizePushR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = swRbaseoffset(self_in_concretizePushR, srcReg, SP, 0);
	((self_in_concretizePushR->machineCode))[4 / 4] = aWord1;
	return ((self_in_concretizePushR->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizeRetN */
static usqInt NoDbgRegParms
concretizeRetN(AbstractInstruction * self_in_concretizeRetN)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt offset;

	offset = ((self_in_concretizeRetN->operands))[0];
	/* begin machineCodeAt:put: */
	aWord1 = jR(self_in_concretizeRetN, RA);
	((self_in_concretizeRetN->machineCode))[0 / 4] = aWord1;
	if (offset == 0) {
		/* begin machineCodeAt:put: */
		((self_in_concretizeRetN->machineCode))[4 / 4] = 0;
	}
	else {
		/* begin machineCodeAt:put: */
		aWord = addiuRRC(self_in_concretizeRetN, SP, SP, offset);
		((self_in_concretizeRetN->machineCode))[4 / 4] = aWord;
	}
	return ((self_in_concretizeRetN->machineCodeSize) = 8);
}

	/* CogMIPSELCompiler>>#concretizeStop */
static usqInt NoDbgRegParms
concretizeStop(AbstractInstruction * self_in_concretizeStop)
{
    sqInt aWord;

	/* begin machineCodeAt:put: */
	aWord = stop(self_in_concretizeStop);
	((self_in_concretizeStop->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeStop->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeSubCheckOverflowCqR */
static usqInt NoDbgRegParms
concretizeSubCheckOverflowCqR(AbstractInstruction * self_in_concretizeSubCheckOverflowCqR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    sqInt aWord4;
    sqInt aWord5;
    sqInt aWord6;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeSubCheckOverflowCqR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeSubCheckOverflowCqR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeSubCheckOverflowCqR, AT, high16BitsOf(self_in_concretizeSubCheckOverflowCqR, rightImm));
	((self_in_concretizeSubCheckOverflowCqR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeSubCheckOverflowCqR, AT, AT, low16BitsOf(self_in_concretizeSubCheckOverflowCqR, rightImm));
	((self_in_concretizeSubCheckOverflowCqR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = adduRRR(self_in_concretizeSubCheckOverflowCqR, OverflowTemp1, leftReg, ZR);
	((self_in_concretizeSubCheckOverflowCqR->machineCode))[8 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = subuRRR(self_in_concretizeSubCheckOverflowCqR, destReg, leftReg, AT);
	((self_in_concretizeSubCheckOverflowCqR->machineCode))[12 / 4] = aWord3;
	/* begin machineCodeAt:put: */
	aWord4 = xorRRR(self_in_concretizeSubCheckOverflowCqR, OverflowTemp2, destReg, AT);
	((self_in_concretizeSubCheckOverflowCqR->machineCode))[16 / 4] = aWord4;
	/* begin machineCodeAt:put: */
	aWord5 = xorRRR(self_in_concretizeSubCheckOverflowCqR, OverflowTemp1, destReg, OverflowTemp1);
	((self_in_concretizeSubCheckOverflowCqR->machineCode))[20 / 4] = aWord5;
	/* begin machineCodeAt:put: */
	aWord6 = andRRR(self_in_concretizeSubCheckOverflowCqR, Overflow, OverflowTemp1, OverflowTemp2);
	((self_in_concretizeSubCheckOverflowCqR->machineCode))[24 / 4] = aWord6;
	return ((self_in_concretizeSubCheckOverflowCqR->machineCodeSize) = 28);
}

	/* CogMIPSELCompiler>>#concretizeSubCheckOverflowRR */
static usqInt NoDbgRegParms
concretizeSubCheckOverflowRR(AbstractInstruction * self_in_concretizeSubCheckOverflowRR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt aWord3;
    sqInt aWord4;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightReg;

	rightReg = ((self_in_concretizeSubCheckOverflowRR->operands))[0];

	/* Save original LHS */
	destReg = (leftReg = ((self_in_concretizeSubCheckOverflowRR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = adduRRR(self_in_concretizeSubCheckOverflowRR, OverflowTemp1, leftReg, ZR);
	((self_in_concretizeSubCheckOverflowRR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = subuRRR(self_in_concretizeSubCheckOverflowRR, destReg, leftReg, rightReg);
	((self_in_concretizeSubCheckOverflowRR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = xorRRR(self_in_concretizeSubCheckOverflowRR, OverflowTemp2, destReg, rightReg);
	((self_in_concretizeSubCheckOverflowRR->machineCode))[8 / 4] = aWord2;
	/* begin machineCodeAt:put: */
	aWord3 = xorRRR(self_in_concretizeSubCheckOverflowRR, OverflowTemp1, destReg, OverflowTemp1);
	((self_in_concretizeSubCheckOverflowRR->machineCode))[12 / 4] = aWord3;
	/* begin machineCodeAt:put: */
	aWord4 = andRRR(self_in_concretizeSubCheckOverflowRR, Overflow, OverflowTemp1, OverflowTemp2);
	((self_in_concretizeSubCheckOverflowRR->machineCode))[16 / 4] = aWord4;
	return ((self_in_concretizeSubCheckOverflowRR->machineCodeSize) = 20);
}

	/* CogMIPSELCompiler>>#concretizeSubCqR */
static usqInt NoDbgRegParms
concretizeSubCqR(AbstractInstruction * self_in_concretizeSubCqR)
{
    sqInt aWord;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeSubCqR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeSubCqR->operands))[1]);
	if (!((((-rightImm) >= -32768) && ((-rightImm) <= 0x7FFF)))) {
		return concretizeSubCwR(self_in_concretizeSubCqR);
	}
	/* begin machineCodeAt:put: */
	aWord = addiuRRC(self_in_concretizeSubCqR, destReg, leftReg, -rightImm);
	((self_in_concretizeSubCqR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeSubCqR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeSubCwR */
static usqInt NoDbgRegParms
concretizeSubCwR(AbstractInstruction * self_in_concretizeSubCwR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeSubCwR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeSubCwR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeSubCwR, AT, high16BitsOf(self_in_concretizeSubCwR, rightImm));
	((self_in_concretizeSubCwR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeSubCwR, AT, AT, low16BitsOf(self_in_concretizeSubCwR, rightImm));
	((self_in_concretizeSubCwR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = subuRRR(self_in_concretizeSubCwR, destReg, leftReg, AT);
	((self_in_concretizeSubCwR->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizeSubCwR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeSubRR */
static usqInt NoDbgRegParms
concretizeSubRR(AbstractInstruction * self_in_concretizeSubRR)
{
    sqInt aWord;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightReg;

	rightReg = ((self_in_concretizeSubRR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeSubRR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = subuRRR(self_in_concretizeSubRR, destReg, leftReg, rightReg);
	((self_in_concretizeSubRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeSubRR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeTstCqR */
static usqInt NoDbgRegParms
concretizeTstCqR(AbstractInstruction * self_in_concretizeTstCqR)
{
    sqInt aWord;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeTstCqR->operands))[0];
	leftReg = ((self_in_concretizeTstCqR->operands))[1];
	if (!(((rightImm >= -32768) && (rightImm <= 0x7FFF)))) {
		return concretizeTstCwR(self_in_concretizeTstCqR);
	}
	/* begin machineCodeAt:put: */
	aWord = andiRRC(self_in_concretizeTstCqR, Cmp, leftReg, rightImm);
	((self_in_concretizeTstCqR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeTstCqR->machineCodeSize) = 4);
}

	/* CogMIPSELCompiler>>#concretizeTstCwR */
static usqInt NoDbgRegParms
concretizeTstCwR(AbstractInstruction * self_in_concretizeTstCwR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeTstCwR->operands))[0];
	leftReg = ((self_in_concretizeTstCwR->operands))[1];
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeTstCwR, AT, high16BitsOf(self_in_concretizeTstCwR, rightImm));
	((self_in_concretizeTstCwR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeTstCwR, AT, AT, low16BitsOf(self_in_concretizeTstCwR, rightImm));
	((self_in_concretizeTstCwR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = andRRR(self_in_concretizeTstCwR, Cmp, leftReg, AT);
	((self_in_concretizeTstCwR->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizeTstCwR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeUnimplemented */
static sqInt NoDbgRegParms
concretizeUnimplemented(AbstractInstruction * self_in_concretizeUnimplemented)
{
	error("Unimplemented RTL instruction");
	return 0;
}

	/* CogMIPSELCompiler>>#concretizeXorCwR */
static usqInt NoDbgRegParms
concretizeXorCwR(AbstractInstruction * self_in_concretizeXorCwR)
{
    sqInt aWord;
    sqInt aWord1;
    sqInt aWord2;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightImm;

	rightImm = ((self_in_concretizeXorCwR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeXorCwR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = luiRC(self_in_concretizeXorCwR, AT, high16BitsOf(self_in_concretizeXorCwR, rightImm));
	((self_in_concretizeXorCwR->machineCode))[0 / 4] = aWord;
	/* begin machineCodeAt:put: */
	aWord1 = oriRRC(self_in_concretizeXorCwR, AT, AT, low16BitsOf(self_in_concretizeXorCwR, rightImm));
	((self_in_concretizeXorCwR->machineCode))[4 / 4] = aWord1;
	/* begin machineCodeAt:put: */
	aWord2 = xorRRR(self_in_concretizeXorCwR, destReg, leftReg, AT);
	((self_in_concretizeXorCwR->machineCode))[8 / 4] = aWord2;
	return ((self_in_concretizeXorCwR->machineCodeSize) = 12);
}

	/* CogMIPSELCompiler>>#concretizeXorRR */
static usqInt NoDbgRegParms
concretizeXorRR(AbstractInstruction * self_in_concretizeXorRR)
{
    sqInt aWord;
    sqInt destReg;
    unsigned long leftReg;
    unsigned long rightReg;

	rightReg = ((self_in_concretizeXorRR->operands))[0];
	destReg = (leftReg = ((self_in_concretizeXorRR->operands))[1]);
	/* begin machineCodeAt:put: */
	aWord = xorRRR(self_in_concretizeXorRR, destReg, leftReg, rightReg);
	((self_in_concretizeXorRR->machineCode))[0 / 4] = aWord;
	return ((self_in_concretizeXorRR->machineCodeSize) = 4);
}


/*	Attempt to generate concrete machine code for the instruction at address.
	This is the inner dispatch of concretizeAt: actualAddress which exists
	only to get around the branch size limits in the SqueakV3 (blue book
	derived) bytecode set. */

	/* CogMIPSELCompiler>>#dispatchConcretize */
static void NoDbgRegParms
dispatchConcretize(AbstractInstruction * self_in_dispatchConcretize)
{
    AbstractInstruction *dependentChain;

	
	switch ((self_in_dispatchConcretize->opcode)) {
	case BrEqualRR:
		concretizeBrEqualRR(self_in_dispatchConcretize);
		return;

	case BrNotEqualRR:
		concretizeBrNotEqualRR(self_in_dispatchConcretize);
		return;

	case BrUnsignedLessRR:
		concretizeBrUnsignedLessRR(self_in_dispatchConcretize);
		return;

	case BrUnsignedLessEqualRR:
		concretizeBrUnsignedLessEqualRR(self_in_dispatchConcretize);
		return;

	case BrUnsignedGreaterRR:
		concretizeBrUnsignedGreaterRR(self_in_dispatchConcretize);
		return;

	case BrUnsignedGreaterEqualRR:
		concretizeBrUnsignedGreaterEqualRR(self_in_dispatchConcretize);
		return;

	case BrSignedLessRR:
		concretizeBrSignedLessRR(self_in_dispatchConcretize);
		return;

	case BrSignedLessEqualRR:
		concretizeBrSignedLessEqualRR(self_in_dispatchConcretize);
		return;

	case BrSignedGreaterRR:
		concretizeBrSignedGreaterRR(self_in_dispatchConcretize);
		return;

	case BrSignedGreaterEqualRR:
		concretizeBrSignedGreaterEqualRR(self_in_dispatchConcretize);
		return;

	case BrLongEqualRR:
		concretizeBrLongEqualRR(self_in_dispatchConcretize);
		return;

	case BrLongNotEqualRR:
		concretizeBrLongNotEqualRR(self_in_dispatchConcretize);
		return;

	case MulRR:
	case JumpNegative:
	case JumpNonNegative:
	case JumpCarry:
	case JumpNoCarry:
	case JumpFPEqual:
	case JumpFPNotEqual:
	case JumpFPLess:
	case JumpFPGreaterOrEqual:
	case JumpFPGreater:
	case JumpFPLessOrEqual:
	case JumpFPOrdered:
	case JumpFPUnordered:
	case XorCqR:
	case AddRdRd:
	case CmpRdRd:
	case DivRdRd:
	case MulRdRd:
	case SubRdRd:
	case SqrtRd:
	case MoveRMbr:
	case MoveM64rRd:
	case MoveRdM64r:
	case ConvertRRd:
		concretizeUnimplemented(self_in_dispatchConcretize);
		return;

	case DivRR:
		concretizeDivRR(self_in_dispatchConcretize);
		return;

	case MoveLowR:
		concretizeMoveLowR(self_in_dispatchConcretize);
		return;

	case MoveHighR:
		concretizeMoveHighR(self_in_dispatchConcretize);
		return;

	case Label:
		/* begin concretizeLabel */
		dependentChain = (self_in_dispatchConcretize->dependent);
		while (!(dependentChain == null)) {
			updateLabel(dependentChain, self_in_dispatchConcretize);
			dependentChain = (dependentChain->dependent);
		}
		((self_in_dispatchConcretize->machineCodeSize) = 0);
		return;

	case AlignmentNops:
		concretizeAlignmentNops(self_in_dispatchConcretize);
		return;

	case Fill32:
		concretizeFill32(self_in_dispatchConcretize);
		return;

	case Nop:
		concretizeNop(self_in_dispatchConcretize);
		return;

	case Call:
		concretizeCall(self_in_dispatchConcretize);
		return;

	case CallFull:
		concretizeCallFull(self_in_dispatchConcretize);
		return;

	case JumpR:
		concretizeJumpR(self_in_dispatchConcretize);
		return;

	case JumpFull:
		concretizeJumpFull(self_in_dispatchConcretize);
		return;

	case JumpLong:
		concretizeJumpLong(self_in_dispatchConcretize);
		return;

	case JumpLongZero:
		concretizeJumpLongZero(self_in_dispatchConcretize);
		return;

	case JumpLongNonZero:
		concretizeJumpLongNonZero(self_in_dispatchConcretize);
		return;

	case Jump:
		concretizeJump(self_in_dispatchConcretize);
		return;

	case JumpZero:
		concretizeJumpZero(self_in_dispatchConcretize);
		return;

	case JumpNonZero:
		concretizeJumpNonZero(self_in_dispatchConcretize);
		return;

	case JumpOverflow:
		concretizeJumpOverflow(self_in_dispatchConcretize);
		return;

	case JumpNoOverflow:
		concretizeJumpNoOverflow(self_in_dispatchConcretize);
		return;

	case JumpLess:
		concretizeJumpSignedLessThan(self_in_dispatchConcretize);
		return;

	case JumpGreaterOrEqual:
		concretizeJumpSignedGreaterEqual(self_in_dispatchConcretize);
		return;

	case JumpGreater:
		concretizeJumpSignedGreaterThan(self_in_dispatchConcretize);
		return;

	case JumpLessOrEqual:
		concretizeJumpSignedLessEqual(self_in_dispatchConcretize);
		return;

	case JumpBelow:
		concretizeJumpUnsignedLessThan(self_in_dispatchConcretize);
		return;

	case JumpAboveOrEqual:
		concretizeJumpUnsignedGreaterEqual(self_in_dispatchConcretize);
		return;

	case JumpAbove:
		concretizeJumpUnsignedGreaterThan(self_in_dispatchConcretize);
		return;

	case JumpBelowOrEqual:
		concretizeJumpUnsignedLessEqual(self_in_dispatchConcretize);
		return;

	case RetN:
		concretizeRetN(self_in_dispatchConcretize);
		return;

	case Stop:
		concretizeStop(self_in_dispatchConcretize);
		return;

	case AddCqR:
		concretizeAddCqR(self_in_dispatchConcretize);
		return;

	case AndCqR:
		concretizeAndCqR(self_in_dispatchConcretize);
		return;

	case AndCqRR:
		concretizeAndCqRR(self_in_dispatchConcretize);
		return;

	case CmpCqR:
		concretizeCmpCqR(self_in_dispatchConcretize);
		return;

	case OrCqR:
		concretizeOrCqR(self_in_dispatchConcretize);
		return;

	case SubCqR:
		concretizeSubCqR(self_in_dispatchConcretize);
		return;

	case TstCqR:
		concretizeTstCqR(self_in_dispatchConcretize);
		return;

	case AddCwR:
		concretizeAddCwR(self_in_dispatchConcretize);
		return;

	case AndCwR:
		concretizeAndCwR(self_in_dispatchConcretize);
		return;

	case CmpCwR:
		concretizeCmpCwR(self_in_dispatchConcretize);
		return;

	case OrCwR:
		concretizeOrCwR(self_in_dispatchConcretize);
		return;

	case SubCwR:
		concretizeSubCwR(self_in_dispatchConcretize);
		return;

	case XorCwR:
		concretizeXorCwR(self_in_dispatchConcretize);
		return;

	case AddRR:
		concretizeAddRR(self_in_dispatchConcretize);
		return;

	case AndRR:
		concretizeAndRR(self_in_dispatchConcretize);
		return;

	case CmpRR:
		concretizeCmpRR(self_in_dispatchConcretize);
		return;

	case OrRR:
		concretizeOrRR(self_in_dispatchConcretize);
		return;

	case SubRR:
		concretizeSubRR(self_in_dispatchConcretize);
		return;

	case XorRR:
		concretizeXorRR(self_in_dispatchConcretize);
		return;

	case NegateR:
		concretizeNegateR(self_in_dispatchConcretize);
		return;

	case LoadEffectiveAddressMwrR:
		concretizeLoadEffectiveAddressMwrR(self_in_dispatchConcretize);
		return;

	case ArithmeticShiftRightCqR:
		concretizeArithmeticShiftRightCqR(self_in_dispatchConcretize);
		return;

	case LogicalShiftRightCqR:
		concretizeLogicalShiftRightCqR(self_in_dispatchConcretize);
		return;

	case LogicalShiftLeftCqR:
		concretizeLogicalShiftLeftCqR(self_in_dispatchConcretize);
		return;

	case ArithmeticShiftRightRR:
		concretizeArithmeticShiftRightRR(self_in_dispatchConcretize);
		return;

	case LogicalShiftLeftRR:
		concretizeLogicalShiftLeftRR(self_in_dispatchConcretize);
		return;

	case LogicalShiftRightRR:
		concretizeLogicalShiftRightRR(self_in_dispatchConcretize);
		return;

	case MoveCqR:
		concretizeMoveCqR(self_in_dispatchConcretize);
		return;

	case MoveCwR:
		concretizeMoveCwR(self_in_dispatchConcretize);
		return;

	case MoveRR:
		concretizeMoveRR(self_in_dispatchConcretize);
		return;

	case MoveAwR:
		concretizeMoveAwR(self_in_dispatchConcretize);
		return;

	case MoveRAw:
		concretizeMoveRAw(self_in_dispatchConcretize);
		return;

	case MoveAbR:
		concretizeMoveAbR(self_in_dispatchConcretize);
		return;

	case MoveRAb:
		concretizeMoveRAb(self_in_dispatchConcretize);
		return;

	case MoveMbrR:
		concretizeMoveMbrR(self_in_dispatchConcretize);
		return;

	case MoveM16rR:
		concretizeMoveM16rR(self_in_dispatchConcretize);
		return;

	case MoveRM16r:
		concretizeMoveRM16r(self_in_dispatchConcretize);
		return;

	case MoveMwrR:
		concretizeMoveMwrR(self_in_dispatchConcretize);
		return;

	case MoveXbrRR:
		concretizeMoveXbrRR(self_in_dispatchConcretize);
		return;

	case MoveRXbrR:
		concretizeMoveRXbrR(self_in_dispatchConcretize);
		return;

	case MoveXwrRR:
		concretizeMoveXwrRR(self_in_dispatchConcretize);
		return;

	case MoveRXwrR:
		concretizeMoveRXwrR(self_in_dispatchConcretize);
		return;

	case MoveRMwr:
		concretizeMoveRMwr(self_in_dispatchConcretize);
		return;

	case PopR:
		concretizePopR(self_in_dispatchConcretize);
		return;

	case PushR:
		concretizePushR(self_in_dispatchConcretize);
		return;

	case PushCq:
		concretizePushCq(self_in_dispatchConcretize);
		return;

	case PushCw:
		concretizePushCw(self_in_dispatchConcretize);
		return;

	case PrefetchAw:
		concretizePrefetchAw(self_in_dispatchConcretize);
		return;

	case AddCheckOverflowCqR:
		concretizeAddCheckOverflowCqR(self_in_dispatchConcretize);
		return;

	case AddCheckOverflowRR:
		concretizeAddCheckOverflowRR(self_in_dispatchConcretize);
		return;

	case SubCheckOverflowCqR:
		concretizeSubCheckOverflowCqR(self_in_dispatchConcretize);
		return;

	case SubCheckOverflowRR:
		concretizeSubCheckOverflowRR(self_in_dispatchConcretize);
		return;

	case MulCheckOverflowRR:
		concretizeMulCheckOverflowRR(self_in_dispatchConcretize);
		return;

	default:
		error("Case not found and no otherwise clause");
	}
	return;
}

	/* CogMIPSELCompiler>>#divR:R: */
static sqInt NoDbgRegParms
divRR(AbstractInstruction * self_in_divRR, sqInt dividendReg, sqInt divisorReg)
{
	flag("todo");
	return rtypersrtrdsafunct(self_in_divRR, SPECIAL, dividendReg, divisorReg, 0, 0, DIV);
}


/*	Answer if CallFull and/or JumpFull are relative and hence need relocating
	on method
	compation. If so, they are annotated with IsRelativeCall in methods and
	relocated in
	relocateIfCallOrMethodReference:mcpc:delta: */

	/* CogMIPSELCompiler>>#fullCallsAreRelative */
static sqInt NoDbgRegParms
fullCallsAreRelative(AbstractInstruction * self_in_fullCallsAreRelative)
{
	return 0;
}

	/* CogMIPSELCompiler>>#functionAtAddress: */
static sqInt NoDbgRegParms
functionAtAddress(AbstractInstruction * self_in_functionAtAddress, sqInt mcpc)
{
	return (longAt(mcpc)) & 0x3F;
}

	/* CogMIPSELCompiler>>#genDivR:R:Quo:Rem: */
static sqInt NoDbgRegParms
genDivRRQuoRem(AbstractInstruction * self_in_genDivRRQuoRem, sqInt abstractRegDivisor, sqInt abstractRegDividend, sqInt abstractRegQuotient, sqInt abstractRegRemainder)
{
	genoperandoperand(DivRR, abstractRegDividend, abstractRegDivisor);
	genoperand(MoveLowR, abstractRegQuotient);
	genoperand(MoveHighR, abstractRegRemainder);
	return 0;
}


/*	Load the stack pointer register with that of the C stack, effecting
	a switch to the C stack. Used when machine code calls into the
	CoInterpreter run-time (e.g. to invoke interpreter primitives). */

	/* CogMIPSELCompiler>>#genLoadCStackPointer */
static sqInt NoDbgRegParms
genLoadCStackPointer(AbstractInstruction * self_in_genLoadCStackPointer)
{
    sqInt address;
    AbstractInstruction *anInstruction;

	/* begin MoveAw:R: */
	address = cStackPointerAddress();
	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(MoveAwR, address, SPReg);
	return 0;
}


/*	Load the frame and stack pointer registers with those of the C stack,
	effecting a switch to the C stack. Used when machine code calls into
	the CoInterpreter run-time (e.g. to invoke interpreter primitives). */

	/* CogMIPSELCompiler>>#genLoadCStackPointers */
static sqInt NoDbgRegParms
genLoadCStackPointers(AbstractInstruction * self_in_genLoadCStackPointers)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;

	/* begin MoveAw:R: */
	address = cStackPointerAddress();
	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(MoveAwR, address, SPReg);
	/* begin MoveAw:R: */
	address1 = cFramePointerAddress();
	/* begin gen:literal:operand: */
	anInstruction1 = genoperandoperand(MoveAwR, address1, FPReg);
	return 0;
}


/*	Switch back to the Smalltalk stack. Assign SPReg first
	because typically it is used immediately afterwards. */

	/* CogMIPSELCompiler>>#genLoadStackPointers */
static sqInt NoDbgRegParms
genLoadStackPointers(AbstractInstruction * self_in_genLoadStackPointers)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;

	/* begin MoveAw:R: */
	address = stackPointerAddress();
	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(MoveAwR, address, SPReg);
	/* begin MoveAw:R: */
	address1 = framePointerAddress();
	/* begin gen:literal:operand: */
	anInstruction1 = genoperandoperand(MoveAwR, address1, FPReg);
	return 0;
}

	/* CogMIPSELCompiler>>#genMulR:R: */
static AbstractInstruction * NoDbgRegParms
genMulRR(AbstractInstruction * self_in_genMulRR, sqInt regSource, sqInt regDest)
{
	return genoperandoperand(MulRR, regSource, regDest);
}


/*	Ensure that the register args are pushed before the outer and
	inner retpcs at an entry miss for arity <= self numRegArgs. The
	outer retpc is that of a call at a send site. The inner is the call
	from a method or PIC abort/miss to the trampoline. */
/*	Putting the receiver and args above the return address means the
	CoInterpreter has a single machine-code frame format which saves
	us a lot of work. */
/*	Iff there are register args convert
	sp		->	outerRetpc			(send site retpc)
	linkReg = innerRetpc			(PIC abort/miss retpc)
	to
	base	->	receiver
	(arg0)
	(arg1)
	sp		->	outerRetpc			(send site retpc)
	sp		->	linkReg/innerRetpc	(PIC abort/miss retpc) */

	/* CogMIPSELCompiler>>#genPushRegisterArgsForAbortMissNumArgs: */
static AbstractInstruction * NoDbgRegParms
genPushRegisterArgsForAbortMissNumArgs(AbstractInstruction * self_in_genPushRegisterArgsForAbortMissNumArgs, sqInt numArgs)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;

	flag("inefficient");
	if (numArgs <= 2) {
		assert((numRegArgs()) <= 2);
		/* begin MoveMw:r:R: */
		anInstruction = genoperandoperandoperand(MoveMwrR, 0, SPReg, TempReg);
		/* begin MoveR:Mw:r: */
		anInstruction1 = genoperandoperandoperand(MoveRMwr, ReceiverResultReg, 0, SPReg);
		if (numArgs > 0) {
			/* begin PushR: */
			genoperand(PushR, Arg0Reg);
			if (numArgs > 1) {
				/* begin PushR: */
				genoperand(PushR, Arg1Reg);
			}
		}
		/* begin PushR: */
		genoperand(PushR, TempReg);
	}
	/* begin PushR: */
	genoperand(PushR, LinkReg);
	return self_in_genPushRegisterArgsForAbortMissNumArgs;
}


/*	Ensure that the register args are pushed before the retpc for arity <=
	self numRegArgs.
 */
/*	This is easy on a RISC like ARM because the return address is in the link
	register. Putting
	the receiver and args above the return address means the CoInterpreter has
	a single
	machine-code frame format which saves us a lot of work
	NOTA BENE: we do NOT push the return address here, which means it must be
	dealt with later. */

	/* CogMIPSELCompiler>>#genPushRegisterArgsForNumArgs:scratchReg: */
static AbstractInstruction * NoDbgRegParms
genPushRegisterArgsForNumArgsscratchReg(AbstractInstruction * self_in_genPushRegisterArgsForNumArgsscratchReg, sqInt numArgs, sqInt ignored)
{
	flag("inefficient");
	if (numArgs <= 2) {
		assert((numRegArgs()) <= 2);
		/* begin PushR: */
		genoperand(PushR, ReceiverResultReg);
		if (numArgs > 0) {
			/* begin PushR: */
			genoperand(PushR, Arg0Reg);
			if (numArgs > 1) {
				/* begin PushR: */
				genoperand(PushR, Arg1Reg);
			}
		}
	}
	return self_in_genPushRegisterArgsForNumArgsscratchReg;
}


/*	This is a no-op on MIPS since the ABI passes up to 4 args in registers and
	trampolines currently observe that limit.
 */

	/* CogMIPSELCompiler>>#genRemoveNArgsFromStack: */
static sqInt NoDbgRegParms
genRemoveNArgsFromStack(AbstractInstruction * self_in_genRemoveNArgsFromStack, sqInt n)
{
	assert(n <= 4);
	return 0;
}


/*	This method is poorly named. Is this for a Smalltalk -> C call or C ->
	Smalltalk call?
	If the former we don't need to do anything because all of the abstract
	registers are
	allocated to C preserved registers. */

	/* CogMIPSELCompiler>>#genRestoreRegs */
static AbstractInstruction * NoDbgRegParms
genRestoreRegs(AbstractInstruction * self_in_genRestoreRegs)
{
	flag("bogus");
	return self_in_genRestoreRegs;
}


/*	Restore the general purpose registers except for abstractReg for a
	trampoline call.
 */

	/* CogMIPSELCompiler>>#genRestoreRegsExcept: */
static AbstractInstruction * NoDbgRegParms
genRestoreRegsExcept(AbstractInstruction * self_in_genRestoreRegsExcept, sqInt abstractReg)
{
	flag("bogus");
	return self_in_genRestoreRegsExcept;
}


/*	Save the general purpose registers for a call into the C run-time from a
	trampoline. We don't need to do anything because all of the abstract
	registers are
	allocated to C preserved registers. */

	/* CogMIPSELCompiler>>#genSaveRegsForCCall */
static AbstractInstruction * NoDbgRegParms
genSaveRegsForCCall(AbstractInstruction * self_in_genSaveRegsForCCall)
{
	flag("this will change with Sista when we hope to be able to allocate arbitrary registers");
	return self_in_genSaveRegsForCCall;
}


/*	Save the frame and stack pointer registers to the framePointer
	and stackPointer variables. Used to save the machine code frame
	for use by the run-time when calling into the CoInterpreter run-time. */

	/* CogMIPSELCompiler>>#genSaveStackPointers */
static sqInt NoDbgRegParms
genSaveStackPointers(AbstractInstruction * self_in_genSaveStackPointers)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;

	/* begin MoveR:Aw: */
	address = framePointerAddress();
	/* begin gen:operand:literal: */
	anInstruction = genoperandoperand(MoveRAw, FPReg, address);
	/* begin MoveR:Aw: */
	address1 = stackPointerAddress();
	/* begin gen:operand:literal: */
	anInstruction1 = genoperandoperand(MoveRAw, SPReg, address1);
	return 0;
}

	/* CogMIPSELCompiler>>#genSubstituteReturnAddress: */
static AbstractInstruction * NoDbgRegParms
genSubstituteReturnAddress(AbstractInstruction * self_in_genSubstituteReturnAddress, sqInt retpc)
{
    AbstractInstruction *anInstruction;

	/* begin MoveCw:R: */
	anInstruction = genoperandoperand(MoveCwR, retpc, RA);
	return anInstruction;
}

	/* CogMIPSELCompiler>>#high16BitsOf: */
static sqInt NoDbgRegParms
high16BitsOf(AbstractInstruction * self_in_high16BitsOf, usqInt word)
{
	return ((usqInt) word) >> 16;
}


/*	Answer the inline cache tag for the return address of a send. */
/*	MoveCwR ClassReg selectorIndex/expectedClass
	Call: unlinked send stub/expectedTarget
	Push ReceiverResult <-- callSiteReturnAddress */
/*	lui s3, selector/tagHigh
	ori s3, s3, selector/tagLow
	lui t9, stub/targetHigh
	ori t9, t9, stub/targetLow
	jalr t9
	nop (delay slot)
	... <-- callSiteReturnAddress */

	/* CogMIPSELCompiler>>#inlineCacheTagAt: */
static sqInt NoDbgRegParms
inlineCacheTagAt(AbstractInstruction * self_in_inlineCacheTagAt, usqInt callSiteReturnAddress)
{
	assert((opcodeAtAddress(self_in_inlineCacheTagAt, callSiteReturnAddress - 24)) == LUI);
	assert((opcodeAtAddress(self_in_inlineCacheTagAt, callSiteReturnAddress - 20)) == ORI);
	assert((opcodeAtAddress(self_in_inlineCacheTagAt, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_inlineCacheTagAt, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_inlineCacheTagAt, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_inlineCacheTagAt, callSiteReturnAddress - 8)) == JALR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_inlineCacheTagAt)));
	return literalAtAddress(self_in_inlineCacheTagAt, callSiteReturnAddress - 20);
}


/*	Answer the instruction size at pc. */

	/* CogMIPSELCompiler>>#instructionSizeAt: */
static sqInt NoDbgRegParms
instructionSizeAt(AbstractInstruction * self_in_instructionSizeAt, sqInt pc)
{
	return 4;
}


/*	Support for addressing variables off the dedicated VarBaseReg */

	/* CogMIPSELCompiler>>#isAddressRelativeToVarBase: */
static sqInt NoDbgRegParms
isAddressRelativeToVarBase(AbstractInstruction * self_in_isAddressRelativeToVarBase, usqInt varAddress)
{
	return (varAddress != null)
	 && ((((varBaseAddress()) - (1 << 15)) < varAddress)
	 && (varAddress < ((varBaseAddress()) + (1 << 15))));
}


/*	Assuming mcpc is a send return pc answer if the instruction before it is a
	call (not a CallFull).
 */
/*	cogit disassembleFrom: mcpc - 8 to: mcpc. */

	/* CogMIPSELCompiler>>#isCallPrecedingReturnPC: */
static sqInt NoDbgRegParms
isCallPrecedingReturnPC(AbstractInstruction * self_in_isCallPrecedingReturnPC, sqInt mcpc)
{
	if ((opcodeAtAddress(self_in_isCallPrecedingReturnPC, mcpc - 8)) == JAL) {
		return 1;
	}
	if (((opcodeAtAddress(self_in_isCallPrecedingReturnPC, mcpc - 8)) == SPECIAL)
	 && ((functionAtAddress(self_in_isCallPrecedingReturnPC, mcpc - 8)) == JALR)) {
		return 1;
	}
	return 0;
}

	/* CogMIPSELCompiler>>#isJump */
static sqInt NoDbgRegParms
isJump(AbstractInstruction * self_in_isJump)
{
	return (((((self_in_isJump->opcode)) >= FirstJump) && (((self_in_isJump->opcode)) <= LastJump)))
	 || (((((self_in_isJump->opcode)) >= BrEqualRR) && (((self_in_isJump->opcode)) <= BrLongNotEqualRR)));
}


/*	cogit disassembleFrom: pc to: pc + 4. */

	/* CogMIPSELCompiler>>#isJumpAt: */
static sqInt NoDbgRegParms
isJumpAt(AbstractInstruction * self_in_isJumpAt, sqInt pc)
{
	if ((opcodeAtAddress(self_in_isJumpAt, pc)) == J) {
		return 1;
	}
	if ((opcodeAtAddress(self_in_isJumpAt, pc)) == SPECIAL) {
		if ((functionAtAddress(self_in_isJumpAt, pc)) == JR) {
			return 1;
		}
	}
	if ((opcodeAtAddress(self_in_isJumpAt, pc)) == BEQ) {
		return 1;
	}
	if ((opcodeAtAddress(self_in_isJumpAt, pc)) == BNE) {
		return 1;
	}
	if ((opcodeAtAddress(self_in_isJumpAt, pc)) == BLEZ) {
		return 1;
	}
	if ((opcodeAtAddress(self_in_isJumpAt, pc)) == BGTZ) {
		return 1;
	}
	if ((opcodeAtAddress(self_in_isJumpAt, pc)) == REGIMM) {
		if ((rtAtAddress(self_in_isJumpAt, pc)) == BLTZ) {
			return 1;
		}
		if ((rtAtAddress(self_in_isJumpAt, pc)) == BGEZ) {
			return 1;
		}
	}
	return 0;
}


/*	Answer if the receiver is a pc-dependent instruction. */

	/* CogMIPSELCompiler>>#isPCDependent */
static sqInt NoDbgRegParms
isPCDependent(AbstractInstruction * self_in_isPCDependent)
{
	return (isJump(self_in_isPCDependent))
	 || (((self_in_isPCDependent->opcode)) == AlignmentNops);
}

	/* CogMIPSELCompiler>>#isShortOffset: */
static sqInt NoDbgRegParms
isShortOffset(AbstractInstruction * self_in_isShortOffset, sqInt offset)
{
	return ((offset >= -32768) && (offset <= 0x7FFF));
}

	/* CogMIPSELCompiler>>#itype:rs:rt:eitherImmediate: */
static sqInt NoDbgRegParms
itypersrteitherImmediate(AbstractInstruction * self_in_itypersrteitherImmediate, sqInt op, sqInt rs, sqInt rt, sqInt immediate)
{
	assert(((op >= 0) && (op <= 0x3F)));
	assert(((rs >= 0) && (rs <= 0x1F)));
	assert(((rt >= 0) && (rt <= 0x1F)));
	return (((op << 26) | (rs << 21)) | (rt << 16)) | (immediate & 0xFFFF);
}

	/* CogMIPSELCompiler>>#itype:rs:rt:signedImmediate: */
static sqInt NoDbgRegParms
itypersrtsignedImmediate(AbstractInstruction * self_in_itypersrtsignedImmediate, sqInt op, sqInt rs, sqInt rt, sqInt immediate)
{
	assert(((op >= 0) && (op <= 0x3F)));
	assert(((rs >= 0) && (rs <= 0x1F)));
	assert(((rt >= 0) && (rt <= 0x1F)));
	assert(((immediate >= -32768) && (immediate <= 0x7FFF)));
	return (((op << 26) | (rs << 21)) | (rt << 16)) | (immediate & 0xFFFF);
}

	/* CogMIPSELCompiler>>#itype:rs:rt:unsignedImmediate: */
static sqInt NoDbgRegParms
itypersrtunsignedImmediate(AbstractInstruction * self_in_itypersrtunsignedImmediate, sqInt op, sqInt rs, sqInt rt, sqInt immediate)
{
	assert(((op >= 0) && (op <= 0x3F)));
	assert(((rs >= 0) && (rs <= 0x1F)));
	assert(((rt >= 0) && (rt <= 0x1F)));
	assert(((immediate >= 0) && (immediate <= 0xFFFF)));
	return (((op << 26) | (rs << 21)) | (rt << 16)) | immediate;
}

	/* CogMIPSELCompiler>>#jA: */
static sqInt NoDbgRegParms
jA(AbstractInstruction * self_in_jA, sqInt target)
{
	assert((target & 3) == 0);
	return jtypetarget(self_in_jA, J, ((usqInt) (target & 0xFFFFFFF)) >> 2);
}

	/* CogMIPSELCompiler>>#jalA: */
static sqInt NoDbgRegParms
jalA(AbstractInstruction * self_in_jalA, sqInt target)
{
	assert((target & 3) == 0);
	return jtypetarget(self_in_jalA, JAL, ((usqInt) (target & 0xFFFFFFF)) >> 2);
}

	/* CogMIPSELCompiler>>#jalR: */
static sqInt NoDbgRegParms
jalR(AbstractInstruction * self_in_jalR, sqInt targetReg)
{
	return rtypersrtrdsafunct(self_in_jalR, SPECIAL, targetReg, 0, RA, 0, JALR);
}

	/* CogMIPSELCompiler>>#jR: */
static sqInt NoDbgRegParms
jR(AbstractInstruction * self_in_jR, sqInt targetReg)
{
	return rtypersrtrdsafunct(self_in_jR, SPECIAL, targetReg, 0, 0, 0, JR);
}

	/* CogMIPSELCompiler>>#jtype:target: */
static sqInt NoDbgRegParms
jtypetarget(AbstractInstruction * self_in_jtypetarget, sqInt op, sqInt target)
{
	assert(((op >= 0) && (op <= 0x3F)));
	assert(((target >= 0) && (target <= 0x7FFFFFF)));
	return (op << 26) | target;
}

	/* CogMIPSELCompiler>>#jumpLongByteSize */
static sqInt NoDbgRegParms
jumpLongByteSize(AbstractInstruction * self_in_jumpLongByteSize)
{
	flag("bogus");
	return 16;
}

	/* CogMIPSELCompiler>>#jumpLongConditionalByteSize */
static sqInt NoDbgRegParms
jumpLongConditionalByteSize(AbstractInstruction * self_in_jumpLongConditionalByteSize)
{
	return 16;
}


/*	mcpc - 16:	beq/ne Cmp, ZR, +12
	mcpc - 12:	nop (delay slot)
	mcpc - 8:	j psuedo-address
	mcpc - 4:	nop (delay slot) */

	/* CogMIPSELCompiler>>#jumpLongConditionalTargetBeforeFollowingAddress: */
static usqInt NoDbgRegParms
jumpLongConditionalTargetBeforeFollowingAddress(AbstractInstruction * self_in_jumpLongConditionalTargetBeforeFollowingAddress, sqInt mcpc)
{
	assert(((opcodeAtAddress(self_in_jumpLongConditionalTargetBeforeFollowingAddress, mcpc - 16)) == BEQ)
	 || ((opcodeAtAddress(self_in_jumpLongConditionalTargetBeforeFollowingAddress, mcpc - 16)) == BNE));
	assert((longAt(mcpc - 12)) == (nop(self_in_jumpLongConditionalTargetBeforeFollowingAddress)));
	assert((opcodeAtAddress(self_in_jumpLongConditionalTargetBeforeFollowingAddress, mcpc - 8)) == J);
	assert((longAt(mcpc - 4)) == (nop(self_in_jumpLongConditionalTargetBeforeFollowingAddress)));
	return targetFromJTypeAtAddress(self_in_jumpLongConditionalTargetBeforeFollowingAddress, mcpc - 8);
}


/*	Answer the target address for the long jump immediately preceding mcpc */

	/* CogMIPSELCompiler>>#jumpLongTargetBeforeFollowingAddress: */
static sqInt NoDbgRegParms
jumpLongTargetBeforeFollowingAddress(AbstractInstruction * self_in_jumpLongTargetBeforeFollowingAddress, sqInt mcpc)
{
	assert((longAt(mcpc - 4)) == (nop(self_in_jumpLongTargetBeforeFollowingAddress)));
	assert((opcodeAtAddress(self_in_jumpLongTargetBeforeFollowingAddress, mcpc - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_jumpLongTargetBeforeFollowingAddress, mcpc - 8)) == JR);
	return literalAtAddress(self_in_jumpLongTargetBeforeFollowingAddress, mcpc - 12);
}

	/* CogMIPSELCompiler>>#jumpShortByteSize */
static sqInt NoDbgRegParms
jumpShortByteSize(AbstractInstruction * self_in_jumpShortByteSize)
{
	return 8;
}


/*	cogit disassembleFrom: pc to: pc + 4. */

	/* CogMIPSELCompiler>>#jumpTargetPCAt: */
static usqInt NoDbgRegParms
jumpTargetPCAt(AbstractInstruction * self_in_jumpTargetPCAt, sqInt pc)
{
	if ((opcodeAtAddress(self_in_jumpTargetPCAt, pc)) == J) {
		return targetFromJTypeAtAddress(self_in_jumpTargetPCAt, pc);
	}
	if ((opcodeAtAddress(self_in_jumpTargetPCAt, pc)) == BEQ) {
		return targetFromITypeAtAddress(self_in_jumpTargetPCAt, pc);
	}
	if ((opcodeAtAddress(self_in_jumpTargetPCAt, pc)) == BNE) {
		return targetFromITypeAtAddress(self_in_jumpTargetPCAt, pc);
	}
	if ((opcodeAtAddress(self_in_jumpTargetPCAt, pc)) == BLEZ) {
		return targetFromITypeAtAddress(self_in_jumpTargetPCAt, pc);
	}
	if ((opcodeAtAddress(self_in_jumpTargetPCAt, pc)) == BGTZ) {
		return targetFromITypeAtAddress(self_in_jumpTargetPCAt, pc);
	}
	if ((opcodeAtAddress(self_in_jumpTargetPCAt, pc)) == REGIMM) {
		if ((rtAtAddress(self_in_jumpTargetPCAt, pc)) == BLTZ) {
			return targetFromITypeAtAddress(self_in_jumpTargetPCAt, pc);
		}
		if ((rtAtAddress(self_in_jumpTargetPCAt, pc)) == BGEZ) {
			return targetFromITypeAtAddress(self_in_jumpTargetPCAt, pc);
		}
	}
	/* begin unreachable */
	error("UNREACHABLE");
	return self_in_jumpTargetPCAt;
}

	/* CogMIPSELCompiler>>#lbR:base:offset: */
static sqInt NoDbgRegParms
lbRbaseoffset(AbstractInstruction * self_in_lbRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset)
{
	return itypersrtsignedImmediate(self_in_lbRbaseoffset, LB, baseReg, destReg, offset);
}

	/* CogMIPSELCompiler>>#lbuR:base:offset: */
static sqInt NoDbgRegParms
lbuRbaseoffset(AbstractInstruction * self_in_lbuRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset)
{
	return itypersrtsignedImmediate(self_in_lbuRbaseoffset, LBU, baseReg, destReg, offset);
}

	/* CogMIPSELCompiler>>#lhR:base:offset: */
static sqInt NoDbgRegParms
lhRbaseoffset(AbstractInstruction * self_in_lhRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset)
{
	return itypersrtsignedImmediate(self_in_lhRbaseoffset, LH, baseReg, destReg, offset);
}

	/* CogMIPSELCompiler>>#lhuR:base:offset: */
static sqInt NoDbgRegParms
lhuRbaseoffset(AbstractInstruction * self_in_lhuRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset)
{
	return itypersrtsignedImmediate(self_in_lhuRbaseoffset, LHU, baseReg, destReg, offset);
}

	/* CogMIPSELCompiler>>#literalAtAddress: */
static sqInt NoDbgRegParms
literalAtAddress(AbstractInstruction * self_in_literalAtAddress, sqInt mcpc)
{
    usqInt high;
    usqInt low;

	assert((opcodeAtAddress(self_in_literalAtAddress, mcpc)) == ORI);
	assert((opcodeAtAddress(self_in_literalAtAddress, mcpc - 4)) == LUI);
	low = (longAt(mcpc)) & 0xFFFF;
	high = (longAt(mcpc - 4)) & 0xFFFF;
	return (high << 16) | low;
}

	/* CogMIPSELCompiler>>#literalAtAddress:put: */
static sqInt NoDbgRegParms
literalAtAddressput(AbstractInstruction * self_in_literalAtAddressput, sqInt mcpc, sqInt newLiteral)
{
    usqInt newLower;
    usqInt newUpper;
    usqInt oldLower;
    usqInt oldUpper;

	assert((opcodeAtAddress(self_in_literalAtAddressput, mcpc - 4)) == LUI);
	assert((opcodeAtAddress(self_in_literalAtAddressput, mcpc)) == ORI);
	oldUpper = longAt(mcpc - 4);
	newUpper = (oldUpper & 0xFFFF0000UL) | (high16BitsOf(self_in_literalAtAddressput, newLiteral));
	longAtput(mcpc - 4, newUpper);
	oldLower = longAt(mcpc);
	newLower = (oldLower & 0xFFFF0000UL) | (low16BitsOf(self_in_literalAtAddressput, newLiteral));
	longAtput(mcpc, newLower);
	assert((opcodeAtAddress(self_in_literalAtAddressput, mcpc - 4)) == LUI);
	assert((opcodeAtAddress(self_in_literalAtAddressput, mcpc)) == ORI);
	assert((literalAtAddress(self_in_literalAtAddressput, mcpc)) == newLiteral);
	return newLiteral;
}


/*	Answer the literal embedded in the instruction immediately preceding
	followingAddress. This is used in the MoveCwR, PushCw and CmpCwR cases. */
/*	Cmp/MoveCwR
	pc-8	lui rx, uper
	pc-4	ori rx, rx, lower */

	/* CogMIPSELCompiler>>#literalBeforeFollowingAddress: */
static sqInt NoDbgRegParms
literalBeforeFollowingAddress(AbstractInstruction * self_in_literalBeforeFollowingAddress, sqInt followingAddress)
{
	if ((opcodeAtAddress(self_in_literalBeforeFollowingAddress, followingAddress - 4)) == ORI) {
		return literalAtAddress(self_in_literalBeforeFollowingAddress, followingAddress - 4);
	}
	if (((opcodeAtAddress(self_in_literalBeforeFollowingAddress, followingAddress - 4)) == SW)
	 && ((opcodeAtAddress(self_in_literalBeforeFollowingAddress, followingAddress - 8)) == ADDIU)) {
		return literalAtAddress(self_in_literalBeforeFollowingAddress, followingAddress - 12);
	}
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#loadLiteralByteSize */
static sqInt NoDbgRegParms
loadLiteralByteSize(AbstractInstruction * self_in_loadLiteralByteSize)
{
	return 8;
}


/*	Answer the byte size of a MoveCwR opcode's corresponding machine code
	when the argument is a PIC. This is for the self-reference at the end of a
	closed PIC. */

	/* CogMIPSELCompiler>>#loadPICLiteralByteSize */
static sqInt NoDbgRegParms
loadPICLiteralByteSize(AbstractInstruction * self_in_loadPICLiteralByteSize)
{
	return loadLiteralByteSize(self_in_loadPICLiteralByteSize);
}

	/* CogMIPSELCompiler>>#low16BitsOf: */
static sqInt NoDbgRegParms
low16BitsOf(AbstractInstruction * self_in_low16BitsOf, usqInt word)
{
	return word & 0xFFFF;
}

	/* CogMIPSELCompiler>>#luiR:C: */
static sqInt NoDbgRegParms
luiRC(AbstractInstruction * self_in_luiRC, sqInt destReg, sqInt imm)
{
	return itypersrteitherImmediate(self_in_luiRC, LUI, 0, destReg, imm);
}

	/* CogMIPSELCompiler>>#lwR:base:offset: */
static sqInt NoDbgRegParms
lwRbaseoffset(AbstractInstruction * self_in_lwRbaseoffset, sqInt destReg, sqInt baseReg, sqInt offset)
{
	return itypersrtsignedImmediate(self_in_lwRbaseoffset, LW, baseReg, destReg, offset);
}

	/* CogMIPSELCompiler>>#machineCodeBytes */
static sqInt NoDbgRegParms
machineCodeBytes(AbstractInstruction * self_in_machineCodeBytes)
{
	return (machineCodeWords(self_in_machineCodeBytes)) * 4;
}


/*	Answer the maximum number of words of machine code generated for any
	abstract instruction.
	e.g. AddCheckOverflowCqR */

	/* CogMIPSELCompiler>>#machineCodeWords */
static sqInt NoDbgRegParms
machineCodeWords(AbstractInstruction * self_in_machineCodeWords)
{
	return 7;
}

	/* CogMIPSELCompiler>>#mfhiR: */
static sqInt NoDbgRegParms
mfhiR(AbstractInstruction * self_in_mfhiR, sqInt destReg)
{
	flag("todo");
	return rtypersrtrdsafunct(self_in_mfhiR, SPECIAL, 0, 0, destReg, 0, MFHI);
}

	/* CogMIPSELCompiler>>#mfloR: */
static sqInt NoDbgRegParms
mfloR(AbstractInstruction * self_in_mfloR, sqInt destReg)
{
	flag("todo");
	return rtypersrtrdsafunct(self_in_mfloR, SPECIAL, 0, 0, destReg, 0, MFLO);
}

	/* CogMIPSELCompiler>>#mipsbreak: */
static sqInt NoDbgRegParms
mipsbreak(AbstractInstruction * self_in_mipsbreak, sqInt code)
{
	assert(((code >= 0) && (code <= 0xFFFFF)));
	return (code << 6) | BREAK;
}

	/* CogMIPSELCompiler>>#multR:R: */
static sqInt NoDbgRegParms
multRR(AbstractInstruction * self_in_multRR, sqInt leftReg, sqInt rightReg)
{
	flag("todo");
	return rtypersrtrdsafunct(self_in_multRR, SPECIAL, leftReg, rightReg, 0, 0, MULT);
}

	/* CogMIPSELCompiler>>#nop */
static sqInt NoDbgRegParms
nop(AbstractInstruction * self_in_nop)
{
	return 0;
}


/*	Support for processors without condition codes, such as the MIPS.
	Answer the branch opcode. Modify the receiver and the branch to
	implement a suitable conditional branch that doesn't depend on
	condition codes being set by the receiver. */

	/* CogMIPSELCompiler>>#noteFollowingConditionalBranch: */
static AbstractInstruction * NoDbgRegParms
noteFollowingConditionalBranch(AbstractInstruction * self_in_noteFollowingConditionalBranch, AbstractInstruction *branch)
{
    unsigned long newBranchLeft;
    sqInt newBranchOpcode;
    unsigned long newBranchRight;

	if ((((branch->opcode)) == JumpOverflow)
	 || (((branch->opcode)) == JumpNoOverflow)) {
		return noteFollowingOverflowBranch(self_in_noteFollowingConditionalBranch, branch);
	}
	
	switch ((branch->opcode)) {
	case JumpZero:
		newBranchOpcode = BrEqualRR;

		break;
	case JumpNonZero:
		newBranchOpcode = BrNotEqualRR;

		break;
	case JumpBelow:
		newBranchOpcode = BrUnsignedLessRR;

		break;
	case JumpBelowOrEqual:
		newBranchOpcode = BrUnsignedLessEqualRR;

		break;
	case JumpAbove:
		newBranchOpcode = BrUnsignedGreaterRR;

		break;
	case JumpAboveOrEqual:
		newBranchOpcode = BrUnsignedGreaterEqualRR;

		break;
	case JumpLess:
	case JumpNegative:
		newBranchOpcode = BrSignedLessRR;

		break;
	case JumpLessOrEqual:
		newBranchOpcode = BrSignedLessEqualRR;

		break;
	case JumpGreater:
		newBranchOpcode = BrSignedGreaterRR;

		break;
	case JumpGreaterOrEqual:
		newBranchOpcode = BrSignedGreaterEqualRR;

		break;
	case JumpLongZero:
		newBranchOpcode = BrLongEqualRR;

		break;
	case JumpLongNonZero:
		newBranchOpcode = BrLongNotEqualRR;

		break;
	default:
		/* begin unreachable */
		error("UNREACHABLE");
		newBranchOpcode = 0;

	}
	
	switch ((self_in_noteFollowingConditionalBranch->opcode)) {
	case BrEqualRR:
	case BrUnsignedLessRR:
		
		/* I.e., two jumps after a compare. */
		newBranchLeft = ((self_in_noteFollowingConditionalBranch->operands))[1];
		newBranchRight = ((self_in_noteFollowingConditionalBranch->operands))[2];
		break;
	case CmpRR:
		newBranchLeft = ((self_in_noteFollowingConditionalBranch->operands))[1];
		newBranchRight = ((self_in_noteFollowingConditionalBranch->operands))[0];
		(self_in_noteFollowingConditionalBranch->opcode) = Label;
		break;
	case CmpCqR:
		newBranchLeft = ((self_in_noteFollowingConditionalBranch->operands))[1];
		newBranchRight = AT;
		(self_in_noteFollowingConditionalBranch->opcode) = MoveCqR;
		((self_in_noteFollowingConditionalBranch->operands))[1] = AT;
		break;
	case CmpCwR:
		newBranchLeft = ((self_in_noteFollowingConditionalBranch->operands))[1];
		newBranchRight = AT;
		(self_in_noteFollowingConditionalBranch->opcode) = MoveCwR;
		((self_in_noteFollowingConditionalBranch->operands))[1] = AT;
		break;
	case TstCqR:
		newBranchLeft = Cmp;
		newBranchRight = ZR;
		break;
	case AndCqR:
	case OrRR:
	case XorRR:
	case SubCwR:
	case SubCqR:
	case ArithmeticShiftRightCqR:
		newBranchLeft = ((self_in_noteFollowingConditionalBranch->operands))[1];
		newBranchRight = ZR;
		break;
	case AndCqRR:
		newBranchLeft = ((self_in_noteFollowingConditionalBranch->operands))[2];
		newBranchRight = ZR;
		break;
	default:
		/* begin unreachable */
		error("UNREACHABLE");

	}
	/* begin rewriteOpcode:with:with: */
	(branch->opcode) = newBranchOpcode;
	((branch->operands))[1] = newBranchLeft;
	((branch->operands))[2] = newBranchRight;
	return branch;
}


/*	Support for processors without condition codes, such as the MIPS.
	Answer the branch opcode. Modify the receiver and the branch to
	implement a suitable conditional branch that doesn't depend on
	condition codes being set by the receiver. */

	/* CogMIPSELCompiler>>#noteFollowingOverflowBranch: */
static AbstractInstruction * NoDbgRegParms
noteFollowingOverflowBranch(AbstractInstruction * self_in_noteFollowingOverflowBranch, AbstractInstruction *branch)
{
    sqInt newBranchOpcode;

	if (((self_in_noteFollowingOverflowBranch->opcode)) == MulRR) {
		(self_in_noteFollowingOverflowBranch->opcode) = MulCheckOverflowRR;
		
		switch ((branch->opcode)) {
		case JumpOverflow:
			newBranchOpcode = BrNotEqualRR;

			break;
		case JumpNoOverflow:
			newBranchOpcode = BrEqualRR;

			break;
		default:
			/* begin unreachable */
			error("UNREACHABLE");
			newBranchOpcode = 0;

		}
		/* begin rewriteOpcode:with:with: */
		(branch->opcode) = newBranchOpcode;
		((branch->operands))[1] = OverflowTemp1;
		((branch->operands))[2] = OverflowTemp2;
		return branch;
	}
	
	switch ((self_in_noteFollowingOverflowBranch->opcode)) {
	case AddCqR:
		(self_in_noteFollowingOverflowBranch->opcode) = AddCheckOverflowCqR;

		break;
	case AddRR:
		(self_in_noteFollowingOverflowBranch->opcode) = AddCheckOverflowRR;

		break;
	case SubCqR:
		(self_in_noteFollowingOverflowBranch->opcode) = SubCheckOverflowCqR;

		break;
	case SubRR:
		(self_in_noteFollowingOverflowBranch->opcode) = SubCheckOverflowRR;

		break;
	default:
		/* begin unreachable */
		error("UNREACHABLE");
		(self_in_noteFollowingOverflowBranch->opcode) = 0;

	}
	
	switch ((branch->opcode)) {
	case JumpOverflow:
		newBranchOpcode = BrSignedLessRR;

		break;
	case JumpNoOverflow:
		newBranchOpcode = BrSignedGreaterEqualRR;

		break;
	default:
		/* begin unreachable */
		error("UNREACHABLE");
		newBranchOpcode = 0;

	}
	/* begin rewriteOpcode:with:with: */
	(branch->opcode) = newBranchOpcode;
	((branch->operands))[1] = Overflow;
	((branch->operands))[2] = ZR;
	return branch;
}

	/* CogMIPSELCompiler>>#numIntRegArgs */
static sqInt NoDbgRegParms
numIntRegArgs(AbstractInstruction * self_in_numIntRegArgs)
{
	flag("OABI");
	return 4;
}

	/* CogMIPSELCompiler>>#opcodeAtAddress: */
static sqInt NoDbgRegParms
opcodeAtAddress(AbstractInstruction * self_in_opcodeAtAddress, sqInt mcpc)
{
	return ((usqInt) (longAt(mcpc))) >> 26;
}

	/* CogMIPSELCompiler>>#oriR:R:C: */
static sqInt NoDbgRegParms
oriRRC(AbstractInstruction * self_in_oriRRC, sqInt destReg, sqInt srcReg, sqInt imm)
{
	return itypersrteitherImmediate(self_in_oriRRC, ORI, srcReg, destReg, imm);
}

	/* CogMIPSELCompiler>>#orR:R:R: */
static sqInt NoDbgRegParms
orRRR(AbstractInstruction * self_in_orRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_orRRR, SPECIAL, leftReg, rightReg, destReg, 0, OR);
}

	/* CogMIPSELCompiler>>#padIfPossibleWithStopsFrom:to: */
static AbstractInstruction * NoDbgRegParms
padIfPossibleWithStopsFromto(AbstractInstruction * self_in_padIfPossibleWithStopsFromto, sqInt startAddr, sqInt endAddr)
{
    sqInt addr;

	for (addr = startAddr; addr < endAddr; addr += 4) {
		longAtput(addr, stop(self_in_padIfPossibleWithStopsFromto));
	}
	return self_in_padIfPossibleWithStopsFromto;
}

	/* CogMIPSELCompiler>>#prefR:offset:hint: */
static sqInt NoDbgRegParms
prefRoffsethint(AbstractInstruction * self_in_prefRoffsethint, sqInt baseReg, sqInt offset, sqInt hint)
{
	flag("todo");
	assert((hint == HintLoad)
	 || (hint == HintStore));
	return itypersrtsignedImmediate(self_in_prefRoffsethint, PREF, baseReg, hint, offset);
}

	/* CogMIPSELCompiler>>#pushLinkRegisterByteSize */
static sqInt NoDbgRegParms
pushLinkRegisterByteSize(AbstractInstruction * self_in_pushLinkRegisterByteSize)
{
	return 8;
}

	/* CogMIPSELCompiler>>#relocateCallBeforeReturnPC:by: */
static AbstractInstruction * NoDbgRegParms
relocateCallBeforeReturnPCby(AbstractInstruction * self_in_relocateCallBeforeReturnPCby, sqInt retpc, sqInt delta)
{
    sqInt target;

	assert((delta % 4) == 0);
	if (delta == 0) {
		return self_in_relocateCallBeforeReturnPCby;
	}
	assert((opcodeAtAddress(self_in_relocateCallBeforeReturnPCby, retpc - 16)) == LUI);
	assert((opcodeAtAddress(self_in_relocateCallBeforeReturnPCby, retpc - 12)) == ORI);
	assert((opcodeAtAddress(self_in_relocateCallBeforeReturnPCby, retpc - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_relocateCallBeforeReturnPCby, retpc - 8)) == JALR);
	assert((longAt(retpc - 4)) == (nop(self_in_relocateCallBeforeReturnPCby)));
	target = literalAtAddress(self_in_relocateCallBeforeReturnPCby, retpc - 12);
	target += delta;
	literalAtAddressput(self_in_relocateCallBeforeReturnPCby, retpc - 12, target);
	assert((opcodeAtAddress(self_in_relocateCallBeforeReturnPCby, retpc - 16)) == LUI);
	assert((opcodeAtAddress(self_in_relocateCallBeforeReturnPCby, retpc - 12)) == ORI);
	assert((opcodeAtAddress(self_in_relocateCallBeforeReturnPCby, retpc - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_relocateCallBeforeReturnPCby, retpc - 8)) == JALR);
	assert((longAt(retpc - 4)) == (nop(self_in_relocateCallBeforeReturnPCby)));
	return self_in_relocateCallBeforeReturnPCby;
}


/*	lui t9, stub/targetHigh
	ori t9, t9, stub/targetLow
	jr t9
	nop (delay slot)
	... <-- pc */

	/* CogMIPSELCompiler>>#relocateJumpLongBeforeFollowingAddress:by: */
static AbstractInstruction * NoDbgRegParms
relocateJumpLongBeforeFollowingAddressby(AbstractInstruction * self_in_relocateJumpLongBeforeFollowingAddressby, sqInt pc, sqInt delta)
{
    sqInt newTarget;
    sqInt oldTarget;

	assert((delta % 4) == 0);
	if (delta == 0) {
		return self_in_relocateJumpLongBeforeFollowingAddressby;
	}
	assert((opcodeAtAddress(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 16)) == LUI);
	assert((opcodeAtAddress(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 12)) == ORI);
	assert((opcodeAtAddress(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 8)) == JR);
	assert((longAt(pc - 4)) == (nop(self_in_relocateJumpLongBeforeFollowingAddressby)));
	oldTarget = literalAtAddress(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 12);
	newTarget = oldTarget + delta;
	literalAtAddressput(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 12, newTarget);
	assert((opcodeAtAddress(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 16)) == LUI);
	assert((opcodeAtAddress(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 12)) == ORI);
	assert((opcodeAtAddress(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_relocateJumpLongBeforeFollowingAddressby, pc - 8)) == JR);
	assert((longAt(pc - 4)) == (nop(self_in_relocateJumpLongBeforeFollowingAddressby)));
	return self_in_relocateJumpLongBeforeFollowingAddressby;
}


/*	lui t9, stub/targetHigh
	ori t9, t9, stub/targetLow
	jalr t9
	nop (delay slot)
	... <-- callSiteReturnAddress */

	/* CogMIPSELCompiler>>#relocateJumpLongConditionalBeforeFollowingAddress:by: */
static AbstractInstruction * NoDbgRegParms
relocateJumpLongConditionalBeforeFollowingAddressby(AbstractInstruction * self_in_relocateJumpLongConditionalBeforeFollowingAddressby, sqInt pc, sqInt delta)
{
	assert((opcodeAtAddress(self_in_relocateJumpLongConditionalBeforeFollowingAddressby, pc - 16)) == BNE);
	assert((longAt(pc - 12)) == (nop(self_in_relocateJumpLongConditionalBeforeFollowingAddressby)));
	assert((opcodeAtAddress(self_in_relocateJumpLongConditionalBeforeFollowingAddressby, pc - 8)) == J);
	assert((longAt(pc - 4)) == (nop(self_in_relocateJumpLongConditionalBeforeFollowingAddressby)));
	rewriteJTypeAtAddressdelta(self_in_relocateJumpLongConditionalBeforeFollowingAddressby, pc - 8, delta);
	assert((opcodeAtAddress(self_in_relocateJumpLongConditionalBeforeFollowingAddressby, pc - 16)) == BNE);
	assert((longAt(pc - 12)) == (nop(self_in_relocateJumpLongConditionalBeforeFollowingAddressby)));
	assert((opcodeAtAddress(self_in_relocateJumpLongConditionalBeforeFollowingAddressby, pc - 8)) == J);
	assert((longAt(pc - 4)) == (nop(self_in_relocateJumpLongConditionalBeforeFollowingAddressby)));
	return self_in_relocateJumpLongConditionalBeforeFollowingAddressby;
}


/*	cogit disassembleFrom: pc - 16 to: pc + 16 a StackToRegisterMappingCogit. */

	/* CogMIPSELCompiler>>#relocateMethodReferenceBeforeAddress:by: */
static AbstractInstruction * NoDbgRegParms
relocateMethodReferenceBeforeAddressby(AbstractInstruction * self_in_relocateMethodReferenceBeforeAddressby, sqInt pc, sqInt delta)
{
    sqInt newValue;
    sqInt oldValue;

	if (((opcodeAtAddress(self_in_relocateMethodReferenceBeforeAddressby, pc - 8)) == ADDIU)
	 && ((opcodeAtAddress(self_in_relocateMethodReferenceBeforeAddressby, pc - 4)) == SW)) {

		/* PushCwR */
		oldValue = literalAtAddress(self_in_relocateMethodReferenceBeforeAddressby, pc - 12);
		newValue = oldValue + delta;
		literalAtAddressput(self_in_relocateMethodReferenceBeforeAddressby, pc - 12, newValue);
		assert((literalAtAddress(self_in_relocateMethodReferenceBeforeAddressby, pc - 12)) == newValue);
		return self_in_relocateMethodReferenceBeforeAddressby;
	}
	oldValue = literalAtAddress(self_in_relocateMethodReferenceBeforeAddressby, pc - 4);
	newValue = oldValue + delta;
	literalAtAddressput(self_in_relocateMethodReferenceBeforeAddressby, pc - 4, newValue);
	assert((literalAtAddress(self_in_relocateMethodReferenceBeforeAddressby, pc - 4)) == newValue);
	return self_in_relocateMethodReferenceBeforeAddressby;
}


/*	Rewrite a call instruction to call a different target. This variant is
	used to link PICs
	in ceSendMiss et al,. 
	Answer the extent of the code change which is used to compute the range of
	the icache to flush. */
/*	lui t9, stub/targetHigh
	ori t9, t9, stub/targetLow
	jalr t9
	nop (delay slot)
	... <-- callSiteReturnAddress */

	/* CogMIPSELCompiler>>#rewriteCallAt:target: */
static sqInt NoDbgRegParms
rewriteCallAttarget(AbstractInstruction * self_in_rewriteCallAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress)
{
	assert((opcodeAtAddress(self_in_rewriteCallAttarget, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteCallAttarget, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteCallAttarget, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_rewriteCallAttarget, callSiteReturnAddress - 8)) == JALR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteCallAttarget)));
	literalAtAddressput(self_in_rewriteCallAttarget, callSiteReturnAddress - 12, callTargetAddress);
	assert((opcodeAtAddress(self_in_rewriteCallAttarget, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteCallAttarget, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteCallAttarget, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_rewriteCallAttarget, callSiteReturnAddress - 8)) == JALR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteCallAttarget)));
	return 20;
}


/*	Rewrite a jump instruction to call a different target. This variant is
	used to reset the 
	jumps in the prototype CPIC to suit each use,. 
	Answer the extent of the code change which is used to compute the range of
	the icache to flush. */

	/* CogMIPSELCompiler>>#rewriteConditionalJumpLongAt:target: */
static AbstractInstruction * NoDbgRegParms
rewriteConditionalJumpLongAttarget(AbstractInstruction * self_in_rewriteConditionalJumpLongAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress)
{
	assert((opcodeAtAddress(self_in_rewriteConditionalJumpLongAttarget, callSiteReturnAddress - 8)) == J);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteConditionalJumpLongAttarget)));
	rewriteJTypeAtAddresstarget(self_in_rewriteConditionalJumpLongAttarget, callSiteReturnAddress - 8, callTargetAddress);
	assert((opcodeAtAddress(self_in_rewriteConditionalJumpLongAttarget, callSiteReturnAddress - 8)) == J);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteConditionalJumpLongAttarget)));
	return self_in_rewriteConditionalJumpLongAttarget;
}


/*	Rewrite a jump instruction to call a different target. This variant is
	used to reset the 
	jumps in the prototype CPIC to suit each use,. 
	Answer the extent of the code change which is used to compute the range of
	the icache to flush. */
/*	self CmpR: ClassReg R: TempReg.
	^self JumpNonZero: 0 */
/*	bne s5, s3, +156 ; =BE7C
	nop (delay slot)
	.... <-- addressFollowingJump */

	/* CogMIPSELCompiler>>#rewriteCPICJumpAt:target: */
static AbstractInstruction * NoDbgRegParms
rewriteCPICJumpAttarget(AbstractInstruction * self_in_rewriteCPICJumpAttarget, usqInt addressFollowingJump, usqInt jumpTargetAddress)
{
	assert((opcodeAtAddress(self_in_rewriteCPICJumpAttarget, addressFollowingJump - 8)) == BNE);
	assert((longAt(addressFollowingJump - 4)) == (nop(self_in_rewriteCPICJumpAttarget)));
	rewriteITypeBranchAtAddresstarget(self_in_rewriteCPICJumpAttarget, addressFollowingJump - 8, jumpTargetAddress);
	assert((opcodeAtAddress(self_in_rewriteCPICJumpAttarget, addressFollowingJump - 8)) == BNE);
	assert((longAt(addressFollowingJump - 4)) == (nop(self_in_rewriteCPICJumpAttarget)));
	return self_in_rewriteCPICJumpAttarget;
}


/*	Rewrite an inline cache to call a different target for a new tag. This
	variant is used
	to link unlinked sends in ceSend:to:numArgs: et al. Answer the extent of
	the code
	change which is used to compute the range of the icache to flush. */
/*	MoveCwR ClassReg selectorIndex/expectedClass
	Call: unlinked send stub/expectedTarget
	Push ReceiverResult <-- callSiteReturnAddress */
/*	lui s3, selector/tagHigh
	ori s3, s3, selector/tagLow
	lui t9, stub/targetHigh
	ori t9, t9, stub/targetLow
	jalr t9
	nop (delay slot)
	... <-- callSiteReturnAddress */

	/* CogMIPSELCompiler>>#rewriteInlineCacheAt:tag:target: */
static sqInt NoDbgRegParms
rewriteInlineCacheAttagtarget(AbstractInstruction * self_in_rewriteInlineCacheAttagtarget, usqInt callSiteReturnAddress, sqInt cacheTag, usqInt callTargetAddress)
{
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 24)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 20)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 8)) == JALR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteInlineCacheAttagtarget)));
	literalAtAddressput(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 20, cacheTag);
	literalAtAddressput(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 12, callTargetAddress);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 24)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 20)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_rewriteInlineCacheAttagtarget, callSiteReturnAddress - 8)) == JALR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteInlineCacheAttagtarget)));
	return 24;
}


/*	Rewrite an inline cache with a new tag. This variant is used
	by the garbage collector. */
/*	MoveCwR ClassReg selectorIndex/expectedClass
	Call: unlinked send stub/expectedTarget
	Push ReceiverResult <-- callSiteReturnAddress */
/*	lui s3, selector/tagHigh
	ori s3, s3, selector/tagLow
	lui t9, stub/targetHigh
	ori t9, t9, stub/targetLow
	jalr t9
	nop (delay slot)
	... <-- callSiteReturnAddress */

	/* CogMIPSELCompiler>>#rewriteInlineCacheTag:at: */
static AbstractInstruction * NoDbgRegParms
rewriteInlineCacheTagat(AbstractInstruction * self_in_rewriteInlineCacheTagat, sqInt cacheTag, usqInt callSiteReturnAddress)
{
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 24)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 20)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 8)) == JALR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteInlineCacheTagat)));
	literalAtAddressput(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 20, cacheTag);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 24)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 20)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_rewriteInlineCacheTagat, callSiteReturnAddress - 8)) == JALR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteInlineCacheTagat)));
	return self_in_rewriteInlineCacheTagat;
}

	/* CogMIPSELCompiler>>#rewriteITypeBranchAtAddress:target: */
static AbstractInstruction * NoDbgRegParms
rewriteITypeBranchAtAddresstarget(AbstractInstruction * self_in_rewriteITypeBranchAtAddresstarget, sqInt mcpc, sqInt newTarget)
{
    sqInt newDisplacement;
    sqInt newInstruction;
    sqInt oldInstruction;


	/* Displacement is relative to delay slot. */
	newDisplacement = newTarget - (mcpc + 4);

	/* Displacement is in words. */
	newDisplacement = ((sqInt) newDisplacement) >> 2;
	newDisplacement = newDisplacement & 0xFFFF;
	oldInstruction = longAt(mcpc);
	newInstruction = (oldInstruction & 0xFFFF0000UL) | newDisplacement;
	longAtput(mcpc, newInstruction);
	return self_in_rewriteITypeBranchAtAddresstarget;
}

	/* CogMIPSELCompiler>>#rewriteJTypeAtAddress:delta: */
static AbstractInstruction * NoDbgRegParms
rewriteJTypeAtAddressdelta(AbstractInstruction * self_in_rewriteJTypeAtAddressdelta, sqInt mcpc, sqInt delta)
{
    usqInt newTarget;
    usqInt oldTarget;

	oldTarget = targetFromJTypeAtAddress(self_in_rewriteJTypeAtAddressdelta, mcpc);
	newTarget = oldTarget + delta;
	rewriteJTypeAtAddresstarget(self_in_rewriteJTypeAtAddressdelta, mcpc, newTarget);
	return self_in_rewriteJTypeAtAddressdelta;
}

	/* CogMIPSELCompiler>>#rewriteJTypeAtAddress:target: */
static AbstractInstruction * NoDbgRegParms
rewriteJTypeAtAddresstarget(AbstractInstruction * self_in_rewriteJTypeAtAddresstarget, sqInt mcpc, sqInt newTarget)
{
    sqInt regionMask;

	assert((opcodeAtAddress(self_in_rewriteJTypeAtAddresstarget, mcpc)) == J);

	/* mcpc + 4: relative to delay slot not j */
	regionMask = 4026531840UL;
	assert(((mcpc + 4) & regionMask) == (newTarget & regionMask));
	longAtput(mcpc, jA(self_in_rewriteJTypeAtAddresstarget, newTarget));
	return self_in_rewriteJTypeAtAddresstarget;
}


/*	Rewrite a jump instruction to call a different target. This variant is
	used to reset the 
	jumps in the prototype CPIC to suit each use,. 
	Answer the extent of the code change which is used to compute the range of
	the icache to flush. */
/*	lui t9, stub/targetHigh
	ori t9, t9, stub/targetLow
	jr t9
	nop (delay slot)
	... <-- callSiteReturnAddress */

	/* CogMIPSELCompiler>>#rewriteJumpLongAt:target: */
static sqInt NoDbgRegParms
rewriteJumpLongAttarget(AbstractInstruction * self_in_rewriteJumpLongAttarget, usqInt callSiteReturnAddress, usqInt callTargetAddress)
{
	assert((opcodeAtAddress(self_in_rewriteJumpLongAttarget, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteJumpLongAttarget, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteJumpLongAttarget, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_rewriteJumpLongAttarget, callSiteReturnAddress - 8)) == JR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteJumpLongAttarget)));
	literalAtAddressput(self_in_rewriteJumpLongAttarget, callSiteReturnAddress - 12, callTargetAddress);
	assert((opcodeAtAddress(self_in_rewriteJumpLongAttarget, callSiteReturnAddress - 16)) == LUI);
	assert((opcodeAtAddress(self_in_rewriteJumpLongAttarget, callSiteReturnAddress - 12)) == ORI);
	assert((opcodeAtAddress(self_in_rewriteJumpLongAttarget, callSiteReturnAddress - 8)) == SPECIAL);
	assert((functionAtAddress(self_in_rewriteJumpLongAttarget, callSiteReturnAddress - 8)) == JR);
	assert((longAt(callSiteReturnAddress - 4)) == (nop(self_in_rewriteJumpLongAttarget)));
	return 20;
}

	/* CogMIPSELCompiler>>#rtAtAddress: */
static sqInt NoDbgRegParms
rtAtAddress(AbstractInstruction * self_in_rtAtAddress, sqInt mcpc)
{
	return (((usqInt) (longAt(mcpc))) >> 16) & 0x1F;
}

	/* CogMIPSELCompiler>>#rtype:rs:rt:rd:sa:funct: */
static sqInt NoDbgRegParms
rtypersrtrdsafunct(AbstractInstruction * self_in_rtypersrtrdsafunct, sqInt op, sqInt rs, sqInt rt, sqInt rd, sqInt sa, sqInt funct)
{
	assert(((op >= 0) && (op <= 0x3F)));
	assert(((rs >= 0) && (rs <= 0x1F)));
	assert(((rt >= 0) && (rt <= 0x1F)));
	assert(((rd >= 0) && (rd <= 0x1F)));
	assert(((sa >= 0) && (sa <= 0x1F)));
	assert(((funct >= 0) && (funct <= 0x3F)));
	return (((((op << 26) | (rs << 21)) | (rt << 16)) | (rd << 11)) | (sa << 6)) | funct;
}

	/* CogMIPSELCompiler>>#sbR:base:offset: */
static sqInt NoDbgRegParms
sbRbaseoffset(AbstractInstruction * self_in_sbRbaseoffset, sqInt srcReg, sqInt baseReg, sqInt offset)
{
	return itypersrtsignedImmediate(self_in_sbRbaseoffset, SB, baseReg, srcReg, offset);
}


/*	Not really, but we can merge this in noteFollowingConditionalBranch:. */

	/* CogMIPSELCompiler>>#setsConditionCodesFor: */
static sqInt NoDbgRegParms
setsConditionCodesFor(AbstractInstruction * self_in_setsConditionCodesFor, sqInt aConditionalJumpOpcode)
{
	if (((self_in_setsConditionCodesFor->opcode)) == XorRR) {
		return 1;
	}
	if (((self_in_setsConditionCodesFor->opcode)) == ArithmeticShiftRightCqR) {
		return 1;
	}
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#shR:base:offset: */
static sqInt NoDbgRegParms
shRbaseoffset(AbstractInstruction * self_in_shRbaseoffset, sqInt srcReg, sqInt baseReg, sqInt offset)
{
	return itypersrtsignedImmediate(self_in_shRbaseoffset, SH, baseReg, srcReg, offset);
}


/*	Size a jump and set its address. The target may be another instruction
	or an absolute address. On entry the address inst var holds our virtual
	address. On exit address is set to eventualAbsoluteAddress, which is
	where this instruction will be output. The span of a jump to a following
	instruction is therefore between that instruction's address and this
	instruction's address ((which are both still their virtual addresses), but
	the span of a jump to a preceding instruction or to an absolute address is
	between that instruction's address (which by now is its eventual absolute
	address) or absolute address and eventualAbsoluteAddress.
	
	ARM is simple; the 26-bit call/jump range means no short jumps. This
	routine only has to determine the targets of jumps, not determine sizes. */

	/* CogMIPSELCompiler>>#sizePCDependentInstructionAt: */
static usqInt NoDbgRegParms
sizePCDependentInstructionAt(AbstractInstruction * self_in_sizePCDependentInstructionAt, sqInt eventualAbsoluteAddress)
{
    unsigned long alignment;

	if (((self_in_sizePCDependentInstructionAt->opcode)) == AlignmentNops) {
		(self_in_sizePCDependentInstructionAt->address) = eventualAbsoluteAddress;
		alignment = ((self_in_sizePCDependentInstructionAt->operands))[0];
		return ((self_in_sizePCDependentInstructionAt->machineCodeSize) = ((eventualAbsoluteAddress + (alignment - 1)) & (-alignment)) - eventualAbsoluteAddress);
	}
	assert((isJump(self_in_sizePCDependentInstructionAt))
	 || ((((self_in_sizePCDependentInstructionAt->opcode)) == Call)
	 || (((self_in_sizePCDependentInstructionAt->opcode)) == CallFull)));
	if (isJump(self_in_sizePCDependentInstructionAt)) {
		resolveJumpTarget(self_in_sizePCDependentInstructionAt);
	}
	(self_in_sizePCDependentInstructionAt->address) = eventualAbsoluteAddress;
	return ((self_in_sizePCDependentInstructionAt->machineCodeSize) = (self_in_sizePCDependentInstructionAt->maxSize));
}

	/* CogMIPSELCompiler>>#sllR:R:C: */
static sqInt NoDbgRegParms
sllRRC(AbstractInstruction * self_in_sllRRC, sqInt destReg, sqInt sourceReg, sqInt shiftAmount)
{
	return rtypersrtrdsafunct(self_in_sllRRC, SPECIAL, 0, sourceReg, destReg, shiftAmount, SLL);
}

	/* CogMIPSELCompiler>>#sllvR:R:R: */
static sqInt NoDbgRegParms
sllvRRR(AbstractInstruction * self_in_sllvRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_sllvRRR, SPECIAL, rightReg, leftReg, destReg, 0, SLLV);
}

	/* CogMIPSELCompiler>>#sltiR:R:C: */
static sqInt NoDbgRegParms
sltiRRC(AbstractInstruction * self_in_sltiRRC, sqInt destReg, sqInt leftReg, sqInt imm)
{
	return itypersrtsignedImmediate(self_in_sltiRRC, SLTI, leftReg, destReg, imm);
}

	/* CogMIPSELCompiler>>#sltiuR:R:C: */
static sqInt NoDbgRegParms
sltiuRRC(AbstractInstruction * self_in_sltiuRRC, sqInt destReg, sqInt leftReg, sqInt imm)
{
	return itypersrtsignedImmediate(self_in_sltiuRRC, SLTIU, leftReg, destReg, imm);
}

	/* CogMIPSELCompiler>>#sltR:R:R: */
static sqInt NoDbgRegParms
sltRRR(AbstractInstruction * self_in_sltRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_sltRRR, SPECIAL, leftReg, rightReg, destReg, 0, SLT);
}

	/* CogMIPSELCompiler>>#sltuR:R:R: */
static sqInt NoDbgRegParms
sltuRRR(AbstractInstruction * self_in_sltuRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_sltuRRR, SPECIAL, leftReg, rightReg, destReg, 0, SLTU);
}

	/* CogMIPSELCompiler>>#sraR:R:C: */
static sqInt NoDbgRegParms
sraRRC(AbstractInstruction * self_in_sraRRC, sqInt destReg, sqInt sourceReg, sqInt shiftAmount)
{
	return rtypersrtrdsafunct(self_in_sraRRC, SPECIAL, 0, sourceReg, destReg, shiftAmount, SRA);
}

	/* CogMIPSELCompiler>>#sravR:R:R: */
static sqInt NoDbgRegParms
sravRRR(AbstractInstruction * self_in_sravRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_sravRRR, SPECIAL, rightReg, leftReg, destReg, 0, SRAV);
}

	/* CogMIPSELCompiler>>#srlR:R:C: */
static sqInt NoDbgRegParms
srlRRC(AbstractInstruction * self_in_srlRRC, sqInt destReg, sqInt sourceReg, sqInt shiftAmount)
{
	return rtypersrtrdsafunct(self_in_srlRRC, SPECIAL, 0, sourceReg, destReg, shiftAmount, SRL);
}

	/* CogMIPSELCompiler>>#srlvR:R:R: */
static sqInt NoDbgRegParms
srlvRRR(AbstractInstruction * self_in_srlvRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_srlvRRR, SPECIAL, rightReg, leftReg, destReg, 0, SRLV);
}

	/* CogMIPSELCompiler>>#stop */
static sqInt NoDbgRegParms
stop(AbstractInstruction * self_in_stop)
{
	return mipsbreak(self_in_stop, 0);
}

	/* CogMIPSELCompiler>>#stopsFrom:to: */
static AbstractInstruction * NoDbgRegParms
stopsFromto(AbstractInstruction * self_in_stopsFromto, sqInt startAddr, sqInt endAddr)
{
    sqInt addr;

	assert((((endAddr - startAddr) + 1) % 4) == 0);
	for (addr = startAddr; addr <= endAddr; addr += 4) {
		longAtput(addr, stop(self_in_stopsFromto));
	}
	return self_in_stopsFromto;
}


/*	Rewrite the long constant loaded by a MoveCwR or PushCwR before the given
	address 
 */

	/* CogMIPSELCompiler>>#storeLiteral:beforeFollowingAddress: */
static sqInt NoDbgRegParms
storeLiteralbeforeFollowingAddress(AbstractInstruction * self_in_storeLiteralbeforeFollowingAddress, sqInt literal, sqInt followingAddress)
{
	flag("bogus");
	if ((opcodeAtAddress(self_in_storeLiteralbeforeFollowingAddress, followingAddress - 4)) == ORI) {
		return literalAtAddressput(self_in_storeLiteralbeforeFollowingAddress, followingAddress - 4, literal);
	}
	if (((opcodeAtAddress(self_in_storeLiteralbeforeFollowingAddress, followingAddress - 4)) == SW)
	 && ((opcodeAtAddress(self_in_storeLiteralbeforeFollowingAddress, followingAddress - 8)) == ADDIU)) {
		return literalAtAddressput(self_in_storeLiteralbeforeFollowingAddress, followingAddress - 12, literal);
	}
	/* begin unreachable */
	error("UNREACHABLE");
	return 0;
}

	/* CogMIPSELCompiler>>#subuR:R:R: */
static sqInt NoDbgRegParms
subuRRR(AbstractInstruction * self_in_subuRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_subuRRR, SPECIAL, leftReg, rightReg, destReg, 0, SUBU);
}

	/* CogMIPSELCompiler>>#swR:base:offset: */
static sqInt NoDbgRegParms
swRbaseoffset(AbstractInstruction * self_in_swRbaseoffset, sqInt srcReg, sqInt baseReg, sqInt offset)
{
	return itypersrtsignedImmediate(self_in_swRbaseoffset, SW, baseReg, srcReg, offset);
}

	/* CogMIPSELCompiler>>#targetFromITypeAtAddress: */
static usqInt NoDbgRegParms
targetFromITypeAtAddress(AbstractInstruction * self_in_targetFromITypeAtAddress, usqInt mcpc)
{
    usqInt offset;

	offset = (longAt(mcpc)) & 0xFFFF;
	offset = offset << 2;
	return (mcpc + offset) + OneInstruction;
}

	/* CogMIPSELCompiler>>#targetFromJTypeAtAddress: */
static usqInt NoDbgRegParms
targetFromJTypeAtAddress(AbstractInstruction * self_in_targetFromJTypeAtAddress, usqInt mcpc)
{
    sqInt targetLow;


	/* mcpc + 4: relative to delay slot not j */
	targetLow = (longAt(mcpc)) & 0x3FFFFFF;
	return ((mcpc + 4) & 4026531840UL) + (targetLow << 2);
}

	/* CogMIPSELCompiler>>#xoriR:R:C: */
static sqInt NoDbgRegParms
xoriRRC(AbstractInstruction * self_in_xoriRRC, sqInt destReg, sqInt srcReg, sqInt imm)
{
	return itypersrteitherImmediate(self_in_xoriRRC, XORI, srcReg, destReg, imm);
}

	/* CogMIPSELCompiler>>#xorR:R:R: */
static sqInt NoDbgRegParms
xorRRR(AbstractInstruction * self_in_xorRRR, sqInt destReg, sqInt leftReg, sqInt rightReg)
{
	return rtypersrtrdsafunct(self_in_xorRRR, SPECIAL, leftReg, rightReg, destReg, 0, XOR);
}


/*	Answer if Call and JumpLong are relative and hence need to take the
	caller's relocation delta into account during code compaction, rather than
	just the
	callee's delta. */

	/* CogMIPSELCompiler>>#zoneCallsAreRelative */
static sqInt NoDbgRegParms
zoneCallsAreRelative(AbstractInstruction * self_in_zoneCallsAreRelative)
{
	return 0;
}

	/* CogObjectRepresentation>>#checkValidObjectReference: */
static sqInt NoDbgRegParms
checkValidObjectReference(sqInt anOop)
{
	return (!(isImmediate(anOop)))
	 && ((heapMapAtWord(pointerForOop(anOop))) != 0);
}

	/* CogObjectRepresentation>>#genCmpClassFloatCompactIndexR: */
static AbstractInstruction * NoDbgRegParms
genCmpClassFloatCompactIndexR(sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin CmpCq:R: */
	anInstruction = genoperandoperand(CmpCqR, ClassFloatCompactIndex, reg);
	return anInstruction;
}

	/* CogObjectRepresentation>>#genCmpClassMethodContextCompactIndexR: */
static AbstractInstruction * NoDbgRegParms
genCmpClassMethodContextCompactIndexR(sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin CmpCq:R: */
	anInstruction = genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, reg);
	return anInstruction;
}


/*	Generate a compare and branch to test if aRegister contains a
	SmallInteger. Answer the jump. Use scratch if required. Subclasses will
	override if scratch is needed. */

	/* CogObjectRepresentation>>#genJumpSmallInteger:scratchReg: */
static AbstractInstruction * NoDbgRegParms
genJumpSmallIntegerscratchReg(sqInt aRegister, sqInt scratch)
{
	return genJumpSmallInteger(aRegister);
}

	/* CogObjectRepresentation>>#genLoadSlot:sourceReg:destReg: */
static sqInt NoDbgRegParms
genLoadSlotsourceRegdestReg(sqInt index, sqInt sourceReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;

	/* begin MoveMw:r:R: */
	anInstruction = genoperandoperandoperand(MoveMwrR, (index * BytesPerWord) + BaseHeaderSize, sourceReg, destReg);
	return 0;
}

	/* CogObjectRepresentation>>#genPrimitiveAdd */
static sqInt
genPrimitiveAdd(void)
{
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;

	if (!(mclassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	genRemoveSmallIntegerTagsInScratchReg(ClassReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, ReceiverResultReg, ClassReg);
	/* begin JumpOverflow: */
	jumpOvfl = genConditionalBranchoperand(JumpOverflow, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOvfl, jmpTarget(jumpNotSI, gLabel()));
	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveBitAnd */
static sqInt
genPrimitiveBitAnd(void)
{
    AbstractInstruction *jumpNotSI;

	if (!(mclassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	/* begin AndR:R: */
	genoperandoperand(AndRR, Arg0Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, gLabel());
	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveBitOr */
static sqInt
genPrimitiveBitOr(void)
{
    AbstractInstruction *jumpNotSI;

	if (!(mclassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	/* begin OrR:R: */
	genoperandoperand(OrRR, Arg0Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, gLabel());
	return CompletePrimitive;
}


/*	rTemp := rArg0
	rClass := tTemp
	rTemp := rTemp & 1
	jz nonInt
	rClass >>= 1
	cmp 0,rClass
	jge neg
	cmp 31,rClass // numSmallIntegerBits, jge for sign
	jge tooBig
	rTemp := rReceiver
	rTemp <<= rClass
	rTemp >>= rClass (arithmetic)
	cmp rTemp,rReceiver
	jnz ovfl
	rReceiver := rReceiver - 1
	rReceiver := rReceiver <<= rClass
	rReceiver := rReceiver + 1
	ret
	neg:
	rClass := 0 - rClass
	cmp 31,rClass // numSmallIntegerBits
	jge inRange
	rClass := 31
	inRange
	rReceiver := rReceiver >>= rClass.
	rReceiver := rReceiver | smallIntegerTags.
	ret
	ovfl
	tooBig
	nonInt:
	fail
 */

	/* CogObjectRepresentation>>#genPrimitiveBitShift */
static sqInt
genPrimitiveBitShift(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *jumpInRange;
    AbstractInstruction *jumpNegative;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;
    AbstractInstruction *jumpTooBig;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;

	if (!(mclassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	genConvertSmallIntegerToIntegerInReg(ClassReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpNegative))) {
		/* begin CmpCq:R: */
		anInstruction = genoperandoperand(CmpCqR, 0, ClassReg);
	}
	/* begin JumpNegative: */
	jumpNegative = genConditionalBranchoperand(JumpNegative, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant = numSmallIntegerBits();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(CmpCqR, quickConstant, ClassReg);
	/* begin JumpGreaterOrEqual: */
	jumpTooBig = genConditionalBranchoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin LogicalShiftLeftR:R: */
	genoperandoperand(LogicalShiftLeftRR, ClassReg, TempReg);
	/* begin ArithmeticShiftRightR:R: */
	genoperandoperand(ArithmeticShiftRightRR, ClassReg, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, ReceiverResultReg);
	/* begin JumpNonZero: */
	jumpOvfl = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	genRemoveSmallIntegerTagsInScratchReg(ReceiverResultReg);
	/* begin LogicalShiftLeftR:R: */
	genoperandoperand(LogicalShiftLeftRR, ClassReg, ReceiverResultReg);
	genAddSmallIntegerTagsTo(ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNegative, gNegateR(ClassReg));
	/* begin CmpCq:R: */
	quickConstant1 = numSmallIntegerBits();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(CmpCqR, quickConstant1, ClassReg);
	/* begin JumpLessOrEqual: */
	jumpInRange = genConditionalBranchoperand(JumpLessOrEqual, ((sqInt)0));
	/* begin MoveCq:R: */
	quickConstant2 = numSmallIntegerBits();
	/* begin gen:quickConstant:operand: */
	anInstruction3 = genoperandoperand(MoveCqR, quickConstant2, ClassReg);
	jmpTarget(jumpInRange, gArithmeticShiftRightRR(ClassReg, ReceiverResultReg));
	genClearAndSetSmallIntegerTagsIn(ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, jmpTarget(jumpTooBig, jmpTarget(jumpOvfl, gLabel())));
	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveBitXor */
static sqInt
genPrimitiveBitXor(void)
{
    AbstractInstruction *jumpNotSI;

	if (!(mclassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	genRemoveSmallIntegerTagsInScratchReg(Arg0Reg);
	/* begin XorR:R: */
	genoperandoperand(XorRR, Arg0Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotSI, gLabel());
	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveClass */
static sqInt
genPrimitiveClass(void)
{
    sqInt reg;
    sqInt reg1;

	reg = ReceiverResultReg;
	if (methodOrBlockNumArgs > 0) {
		if (methodOrBlockNumArgs > 1) {
			return UnimplementedPrimitive;
		}
		/* begin genLoadArgAtDepth:into: */
		reg1 = (reg = Arg0Reg);
		assert(0 < (numRegArgs()));
	}
	if ((genGetClassObjectOfintoscratchReginstRegIsReceiver(reg, ReceiverResultReg, TempReg, reg == ReceiverResultReg)) == BadRegisterSet) {
		genGetClassObjectOfintoscratchReginstRegIsReceiver(reg, ClassReg, TempReg, reg == ReceiverResultReg);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	}
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	return UnfailingPrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveDiv */
static sqInt
genPrimitiveDiv(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *convert;
    AbstractInstruction *jumpExact;
    AbstractInstruction *jumpIsSI;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpSameSign;
    AbstractInstruction *jumpZero;

	if (!(processorHasDivQuoRemAndMClassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, Arg1Reg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		anInstruction = genoperandoperand(CmpCqR, 0, ClassReg);
	}
	/* begin JumpZero: */
	jumpZero = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	anInstruction2 = genoperandoperand(CmpCqR, 0, ClassReg);
	/* begin JumpZero: */
	jumpExact = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin XorR:R: */
	genoperandoperand(XorRR, ClassReg, Arg1Reg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		anInstruction1 = genoperandoperand(CmpCqR, 0, Arg1Reg);
	}
	/* begin JumpGreaterOrEqual: */
	jumpSameSign = genConditionalBranchoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin SubCq:R: */
	anInstruction3 = genoperandoperand(SubCqR, 1, TempReg);
	jmpTarget(jumpSameSign, (convert = gLabel()));
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpExact, gLabel());
	jumpIsSI = genJumpIsSmallIntegerValuescratch(TempReg, Arg1Reg);
	jmpTarget(jumpIsSI, convert);
	jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()));
	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveDivide */
static sqInt
genPrimitiveDivide(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *jumpInexact;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOverflow;
    AbstractInstruction *jumpZero;

	if (!(processorHasDivQuoRemAndMClassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	/* begin JumpZero: */
	jumpZero = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	anInstruction = genoperandoperand(CmpCqR, 0, ClassReg);
	/* begin JumpNonZero: */
	jumpInexact = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	jumpOverflow = genJumpNotSmallIntegerValuescratch(TempReg, Arg1Reg);
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOverflow, jmpTarget(jumpInexact, jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()))));
	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveEqual */
static sqInt
genPrimitiveEqual(void)
{
	return genSmallIntegerComparisonorDoubleComparisoninvert(JumpZero, gJumpFPEqual, 0);
}

	/* CogObjectRepresentation>>#genPrimitiveGreaterOrEqual */
static sqInt
genPrimitiveGreaterOrEqual(void)
{
	return genSmallIntegerComparisonorDoubleComparisoninvert(JumpGreaterOrEqual, gJumpFPGreaterOrEqual, 0);
}

	/* CogObjectRepresentation>>#genPrimitiveGreaterThan */
static sqInt
genPrimitiveGreaterThan(void)
{
	return genSmallIntegerComparisonorDoubleComparisoninvert(JumpGreater, gJumpFPGreater, 0);
}

	/* CogObjectRepresentation>>#genPrimitiveIdentical */
static sqInt
genPrimitiveIdentical(void)
{
	return genPrimitiveIdenticalOrNotIf(0);
}

	/* CogObjectRepresentation>>#genPrimitiveLessOrEqual */
static sqInt
genPrimitiveLessOrEqual(void)
{
	return genSmallIntegerComparisonorDoubleComparisoninvert(JumpLessOrEqual, gJumpFPGreaterOrEqual, 1);
}

	/* CogObjectRepresentation>>#genPrimitiveLessThan */
static sqInt
genPrimitiveLessThan(void)
{
	return genSmallIntegerComparisonorDoubleComparisoninvert(JumpLess, gJumpFPGreater, 1);
}

	/* CogObjectRepresentation>>#genPrimitiveMod */
static sqInt
genPrimitiveMod(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *jumpExact;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpSameSign;
    AbstractInstruction *jumpZero;

	if (!(processorHasDivQuoRemAndMClassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	genRemoveSmallIntegerTagsInScratchReg(ClassReg);
	/* begin JumpZero: */
	jumpZero = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, Arg1Reg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genRemoveSmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	anInstruction1 = genoperandoperand(CmpCqR, 0, ClassReg);
	/* begin JumpZero: */
	jumpExact = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin XorR:R: */
	genoperandoperand(XorRR, ClassReg, Arg1Reg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		anInstruction = genoperandoperand(CmpCqR, 0, Arg1Reg);
	}
	/* begin JumpGreaterOrEqual: */
	jumpSameSign = genConditionalBranchoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin XorR:R: */
	genoperandoperand(XorRR, ClassReg, Arg1Reg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, ClassReg);
	jmpTarget(jumpSameSign, jmpTarget(jumpExact, gLabel()));
	genSetSmallIntegerTagsIn(ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()));
	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveMultiply */
static sqInt
genPrimitiveMultiply(void)
{
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;

	if (!(processorHasMultiplyAndMClassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, Arg1Reg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	genRemoveSmallIntegerTagsInScratchReg(Arg1Reg);
	/* begin MulR:R: */
	genMulRR(backEnd, Arg1Reg, ClassReg);
	/* begin JumpOverflow: */
	jumpOvfl = genConditionalBranchoperand(JumpOverflow, ((sqInt)0));
	genSetSmallIntegerTagsIn(ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOvfl, jmpTarget(jumpNotSI, gLabel()));
	return CompletePrimitive;
}


/*	subclasses override if they can */

	/* CogObjectRepresentation>>#genPrimitiveNewMethod */
static sqInt
genPrimitiveNewMethod(void)
{
	return UnimplementedPrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveNotEqual */
static sqInt
genPrimitiveNotEqual(void)
{
	return genSmallIntegerComparisonorDoubleComparisoninvert(JumpNonZero, gJumpFPNotEqual, 0);
}

	/* CogObjectRepresentation>>#genPrimitiveNotIdentical */
static sqInt
genPrimitiveNotIdentical(void)
{
	return genPrimitiveIdenticalOrNotIf(1);
}

	/* CogObjectRepresentation>>#genPrimitiveQuo */
static sqInt
genPrimitiveQuo(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *convert;
    AbstractInstruction *jumpExact;
    AbstractInstruction *jumpIsSI;
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpZero;

	if (!(processorHasDivQuoRemAndMClassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, ClassReg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	genShiftAwaySmallIntegerTagsInScratchReg(ClassReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpZero))) {
		/* begin CmpCq:R: */
		anInstruction = genoperandoperand(CmpCqR, 0, ClassReg);
	}
	/* begin JumpZero: */
	jumpZero = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	genShiftAwaySmallIntegerTagsInScratchReg(TempReg);
	gDivRRQuoRem(ClassReg, TempReg, TempReg, ClassReg);
	/* begin CmpCq:R: */
	anInstruction1 = genoperandoperand(CmpCqR, 0, ClassReg);
	/* begin JumpZero: */
	jumpExact = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin Label */
	convert = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpExact, gLabel());
	jumpIsSI = genJumpIsSmallIntegerValuescratch(TempReg, Arg1Reg);
	jmpTarget(jumpIsSI, convert);
	jmpTarget(jumpZero, jmpTarget(jumpNotSI, gLabel()));
	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#genPrimitiveSubtract */
static sqInt
genPrimitiveSubtract(void)
{
    AbstractInstruction *jumpNotSI;
    AbstractInstruction *jumpOvfl;

	if (!(mclassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNotSI = genJumpNotSmallInteger(Arg0Reg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, Arg0Reg, TempReg);
	/* begin JumpOverflow: */
	jumpOvfl = genConditionalBranchoperand(JumpOverflow, ((sqInt)0));
	genAddSmallIntegerTagsTo(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOvfl, jmpTarget(jumpNotSI, gLabel()));
	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#genSmallIntegerComparison: */
static sqInt NoDbgRegParms
genSmallIntegerComparison(sqInt jumpOpcode)
{
    AbstractInstruction *anInstruction;
    sqInt constant;
    AbstractInstruction *jumpFail;
    AbstractInstruction *jumpTrue;

	if (!(mclassIsSmallInteger())) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpFail = genJumpNotSmallInteger(Arg0Reg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ReceiverResultReg);
	jumpTrue = genConditionalBranchoperand(jumpOpcode, 0);
	/* begin genMoveFalseR: */
	constant = falseObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, constant, ReceiverResultReg);
	}
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpTrue, genMoveTrueR(ReceiverResultReg));
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpFail, gLabel());
	return CompletePrimitive;
}


/*	Stack looks like
	return address */

	/* CogObjectRepresentation>>#genSmallIntegerComparison:orDoubleComparison:invert: */
static sqInt NoDbgRegParms
genSmallIntegerComparisonorDoubleComparisoninvert(sqInt jumpOpcode, AbstractInstruction *(*jumpFPOpcodeGenerator)(void *), sqInt invertComparison)
{
    AbstractInstruction *anInstruction;
    sqInt constant;
    AbstractInstruction *jumpCond;
    AbstractInstruction *jumpFail;
    AbstractInstruction *jumpNonInt;
    sqInt r;

	r = genSmallIntegerComparison(jumpOpcode);
	if (r < 0) {
		return r;
	}
	
#  if defined(DPFPReg0)

	/* Fall through on non-SmallInteger argument.  Argument may be a Float : let us check or fail */
	jumpNonInt = genJumpImmediate(Arg0Reg);

	genGetCompactClassIndexNonImmOfinto(Arg0Reg, SendNumArgsReg);
	genCmpClassFloatCompactIndexR(SendNumArgsReg);
	/* begin JumpNonZero: */
	jumpFail = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	genConvertSmallIntegerToIntegerInReg(ReceiverResultReg);
	/* begin ConvertR:Rd: */
	genoperandoperand(ConvertRRd, ReceiverResultReg, DPFPReg0);
	genGetDoubleValueOfinto(Arg0Reg, DPFPReg1);
	if (invertComparison) {

		/* May need to invert for NaNs */
		/* begin CmpRd:Rd: */
		genoperandoperand(CmpRdRd, DPFPReg0, DPFPReg1);
	}
	else {
		/* begin CmpRd:Rd: */
		genoperandoperand(CmpRdRd, DPFPReg1, DPFPReg0);
	}

	/* FP jumps are a little weird */
	jumpCond = jumpFPOpcodeGenerator(0);
	/* begin genMoveFalseR: */
	constant = falseObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, constant, ReceiverResultReg);
	}
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpCond, genMoveTrueR(ReceiverResultReg));
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNonInt, jmpTarget(jumpFail, gLabel()));


#  endif /* defined(DPFPReg0) */

	return CompletePrimitive;
}

	/* CogObjectRepresentation>>#isUnannotatableConstant: */
static sqInt NoDbgRegParms
isUnannotatableConstant(CogSimStackEntry *simStackEntry)
{
	return (((simStackEntry->type)) == SSConstant)
	 && (!(shouldAnnotateObjectReference((simStackEntry->constant))));
}

	/* CogObjectRepresentationFor32BitSpur>>#genAddSmallIntegerTagsTo: */
static sqInt NoDbgRegParms
genAddSmallIntegerTagsTo(sqInt aRegister)
{
    AbstractInstruction *anInstruction;

	/* begin AddCq:R: */
	anInstruction = genoperandoperand(AddCqR, 1, aRegister);
	return 0;
}


/*	Set the SmallInteger tag bits when the tag bits may be filled with
	garbage. 
 */

	/* CogObjectRepresentationFor32BitSpur>>#genClearAndSetSmallIntegerTagsIn: */
static sqInt NoDbgRegParms
genClearAndSetSmallIntegerTagsIn(sqInt scratchReg)
{
	return genSetSmallIntegerTagsIn(scratchReg);
}


/*	Convert the Character in reg to a SmallInteger, assuming
	the Character's value is a valid character. */
/*	self assume: objectMemory smallIntegerTag = 1 */

	/* CogObjectRepresentationFor32BitSpur>>#genConvertCharacterToSmallIntegerInReg: */
static void NoDbgRegParms
genConvertCharacterToSmallIntegerInReg(sqInt reg)
{
	assert(((numCharacterBits()) + 1) == (numSmallIntegerBits()));
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, 1, reg);
}

	/* CogObjectRepresentationFor32BitSpur>>#genConvertIntegerToSmallIntegerInReg: */
static sqInt NoDbgRegParms
genConvertIntegerToSmallIntegerInReg(sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, 1, reg);
	/* begin AddCq:R: */
	anInstruction = genoperandoperand(AddCqR, 1, reg);
	return 0;
}


/*	Convert the SmallInteger in reg to a Character, assuming
	the SmallInteger's value is a valid character. */
/*	self assume: objectMemory smallIntegerTag = 1 */

	/* CogObjectRepresentationFor32BitSpur>>#genConvertSmallIntegerToCharacterInReg: */
static void NoDbgRegParms
genConvertSmallIntegerToCharacterInReg(sqInt reg)
{
	assert(((numCharacterBits()) + 1) == (numSmallIntegerBits()));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, 1, reg);
}

	/* CogObjectRepresentationFor32BitSpur>>#genConvertSmallIntegerToIntegerInReg: */
static sqInt NoDbgRegParms
genConvertSmallIntegerToIntegerInReg(sqInt reg)
{
	/* begin ArithmeticShiftRightCq:R: */
	genoperandoperand(ArithmeticShiftRightCqR, 1, reg);
	return 0;
}


/*	indexReg contains the 1-relative index of an element in tableObj.
	Since BaseHeaderSize > BytesPerOop we must adjust it to use
	it as a zero-relative index from the beginning of the object. */

	/* CogObjectRepresentationFor32BitSpur>>#genFetchIndexRegister:from:into: */
static sqInt NoDbgRegParms
genFetchIndexRegisterfrominto(sqInt indexReg, sqInt tableObj, sqInt destReg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;

	assert(indexReg != destReg);
	/* begin AddCq:R: */
	anInstruction = genoperandoperand(AddCqR, (BaseHeaderSize / BytesPerWord) - 1, indexReg);
	/* begin genMoveConstant:R: */
	if (shouldAnnotateObjectReference(tableObj)) {
		annotateobjRef(gMoveCwR(tableObj, destReg), tableObj);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction1 = genoperandoperand(MoveCqR, tableObj, destReg);
	}
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, indexReg, destReg, destReg);
	return 0;
}


/*	Fetch the instance's identity hash into destReg, encoded as a
	SmallInteger. 
 */
/*	Get header word in scratchReg */

	/* CogObjectRepresentationFor32BitSpur>>#genGetHashFieldNonImmOf:asSmallIntegerInto: */
static sqInt NoDbgRegParms
genGetHashFieldNonImmOfasSmallIntegerInto(sqInt instReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    sqInt quickConstant;

	/* begin MoveMw:r:R: */
	anInstruction1 = genoperandoperandoperand(MoveMwrR, 4, instReg, destReg);
	/* begin AndCq:R: */
	quickConstant = identityHashHalfWordMask();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AndCqR, quickConstant, destReg);
	genConvertIntegerToSmallIntegerInReg(destReg);
	return 0;
}


/*	Fetch the instance's identity hash into destReg, unencoded. */

	/* CogObjectRepresentationFor32BitSpur>>#genGetHashFieldNonImmOf:into: */
static sqInt NoDbgRegParms
genGetHashFieldNonImmOfinto(sqInt instReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    sqInt quickConstant;

	/* begin MoveMw:r:R: */
	anInstruction1 = genoperandoperandoperand(MoveMwrR, 4, instReg, destReg);
	/* begin AndCq:R: */
	quickConstant = identityHashHalfWordMask();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AndCqR, quickConstant, destReg);
	return 0;
}


/*	Extract the inline cache tag for the object in sourceReg into destReg. The
	inline cache tag for a given object is the value loaded in inline caches
	to distinguish
	objects of different classes. In Spur this is either the tags for
	immediates, (with
	1 & 3 collapsed to 1 for SmallIntegers, and 2 collapsed to 0 for
	Characters), or
	the receiver's classIndex.
	If forEntry is true answer the entry label at which control is to enter
	(cmEntryOffset). If forEntry is false, control enters at the start.
	If forEntry is true, generate something like this:
	Limm:
	andl $0x1, rDest
	j Lcmp
	Lentry:
	movl rSource, rDest
	andl $0x3, rDest
	jnz Limm
	movl 0(%edx), rDest
	andl $0x3fffff, rDest
	Lcmp:
	If forEntry is false, generate something like the following.
	At least on a 2.2GHz Intel Core i7 the following is slightly faster than
	the above,
	136m sends/sec vs 130m sends/sec for nfib in tinyBenchmarks
	Lentry:
	movl rSource, rDest
	andl $0x3, rDest
	jz LnotImm
	andl $1, rDest
	j Lcmp
	LnotImm:
	movl 0(%edx), rDest
	andl $0x3fffff, rDest
	Lcmp:
	But we expect most SmallInteger arithmetic to be performed in-line and so
	prefer the
	version that is faster for non-immediates (because it branches for
	immediates only). */

	/* CogObjectRepresentationFor32BitSpur>>#genGetInlineCacheClassTagFrom:into:forEntry: */
static AbstractInstruction * NoDbgRegParms
genGetInlineCacheClassTagFromintoforEntry(sqInt sourceReg, sqInt destReg, sqInt forEntry)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *entryLabel;
    AbstractInstruction *immLabel;
    AbstractInstruction *jumpCompare;
    AbstractInstruction *jumpNotImm;
    sqInt quickConstant;

	if (forEntry) {
		/* begin AlignmentNops: */
		genoperand(AlignmentNops, BytesPerWord);
		/* begin Label */
		immLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		/* begin AndCq:R: */
		anInstruction = genoperandoperand(AndCqR, 1, destReg);
		/* begin Jump: */
		jumpCompare = genoperand(Jump, ((sqInt)0));
		/* begin AlignmentNops: */
		genoperand(AlignmentNops, BytesPerWord);
		/* begin Label */
		entryLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		gAndCqRR(tagMask(), sourceReg, destReg);
		/* begin JumpNonZero: */
		genConditionalBranchoperand(JumpNonZero, ((sqInt)immLabel));
		flag("endianness");
		/* begin MoveMw:r:R: */
		anInstruction3 = genoperandoperandoperand(MoveMwrR, 0, sourceReg, destReg);
		/* begin AndCq:R: */
		quickConstant = classIndexMask();
		/* begin gen:quickConstant:operand: */
		anInstruction1 = genoperandoperand(AndCqR, quickConstant, destReg);
		jmpTarget(jumpCompare, gLabel());
	}
	else {
		/* begin Label */
		entryLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		gAndCqRR(tagMask(), sourceReg, destReg);
		/* begin JumpZero: */
		jumpNotImm = genConditionalBranchoperand(JumpZero, ((sqInt)0));
		/* begin AndCq:R: */
		anInstruction2 = genoperandoperand(AndCqR, 1, destReg);
		/* begin Jump: */
		jumpCompare = genoperand(Jump, ((sqInt)0));
		flag("endianness");
		jmpTarget(jumpNotImm, gMoveMwrR(0, sourceReg, destReg));
		jmpTarget(jumpCompare, gAndCqR(classIndexMask(), destReg));
	}
	return entryLabel;
}

	/* CogObjectRepresentationFor32BitSpur>>#genGetOverflowSlotsOf:into: */
static sqInt NoDbgRegParms
genGetOverflowSlotsOfinto(sqInt srcReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;

	/* begin MoveMw:r:R: */
	anInstruction = genoperandoperandoperand(MoveMwrR, -BaseHeaderSize, srcReg, destReg);
	return 0;
}


/*	Generate a test for aRegister containing an integer value in the
	SmallInteger range, and a jump if so, answering the jump.
	c.f. Spur32BitMemoryManager>>isIntegerValue: */

	/* CogObjectRepresentationFor32BitSpur>>#genJumpIsSmallIntegerValue:scratch: */
static AbstractInstruction * NoDbgRegParms
genJumpIsSmallIntegerValuescratch(sqInt aRegister, sqInt scratchReg)
{
	return (/* begin MoveR:R: */
		genoperandoperand(MoveRR, aRegister, scratchReg),
		/* begin ArithmeticShiftRightCq:R: */
		genoperandoperand(ArithmeticShiftRightCqR, 1, scratchReg),
		/* begin XorR:R: */
		genoperandoperand(XorRR, aRegister, scratchReg),
		/* begin JumpGreaterOrEqual: */
		genConditionalBranchoperand(JumpGreaterOrEqual, ((sqInt)0)));
}

	/* CogObjectRepresentationFor32BitSpur>>#genJumpNotSmallIntegerInScratchReg: */
static AbstractInstruction * NoDbgRegParms
genJumpNotSmallIntegerInScratchReg(sqInt aRegister)
{
    AbstractInstruction *anInstruction;

	/* begin AndCq:R: */
	anInstruction = genoperandoperand(AndCqR, 1, aRegister);
	/* begin JumpZero: */
	return genConditionalBranchoperand(JumpZero, ((sqInt)0));
}


/*	Generate a test for aRegister containing an integer value outside the
	SmallInteger range, and a jump if so, answering the jump.
	c.f. Spur32BitMemoryManager>>isIntegerValue: */

	/* CogObjectRepresentationFor32BitSpur>>#genJumpNotSmallIntegerValue:scratch: */
static AbstractInstruction * NoDbgRegParms
genJumpNotSmallIntegerValuescratch(sqInt aRegister, sqInt scratchReg)
{
	return (/* begin MoveR:R: */
		genoperandoperand(MoveRR, aRegister, scratchReg),
		/* begin ArithmeticShiftRightCq:R: */
		genoperandoperand(ArithmeticShiftRightCqR, 1, scratchReg),
		/* begin XorR:R: */
		genoperandoperand(XorRR, aRegister, scratchReg),
		/* begin JumpLess: */
		genConditionalBranchoperand(JumpLess, ((sqInt)0)));
}

	/* CogObjectRepresentationFor32BitSpur>>#genJumpNotSmallInteger: */
static AbstractInstruction * NoDbgRegParms
genJumpNotSmallInteger(sqInt aRegister)
{
    AbstractInstruction *anInstruction;

	/* begin TstCq:R: */
	anInstruction = genoperandoperand(TstCqR, 1, aRegister);
	/* begin JumpZero: */
	return genConditionalBranchoperand(JumpZero, ((sqInt)0));
}

	/* CogObjectRepresentationFor32BitSpur>>#genJumpSmallInteger: */
static AbstractInstruction * NoDbgRegParms
genJumpSmallInteger(sqInt aRegister)
{
    AbstractInstruction *anInstruction;

	/* begin TstCq:R: */
	anInstruction = genoperandoperand(TstCqR, 1, aRegister);
	/* begin JumpNonZero: */
	return genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
}


/*	c.f. StackInterpreter>>stSizeOf: SpurMemoryManager>>lengthOf:format:
	fixedFieldsOf:format:length: 
 */

	/* CogObjectRepresentationFor32BitSpur>>#genPrimitiveAt */
static sqInt
genPrimitiveAt(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction10;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction12;
    AbstractInstruction *anInstruction13;
    AbstractInstruction *anInstruction14;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    AbstractInstruction *convertToIntAndReturn;
    sqInt formatReg;
    AbstractInstruction *jumpArrayOutOfBounds;
    AbstractInstruction *jumpBadIndex;
    AbstractInstruction *jumpBytesOutOfBounds;
    AbstractInstruction *jumpFixedFieldsOutOfBounds;
    AbstractInstruction *jumpHasFixedFields;
    AbstractInstruction *jumpImmediate;
    AbstractInstruction * jumpIsArray;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction *jumpIsContext;
    AbstractInstruction *jumpIsShorts;
    AbstractInstruction * jumpIsWords;
    AbstractInstruction *jumpNotIndexable;
    AbstractInstruction *jumpShortsOutOfBounds;
    AbstractInstruction *jumpWordsOutOfBounds;
    AbstractInstruction *jumpWordTooBig;
    sqInt literal;
    sqInt literal1;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;
    sqInt quickConstant6;
    sqInt quickConstant7;
    sqInt quickConstant8;

	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	jumpImmediate = genJumpImmediate(ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, Arg1Reg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpBadIndex = genJumpNotSmallInteger(Arg0Reg);
	genConvertSmallIntegerToIntegerInReg(Arg1Reg);
	/* begin SubCq:R: */
	anInstruction = genoperandoperand(SubCqR, 1, Arg1Reg);
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), TempReg);
	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(CmpCqR, quickConstant, formatReg);
	/* begin JumpAboveOrEqual: */
	jumpIsBytes = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant1 = arrayFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(CmpCqR, quickConstant1, formatReg);
	/* begin JumpZero: */
	jumpIsArray = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin JumpBelow: */
	jumpNotIndexable = genConditionalBranchoperand(JumpBelow, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant2 = weakArrayFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction3 = genoperandoperand(CmpCqR, quickConstant2, formatReg);
	/* begin JumpBelowOrEqual: */
	jumpHasFixedFields = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant3 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction4 = genoperandoperand(CmpCqR, quickConstant3, formatReg);
	/* begin JumpAboveOrEqual: */
	jumpIsShorts = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction5 = genoperandoperand(CmpCqR, quickConstant4, formatReg);
	/* begin JumpAboveOrEqual: */
	jumpIsWords = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	jmpTarget(jumpNotIndexable, gLabel());
	/* begin Jump: */
	jumpNotIndexable = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsBytes, gLogicalShiftLeftCqR(shiftForWord(), ClassReg));
	/* begin AndCq:R: */
	literal = BytesPerWord - 1;
	anInstruction6 = genoperandoperand(AndCqR, BytesPerWord - 1, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpBytesOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	literal1 = BaseHeaderSize;
	anInstruction7 = genoperandoperand(AddCqR, BaseHeaderSize, Arg1Reg);
	
	/* formatReg already contains a value <= 16r1f, so no need to zero it */
	/* begin MoveXbr:R:R: */
	genoperandoperandoperand(MoveXbrRR, Arg1Reg, ReceiverResultReg, formatReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, formatReg, ReceiverResultReg);

	/* begin Label */
	convertToIntAndReturn = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	genConvertIntegerToSmallIntegerInReg(ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpIsShorts, gLogicalShiftLeftCqR((shiftForWord()) - 1, ClassReg));
	/* begin AndCq:R: */
	anInstruction8 = genoperandoperand(AndCqR, 1, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpShortsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, ReceiverResultReg);
	/* begin MoveM16:r:R: */
	anInstruction9 = genoperandoperandoperand(MoveM16rR, BaseHeaderSize, ReceiverResultReg, ReceiverResultReg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)convertToIntAndReturn));
	jmpTarget(jumpIsWords, gCmpRR(Arg1Reg, ClassReg));
	/* begin JumpBelowOrEqual: */
	jumpWordsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	quickConstant5 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	/* begin gen:quickConstant:operand: */
	anInstruction10 = genoperandoperand(AddCqR, quickConstant5, Arg1Reg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, TempReg);
	jumpWordTooBig = jumpNotSmallIntegerUnsignedValueInRegister(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)convertToIntAndReturn));
	jmpTarget(jumpHasFixedFields, gAndCqR(classIndexMask(), TempReg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, formatReg);
	/* begin CmpCq:R: */
	anInstruction11 = genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, TempReg);
	/* begin JumpZero: */
	jumpIsContext = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin PushR: */
	genoperand(PushR, ClassReg);
	genGetClassObjectOfClassIndexintoscratchReg(formatReg, ClassReg, TempReg);
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ClassReg, formatReg);
	/* begin PopR: */
	genoperand(PopR, ClassReg);
	genConvertSmallIntegerToIntegerInReg(formatReg);
	/* begin AndCq:R: */
	quickConstant6 = fixedFieldsOfClassFormatMask();
	/* begin gen:quickConstant:operand: */
	anInstruction12 = genoperandoperand(AndCqR, quickConstant6, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpFixedFieldsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddR:R: */
	genoperandoperand(AddRR, formatReg, Arg1Reg);
	/* begin AddCq:R: */
	quickConstant7 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	/* begin gen:quickConstant:operand: */
	anInstruction13 = genoperandoperand(AddCqR, quickConstant7, Arg1Reg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpIsArray, gCmpRR(Arg1Reg, ClassReg));
	/* begin JumpBelowOrEqual: */
	jumpArrayOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	quickConstant8 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	/* begin gen:quickConstant:operand: */
	anInstruction14 = genoperandoperand(AddCqR, quickConstant8, Arg1Reg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpWordTooBig, gSubCqR(((usqInt) BaseHeaderSize) >> (shiftForWord()), Arg1Reg));
	jmpTarget(jumpFixedFieldsOutOfBounds, jmpTarget(jumpArrayOutOfBounds, jmpTarget(jumpBytesOutOfBounds, jmpTarget(jumpShortsOutOfBounds, jmpTarget(jumpWordsOutOfBounds, jmpTarget(jumpNotIndexable, jmpTarget(jumpIsContext, jmpTarget(jumpBadIndex, jmpTarget(jumpImmediate, gLabel())))))))));
	return 0;
}


/*	c.f. StackInterpreter>>stSizeOf: SpurMemoryManager>>lengthOf:format:
	fixedFieldsOf:format:length: 
 */

	/* CogObjectRepresentationFor32BitSpur>>#genPrimitiveAtPut */
static sqInt
genPrimitiveAtPut(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction10;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction12;
    AbstractInstruction *anInstruction13;
    AbstractInstruction *anInstruction14;
    AbstractInstruction *anInstruction15;
    AbstractInstruction *anInstruction16;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    sqInt formatReg;
    AbstractInstruction *jumpArrayOutOfBounds;
    AbstractInstruction *jumpBadIndex;
    AbstractInstruction *jumpBytesOutOfBounds;
    AbstractInstruction *jumpBytesOutOfRange;
    AbstractInstruction * jumpFixedFieldsOutOfBounds;
    AbstractInstruction *jumpHasFixedFields;
    AbstractInstruction *jumpImmediate;
    sqInt jumpImmutable;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction * jumpIsCompiledMethod;
    AbstractInstruction *jumpIsContext;
    AbstractInstruction *jumpIsShorts;
    AbstractInstruction * jumpNonSmallIntegerValue;
    AbstractInstruction *jumpNotIndexableBits;
    AbstractInstruction *jumpNotIndexablePointers;
    AbstractInstruction * jumpNotPointers;
    AbstractInstruction *jumpShortsOutOfBounds;
    AbstractInstruction *jumpShortsOutOfRange;
    AbstractInstruction *jumpWordsOutOfBounds;
    AbstractInstruction *jumpWordsOutOfRange;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;

	jumpImmutable = 0;
	/* begin genLoadArgAtDepth:into: */
	assert(1 < (numRegArgs()));
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	jumpImmediate = genJumpImmediate(ReceiverResultReg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpBadIndex = genJumpNotSmallInteger(Arg0Reg);
	genConvertSmallIntegerToIntegerInReg(Arg0Reg);
	/* begin SubCq:R: */
	anInstruction15 = genoperandoperand(SubCqR, 1, Arg0Reg);
	
#  if IMMUTABILITY
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), TempReg);
	jumpImmutable = genJumpBaseHeaderImmutable(TempReg);

#  else /* IMMUTABILITY */
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), NoReg);

#  endif /* IMMUTABILITY */

	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = weakArrayFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(CmpCqR, quickConstant, formatReg);
	/* begin JumpAbove: */
	jumpNotPointers = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	genStoreCheckReceiverRegvalueRegscratchReginFrame(ReceiverResultReg, Arg1Reg, TempReg, 0);
	/* begin CmpCq:R: */
	quickConstant1 = arrayFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(CmpCqR, quickConstant1, formatReg);
	/* begin JumpBelow: */
	jumpNotIndexablePointers = genConditionalBranchoperand(JumpBelow, ((sqInt)0));
	/* begin JumpNonZero: */
	jumpHasFixedFields = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpArrayOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	anInstruction3 = genoperandoperand(AddCqR, ((usqInt) BaseHeaderSize) >> (shiftForWord()), Arg0Reg);
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, Arg1Reg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpHasFixedFields, gLabel());
	genGetClassIndexOfNonImminto(ReceiverResultReg, formatReg);
	/* begin CmpCq:R: */
	anInstruction4 = genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, formatReg);
	/* begin JumpZero: */
	jumpIsContext = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin PushR: */
	genoperand(PushR, ClassReg);
	genGetClassObjectOfClassIndexintoscratchReg(formatReg, ClassReg, TempReg);
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ClassReg, formatReg);
	/* begin PopR: */
	genoperand(PopR, ClassReg);
	genConvertSmallIntegerToIntegerInReg(formatReg);
	/* begin AndCq:R: */
	quickConstant2 = fixedFieldsOfClassFormatMask();
	/* begin gen:quickConstant:operand: */
	anInstruction5 = genoperandoperand(AndCqR, quickConstant2, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin AddCq:R: */
	anInstruction6 = genoperandoperand(AddCqR, ((usqInt) BaseHeaderSize) >> (shiftForWord()), formatReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpFixedFieldsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddR:R: */
	genoperandoperand(AddRR, formatReg, Arg0Reg);
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, Arg1Reg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotPointers, gCmpCqR(firstCompiledMethodFormat(), formatReg));
	/* begin JumpAboveOrEqual: */
	jumpIsCompiledMethod = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpNonSmallIntegerValue = genJumpNotSmallInteger(Arg1Reg);
	/* begin CmpCq:R: */
	quickConstant3 = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction7 = genoperandoperand(CmpCqR, quickConstant3, formatReg);
	/* begin JumpAboveOrEqual: */
	jumpIsBytes = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction8 = genoperandoperand(CmpCqR, quickConstant4, formatReg);
	/* begin JumpAboveOrEqual: */
	jumpIsShorts = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant5 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction9 = genoperandoperand(CmpCqR, quickConstant5, formatReg);
	/* begin JumpBelow: */
	jumpNotIndexableBits = genConditionalBranchoperand(JumpBelow, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpWordsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	if (!(setsConditionCodesFor(lastOpcode(), JumpLess))) {
		/* begin CmpCq:R: */
		anInstruction = genoperandoperand(CmpCqR, 0, TempReg);
	}
	/* begin JumpLess: */
	jumpWordsOutOfRange = genConditionalBranchoperand(JumpLess, ((sqInt)0));
	/* begin AddCq:R: */
	anInstruction10 = genoperandoperand(AddCqR, ((usqInt) BaseHeaderSize) >> (shiftForWord()), Arg0Reg);
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpIsBytes, gCmpCqR(((0xFF << 1) | 1), Arg1Reg));
	/* begin JumpAbove: */
	jumpBytesOutOfRange = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), ClassReg);
	/* begin AndCq:R: */
	anInstruction11 = genoperandoperand(AndCqR, BytesPerWord - 1, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpBytesOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin AddCq:R: */
	anInstruction12 = genoperandoperand(AddCqR, BaseHeaderSize, Arg0Reg);
	/* begin MoveR:Xbr:R: */
	genoperandoperandoperand(MoveRXbrR, TempReg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpIsShorts, gCmpCqR(((0xFFFF << 1) | 1), Arg1Reg));
	/* begin JumpAbove: */
	jumpShortsOutOfRange = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, (shiftForWord()) - 1, ClassReg);
	/* begin AndCq:R: */
	anInstruction13 = genoperandoperand(AndCqR, (BytesPerWord / 2) - 1, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpShortsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:M16:r: */
	anInstruction16 = genoperandoperandoperand(MoveRM16r, TempReg, BaseHeaderSize, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpIsContext, jmpTarget(jumpNotIndexableBits, jmpTarget(jumpBytesOutOfRange, jmpTarget(jumpWordsOutOfRange, jmpTarget(jumpShortsOutOfRange, jmpTarget(jumpIsCompiledMethod, jmpTarget(jumpArrayOutOfBounds, jmpTarget(jumpBytesOutOfBounds, jmpTarget(jumpShortsOutOfBounds, jmpTarget(jumpWordsOutOfBounds, jmpTarget(jumpNotIndexablePointers, jmpTarget(jumpNonSmallIntegerValue, jmpTarget(jumpFixedFieldsOutOfBounds, gLabel())))))))))))));
	
#  if IMMUTABILITY
	jmpTarget(jumpImmutable, getJmpTarget(jumpIsContext));

#  endif /* IMMUTABILITY */

	/* begin AddCq:R: */
	anInstruction14 = genoperandoperand(AddCqR, 1, Arg0Reg);
	genConvertIntegerToSmallIntegerInReg(Arg0Reg);
	jmpTarget(jumpBadIndex, jmpTarget(jumpImmediate, gLabel()));
	return 0;
}

	/* CogObjectRepresentationFor32BitSpur>>#genPrimitiveIdentityHash */
static sqInt
genPrimitiveIdentityHash(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *jumpImm;
    AbstractInstruction *jumpNotSet;
    AbstractInstruction *jumpSI;
    AbstractInstruction * ret;

	jumpImm = genJumpImmediate(ReceiverResultReg);
	genGetHashFieldNonImmOfasSmallIntegerInto(ReceiverResultReg, TempReg);
	/* begin CmpCq:R: */
	anInstruction = genoperandoperand(CmpCqR, ConstZero, TempReg);
	/* begin JumpZero: */
	jumpNotSet = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	ret = genoperand(RetN, 0);
	jmpTarget(jumpImm, gLabel());
	jumpSI = genJumpSmallInteger(ReceiverResultReg);
	jmpTarget(jumpSI, ret);
	genConvertCharacterToSmallIntegerInReg(ReceiverResultReg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)ret));
	jmpTarget(jumpNotSet, gLabel());
	return 0;
}


/*	Implement primitiveNew for convenient cases:
	- the receiver has a hash
	- the receiver is fixed size (excluding ephemerons to save instructions &
	miniscule time)
	- single word header/num slots < numSlotsMask
	- the result fits in eden (actually below scavengeThreshold)
 */

	/* CogObjectRepresentationFor32BitSpur>>#genPrimitiveNew */
static sqInt
genPrimitiveNew(void)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction10;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction12;
    AbstractInstruction *anInstruction13;
    AbstractInstruction *anInstruction14;
    AbstractInstruction *anInstruction15;
    AbstractInstruction *anInstruction16;
    AbstractInstruction *anInstruction17;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    sqInt byteSizeReg;
    AbstractInstruction *fillLoop;
    sqInt fillReg;
    sqInt halfHeaderReg;
    sqInt instSpecReg;
    AbstractInstruction *jumpHasSlots;
    AbstractInstruction *jumpNoSpace;
    AbstractInstruction *jumpTooBig;
    AbstractInstruction *jumpUnhashed;
    AbstractInstruction *jumpVariableOrEphemeron;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;
    sqInt quickConstant6;
    sqInt quickConstant7;
    sqInt quickConstant8;
    AbstractInstruction *skip;

	if (methodOrBlockNumArgs != 0) {
		return UnimplementedPrimitive;
	}

	/* inst spec will hold class's instance specification, then byte size and finally end of new object. */
	halfHeaderReg = (fillReg = SendNumArgsReg);

	/* get freeStart as early as possible so as not to wait later... */
	instSpecReg = (byteSizeReg = ClassReg);
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(MoveAwR, address, Arg1Reg);
	genGetHashFieldNonImmOfinto(ReceiverResultReg, halfHeaderReg);
	/* begin JumpZero: */
	jumpUnhashed = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ReceiverResultReg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, instSpecReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = fixedFieldsFieldWidth();
	genoperandoperand(LogicalShiftRightCqR, quickConstant, TempReg);
	/* begin AndCq:R: */
	quickConstant1 = formatMask();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(AndCqR, quickConstant1, TempReg);
	/* begin AndCq:R: */
	quickConstant2 = fixedFieldsOfClassFormatMask();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(AndCqR, quickConstant2, instSpecReg);
	/* begin CmpCq:R: */
	quickConstant3 = nonIndexablePointerFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction3 = genoperandoperand(CmpCqR, quickConstant3, TempReg);
	/* begin JumpAbove: */
	jumpVariableOrEphemeron = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = numSlotsMask();
	/* begin gen:quickConstant:operand: */
	anInstruction4 = genoperandoperand(CmpCqR, quickConstant4, instSpecReg);
	/* begin JumpAboveOrEqual: */
	jumpTooBig = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin LogicalShiftLeftCq:R: */
	quickConstant5 = formatShift();
	genoperandoperand(LogicalShiftLeftCqR, quickConstant5, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, halfHeaderReg);
	/* begin MoveR:Mw:r: */
	anInstruction5 = genoperandoperandoperand(MoveRMwr, halfHeaderReg, 0, Arg1Reg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instSpecReg, halfHeaderReg);
	/* begin CmpCq:R: */
	anInstruction6 = genoperandoperand(CmpCqR, 0, byteSizeReg);
	/* begin JumpNonZero: */
	jumpHasSlots = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveCq:R: */
	anInstruction7 = genoperandoperand(MoveCqR, BaseHeaderSize * 2, byteSizeReg);
	/* begin Jump: */
	skip = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpHasSlots, gMoveRR(byteSizeReg, TempReg));
	/* begin AndCq:R: */
	anInstruction8 = genoperandoperand(AndCqR, 1, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, byteSizeReg);
	/* begin AddCq:R: */
	quickConstant6 = BaseHeaderSize / BytesPerWord;
	/* begin gen:quickConstant:operand: */
	anInstruction9 = genoperandoperand(AddCqR, quickConstant6, byteSizeReg);
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), byteSizeReg);
	jmpTarget(skip, gLogicalShiftLeftCqR(numSlotsHalfShift(), halfHeaderReg));
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, byteSizeReg);
	/* begin CmpCq:R: */
	quickConstant7 = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	anInstruction10 = genoperandoperand(CmpCqR, quickConstant7, byteSizeReg);
	/* begin JumpAboveOrEqual: */
	jumpNoSpace = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	anInstruction11 = genoperandoperand(MoveRAw, byteSizeReg, address1);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin MoveR:Mw:r: */
	anInstruction12 = genoperandoperandoperand(MoveRMwr, halfHeaderReg, 4, Arg1Reg);
	/* begin LoadEffectiveAddressMw:r:R: */
	anInstruction13 = genoperandoperandoperand(LoadEffectiveAddressMwrR, BaseHeaderSize, ReceiverResultReg, Arg1Reg);
	/* begin MoveCq:R: */
	quickConstant8 = nilObject();
	/* begin gen:quickConstant:operand: */
	anInstruction14 = genoperandoperand(MoveCqR, quickConstant8, fillReg);
	/* begin MoveR:Mw:r: */
	anInstruction15 = genoperandoperandoperand(MoveRMwr, fillReg, 0, Arg1Reg);
	fillLoop = anInstruction15;
	/* begin MoveR:Mw:r: */
	anInstruction16 = genoperandoperandoperand(MoveRMwr, fillReg, 4, Arg1Reg);
	/* begin AddCq:R: */
	anInstruction17 = genoperandoperand(AddCqR, 8, Arg1Reg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, byteSizeReg);
	/* begin JumpAbove: */
	genConditionalBranchoperand(JumpAbove, ((sqInt)fillLoop));
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpUnhashed, jmpTarget(jumpVariableOrEphemeron, jmpTarget(jumpTooBig, jmpTarget(jumpNoSpace, gLabel()))));
	return 0;
}


/*	Implement primitiveNewWithArg for convenient cases:
	- the receiver has a hash
	- the receiver is variable and not compiled method
	- single word header/num slots < numSlotsMask
	- the result fits in eden
	See superclass method for dynamic frequencies of formats.
	For the moment we implement only arrayFormat, firstByteFormat &
	firstLongFormat 
 */

	/* CogObjectRepresentationFor32BitSpur>>#genPrimitiveNewWithArg */
static sqInt
genPrimitiveNewWithArg(void)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction10;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction12;
    AbstractInstruction *anInstruction13;
    AbstractInstruction *anInstruction14;
    AbstractInstruction *anInstruction15;
    AbstractInstruction *anInstruction16;
    AbstractInstruction *anInstruction17;
    AbstractInstruction *anInstruction18;
    AbstractInstruction *anInstruction19;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction20;
    AbstractInstruction *anInstruction21;
    AbstractInstruction *anInstruction22;
    AbstractInstruction *anInstruction23;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    sqInt byteSizeReg;
    AbstractInstruction *fillLoop;
    sqInt fillReg;
    sqInt halfHeaderReg;
    sqInt instSpecReg;
    AbstractInstruction *jumpArrayFormat;
    AbstractInstruction *jumpArrayTooBig;
    AbstractInstruction *jumpByteFormat;
    AbstractInstruction *jumpBytePrepDone;
    AbstractInstruction *jumpByteTooBig;
    AbstractInstruction *jumpFailCuzFixed;
    AbstractInstruction *jumpHasSlots;
    AbstractInstruction *jumpLongPrepDone;
    AbstractInstruction *jumpLongTooBig;
    AbstractInstruction *jumpNElementsNonInt;
    AbstractInstruction *jumpNoSpace;
    AbstractInstruction *jumpUnhashed;
    sqInt literal;
    sqInt literal1;
    sqInt literal2;
    sqInt maxSlots;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;
    sqInt quickConstant6;
    sqInt quickConstant7;
    sqInt quickConstant8;
    AbstractInstruction *skip;
    sqInt wordConstant;

	if (methodOrBlockNumArgs != 1) {
		return UnimplementedPrimitive;
	}
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));

	/* inst spec will hold class's instance specification and then byte size and finally numSlots half of header */
	halfHeaderReg = (fillReg = SendNumArgsReg);

	/* The max slots we'll allocate here are those for a single header */
	instSpecReg = (byteSizeReg = ClassReg);

	/* get freeStart as early as possible so as not to wait later... */
	maxSlots = (numSlotsMask()) - 1;
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(MoveAwR, address, Arg1Reg);
	genGetHashFieldNonImmOfinto(ReceiverResultReg, halfHeaderReg);
	/* begin JumpZero: */
	jumpUnhashed = genConditionalBranchoperand(JumpZero, ((sqInt)0));

	/* get class's format inst var for inst spec (format field) */
	jumpNElementsNonInt = genJumpNotSmallInteger(Arg0Reg);
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ReceiverResultReg, instSpecReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant = (fixedFieldsFieldWidth()) + 1;
	genoperandoperand(LogicalShiftRightCqR, quickConstant, instSpecReg);
	/* begin AndCq:R: */
	quickConstant1 = formatMask();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(AndCqR, quickConstant1, instSpecReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instSpecReg, TempReg);
	/* begin LogicalShiftLeftCq:R: */
	quickConstant2 = formatShift();
	genoperandoperand(LogicalShiftLeftCqR, quickConstant2, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, halfHeaderReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	/* begin CmpCq:R: */
	quickConstant3 = arrayFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(CmpCqR, quickConstant3, instSpecReg);
	/* begin JumpZero: */
	jumpArrayFormat = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction3 = genoperandoperand(CmpCqR, quickConstant4, instSpecReg);
	/* begin JumpZero: */
	jumpByteFormat = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant5 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction4 = genoperandoperand(CmpCqR, quickConstant5, instSpecReg);
	/* begin JumpNonZero: */
	jumpFailCuzFixed = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	/* begin CmpCq:R: */
	literal = ((maxSlots << 1) | 1);
	anInstruction5 = genoperandoperand(CmpCqR, ((maxSlots << 1) | 1), Arg0Reg);
	/* begin JumpAbove: */
	jumpLongTooBig = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, instSpecReg);
	/* begin PushCq: */
	anInstruction6 = genoperand(PushCq, 0);
	/* begin Jump: */
	jumpLongPrepDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpByteFormat, gCmpCqR((((maxSlots * BytesPerWord) << 1) | 1), Arg0Reg));
	/* begin JumpAbove: */
	jumpByteTooBig = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, instSpecReg);
	/* begin MoveCq:R: */
	anInstruction7 = genoperandoperand(MoveCqR, BytesPerWord, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, instSpecReg, TempReg);
	/* begin AndCq:R: */
	literal1 = BytesPerWord - 1;
	anInstruction8 = genoperandoperand(AndCqR, BytesPerWord - 1, TempReg);
	/* begin LogicalShiftLeftCq:R: */
	quickConstant6 = formatShift();
	genoperandoperand(LogicalShiftLeftCqR, quickConstant6, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, halfHeaderReg);
	/* begin AddCq:R: */
	literal2 = BytesPerWord - 1;
	anInstruction9 = genoperandoperand(AddCqR, BytesPerWord - 1, instSpecReg);
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, shiftForWord(), instSpecReg);
	/* begin PushCq: */
	anInstruction10 = genoperand(PushCq, 0);
	/* begin Jump: */
	jumpBytePrepDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpArrayFormat, gCmpCqR(((maxSlots << 1) | 1), Arg0Reg));
	/* begin JumpAbove: */
	jumpArrayTooBig = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, instSpecReg);
	/* begin PushCw: */
	wordConstant = nilObject();
	/* begin gen:literal: */
	anInstruction11 = genoperand(PushCw, wordConstant);
	jmpTarget(jumpBytePrepDone, jmpTarget(jumpLongPrepDone, gLabel()));
	/* begin MoveR:Mw:r: */
	anInstruction12 = genoperandoperandoperand(MoveRMwr, halfHeaderReg, 0, Arg1Reg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instSpecReg, halfHeaderReg);
	/* begin CmpCq:R: */
	anInstruction13 = genoperandoperand(CmpCqR, 0, byteSizeReg);
	/* begin JumpNonZero: */
	jumpHasSlots = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveCq:R: */
	anInstruction14 = genoperandoperand(MoveCqR, BaseHeaderSize * 2, byteSizeReg);
	/* begin Jump: */
	skip = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpHasSlots, gMoveRR(byteSizeReg, TempReg));
	/* begin AndCq:R: */
	anInstruction15 = genoperandoperand(AndCqR, 1, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, TempReg, byteSizeReg);
	/* begin AddCq:R: */
	quickConstant7 = BaseHeaderSize / BytesPerWord;
	/* begin gen:quickConstant:operand: */
	anInstruction16 = genoperandoperand(AddCqR, quickConstant7, byteSizeReg);
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), byteSizeReg);
	jmpTarget(skip, gLogicalShiftLeftCqR(numSlotsHalfShift(), halfHeaderReg));
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, byteSizeReg);
	/* begin CmpCq:R: */
	quickConstant8 = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	anInstruction17 = genoperandoperand(CmpCqR, quickConstant8, byteSizeReg);
	/* begin JumpAboveOrEqual: */
	jumpNoSpace = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	anInstruction18 = genoperandoperand(MoveRAw, byteSizeReg, address1);
	/* begin MoveR:Mw:r: */
	anInstruction19 = genoperandoperandoperand(MoveRMwr, halfHeaderReg, 4, ReceiverResultReg);
	/* begin PopR: */
	genoperand(PopR, fillReg);
	/* begin LoadEffectiveAddressMw:r:R: */
	anInstruction20 = genoperandoperandoperand(LoadEffectiveAddressMwrR, BaseHeaderSize, ReceiverResultReg, Arg1Reg);
	/* begin MoveR:Mw:r: */
	anInstruction21 = genoperandoperandoperand(MoveRMwr, fillReg, 0, Arg1Reg);
	fillLoop = anInstruction21;
	/* begin MoveR:Mw:r: */
	anInstruction22 = genoperandoperandoperand(MoveRMwr, fillReg, 4, Arg1Reg);
	/* begin AddCq:R: */
	anInstruction23 = genoperandoperand(AddCqR, 8, Arg1Reg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, byteSizeReg);
	/* begin JumpAbove: */
	genConditionalBranchoperand(JumpAbove, ((sqInt)fillLoop));
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNoSpace, gPopR(TempReg));
	jmpTarget(jumpUnhashed, jmpTarget(jumpFailCuzFixed, jmpTarget(jumpArrayTooBig, jmpTarget(jumpByteTooBig, jmpTarget(jumpLongTooBig, jmpTarget(jumpNElementsNonInt, gLabel()))))));
	return 0;
}


/*	c.f. StackInterpreter>>stSizeOf: SpurMemoryManager>>lengthOf:format:
	fixedFieldsOf:format:length: 
 */

	/* CogObjectRepresentationFor32BitSpur>>#genPrimitiveStringAt */
static sqInt
genPrimitiveStringAt(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    AbstractInstruction *done;
    sqInt formatReg;
    AbstractInstruction *jumpBadIndex;
    AbstractInstruction *jumpBytesOutOfBounds;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction *jumpIsShorts;
    AbstractInstruction *jumpNotIndexable;
    AbstractInstruction *jumpShortsOutOfBounds;
    AbstractInstruction *jumpWordsDone;
    AbstractInstruction *jumpWordsOutOfBounds;
    AbstractInstruction *jumpWordTooBig;
    sqInt literal;
    sqInt literal1;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;

	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg0Reg, Arg1Reg);
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpBadIndex = genJumpNotSmallInteger(Arg0Reg);
	genConvertSmallIntegerToIntegerInReg(Arg1Reg);
	/* begin SubCq:R: */
	anInstruction1 = genoperandoperand(SubCqR, 1, Arg1Reg);
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), NoReg);
	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(CmpCqR, quickConstant, formatReg);
	/* begin JumpGreaterOrEqual: */
	jumpIsBytes = genConditionalBranchoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant1 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction3 = genoperandoperand(CmpCqR, quickConstant1, formatReg);
	/* begin JumpGreaterOrEqual: */
	jumpIsShorts = genConditionalBranchoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant2 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction4 = genoperandoperand(CmpCqR, quickConstant2, formatReg);
	/* begin JumpLess: */
	jumpNotIndexable = genConditionalBranchoperand(JumpLess, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpWordsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	quickConstant3 = ((usqInt) BaseHeaderSize) >> (shiftForWord());
	/* begin gen:quickConstant:operand: */
	anInstruction5 = genoperandoperand(AddCqR, quickConstant3, Arg1Reg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg1Reg, ReceiverResultReg, TempReg);
	jumpWordTooBig = jumpNotCharacterUnsignedValueInRegister(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ReceiverResultReg);
	/* begin Jump: */
	jumpWordsDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsBytes, gLogicalShiftLeftCqR(shiftForWord(), ClassReg));
	/* begin AndCq:R: */
	literal = BytesPerWord - 1;
	anInstruction6 = genoperandoperand(AndCqR, BytesPerWord - 1, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpBytesOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddCq:R: */
	literal1 = BaseHeaderSize;
	anInstruction7 = genoperandoperand(AddCqR, BaseHeaderSize, Arg1Reg);
	/* begin MoveXbr:R:R: */
	genoperandoperandoperand(MoveXbrRR, Arg1Reg, ReceiverResultReg, ReceiverResultReg);
	/* begin AndCq:R: */
	anInstruction = genoperandoperand(AndCqR, 0xFF, ReceiverResultReg);

	jmpTarget(jumpWordsDone, (done = gLabel()));
	genConvertIntegerToCharacterInReg(ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpIsShorts, gLogicalShiftLeftCqR((shiftForWord()) - 1, ClassReg));
	/* begin AndCq:R: */
	quickConstant4 = (BytesPerWord / 1) - 1;
	/* begin gen:quickConstant:operand: */
	anInstruction8 = genoperandoperand(AndCqR, quickConstant4, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg1Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpShortsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg1Reg, ReceiverResultReg);
	/* begin MoveM16:r:R: */
	anInstruction9 = genoperandoperandoperand(MoveM16rR, BaseHeaderSize, ReceiverResultReg, ReceiverResultReg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)done));
	jmpTarget(jumpWordTooBig, jmpTarget(jumpBytesOutOfBounds, jmpTarget(jumpShortsOutOfBounds, jmpTarget(jumpWordsOutOfBounds, jmpTarget(jumpNotIndexable, jmpTarget(jumpBadIndex, gLabel()))))));
	return CompletePrimitive;
}


/*	c.f. StackInterpreter>>stSizeOf: SpurMemoryManager>>lengthOf:format:
	fixedFieldsOf:format:length: 
 */

	/* CogObjectRepresentationFor32BitSpur>>#genPrimitiveStringAtPut */
static sqInt
genPrimitiveStringAtPut(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction10;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    sqInt formatReg;
    AbstractInstruction *jumpBadArg;
    AbstractInstruction *jumpBadIndex;
    AbstractInstruction *jumpBytesOutOfBounds;
    AbstractInstruction *jumpBytesOutOfRange;
    sqInt jumpImmutable;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction * jumpIsCompiledMethod;
    AbstractInstruction *jumpIsShorts;
    AbstractInstruction * jumpNotString;
    AbstractInstruction *jumpShortsOutOfBounds;
    AbstractInstruction *jumpShortsOutOfRange;
    AbstractInstruction *jumpWordsOutOfBounds;
    AbstractInstruction *jumpWordsOutOfRange;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;

	jumpImmutable = 0;
	/* begin genLoadArgAtDepth:into: */
	assert(1 < (numRegArgs()));
	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	jumpBadIndex = genJumpNotSmallInteger(Arg0Reg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	jumpBadArg = genJumpNotCharacterInScratchReg(TempReg);
	genConvertSmallIntegerToIntegerInReg(Arg0Reg);
	/* begin SubCq:R: */
	anInstruction10 = genoperandoperand(SubCqR, 1, Arg0Reg);
	
#  if IMMUTABILITY
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), TempReg);
	jumpImmutable = genJumpBaseHeaderImmutable(TempReg);

#  else /* IMMUTABILITY */
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, (formatReg = SendNumArgsReg), NoReg);

#  endif /* IMMUTABILITY */

	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(CmpCqR, quickConstant, formatReg);
	/* begin JumpBelow: */
	jumpNotString = genConditionalBranchoperand(JumpBelow, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant1 = firstCompiledMethodFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(CmpCqR, quickConstant1, formatReg);
	/* begin JumpAboveOrEqual: */
	jumpIsCompiledMethod = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant2 = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(CmpCqR, quickConstant2, formatReg);
	/* begin JumpAboveOrEqual: */
	jumpIsBytes = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant3 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction3 = genoperandoperand(CmpCqR, quickConstant3, formatReg);
	/* begin JumpAboveOrEqual: */
	jumpIsShorts = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	anInstruction4 = genoperandoperand(CmpCqR, 0, Arg1Reg);
	/* begin JumpLess: */
	jumpWordsOutOfRange = genConditionalBranchoperand(JumpLess, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpWordsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertCharacterToCodeInReg(TempReg);
	/* begin AddCq:R: */
	anInstruction5 = genoperandoperand(AddCqR, ((usqInt) BaseHeaderSize) >> (shiftForWord()), Arg0Reg);
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpIsShorts, gCmpCqR(characterObjectOf(0xFFFF), Arg1Reg));
	/* begin JumpAbove: */
	jumpShortsOutOfRange = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, (shiftForWord()) - 1, ClassReg);
	/* begin AndCq:R: */
	anInstruction6 = genoperandoperand(AndCqR, (BytesPerWord / 2) - 1, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpShortsOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertCharacterToCodeInReg(TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:M16:r: */
	anInstruction11 = genoperandoperandoperand(MoveRM16r, TempReg, BaseHeaderSize, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpIsBytes, gCmpCqR(characterObjectOf(0xFF), Arg1Reg));
	/* begin JumpAbove: */
	jumpBytesOutOfRange = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), ClassReg);
	/* begin AndCq:R: */
	anInstruction7 = genoperandoperand(AndCqR, BytesPerWord - 1, formatReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, formatReg, ClassReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, Arg0Reg, ClassReg);
	/* begin JumpBelowOrEqual: */
	jumpBytesOutOfBounds = genConditionalBranchoperand(JumpBelowOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, TempReg);
	genConvertCharacterToCodeInReg(TempReg);
	/* begin AddCq:R: */
	anInstruction8 = genoperandoperand(AddCqR, BaseHeaderSize, Arg0Reg);
	/* begin MoveR:Xbr:R: */
	genoperandoperandoperand(MoveRXbrR, TempReg, Arg0Reg, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, Arg1Reg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotString, jmpTarget(jumpBytesOutOfRange, jmpTarget(jumpShortsOutOfRange, jmpTarget(jumpWordsOutOfRange, jmpTarget(jumpIsCompiledMethod, jmpTarget(jumpBytesOutOfBounds, jmpTarget(jumpShortsOutOfBounds, jmpTarget(jumpWordsOutOfBounds, gLabel()))))))));
	
#  if IMMUTABILITY
	jmpTarget(jumpImmutable, getJmpTarget(jumpNotString));

#  endif /* IMMUTABILITY */

	/* begin AddCq:R: */
	anInstruction9 = genoperandoperand(AddCqR, 1, Arg0Reg);
	genConvertIntegerToSmallIntegerInReg(Arg0Reg);
	jmpTarget(jumpBadArg, jmpTarget(jumpBadIndex, gLabel()));
	return CompletePrimitive;
}

	/* CogObjectRepresentationFor32BitSpur>>#genRemoveSmallIntegerTagsInScratchReg: */
static sqInt NoDbgRegParms
genRemoveSmallIntegerTagsInScratchReg(sqInt scratchReg)
{
    AbstractInstruction *anInstruction;

	/* begin SubCq:R: */
	anInstruction = genoperandoperand(SubCqR, 1, scratchReg);
	return 0;
}

	/* CogObjectRepresentationFor32BitSpur>>#genShiftAwaySmallIntegerTagsInScratchReg: */
static sqInt NoDbgRegParms
genShiftAwaySmallIntegerTagsInScratchReg(sqInt scratchReg)
{
	/* begin ArithmeticShiftRightCq:R: */
	genoperandoperand(ArithmeticShiftRightCqR, 1, scratchReg);
	return 0;
}


/*	Answer the relevant inline cache tag for an instance.
	c.f. getInlineCacheClassTagFrom:into: & inlineCacheTagForClass: */

	/* CogObjectRepresentationFor32BitSpur>>#inlineCacheTagForInstance: */
static sqInt NoDbgRegParms
inlineCacheTagForInstance(sqInt oop)
{
	return (isImmediate(oop)
		? oop & 1
		: classIndexOf(oop));
}

	/* CogObjectRepresentationFor32BitSpur>>#jumpNotSmallIntegerUnsignedValueInRegister: */
static AbstractInstruction * NoDbgRegParms
jumpNotSmallIntegerUnsignedValueInRegister(sqInt reg)
{
    AbstractInstruction *anInstruction;

	/* begin CmpCq:R: */
	anInstruction = genoperandoperand(CmpCqR, 0x3FFFFFFF, reg);
	/* begin JumpAbove: */
	return genConditionalBranchoperand(JumpAbove, ((sqInt)0));
}


/*	Mark and trace a literal in an inline cache preceding address in
	cogMethodOrNil. Answer if code was modified. */

	/* CogObjectRepresentationFor32BitSpur>>#markAndTraceCacheTagLiteral:in:atpc: */
static sqInt NoDbgRegParms
markAndTraceCacheTagLiteralinatpc(sqInt literal, CogMethod *cogMethodOrNil, usqInt address)
{
    sqInt objOop;

	if (!(couldBeObject(literal))) {
		return 0;
	}
	assert(addressCouldBeObj(literal));
	if (!(isForwarded(literal))) {
		markAndTrace(literal);
		return 0;
	}
	objOop = followForwarded(literal);
	rewriteInlineCacheTagat(backEnd(), objOop, address);
	markAndTraceUpdatedLiteralin(objOop, cogMethodOrNil);
	return 1;
}

	/* CogObjectRepresentationFor32BitSpur>>#numSmallIntegerBits */
static sqInt
numSmallIntegerBits(void)
{
	return 0x1F;
}


/*	The two valid tag patterns are 0 (Character) and 1 (SmallInteger) */

	/* CogObjectRepresentationFor32BitSpur>>#validInlineCacheTag: */
static sqInt NoDbgRegParms
validInlineCacheTag(usqInt classIndexOrTagPattern)
{
	return (classIndexOrTagPattern <= 1)
	 || ((classAtIndex(classIndexOrTagPattern)) != null);
}


/*	Answer if the cacheTag is not unmarked, i.e. answer true for compact class
	indices and immediates; only answer false for unmarked objects. In Spur
	linked send cache tags are class indices so effectively they're always
	marked.  */

	/* CogObjectRepresentationForSpur>>#cacheTagIsMarked: */
static sqInt NoDbgRegParms
cacheTagIsMarked(sqInt cacheTag)
{
	return 1;
}

	/* CogObjectRepresentationForSpur>>#checkValidOopReference: */
static sqInt NoDbgRegParms
checkValidOopReference(sqInt anOop)
{
	return (isImmediate(anOop))
	 || ((heapMapAtWord(pointerForOop(anOop))) != 0);
}

	/* CogObjectRepresentationForSpur>>#couldBeObject: */
static sqInt NoDbgRegParms
couldBeObject(sqInt literal)
{
	return (isNonImmediate(literal))
	 && (oopisGreaterThanOrEqualTo(literal, startOfMemory()));
}


/*	Create a trampoline to answer the active context that will
	answer it if a frame is already married, and create it otherwise.
	Assume numArgs is in SendNumArgsReg and ClassReg is free. */

	/* CogObjectRepresentationForSpur>>#genActiveContextTrampolineLarge:inBlock:called: */
static sqInt NoDbgRegParms
genActiveContextTrampolineLargeinBlockcalled(sqInt isLarge, sqInt isInBlock, char *aString)
{
    sqInt startAddress;

	startAddress = methodZoneBase();
	zeroOpcodeIndex();
	genGetActiveContextLargeinBlock(isLarge, isInBlock);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress(aString, startAddress);
	recordRunTimeObjectReferences();
	return startAddress;
}

	/* CogObjectRepresentationForSpur>>#genConvertCharacterToCodeInReg: */
static sqInt NoDbgRegParms
genConvertCharacterToCodeInReg(sqInt reg)
{
    sqInt quickConstant;

	/* begin LogicalShiftRightCq:R: */
	quickConstant = numTagBits();
	genoperandoperand(LogicalShiftRightCqR, quickConstant, reg);
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genConvertIntegerToCharacterInReg: */
static sqInt NoDbgRegParms
genConvertIntegerToCharacterInReg(sqInt reg)
{
    AbstractInstruction *anInstruction;
    sqInt quickConstant;
    sqInt quickConstant1;

	/* begin LogicalShiftLeftCq:R: */
	quickConstant = numTagBits();
	genoperandoperand(LogicalShiftLeftCqR, quickConstant, reg);
	/* begin AddCq:R: */
	quickConstant1 = characterTag();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AddCqR, quickConstant1, reg);
	return 0;
}


/*	Create a closure with the given startpc, numArgs and numCopied
	within a context with ctxtNumArgs, large if isLargeCtxt that is in a
	block if isInBlock. If numCopied > 0 pop those values off the stack. */

	/* CogObjectRepresentationForSpur>>#genCreateClosureAt:numArgs:numCopied:contextNumArgs:large:inBlock: */
static sqInt NoDbgRegParms
genCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock)
{
    AbstractInstruction *anInstruction;
    sqInt i;

	genNoPopCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(bcpc, numArgs, numCopied, ctxtNumArgs, isLargeCtxt, isInBlock);
	for (i = 1; i <= numCopied; i += 1) {
		/* begin PopR: */
		genoperand(PopR, TempReg);
		/* begin MoveR:Mw:r: */
		anInstruction = genoperandoperandoperand(MoveRMwr, TempReg, (((numCopied - i) + ClosureFirstCopiedValueIndex) * BytesPerOop) + BaseHeaderSize, ReceiverResultReg);
	}
	return 0;
}


/*	Make sure that the object in reg is not forwarded. This routine assumes
	the object will
	never be forwarded to an immediate, as it is used to unforward literal
	variables (associations). 
	Use the fact that isForwardedObjectClassIndexPun is a power of two to save
	an instruction. */

	/* CogObjectRepresentationForSpur>>#genEnsureObjInRegNotForwarded:scratchReg: */
static sqInt NoDbgRegParms
genEnsureObjInRegNotForwardedscratchReg(sqInt reg, sqInt scratch)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *loop;
    AbstractInstruction *ok;
    sqInt quickConstant;

	assert(reg != scratch);
	/* begin Label */
	loop = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin MoveMw:r:R: */
	anInstruction1 = genoperandoperandoperand(MoveMwrR, 0, reg, scratch);
	/* begin AndCq:R: */
	quickConstant = (classIndexMask()) - (isForwardedObjectClassIndexPun());
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AndCqR, quickConstant, scratch);
	/* begin JumpNonZero: */
	ok = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(0, reg, reg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)loop));
	jmpTarget(ok, gLabel());
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genEnsureOopInRegNotForwarded:scratchReg: */
static sqInt NoDbgRegParms
genEnsureOopInRegNotForwardedscratchReg(sqInt reg, sqInt scratch)
{
	return genEnsureOopInRegNotForwardedscratchRegjumpBackTo(reg, scratch, gLabel());
}

	/* CogObjectRepresentationForSpur>>#genEnsureOopInRegNotForwarded:scratchReg:jumpBackTo: */
static sqInt NoDbgRegParms
genEnsureOopInRegNotForwardedscratchRegjumpBackTo(sqInt reg, sqInt scratch, AbstractInstruction *instruction)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *finished;
    AbstractInstruction *imm;
    AbstractInstruction *ok;
    sqInt quickConstant;

	/* begin genEnsureOopInRegNotForwarded:scratchReg:ifForwarder:ifNotForwarder: */
	assert(reg != scratch);

	/* notionally
	   self genGetClassIndexOfNonImm: reg into: scratch.
	   cogit CmpCq: objectMemory isForwardedObjectClassIndexPun R: TempReg.
	   but the following is an instruction shorter: */
	imm = genJumpImmediate(reg);
	/* begin MoveMw:r:R: */
	anInstruction = genoperandoperandoperand(MoveMwrR, 0, reg, scratch);
	/* begin AndCq:R: */
	quickConstant = (classIndexMask()) - (isForwardedObjectClassIndexPun());
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(AndCqR, quickConstant, scratch);
	/* begin JumpNonZero: */
	ok = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(0, reg, reg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)(((void *) instruction))));
	/* begin Label */
	finished = genoperandoperand(Label, (labelCounter += 1), bytecodePC);

	jmpTarget(imm, jmpTarget(ok, finished));
	return 0;
}


/*	Make sure that the oop in reg is not forwarded, updating the slot in
	objReg with the value.
 */

	/* CogObjectRepresentationForSpur>>#genEnsureOopInRegNotForwarded:scratchReg:updatingSlot:in: */
static sqInt NoDbgRegParms
genEnsureOopInRegNotForwardedscratchRegupdatingSlotin(sqInt reg, sqInt scratch, sqInt index, sqInt objReg)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *imm;
    AbstractInstruction *loop;
    AbstractInstruction *ok;
    sqInt quickConstant;


	/* Open-code
	   self genEnsureOopInRegNotForwarded: reg
	   scratchReg: scratch
	   updatingMw: index * objectMemory wordSize + objectMemory baseHeaderSize
	   r: objReg.
	   to avoid calling the store check unless the receiver is forwarded. */
	assert((reg != scratch)
	 && (objReg != scratch));
	/* begin Label */
	loop = genoperandoperand(Label, (labelCounter += 1), bytecodePC);

	/* notionally
	   self genGetClassIndexOfNonImm: reg into: scratch.
	   cogit CmpCq: objectMemory isForwardedObjectClassIndexPun R: TempReg.
	   but the following is an instruction shorter: */
	imm = genJumpImmediate(reg);
	/* begin MoveMw:r:R: */
	anInstruction1 = genoperandoperandoperand(MoveMwrR, 0, reg, scratch);
	/* begin AndCq:R: */
	quickConstant = (classIndexMask()) - (isForwardedObjectClassIndexPun());
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AndCqR, quickConstant, scratch);
	/* begin JumpNonZero: */
	ok = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(0, reg, reg);
	/* begin MoveR:Mw:r: */
	anInstruction2 = genoperandoperandoperand(MoveRMwr, reg, (index * BytesPerWord) + BaseHeaderSize, objReg);
	assert((reg == Arg0Reg)
	 && ((scratch == TempReg)
	 && (objReg == ReceiverResultReg)));
	/* begin CallRT: */
	abstractInstruction = genoperand(Call, ceStoreCheckContextReceiverTrampoline);
	(abstractInstruction->annotation = IsRelativeCall);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)loop));
	jmpTarget(ok, jmpTarget(imm, gLabel()));
	return 0;
}


/*	Do the store check. Answer the argument for the benefit of the code
	generator; ReceiverResultReg may be caller-saved and hence smashed by this
	call. Answering
	it allows the code generator to reload ReceiverResultReg cheaply.
	In Spur the only thing we leave to the run-time is adding the receiver to
	the remembered set and setting its isRemembered bit. */

	/* CogObjectRepresentationForSpur>>#generateObjectRepresentationTrampolines */
static void
generateObjectRepresentationTrampolines(void)
{
    sqInt ceCannotAssignToWithIndexTrampoline;

	
#  if IMMUTABILITY

	/* c.f. genImmutableCheck:slotIndex:sourceReg:scratchReg:popBoolean:needRestoreRcvr: */
	ceCannotAssignToWithIndexTrampoline = genTrampolineForcalledargargarg(ceCannotAssignTowithIndexvalueToAssign, "ceCannotAssignToWithIndexTrampoline", ReceiverResultReg, TempReg, ClassReg);

#  endif /* IMMUTABILITY */

	ceStoreCheckTrampoline = genTrampolineForcalledargresult(remember, "ceStoreCheckTrampoline", ReceiverResultReg, returnRegForStoreCheck());
	ceStoreCheckContextReceiverTrampoline = genStoreCheckContextReceiverTrampoline();
	ceScheduleScavengeTrampoline = genSafeTrampolineForcalled(ceScheduleScavenge, "ceScheduleScavengeTrampoline");
	ceSmallActiveContextInMethodTrampoline = genActiveContextTrampolineLargeinBlockcalled(0, 0, "ceSmallMethodContext");
	ceSmallActiveContextInBlockTrampoline = genActiveContextTrampolineLargeinBlockcalled(0, 1, "ceSmallBlockContext");
	ceLargeActiveContextInMethodTrampoline = genActiveContextTrampolineLargeinBlockcalled(1, 0, "ceLargeMethodContext");
	ceLargeActiveContextInBlockTrampoline = genActiveContextTrampolineLargeinBlockcalled(1, 1, "ceLargeBlockContext");
}


/*	Create a trampoline to answer the active context that will
	answer it if a frame is already married, and create it otherwise.
	Assume numArgs is in SendNumArgsReg and ClassReg is free. */

	/* CogObjectRepresentationForSpur>>#genGetActiveContextLarge:inBlock: */
static sqInt NoDbgRegParms
genGetActiveContextLargeinBlock(sqInt isLarge, sqInt isInBlock)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction10;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction12;
    AbstractInstruction *anInstruction13;
    AbstractInstruction *anInstruction14;
    AbstractInstruction *anInstruction15;
    AbstractInstruction *anInstruction16;
    AbstractInstruction *anInstruction17;
    AbstractInstruction *anInstruction18;
    AbstractInstruction *anInstruction19;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction20;
    AbstractInstruction *anInstruction21;
    AbstractInstruction *anInstruction22;
    AbstractInstruction *anInstruction23;
    AbstractInstruction *anInstruction24;
    AbstractInstruction *anInstruction25;
    AbstractInstruction *anInstruction26;
    AbstractInstruction *anInstruction27;
    AbstractInstruction *anInstruction28;
    AbstractInstruction *anInstruction29;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction30;
    AbstractInstruction *anInstruction31;
    AbstractInstruction *anInstruction32;
    AbstractInstruction *anInstruction33;
    AbstractInstruction *anInstruction34;
    AbstractInstruction *anInstruction35;
    AbstractInstruction *anInstruction36;
    AbstractInstruction *anInstruction37;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    sqInt constant;
    AbstractInstruction *continuation;
    AbstractInstruction *exit;
    usqLong header;
    AbstractInstruction * inst;
    AbstractInstruction *jumpNeedScavenge;
    AbstractInstruction *jumpSingle;
    AbstractInstruction *loopHead;
    sqInt offset;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    AbstractInstruction * self_in_saveAndRestoreLinkRegAround;
    sqInt slotSize;


	/* load the flag; stash it in both TempReg & ClassReg; do the compare (a prime candidated for use of AndCq:R:R:) */
	/* begin MoveMw:r:R: */
	anInstruction6 = genoperandoperandoperand(MoveMwrR, FoxMethod, FPReg, ClassReg);
	gAndCqRR(MFMethodFlagHasContextFlag, ClassReg, TempReg);
	/* begin JumpZero: */
	jumpSingle = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	anInstruction7 = genoperandoperandoperand(MoveMwrR, FoxThisContext, FPReg, ReceiverResultReg);
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpSingle, gLabel());
	/* begin OrCq:R: */
	anInstruction8 = genoperandoperand(OrCqR, MFMethodFlagHasContextFlag, ClassReg);
	/* begin MoveR:Mw:r: */
	anInstruction9 = genoperandoperandoperand(MoveRMwr, ClassReg, FoxMethod, FPReg);
	if (isInBlock) {
		/* begin SubCq:R: */
		anInstruction = genoperandoperand(SubCqR, 3, ClassReg);
		/* begin MoveM16:r:R: */
		anInstruction1 = genoperandoperandoperand(MoveM16rR, 0, ClassReg, TempReg);
		/* begin SubR:R: */
		genoperandoperand(SubRR, TempReg, ClassReg);
	}
	else {
		/* begin SubCq:R: */
		anInstruction2 = genoperandoperand(SubCqR, 1, ClassReg);
	}
	slotSize = (isLarge
		? LargeContextSlots
		: SmallContextSlots);
	header = headerForSlotsformatclassIndex(slotSize, indexablePointersFormat(), ClassMethodContextCompactIndex);
	flag("endianness");
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	anInstruction10 = genoperandoperand(MoveAwR, address, ReceiverResultReg);
	/* begin genStoreHeader:intoNewInstance:using: */
	flag("endianness");
	/* begin MoveCq:R: */
	quickConstant1 = ((usqInt) header);
	/* begin gen:quickConstant:operand: */
	anInstruction11 = genoperandoperand(MoveCqR, quickConstant1, TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction12 = genoperandoperandoperand(MoveRMwr, TempReg, 0, ReceiverResultReg);
	/* begin MoveCq:R: */
	anInstruction21 = genoperandoperand(MoveCqR, header >> 32, TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction31 = genoperandoperandoperand(MoveRMwr, TempReg, 4, ReceiverResultReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	/* begin AddCq:R: */
	quickConstant2 = smallObjectBytesForSlots(slotSize);
	/* begin gen:quickConstant:operand: */
	anInstruction13 = genoperandoperand(AddCqR, quickConstant2, TempReg);
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	anInstruction14 = genoperandoperand(MoveRAw, TempReg, address1);
	/* begin CmpCq:R: */
	quickConstant3 = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	anInstruction15 = genoperandoperand(CmpCqR, quickConstant3, TempReg);
	/* begin JumpAboveOrEqual: */
	jumpNeedScavenge = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	/* begin MoveR:R: */
	continuation = genoperandoperand(MoveRR, FPReg, TempReg);
	genSetSmallIntegerTagsIn(TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction16 = genoperandoperandoperand(MoveRMwr, TempReg, BaseHeaderSize + (SenderIndex * BytesPerOop), ReceiverResultReg);
	/* begin MoveMw:r:R: */
	anInstruction17 = genoperandoperandoperand(MoveMwrR, FoxSavedFP, FPReg, TempReg);
	genSetSmallIntegerTagsIn(TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction18 = genoperandoperandoperand(MoveRMwr, TempReg, BaseHeaderSize + (InstructionPointerIndex * BytesPerOop), ReceiverResultReg);
	/* begin MoveMw:r:R: */
	offset = offsetof(CogMethod, methodObject);
	/* begin gen:quickConstant:operand:operand: */
	anInstruction19 = genoperandoperandoperand(MoveMwrR, offset, ClassReg, TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction20 = genoperandoperandoperand(MoveRMwr, TempReg, BaseHeaderSize + (MethodIndex * BytesPerWord), ReceiverResultReg);
	/* begin MoveR:Mw:r: */
	anInstruction22 = genoperandoperandoperand(MoveRMwr, ReceiverResultReg, FoxThisContext, FPReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, FPReg, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SPReg, TempReg);
	/* begin LogicalShiftRightCq:R: */
	genoperandoperand(LogicalShiftRightCqR, 2, TempReg);
	/* begin SubCq:R: */
	quickConstant4 = 3;
	/* begin gen:quickConstant:operand: */
	anInstruction23 = genoperandoperand(SubCqR, quickConstant4, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, SendNumArgsReg, TempReg);
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction24 = genoperandoperandoperand(MoveRMwr, TempReg, BaseHeaderSize + (StackPointerIndex * BytesPerOop), ReceiverResultReg);
	if (isInBlock) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, SendNumArgsReg, TempReg);
		/* begin AddCq:R: */
		anInstruction3 = genoperandoperand(AddCqR, 2, TempReg);
		/* begin MoveXwr:R:R: */
		genoperandoperandoperand(MoveXwrRR, TempReg, FPReg, TempReg);
	}
	else {
		/* begin genMoveConstant:R: */
		constant = nilObject();
		if (shouldAnnotateObjectReference(constant)) {
			annotateobjRef(gMoveCwR(constant, TempReg), constant);
		}
		else {
			/* begin MoveCq:R: */
			anInstruction37 = genoperandoperand(MoveCqR, constant, TempReg);
		}
	}
	/* begin MoveR:Mw:r: */
	anInstruction25 = genoperandoperandoperand(MoveRMwr, TempReg, BaseHeaderSize + (ClosureIndex * BytesPerOop), ReceiverResultReg);
	/* begin MoveMw:r:R: */
	anInstruction26 = genoperandoperandoperand(MoveMwrR, FoxMFReceiver, FPReg, TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction27 = genoperandoperandoperand(MoveRMwr, TempReg, BaseHeaderSize + (ReceiverIndex * BytesPerOop), ReceiverResultReg);
	/* begin MoveCq:R: */
	anInstruction28 = genoperandoperand(MoveCqR, 1, ClassReg);
	/* begin CmpR:R: */
	loopHead = genoperandoperand(CmpRR, SendNumArgsReg, ClassReg);
	/* begin JumpGreater: */
	exit = genConditionalBranchoperand(JumpGreater, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, TempReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, ClassReg, TempReg);
	/* begin AddCq:R: */
	anInstruction29 = genoperandoperand(AddCqR, 2, TempReg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, TempReg, FPReg, TempReg);
	/* begin AddCq:R: */
	anInstruction30 = genoperandoperand(AddCqR, ReceiverIndex + (BaseHeaderSize / BytesPerWord), ClassReg);
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, ClassReg, ReceiverResultReg);
	/* begin SubCq:R: */
	anInstruction32 = genoperandoperand(SubCqR, (ReceiverIndex + (BaseHeaderSize / BytesPerWord)) - 1, ClassReg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)loopHead));
	jmpTarget(exit, gLabel());
	/* begin MoveCq:R: */
	quickConstant = nilObject();
	/* begin gen:quickConstant:operand: */
	anInstruction4 = genoperandoperand(MoveCqR, quickConstant, TempReg);

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, FPReg, ClassReg);
	/* begin AddCq:R: */
	anInstruction33 = genoperandoperand(AddCqR, FoxMFReceiver, ClassReg);
	/* begin AddCq:R: */
	anInstruction34 = genoperandoperand(AddCqR, (ReceiverIndex + 1) + (BaseHeaderSize / BytesPerWord), SendNumArgsReg);
	/* begin SubCq:R: */
	anInstruction35 = genoperandoperand(SubCqR, BytesPerWord, ClassReg);
	loopHead = anInstruction35;
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SPReg, ClassReg);
	/* begin JumpBelow: */
	exit = genConditionalBranchoperand(JumpBelow, ((sqInt)0));

	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, SendNumArgsReg, ReceiverResultReg);
	/* begin AddCq:R: */
	anInstruction36 = genoperandoperand(AddCqR, 1, SendNumArgsReg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)loopHead));
	jmpTarget(exit, gLabel());
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNeedScavenge, gLabel());
	/* begin saveAndRestoreLinkRegAround: */
	self_in_saveAndRestoreLinkRegAround = ((AbstractInstruction *) (backEnd()));
	/* begin PushR: */
	inst = genoperand(PushR, LinkReg);
	/* begin CallRT: */
	abstractInstruction = genoperand(Call, ceScheduleScavengeTrampoline);
	(abstractInstruction->annotation = IsRelativeCall);

	/* begin PopR: */
	genoperand(PopR, LinkReg);
	/* begin Jump: */
	genoperand(Jump, ((sqInt)continuation));
	return 0;
}


/*	Get the active context into ReceiverResultReg, creating it if necessary. */

	/* CogObjectRepresentationForSpur>>#genGetActiveContextNumArgs:large:inBlock: */
static sqInt NoDbgRegParms
genGetActiveContextNumArgslargeinBlock(sqInt numArgs, sqInt isLargeContext, sqInt isInBlock)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *anInstruction;
    sqInt routine;

	routine = (isLargeContext
		? (isInBlock
				? ceLargeActiveContextInBlockTrampoline
				: ceLargeActiveContextInMethodTrampoline)
		: (isInBlock
				? ceSmallActiveContextInBlockTrampoline
				: ceSmallActiveContextInMethodTrampoline));
	/* begin MoveCq:R: */
	anInstruction = genoperandoperand(MoveCqR, numArgs, SendNumArgsReg);
	/* begin CallRT: */
	abstractInstruction = genoperand(Call, routine);
	(abstractInstruction->annotation = IsRelativeCall);
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genGetBits:ofFormatByteOf:into: */
static sqInt NoDbgRegParms
genGetBitsofFormatByteOfinto(sqInt mask, sqInt sourceReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;

	flag("endianness");
	/* begin MoveMb:r:R: */
	anInstruction1 = genoperandoperandoperand(MoveMbrR, 3, sourceReg, destReg);
	/* begin AndCq:R: */
	anInstruction = genoperandoperand(AndCqR, mask, destReg);
	return 0;
}


/*	Fetch the instance's class index into destReg. */

	/* CogObjectRepresentationForSpur>>#genGetClassIndexOfNonImm:into: */
static sqInt NoDbgRegParms
genGetClassIndexOfNonImminto(sqInt sourceReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    sqInt quickConstant;

	/* begin MoveMw:r:R: */
	anInstruction1 = genoperandoperandoperand(MoveMwrR, 0, sourceReg, destReg);
	/* begin AndCq:R: */
	quickConstant = classIndexMask();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AndCqR, quickConstant, destReg);
	return 0;
}


/*	Fetch the class object whose index is in instReg into destReg.
	It is non-obvious, but the Cogit assumes loading a class does not involve
	a runtime call, so do not call classAtIndex: */

	/* CogObjectRepresentationForSpur>>#genGetClassObjectOfClassIndex:into:scratchReg: */
static sqInt NoDbgRegParms
genGetClassObjectOfClassIndexintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    sqInt offset;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;

	assert(instReg != destReg);
	assert(instReg != scratchReg);
	assert(destReg != scratchReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instReg, scratchReg);
	/* begin LogicalShiftRightCq:R: */
	quickConstant1 = classTableMajorIndexShift();
	genoperandoperand(LogicalShiftRightCqR, quickConstant1, scratchReg);
	/* begin LogicalShiftLeftCq:R: */
	genoperandoperand(LogicalShiftLeftCqR, shiftForWord(), scratchReg);
	assert(!(shouldAnnotateObjectReference(classTableRootObj())));
	/* begin MoveMw:r:R: */
	offset = (classTableRootObj()) + BaseHeaderSize;
	/* begin gen:quickConstant:operand:operand: */
	anInstruction3 = genoperandoperandoperand(MoveMwrR, offset, scratchReg, destReg);

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instReg, scratchReg);
	/* begin AndCq:R: */
	quickConstant2 = classTableMinorIndexMask();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(AndCqR, quickConstant2, scratchReg);
	/* begin AddCq:R: */
	anInstruction2 = genoperandoperand(AddCqR, ((usqInt) BaseHeaderSize) >> (shiftForWord()), scratchReg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, scratchReg, destReg, destReg);
	return 0;
}


/*	Fetch the instance's class into destReg. If the instance is not the
	receiver and is forwarded, follow forwarding. */

	/* CogObjectRepresentationForSpur>>#genGetClassObjectOf:into:scratchReg:instRegIsReceiver: */
static sqInt NoDbgRegParms
genGetClassObjectOfintoscratchReginstRegIsReceiver(sqInt instReg, sqInt destReg, sqInt scratchReg, sqInt instRegIsReceiver)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *jumpIsImm;
    AbstractInstruction *jumpNotForwarded;
    AbstractInstruction *loop;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;

	if (instReg == destReg) {
		return BadRegisterSet;
	}
	/* begin MoveR:R: */
	loop = genoperandoperand(MoveRR, instReg, scratchReg);
	/* begin AndCq:R: */
	quickConstant1 = tagMask();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(AndCqR, quickConstant1, scratchReg);
	/* begin JumpNonZero: */
	jumpIsImm = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	flag("endianness");
	/* begin MoveMw:r:R: */
	anInstruction4 = genoperandoperandoperand(MoveMwrR, 0, instReg, scratchReg);
	/* begin AndCq:R: */
	quickConstant2 = classIndexMask();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(AndCqR, quickConstant2, scratchReg);
	if (!instRegIsReceiver) {

		/* if it is forwarded... */
		/* begin CmpCq:R: */
		quickConstant = isForwardedObjectClassIndexPun();
		/* begin gen:quickConstant:operand: */
		anInstruction = genoperandoperand(CmpCqR, quickConstant, scratchReg);
		/* begin JumpNonZero: */
		jumpNotForwarded = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
		/* begin MoveMw:r:R: */
		anInstruction3 = genoperandoperandoperand(MoveMwrR, BaseHeaderSize, instReg, instReg);
		/* begin Jump: */
		genoperand(Jump, ((sqInt)loop));
		jmpTarget(jumpNotForwarded, gLabel());
	}
	jmpTarget(jumpIsImm, gMoveRR(scratchReg, destReg));
	/* begin PushR: */
	genoperand(PushR, instReg);
	genGetClassObjectOfClassIndexintoscratchReg(destReg, instReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, instReg, destReg);
	/* begin PopR: */
	genoperand(PopR, instReg);
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genGetClassTagOf:into:scratchReg: */
static AbstractInstruction * NoDbgRegParms
genGetClassTagOfintoscratchReg(sqInt instReg, sqInt destReg, sqInt scratchReg)
{
	return genGetInlineCacheClassTagFromintoforEntry(instReg, destReg, 1);
}


/*	Fetch the instance's class index into destReg. */

	/* CogObjectRepresentationForSpur>>#genGetCompactClassIndexNonImmOf:into: */
static sqInt NoDbgRegParms
genGetCompactClassIndexNonImmOfinto(sqInt instReg, sqInt destReg)
{
	return genGetClassIndexOfNonImminto(instReg, destReg);
}

	/* CogObjectRepresentationForSpur>>#genGetDoubleValueOf:into: */
static sqInt NoDbgRegParms
genGetDoubleValueOfinto(sqInt srcReg, sqInt destFPReg)
{
    AbstractInstruction *anInstruction;

	/* begin MoveM64:r:Rd: */
	anInstruction = genoperandoperandoperand(MoveM64rRd, BaseHeaderSize, srcReg, destFPReg);
	return 0;
}


/*	Get the format field of the object in srcReg into destReg.
	srcReg may equal destReg. */

	/* CogObjectRepresentationForSpur>>#genGetFormatOf:into: */
static sqInt NoDbgRegParms
genGetFormatOfinto(sqInt srcReg, sqInt destReg)
{
	return genGetBitsofFormatByteOfinto(formatMask(), srcReg, destReg);
}


/*	Get the format of the object in sourceReg into destReg. If
	scratchRegOrNone is not NoReg, load at least the least significant 32-bits
	(64-bits in 64-bits) of the
	header word, which contains the format, into scratchRegOrNone. */

	/* CogObjectRepresentationForSpur>>#genGetFormatOf:into:leastSignificantHalfOfBaseHeaderIntoScratch: */
static sqInt NoDbgRegParms
genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(sqInt sourceReg, sqInt destReg, sqInt scratchRegOrNone)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    sqInt quickConstant;
    sqInt quickConstant1;

	if (scratchRegOrNone == NoReg) {
		flag("endianness");
		/* begin MoveMb:r:R: */
		anInstruction1 = genoperandoperandoperand(MoveMbrR, 3, sourceReg, destReg);
	}
	else {
		/* begin MoveMw:r:R: */
		anInstruction2 = genoperandoperandoperand(MoveMwrR, 0, sourceReg, destReg);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, destReg, scratchRegOrNone);
		/* begin LogicalShiftRightCq:R: */
		quickConstant = formatShift();
		genoperandoperand(LogicalShiftRightCqR, quickConstant, destReg);
	}
	/* begin AndCq:R: */
	quickConstant1 = formatMask();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AndCqR, quickConstant1, destReg);
	return 0;
}


/*	Get the size in word-sized slots of the object in srcReg into destReg.
	srcReg may equal destReg. */

	/* CogObjectRepresentationForSpur>>#genGetNumSlotsOf:into: */
static sqInt NoDbgRegParms
genGetNumSlotsOfinto(sqInt srcReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *jmp;
    sqInt quickConstant;

	assert(srcReg != destReg);
	genGetRawSlotSizeOfNonImminto(srcReg, destReg);
	/* begin CmpCq:R: */
	quickConstant = numSlotsMask();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(CmpCqR, quickConstant, destReg);
	/* begin JumpLess: */
	jmp = genConditionalBranchoperand(JumpLess, ((sqInt)0));
	genGetOverflowSlotsOfinto(srcReg, destReg);
	jmpTarget(jmp, gLabel());
	return 0;
}


/*	The raw numSlots field is the most significant byte of the 64-bit header
	word. MoveMbrR zero-extends. */

	/* CogObjectRepresentationForSpur>>#genGetRawSlotSizeOfNonImm:into: */
static sqInt NoDbgRegParms
genGetRawSlotSizeOfNonImminto(sqInt sourceReg, sqInt destReg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;

	/* begin MoveCq:R: */
	anInstruction = genoperandoperand(MoveCqR, 0, destReg);

	/* begin MoveMb:r:R: */
	anInstruction1 = genoperandoperandoperand(MoveMbrR, 7, sourceReg, destReg);
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genJumpImmediate: */
static AbstractInstruction * NoDbgRegParms
genJumpImmediate(sqInt aRegister)
{
    AbstractInstruction *anInstruction;
    sqInt quickConstant;

	/* begin TstCq:R: */
	quickConstant = tagMask();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(TstCqR, quickConstant, aRegister);
	/* begin JumpNonZero: */
	return genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
}

	/* CogObjectRepresentationForSpur>>#genJumpNotCharacterInScratchReg: */
static AbstractInstruction * NoDbgRegParms
genJumpNotCharacterInScratchReg(sqInt reg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    sqInt quickConstant;
    sqInt quickConstant1;

	/* begin AndCq:R: */
	quickConstant = tagMask();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AndCqR, quickConstant, reg);
	/* begin CmpCq:R: */
	quickConstant1 = characterTag();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(CmpCqR, quickConstant1, reg);
	/* begin JumpNonZero: */
	return genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
}


/*	Generate a call to code that allocates a new Array of size.
	The Array should be initialized with nils iff initialized is true.
	The size arg is passed in SendNumArgsReg, the result
	must come back in ReceiverResultReg. */

	/* CogObjectRepresentationForSpur>>#genNewArrayOfSize:initialized: */
static sqInt NoDbgRegParms
genNewArrayOfSizeinitialized(sqInt size, sqInt initialized)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    sqInt constant;
    usqLong header;
    sqInt i;
    sqInt offset;
    sqInt quickConstant;
    sqInt quickConstant1;
    AbstractInstruction *skip;

	assert(size < (numSlotsMask()));
	header = headerForSlotsformatclassIndex(size, arrayFormat(), ClassArrayCompactIndex);
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	anInstruction3 = genoperandoperand(MoveAwR, address, ReceiverResultReg);
	/* begin genStoreHeader:intoNewInstance:using: */
	flag("endianness");
	/* begin MoveCq:R: */
	quickConstant1 = ((usqInt) header);
	/* begin gen:quickConstant:operand: */
	anInstruction4 = genoperandoperand(MoveCqR, quickConstant1, TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction5 = genoperandoperandoperand(MoveRMwr, TempReg, 0, ReceiverResultReg);
	/* begin MoveCq:R: */
	anInstruction6 = genoperandoperand(MoveCqR, header >> 32, TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction7 = genoperandoperandoperand(MoveRMwr, TempReg, 4, ReceiverResultReg);
	if (initialized
	 && (size > 0)) {
		/* begin genMoveConstant:R: */
		constant = nilObject();
		if (shouldAnnotateObjectReference(constant)) {
			annotateobjRef(gMoveCwR(constant, TempReg), constant);
		}
		else {
			/* begin MoveCq:R: */
			anInstruction1 = genoperandoperand(MoveCqR, constant, TempReg);
		}
		for (i = 0; i < size; i += 1) {
			/* begin MoveR:Mw:r: */
			anInstruction2 = genoperandoperandoperand(MoveRMwr, TempReg, (i * BytesPerWord) + BaseHeaderSize, ReceiverResultReg);
		}
	}
	/* begin LoadEffectiveAddressMw:r:R: */
	offset = smallObjectBytesForSlots(size);
	/* begin gen:quickConstant:operand:operand: */
	anInstruction8 = genoperandoperandoperand(LoadEffectiveAddressMwrR, offset, ReceiverResultReg, TempReg);
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	anInstruction9 = genoperandoperand(MoveRAw, TempReg, address1);
	/* begin CmpCq:R: */
	quickConstant = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(CmpCqR, quickConstant, TempReg);
	/* begin JumpBelow: */
	skip = genConditionalBranchoperand(JumpBelow, ((sqInt)0));
	/* begin CallRT: */
	abstractInstruction = genoperand(Call, ceScheduleScavengeTrampoline);
	(abstractInstruction->annotation = IsRelativeCall);
	jmpTarget(skip, gLabel());
	return 0;
}


/*	Create a closure with the given startpc, numArgs and numCopied
	within a context with ctxtNumArgs, large if isLargeCtxt that is in a
	block if isInBlock. Do /not/ initialize the copied values. */

	/* CogObjectRepresentationForSpur>>#genNoPopCreateClosureAt:numArgs:numCopied:contextNumArgs:large:inBlock: */
static sqInt NoDbgRegParms
genNoPopCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(sqInt bcpc, sqInt numArgs, sqInt numCopied, sqInt ctxtNumArgs, sqInt isLargeCtxt, sqInt isInBlock)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction10;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction12;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    usqInt byteSize;
    usqLong header;
    sqInt numSlots;
    sqInt quickConstant;
    sqInt quickConstant1;
    AbstractInstruction *skip;


	/* First get thisContext into ReceiverResultRega and thence in ClassReg. */
	genGetActiveContextNumArgslargeinBlock(ctxtNumArgs, isLargeCtxt, isInBlock);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, ClassReg);
	numSlots = ClosureFirstCopiedValueIndex + numCopied;
	byteSize = smallObjectBytesForSlots(numSlots);
	header = headerForSlotsformatclassIndex(numSlots, indexablePointersFormat(), ClassBlockClosureCompactIndex);
	/* begin MoveAw:R: */
	address = freeStartAddress();
	/* begin gen:literal:operand: */
	anInstruction1 = genoperandoperand(MoveAwR, address, ReceiverResultReg);
	/* begin genStoreHeader:intoNewInstance:using: */
	flag("endianness");
	/* begin MoveCq:R: */
	quickConstant1 = ((usqInt) header);
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(MoveCqR, quickConstant1, TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction3 = genoperandoperandoperand(MoveRMwr, TempReg, 0, ReceiverResultReg);
	/* begin MoveCq:R: */
	anInstruction4 = genoperandoperand(MoveCqR, header >> 32, TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction5 = genoperandoperandoperand(MoveRMwr, TempReg, 4, ReceiverResultReg);
	/* begin LoadEffectiveAddressMw:r:R: */
	anInstruction6 = genoperandoperandoperand(LoadEffectiveAddressMwrR, byteSize, ReceiverResultReg, TempReg);
	/* begin MoveR:Aw: */
	address1 = freeStartAddress();
	/* begin gen:operand:literal: */
	anInstruction7 = genoperandoperand(MoveRAw, TempReg, address1);
	/* begin CmpCq:R: */
	quickConstant = getScavengeThreshold();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(CmpCqR, quickConstant, TempReg);
	/* begin JumpBelow: */
	skip = genConditionalBranchoperand(JumpBelow, ((sqInt)0));
	/* begin CallRT: */
	abstractInstruction = genoperand(Call, ceScheduleScavengeTrampoline);
	(abstractInstruction->annotation = IsRelativeCall);
	jmpTarget(skip, gLabel());
	/* begin MoveR:Mw:r: */
	anInstruction8 = genoperandoperandoperand(MoveRMwr, ClassReg, (ClosureOuterContextIndex * BytesPerOop) + BaseHeaderSize, ReceiverResultReg);
	/* begin MoveCq:R: */
	anInstruction9 = genoperandoperand(MoveCqR, ((bcpc << 1) | 1), TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction10 = genoperandoperandoperand(MoveRMwr, TempReg, (ClosureStartPCIndex * BytesPerOop) + BaseHeaderSize, ReceiverResultReg);
	/* begin MoveCq:R: */
	anInstruction11 = genoperandoperand(MoveCqR, ((numArgs << 1) | 1), TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction12 = genoperandoperandoperand(MoveRMwr, TempReg, (ClosureNumArgsIndex * BytesPerOop) + BaseHeaderSize, ReceiverResultReg);
	return 0;
}

	/* CogObjectRepresentationForSpur>>#genPrimitiveAsCharacter */
static sqInt
genPrimitiveAsCharacter(void)
{
    AbstractInstruction *jumpNotInt;
    AbstractInstruction *jumpOutOfRange;
    sqInt reg;

	if (methodOrBlockNumArgs == 0) {
		reg = ReceiverResultReg;
	}
	else {
		if (methodOrBlockNumArgs > 1) {
			return UnimplementedPrimitive;
		}
		reg = Arg0Reg;
		/* begin genLoadArgAtDepth:into: */
		assert(0 < (numRegArgs()));
		/* begin genJumpNotSmallInteger:scratchReg: */
		jumpNotInt = genJumpNotSmallInteger(reg);
	}
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, reg, TempReg);
	genConvertSmallIntegerToIntegerInReg(TempReg);
	jumpOutOfRange = jumpNotCharacterUnsignedValueInRegister(TempReg);
	genConvertSmallIntegerToCharacterInReg(reg);
	if (reg != ReceiverResultReg) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, reg, ReceiverResultReg);
	}
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpOutOfRange, gLabel());
	if (reg != ReceiverResultReg) {
		jmpTarget(jumpNotInt, getJmpTarget(jumpOutOfRange));
	}
	return CompletePrimitive;
}

	/* CogObjectRepresentationForSpur>>#genPrimitiveCharacterValue */
static sqInt
genPrimitiveCharacterValue(void)
{
	genConvertCharacterToSmallIntegerInReg(ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	return UnfailingPrimitive;
}

	/* CogObjectRepresentationForSpur>>#genPrimitiveIdenticalOrNotIf: */
static sqInt NoDbgRegParms
genPrimitiveIdenticalOrNotIf(sqInt orNot)
{
    AbstractInstruction *anInstruction;
    sqInt constant;
    AbstractInstruction *jumpCmp;
    AbstractInstruction *jumpImmediate;

	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	jumpImmediate = genJumpImmediate(Arg0Reg);
	genEnsureObjInRegNotForwardedscratchReg(Arg0Reg, TempReg);
	jmpTarget(jumpImmediate, gCmpRR(Arg0Reg, ReceiverResultReg));
	if (orNot) {
		/* begin JumpZero: */
		jumpCmp = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	}
	else {
		/* begin JumpNonZero: */
		jumpCmp = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	}
	/* begin genMoveTrueR: */
	constant = trueObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, constant, ReceiverResultReg);
	}
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpCmp, genMoveFalseR(ReceiverResultReg));
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	return UnfailingPrimitive;
}

	/* CogObjectRepresentationForSpur>>#genPrimitiveObjectAt */
static sqInt
genPrimitiveObjectAt(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    sqInt destReg;
    sqInt headerReg;
    AbstractInstruction *jumpBadIndex;
    AbstractInstruction *jumpBounds;
    AbstractInstruction *jumpNotCogMethod;
    AbstractInstruction *jumpNotHeaderIndex;
    sqInt offset;
    sqInt quickConstant;

	/* begin genLoadArgAtDepth:into: */
	assert(0 < (numRegArgs()));
	/* begin genJumpNotSmallInteger:scratchReg: */
	jumpBadIndex = genJumpNotSmallInteger(Arg0Reg);
	/* begin MoveMw:r:R: */
	destReg = (headerReg = Arg1Reg);
	/* begin gen:quickConstant:operand:operand: */
	anInstruction1 = genoperandoperandoperand(MoveMwrR, BaseHeaderSize, ReceiverResultReg, destReg);
	jumpNotCogMethod = genJumpSmallIntegerscratchReg(headerReg, TempReg);
	/* begin MoveMw:r:R: */
	offset = offsetof(CogMethod, methodHeader);
	/* begin gen:quickConstant:operand:operand: */
	anInstruction2 = genoperandoperandoperand(MoveMwrR, offset, headerReg, headerReg);
	jmpTarget(jumpNotCogMethod, gCmpCqR(((1 << 1) | 1), Arg0Reg));
	/* begin JumpNonZero: */
	jumpNotHeaderIndex = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, headerReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpNotHeaderIndex, gAndCqR((((alternateHeaderNumLiteralsMask()) << 1) | 1), headerReg));
	/* begin SubCq:R: */
	quickConstant = (((1 << 1) | 1)) - (smallIntegerTag());
	/* begin gen:quickConstant:operand: */
	anInstruction3 = genoperandoperand(SubCqR, quickConstant, Arg0Reg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, headerReg, Arg0Reg);
	/* begin JumpAbove: */
	jumpBounds = genConditionalBranchoperand(JumpAbove, ((sqInt)0));
	genConvertSmallIntegerToIntegerInReg(Arg0Reg);
	/* begin AddCq:R: */
	anInstruction = genoperandoperand(AddCqR, ((usqInt) BaseHeaderSize) >> (shiftForWord()), Arg0Reg);
	/* begin MoveXwr:R:R: */
	genoperandoperandoperand(MoveXwrRR, Arg0Reg, ReceiverResultReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpBounds, gAddCqR((((1 << 1) | 1)) - (smallIntegerTag()), Arg0Reg));
	jmpTarget(jumpBadIndex, gLabel());
	return CompletePrimitive;
}


/*	c.f. StackInterpreter>>stSizeOf: lengthOf:baseHeader:format:
	fixedFieldsOf:format:length: 
 */

	/* CogObjectRepresentationForSpur>>#genPrimitiveSize */
static sqInt
genPrimitiveSize(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    sqInt jic;
    sqInt jnx;
    AbstractInstruction *jump32BitLongsDone;
    AbstractInstruction *jumpArrayDone;
    AbstractInstruction * jumpBytesDone;
    AbstractInstruction *jumpHasFixedFields;
    AbstractInstruction *jumpImm;
    AbstractInstruction *jumpIsBytes;
    AbstractInstruction *jumpIsContext;
    AbstractInstruction *jumpIsContext1;
    AbstractInstruction *jumpIsShorts;
    AbstractInstruction *jumpNotIndexable;
    AbstractInstruction *jumpNotIndexable1;
    AbstractInstruction * jumpShortsDone;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt quickConstant2;
    sqInt quickConstant3;
    sqInt quickConstant4;
    sqInt quickConstant5;

	jumpImm = genJumpImmediate(ReceiverResultReg);
	/* begin genGetSizeOf:into:formatReg:scratchReg:abortJumpsInto: */
	genGetFormatOfintoleastSignificantHalfOfBaseHeaderIntoScratch(ReceiverResultReg, SendNumArgsReg, TempReg);
	genGetNumSlotsOfinto(ReceiverResultReg, ClassReg);
	/* begin CmpCq:R: */
	quickConstant = firstByteFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(CmpCqR, quickConstant, SendNumArgsReg);
	/* begin JumpGreaterOrEqual: */
	jumpIsBytes = genConditionalBranchoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant1 = arrayFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction1 = genoperandoperand(CmpCqR, quickConstant1, SendNumArgsReg);
	/* begin JumpZero: */
	jumpArrayDone = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin JumpLess: */
	jumpNotIndexable1 = genConditionalBranchoperand(JumpLess, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant2 = weakArrayFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(CmpCqR, quickConstant2, SendNumArgsReg);
	/* begin JumpLessOrEqual: */
	jumpHasFixedFields = genConditionalBranchoperand(JumpLessOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant3 = firstShortFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction3 = genoperandoperand(CmpCqR, quickConstant3, SendNumArgsReg);
	/* begin JumpGreaterOrEqual: */
	jumpIsShorts = genConditionalBranchoperand(JumpGreaterOrEqual, ((sqInt)0));
	/* begin CmpCq:R: */
	quickConstant4 = firstLongFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction4 = genoperandoperand(CmpCqR, quickConstant4, SendNumArgsReg);
	/* begin JumpGreaterOrEqual: */
	jump32BitLongsDone = genConditionalBranchoperand(JumpGreaterOrEqual, ((sqInt)0));
	jmpTarget(jumpNotIndexable1, gLabel());
	/* begin Jump: */
	jumpNotIndexable1 = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsBytes, gLogicalShiftLeftCqR(shiftForWord(), ClassReg));
	/* begin AndCq:R: */
	anInstruction5 = genoperandoperand(AndCqR, BytesPerWord - 1, SendNumArgsReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	/* begin Jump: */
	jumpBytesDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpIsShorts, gLogicalShiftLeftCqR((shiftForWord()) - 1, ClassReg));
	/* begin AndCq:R: */
	anInstruction6 = genoperandoperand(AndCqR, 1, SendNumArgsReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	/* begin Jump: */
	jumpShortsDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpHasFixedFields, gAndCqR(classIndexMask(), TempReg));
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, SendNumArgsReg);
	/* begin CmpCq:R: */
	anInstruction7 = genoperandoperand(CmpCqR, ClassMethodContextCompactIndex, TempReg);
	/* begin JumpZero: */
	jumpIsContext1 = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin PushR: */
	genoperand(PushR, ClassReg);
	genGetClassObjectOfClassIndexintoscratchReg(SendNumArgsReg, ClassReg, TempReg);
	genLoadSlotsourceRegdestReg(InstanceSpecificationIndex, ClassReg, SendNumArgsReg);
	genConvertSmallIntegerToIntegerInReg(SendNumArgsReg);
	/* begin PopR: */
	genoperand(PopR, ClassReg);
	/* begin AndCq:R: */
	quickConstant5 = fixedFieldsOfClassFormatMask();
	/* begin gen:quickConstant:operand: */
	anInstruction8 = genoperandoperand(AndCqR, quickConstant5, SendNumArgsReg);
	/* begin SubR:R: */
	genoperandoperand(SubRR, SendNumArgsReg, ClassReg);
	jmpTarget(jumpArrayDone, jmpTarget(jump32BitLongsDone, jmpTarget(jumpShortsDone, jmpTarget(jumpBytesDone, gLabel()))));
	jumpNotIndexable = jumpNotIndexable1;
	jumpIsContext = jumpIsContext1;

	genConvertIntegerToSmallIntegerInReg(ClassReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, ReceiverResultReg);
	/* begin genPrimReturn */
	assert(methodOrBlockNumArgs <= (numRegArgs()));
	/* begin RetN: */
	genoperand(RetN, 0);
	jmpTarget(jumpImm, jmpTarget(jumpNotIndexable, jmpTarget(jumpIsContext, gLabel())));
	return CompletePrimitive;
}

	/* CogObjectRepresentationForSpur>>#genSetSmallIntegerTagsIn: */
static sqInt NoDbgRegParms
genSetSmallIntegerTagsIn(sqInt scratchReg)
{
    AbstractInstruction *anInstruction;

	/* begin OrCq:R: */
	anInstruction = genoperandoperand(OrCqR, 1, scratchReg);
	return 0;
}


/*	Create a trampoline to store-check the update of the receiver in a
	closure's outerContext in compileBlockFrameBuild:. */

	/* CogObjectRepresentationForSpur>>#genStoreCheckContextReceiverTrampoline */
static sqInt
genStoreCheckContextReceiverTrampoline(void)
{
    sqInt startAddress;

	startAddress = methodZoneBase();
	zeroOpcodeIndex();
	genStoreCheckReceiverRegvalueRegscratchReginFrame(ReceiverResultReg, Arg0Reg, TempReg, 0);
	/* begin RetN: */
	genoperand(RetN, 0);
	outputInstructionsForGeneratedRuntimeAt(startAddress);
	recordGeneratedRunTimeaddress("ceStoreCheckContextReceiver", startAddress);
	recordRunTimeObjectReferences();
	return startAddress;
}


/*	Generate the code for a store check of valueReg into destReg. */

	/* CogObjectRepresentationForSpur>>#genStoreCheckReceiverReg:valueReg:scratchReg:inFrame: */
static sqInt NoDbgRegParms
genStoreCheckReceiverRegvalueRegscratchReginFrame(sqInt destReg, sqInt valueReg, sqInt scratchReg, sqInt inFrame)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction * inst;
    AbstractInstruction *jmpAlreadyRemembered;
    AbstractInstruction *jmpDestYoung;
    AbstractInstruction *jmpImmediate;
    AbstractInstruction *jmpSourceOld;
    sqInt mask;
    sqInt quickConstant;
    sqInt rememberedBitByteOffset;
    sqInt wordConstant;


	/* Is value stored an integer?  If so we're done */
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, valueReg, scratchReg);
	/* begin AndCq:R: */
	quickConstant = tagMask();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(AndCqR, quickConstant, scratchReg);
	/* begin JumpNonZero: */
	jmpImmediate = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveCw:R: */
	wordConstant = storeCheckBoundary();
	/* begin gen:literal:operand: */
	anInstruction1 = genoperandoperand(MoveCwR, wordConstant, scratchReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, scratchReg, destReg);
	/* begin JumpBelow: */
	jmpDestYoung = genConditionalBranchoperand(JumpBelow, ((sqInt)0));
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, scratchReg, valueReg);
	/* begin JumpAboveOrEqual: */
	jmpSourceOld = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	rememberedBitByteOffset = (rememberedBitShift()) / 8;
	mask = 1 << ((rememberedBitShift()) % 8);
	/* begin MoveMb:r:R: */
	anInstruction2 = genoperandoperandoperand(MoveMbrR, rememberedBitByteOffset, destReg, scratchReg);
	/* begin AndCq:R: */
	anInstruction3 = genoperandoperand(AndCqR, mask, scratchReg);
	/* begin JumpNonZero: */
	jmpAlreadyRemembered = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	assert(destReg == ReceiverResultReg);
	/* begin evaluateTrampolineCallBlock:protectLinkRegIfNot: */
	if (inFrame) {
		CallRTregistersToBeSavedMask(ceStoreCheckTrampoline, ((((registerMaskFor(valueReg)) | (callerSavedRegMask())) | (registerMaskForand(ReceiverResultReg, scratchReg))) - (registerMaskForand(ReceiverResultReg, scratchReg))));

	}
	else {
		/* begin saveAndRestoreLinkRegAround: */
		inst = genoperand(PushR, LinkReg);
		CallRTregistersToBeSavedMask(ceStoreCheckTrampoline, ((((registerMaskFor(valueReg)) | (callerSavedRegMask())) | (registerMaskForand(ReceiverResultReg, scratchReg))) - (registerMaskForand(ReceiverResultReg, scratchReg))));


		/* begin PopR: */
		genoperand(PopR, LinkReg);
	}
	jmpTarget(jmpImmediate, jmpTarget(jmpDestYoung, jmpTarget(jmpSourceOld, jmpTarget(jmpAlreadyRemembered, gLabel()))));
	return 0;
}


/*	do the store */

	/* CogObjectRepresentationForSpur>>#genStoreSourceReg:slotIndex:destReg:scratchReg:inFrame:needsStoreCheck: */
static sqInt NoDbgRegParms
genStoreSourceRegslotIndexdestRegscratchReginFrameneedsStoreCheck(sqInt sourceReg, sqInt index, sqInt destReg, sqInt scratchReg, sqInt inFrame, sqInt needsStoreCheck)
{
    AbstractInstruction *anInstruction;

	/* begin MoveR:Mw:r: */
	anInstruction = genoperandoperandoperand(MoveRMwr, sourceReg, (index * BytesPerWord) + BaseHeaderSize, destReg);
	if (needsStoreCheck) {
		return genStoreCheckReceiverRegvalueRegscratchReginFrame(destReg, sourceReg, scratchReg, inFrame);
	}
	return 0;
}


/*	This method is used for unchecked stores in objects after their creation
	(typically, inlined creation of Array, closures and some temp vectors). 
	Currently there is no need to do the immutability check here
 */

	/* CogObjectRepresentationForSpur>>#genStoreSourceReg:slotIndex:intoNewObjectInDestReg: */
static sqInt NoDbgRegParms
genStoreSourceRegslotIndexintoNewObjectInDestReg(sqInt sourceReg, sqInt index, sqInt destReg)
{
    AbstractInstruction *anInstruction;

	/* begin MoveR:Mw:r: */
	anInstruction = genoperandoperandoperand(MoveRMwr, sourceReg, (index * BytesPerWord) + BaseHeaderSize, destReg);
	return 0;
}


/*	Make sure SendNumArgsReg and ClassReg are available in addition to
	ReceiverResultReg and TempReg in
	genGetActiveContextNumArgs:large:inBlock:. 
 */

	/* CogObjectRepresentationForSpur>>#getActiveContextAllocatesInMachineCode */
static sqInt
getActiveContextAllocatesInMachineCode(void)
{
	return 1;
}


/*	Since all cache tags in Spur are class indices none of
	them are young or have to be updated in a scavenge. */

	/* CogObjectRepresentationForSpur>>#inlineCacheTagIsYoung: */
static sqInt NoDbgRegParms
inlineCacheTagIsYoung(sqInt cacheTag)
{
	return 0;
}

	/* CogObjectRepresentationForSpur>>#jumpNotCharacterUnsignedValueInRegister: */
static AbstractInstruction * NoDbgRegParms
jumpNotCharacterUnsignedValueInRegister(sqInt reg)
{
    AbstractInstruction *anInstruction;
    sqInt quickConstant;

	/* begin CmpCq:R: */
	quickConstant = (1 << (numCharacterBits())) - 1;
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(CmpCqR, quickConstant, reg);
	/* begin JumpAbove: */
	return genConditionalBranchoperand(JumpAbove, ((sqInt)0));
}


/*	Mark and trace a literal in a machine code instruction preceding address
	in cogMethodOrNil.
	Answer if code was modified. */

	/* CogObjectRepresentationForSpur>>#markAndTraceLiteral:in:atpc: */
static sqInt NoDbgRegParms
markAndTraceLiteralinatpc(sqInt literal, CogMethod *cogMethodOrNil, usqInt address)
{
    sqInt objOop;

	if (!(couldBeObject(literal))) {
		return 0;
	}
	assert(addressCouldBeObj(literal));
	if (!(isForwarded(literal))) {
		markAndTrace(literal);
		return 0;
	}
	objOop = followForwarded(literal);
	storeLiteralbeforeFollowingAddress(backEnd(), objOop, address);
	markAndTraceUpdatedLiteralin(objOop, cogMethodOrNil);
	return 1;
}


/*	Mark and trace a literal in a sqInt variable of cogMethod. */

	/* CogObjectRepresentationForSpur>>#markAndTraceLiteral:in:at: */
static void NoDbgRegParms
markAndTraceLiteralinat(sqInt literal, CogMethod *cogMethod, sqInt *address)
{
    sqInt objOop;

	if (!(couldBeObject(literal))) {
		return;
	}
	assert(addressCouldBeObj(literal));
	if (!(isForwarded(literal))) {
		markAndTrace(literal);
		return;
	}
	objOop = followForwarded(literal);
	address[0] = objOop;
	markAndTraceUpdatedLiteralin(objOop, cogMethod);
}


/*	Common code to mark a literal in cogMethod and add
	the cogMethod to youngReferrers if the literal is young. */

	/* CogObjectRepresentationForSpur>>#markAndTraceUpdatedLiteral:in: */
static void NoDbgRegParms
markAndTraceUpdatedLiteralin(sqInt objOop, CogMethod *cogMethodOrNil)
{
	if (isNonImmediate(objOop)) {
		if ((cogMethodOrNil != null)
		 && (isYoungObject(objOop))) {
			ensureInYoungReferrers(cogMethodOrNil);
		}
		markAndTrace(objOop);
	}
}


/*	If primIndex has an accessorDepth, check for primitive failure and call
	ceCheckForAndFollowForwardedPrimitiveState if so If ceCheck.... answers
	true, retry the primitive. */

	/* CogObjectRepresentationForSpur>>#maybeCompileRetry:onPrimitiveFail: */
static sqInt NoDbgRegParms
maybeCompileRetryonPrimitiveFail(AbstractInstruction *retryInst, sqInt primIndex)
{
    sqInt address;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *jmp;

	if ((accessorDepthForPrimitiveIndex(primIndex)) < 0) {
		return 0;
	}
	/* begin MoveAw:R: */
	address = primFailCodeAddress();
	/* begin gen:literal:operand: */
	anInstruction2 = genoperandoperand(MoveAwR, address, TempReg);
	/* begin CmpCq:R: */
	anInstruction = genoperandoperand(CmpCqR, 0, TempReg);
	/* begin JumpZero: */
	jmp = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	compileCallFornumArgsargargargargresultRegsaveRegs(ceCheckForAndFollowForwardedPrimitiveState, 0, null, null, null, null, TempReg, 0);
	/* begin CmpCq:R: */
	anInstruction1 = genoperandoperand(CmpCqR, 0, TempReg);
	/* begin JumpNonZero: */
	genConditionalBranchoperand(JumpNonZero, ((sqInt)retryInst));
	jmpTarget(jmp, gLabel());
	return 0;
}

	/* CogObjectRepresentationForSpur>>#numCharacterBits */
static sqInt
numCharacterBits(void)
{
	return 30;
}


/*	Define how many register arguments a StackToRegisterMappingCogit can
	and should use with the receiver. The value must be 0, 1 or 2. Note that a
	SimpleStackBasedCogit always has 0 register args (although the receiver is
	passed in a register). The Spur object representation is simple enough
	that implementing at:put: is straight-forward and hence 2 register args
	are worth
	while. The method must be inlined in CoInterpreter, and dead code
	eliminated so that the register-popping enilopmarts such as
	enterRegisterArgCogMethod:- at:receiver: do not have to be implemented in
	SimpleStackBasedCogit.  */

	/* CogObjectRepresentationForSpur>>#numRegArgs */
sqInt
numRegArgs(void)
{
	return 2;
}

	/* CogObjectRepresentationForSpur>>#remapObject: */
static sqInt NoDbgRegParms
remapObject(sqInt objOop)
{
	return (shouldRemapObj(objOop)
		? remapObj(objOop)
		: objOop);
}

	/* CogObjectRepresentationForSpur>>#remapOop: */
static sqInt NoDbgRegParms
remapOop(sqInt objOop)
{
	return (shouldRemapOop(objOop)
		? remapObj(objOop)
		: objOop);
}


/*	Objects in newSpace or oldSpace except nil, true, false &
	classTableRootObj need to be annotated.
 */

	/* CogObjectRepresentationForSpur>>#shouldAnnotateObjectReference: */
static sqInt NoDbgRegParms
shouldAnnotateObjectReference(sqInt anOop)
{
	return (isNonImmediate(anOop))
	 && ((oopisGreaterThan(anOop, classTableRootObj()))
	 || (oopisLessThan(anOop, nilObject())));
}

	/* CogObjectRepresentationForSpur>>#slotOffsetOfInstVarIndex: */
static sqInt NoDbgRegParms
slotOffsetOfInstVarIndex(sqInt index)
{
	return (index * BytesPerWord) + BaseHeaderSize;
}

	/* CogSimStackEntry>>#ensureSpilledAt:from: */
static CogSimStackEntry * NoDbgRegParms
ensureSpilledAtfrom(CogSimStackEntry * self_in_ensureSpilledAtfrom, sqInt baseOffset, sqInt baseRegister)
{
    AbstractInstruction *anInstruction;
    sqInt baseReg;
    AbstractInstruction *inst;
    sqInt offset;
    sqInt reg;

	if ((self_in_ensureSpilledAtfrom->spilled)) {
		if (((self_in_ensureSpilledAtfrom->type)) == SSSpill) {
			assert((((self_in_ensureSpilledAtfrom->offset)) == baseOffset)
			 && (((self_in_ensureSpilledAtfrom->registerr)) == baseRegister));
			return self_in_ensureSpilledAtfrom;
		}
	}
	assert(((self_in_ensureSpilledAtfrom->type)) != SSSpill);
	traceSpill(self_in_ensureSpilledAtfrom);
	if (((self_in_ensureSpilledAtfrom->type)) == SSConstant) {
		inst = annotateobjRef(gPushCw((self_in_ensureSpilledAtfrom->constant)), (self_in_ensureSpilledAtfrom->constant));
	}
	else {
		if (((self_in_ensureSpilledAtfrom->type)) == SSBaseOffset) {
			/* begin MoveMw:r:R: */
			offset = (self_in_ensureSpilledAtfrom->offset);
			baseReg = (self_in_ensureSpilledAtfrom->registerr);
			/* begin gen:quickConstant:operand:operand: */
			anInstruction = genoperandoperandoperand(MoveMwrR, offset, baseReg, TempReg);
			/* begin PushR: */
			inst = genoperand(PushR, TempReg);
		}
		else {
			assert(((self_in_ensureSpilledAtfrom->type)) == SSRegister);
			/* begin PushR: */
			reg = (self_in_ensureSpilledAtfrom->registerr);
			inst = genoperand(PushR, reg);
		}
		(self_in_ensureSpilledAtfrom->type) = SSSpill;
		(self_in_ensureSpilledAtfrom->offset) = baseOffset;
		(self_in_ensureSpilledAtfrom->registerr) = baseRegister;
	}
	(self_in_ensureSpilledAtfrom->spilled) = 1;
	if ((self_in_ensureSpilledAtfrom->annotateUse)) {
		/* begin annotateBytecode: */
		(inst->annotation = HasBytecodePC);
		(self_in_ensureSpilledAtfrom->annotateUse) = 0;
	}
	return self_in_ensureSpilledAtfrom;
}


/*	Discard type information because of a control-flow merge. */

	/* CogSimStackEntry>>#mergeAt:from: */
static CogSimStackEntry * NoDbgRegParms
mergeAtfrom(CogSimStackEntry * self_in_mergeAtfrom, sqInt baseOffset, sqInt baseRegister)
{
	assert((self_in_mergeAtfrom->spilled));
	if (((self_in_mergeAtfrom->type)) == SSSpill) {
		assert((((self_in_mergeAtfrom->offset)) == baseOffset)
		 && (((self_in_mergeAtfrom->registerr)) == baseRegister));
	}
	else {
		(self_in_mergeAtfrom->type) = SSSpill;
		(self_in_mergeAtfrom->offset) = baseOffset;
		(self_in_mergeAtfrom->registerr) = baseRegister;
	}
	return self_in_mergeAtfrom;
}

	/* CogSimStackEntry>>#popToReg: */
static CogSimStackEntry * NoDbgRegParms
popToReg(CogSimStackEntry * self_in_popToReg, sqInt reg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    sqInt baseReg;
    sqInt constant;
    AbstractInstruction *inst;
    sqInt offset;
    sqInt reg1;

	if ((self_in_popToReg->spilled)) {
		/* begin PopR: */
		inst = genoperand(PopR, reg);
	}
	else {
		
		switch ((self_in_popToReg->type)) {
		case SSBaseOffset:
			/* begin MoveMw:r:R: */
			offset = (self_in_popToReg->offset);
			baseReg = (self_in_popToReg->registerr);
			/* begin gen:quickConstant:operand:operand: */
			anInstruction = genoperandoperandoperand(MoveMwrR, offset, baseReg, reg);
			inst = anInstruction;
			break;
		case SSConstant:
			/* begin genMoveConstant:R: */
			constant = (self_in_popToReg->constant);
			if (shouldAnnotateObjectReference(constant)) {
				inst = annotateobjRef(gMoveCwR(constant, reg), constant);
			}
			else {
				/* begin MoveCq:R: */
				anInstruction1 = genoperandoperand(MoveCqR, constant, reg);
				inst = anInstruction1;
			}
			break;
		case SSRegister:
			if (reg != ((self_in_popToReg->registerr))) {
				/* begin MoveR:R: */
				reg1 = (self_in_popToReg->registerr);
				inst = genoperandoperand(MoveRR, reg1, reg);
			}
			else {
				/* begin Label */
				inst = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
			break;
		default:
			error("Case not found and no otherwise clause");
		}
	}
	if ((self_in_popToReg->annotateUse)) {
		/* begin annotateBytecode: */
		(inst->annotation = HasBytecodePC);
		(self_in_popToReg->annotateUse) = 0;
	}
	return self_in_popToReg;
}


/*	Answer a bit mask for the receiver's register, if any. */

	/* CogSimStackEntry>>#registerMask */
static sqInt NoDbgRegParms
registerMask(CogSimStackEntry * self_in_registerMask)
{
	return ((((self_in_registerMask->type)) == SSBaseOffset)
	 || (((self_in_registerMask->type)) == SSRegister)
		? registerMaskFor((self_in_registerMask->registerr))
		: 0);
}

	/* CogSimStackEntry>>#registerOrNone */
static sqInt NoDbgRegParms
registerOrNone(CogSimStackEntry * self_in_registerOrNone)
{
	return (((self_in_registerOrNone->type)) == SSRegister
		? (self_in_registerOrNone->registerr)
		: NoReg);
}

	/* CogSimStackEntry>>#storeToReg: */
static CogSimStackEntry * NoDbgRegParms
storeToReg(CogSimStackEntry * self_in_storeToReg, sqInt reg)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    sqInt baseReg;
    sqInt constant;
    AbstractInstruction *inst;
    sqInt offset;
    sqInt reg1;

	
	switch ((self_in_storeToReg->type)) {
	case SSBaseOffset:
	case SSSpill:
		/* begin MoveMw:r:R: */
		offset = (self_in_storeToReg->offset);
		baseReg = (self_in_storeToReg->registerr);
		/* begin gen:quickConstant:operand:operand: */
		anInstruction = genoperandoperandoperand(MoveMwrR, offset, baseReg, reg);
		inst = anInstruction;
		break;
	case SSConstant:
		/* begin genMoveConstant:R: */
		constant = (self_in_storeToReg->constant);
		if (shouldAnnotateObjectReference(constant)) {
			inst = annotateobjRef(gMoveCwR(constant, reg), constant);
		}
		else {
			/* begin MoveCq:R: */
			anInstruction1 = genoperandoperand(MoveCqR, constant, reg);
			inst = anInstruction1;
		}
		break;
	case SSRegister:
		if (reg != ((self_in_storeToReg->registerr))) {
			/* begin MoveR:R: */
			reg1 = (self_in_storeToReg->registerr);
			inst = genoperandoperand(MoveRR, reg1, reg);
		}
		else {
			/* begin Label */
			inst = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	if ((self_in_storeToReg->annotateUse)) {
		/* begin annotateBytecode: */
		(inst->annotation = HasBytecodePC);
		(self_in_storeToReg->annotateUse) = 0;
	}
	return self_in_storeToReg;
}


/*	Compile the jump instruction(s) at the end of the method that dispatch to
	each block body.
 */

	/* SimpleStackBasedCogit>>#compileBlockDispatch */
static sqInt
compileBlockDispatch(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *jumpSkip;

	assert(blockCount > 0);
	/* begin MoveCq:R: */
	anInstruction = genoperandoperand(MoveCqR, 0, SendNumArgsReg);
	blockEntryNoContextSwitch = anInstruction;
	/* begin Jump: */
	jumpSkip = genoperand(Jump, ((sqInt)0));
	/* begin MoveR:R: */
	blockEntryLabel = genoperandoperand(MoveRR, ReceiverResultReg, SendNumArgsReg);
	jmpTarget(jumpSkip, gLabel());
	if (blockCount > 1) {
		genLoadSlotsourceRegdestReg(ClosureStartPCIndex, ReceiverResultReg, TempReg);
	}
	compileBlockDispatchFromto(0, blockCount - 1);
	return 0;
}


/*	After pushing the temporaries but before the stack limit check a primitive
	method needs to fetch the error code, if any, and replace the last temp
	with it. */

	/* SimpleStackBasedCogit>>#compileGetErrorCode */
static void
compileGetErrorCode(void)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *jmpGotError;
    AbstractInstruction *jmpIntError;
    AbstractInstruction *jmpNoError;
    sqInt primErrorTable;
    sqInt primErrorTableSize;

	/* begin MoveAw:R: */
	address = primFailCodeAddress();
	/* begin gen:literal:operand: */
	anInstruction2 = genoperandoperand(MoveAwR, address, TempReg);
	flag("ask concrete code gen if move sets condition codes?");
	/* begin CmpCq:R: */
	anInstruction = genoperandoperand(CmpCqR, 0, TempReg);
	/* begin JumpZero: */
	jmpNoError = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	primErrorTable = primErrTable();
	primErrorTableSize = lengthOf(primErrorTable);
	flag("use CmpCqR if pc mapping means stable contexts never contain native pcs");
	/* begin CmpCw:R: */
	anInstruction1 = genoperandoperand(CmpCwR, primErrorTableSize, TempReg);
	/* begin JumpAboveOrEqual: */
	jmpIntError = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
	genFetchIndexRegisterfrominto(TempReg, primErrorTable, ClassReg);
	/* begin Jump: */
	jmpGotError = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpIntError, gLabel());
	genConvertIntegerToSmallIntegerInReg(TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, TempReg, ClassReg);
	jmpTarget(jmpGotError, gMoveRMwr(ClassReg, 0, SPReg));
	/* begin MoveCq:R: */
	anInstruction3 = genoperandoperand(MoveCqR, 0, TempReg);
	/* begin MoveR:Aw: */
	address1 = primFailCodeAddress();
	/* begin gen:operand:literal: */
	anInstruction4 = genoperandoperand(MoveRAw, TempReg, address1);
	jmpTarget(jmpNoError, gLabel());
}


/*	Compile a call to an interpreter primitive. Call the C routine with the
	usual stack-switching dance, test the primFailCode and then either
	return on success or continue to the method body. */

	/* SimpleStackBasedCogit>>#compileInterpreterPrimitive: */
static sqInt NoDbgRegParms
compileInterpreterPrimitive(void (*primitiveRoutine)(void))
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    AbstractInstruction *abstractInstruction2;
    AbstractInstruction *abstractInstruction3;
    sqInt address;
    sqInt address1;
    sqInt address10;
    sqInt address11;
    sqInt address12;
    sqInt address13;
    sqInt address2;
    sqInt address3;
    sqInt address4;
    sqInt address5;
    sqInt address6;
    sqInt address7;
    sqInt address8;
    sqInt address9;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction10;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction110;
    AbstractInstruction *anInstruction111;
    AbstractInstruction *anInstruction112;
    AbstractInstruction *anInstruction12;
    AbstractInstruction *anInstruction13;
    AbstractInstruction *anInstruction14;
    AbstractInstruction *anInstruction15;
    AbstractInstruction *anInstruction16;
    AbstractInstruction *anInstruction17;
    AbstractInstruction *anInstruction18;
    AbstractInstruction *anInstruction19;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction20;
    AbstractInstruction *anInstruction21;
    AbstractInstruction *anInstruction22;
    AbstractInstruction *anInstruction23;
    AbstractInstruction *anInstruction24;
    AbstractInstruction *anInstruction25;
    AbstractInstruction *anInstruction26;
    AbstractInstruction *anInstruction27;
    AbstractInstruction *anInstruction28;
    AbstractInstruction *anInstruction29;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    sqInt callTarget;
    sqInt callTarget1;
    AbstractInstruction *continuePostSampleNonPrim;
    AbstractInstruction *continuePostSamplePrim;
    sqInt flags;
    AbstractInstruction *jmp;
    AbstractInstruction *jmpSampleNonPrim;
    AbstractInstruction *jmpSamplePrim;
    sqInt literal;
    sqInt literal1;
    sqInt offset;
    sqInt offset1;
    sqInt offset2;
    sqInt reg;
    sqInt retpc;
    AbstractInstruction *retry;


	/* Save processor fp, sp and return pc in the interpreter's frame stack and instruction pointers */
	genExternalizePointersForPrimitiveCall();
	genLoadCStackPointersForPrimCall();
	flags = primitivePropertyFlags(primitiveIndex);
	if (flags & PrimCallDoNotJIT) {
		return ShouldNotJIT;
	}
	if (flags & PrimCallCollectsProfileSamples) {

		/* Test nextProfileTick for being non-zero and call checkProfileTick if so */
		/* begin MoveAw:R: */
		address = nextProfileTickAddress();
		/* begin gen:literal:operand: */
		anInstruction = genoperandoperand(MoveAwR, address, TempReg);
		/* begin MoveAw:R: */
		address1 = (nextProfileTickAddress()) + BytesPerWord;
		/* begin gen:literal:operand: */
		anInstruction1 = genoperandoperand(MoveAwR, address1, ClassReg);
		/* begin OrR:R: */
		genoperandoperand(OrRR, TempReg, ClassReg);

		/* begin JumpNonZero: */
		jmpSampleNonPrim = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
		/* begin Label */
		continuePostSampleNonPrim = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	}
	if (recordPrimTrace()) {
		genFastPrimTraceUsingand(ClassReg, SendNumArgsReg);
	}
	/* begin MoveCq:R: */
	anInstruction21 = genoperandoperand(MoveCqR, 0, TempReg);
	retry = anInstruction21;
	/* begin MoveR:Aw: */
	address11 = primFailCodeAddress();
	/* begin gen:operand:literal: */
	anInstruction22 = genoperandoperand(MoveRAw, TempReg, address11);
	if (methodOrBlockNumArgs != 0) {
		/* begin MoveCq:R: */
		anInstruction4 = genoperandoperand(MoveCqR, methodOrBlockNumArgs, TempReg);
	}
	/* begin MoveR:Aw: */
	address12 = argumentCountAddress();
	/* begin gen:operand:literal: */
	anInstruction23 = genoperandoperand(MoveRAw, TempReg, address12);
	if (flags & PrimCallNeedsPrimitiveFunction) {
		/* begin MoveCw:R: */
		anInstruction5 = genoperandoperand(MoveCwR, ((sqInt)primitiveRoutine), TempReg);
		/* begin MoveR:Aw: */
		address3 = primitiveFunctionPointerAddress();
		/* begin gen:operand:literal: */
		anInstruction6 = genoperandoperand(MoveRAw, TempReg, address3);
		primSetFunctionLabel = anInstruction6;
	}
	if (flags & (PrimCallNeedsNewMethod + PrimCallMayCallBack)) {

		/* The ceActivateFailingPrimitiveMethod: machinery can't handle framelessness. */
		if (flags & PrimCallMayCallBack) {
			needsFrame = 1;
		}
		addDependent(methodLabel, annotateAbsolutePCRef(gMoveCwR(((sqInt)methodLabel), ClassReg)));
		/* begin MoveMw:r:R: */
		offset = offsetof(CogMethod, methodObject);
		/* begin gen:quickConstant:operand:operand: */
		anInstruction7 = genoperandoperandoperand(MoveMwrR, offset, ClassReg, TempReg);
		/* begin MoveR:Aw: */
		address4 = newMethodAddress();
		/* begin gen:operand:literal: */
		anInstruction8 = genoperandoperand(MoveRAw, TempReg, address4);
	}
	/* begin PrefetchAw: */
	address13 = primFailCodeAddress();
	/* begin gen:literal: */
	anInstruction24 = genoperand(PrefetchAw, address13);
	if (flags & PrimCallMayCallBack) {

		/* Sideways call the C primitive routine so that we return through cePrimReturnEnterCogCode. */
		/* On Spur ceActivateFailingPrimitiveMethod: would like to retry if forwarders
		   are found. So insist on PrimCallNeedsPrimitiveFunction being set too. */
		assert(flags & PrimCallNeedsPrimitiveFunction);
		/* begin genSubstituteReturnAddress: */
		retpc = (flags & PrimCallCollectsProfileSamples
			? cePrimReturnEnterCogCodeProfiling
			: cePrimReturnEnterCogCode);
		/* begin MoveCw:R: */
		anInstruction9 = genoperandoperand(MoveCwR, retpc, RA);
		/* begin JumpFullRT: */
		/* begin JumpFull: */
		literal1 = ((sqInt)(((sqInt)primitiveRoutine)));
		anInstruction26 = genoperand(JumpFull, ((sqInt)(((sqInt)primitiveRoutine))));
		primInvokeInstruction = anInstruction26;

		jmp = (jmpSamplePrim = (continuePostSamplePrim = null));
	}
	else {

		/* Call the C primitive routine. */
		/* begin CallFullRT: */
		/* begin CallFull: */
		anInstruction27 = genoperand(CallFull, ((sqInt)primitiveRoutine));
		primInvokeInstruction = anInstruction27;

		if (flags & PrimCallCollectsProfileSamples) {
			assert(flags & PrimCallNeedsNewMethod);
			/* begin MoveAw:R: */
			address5 = nextProfileTickAddress();
			/* begin gen:literal:operand: */
			anInstruction10 = genoperandoperand(MoveAwR, address5, TempReg);
			/* begin MoveAw:R: */
			address6 = (nextProfileTickAddress()) + BytesPerWord;
			/* begin gen:literal:operand: */
			anInstruction11 = genoperandoperand(MoveAwR, address6, ClassReg);
			/* begin OrR:R: */
			genoperandoperand(OrRR, TempReg, ClassReg);

			/* begin JumpNonZero: */
			jmpSamplePrim = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
			/* begin Label */
			continuePostSamplePrim = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
		maybeCompileRetryonPrimitiveFail(retry, primitiveIndex);
		maybeCompileAllocFillerCheck();
		/* begin MoveAw:R: */
		address8 = instructionPointerAddress();
		reg = LinkReg;
		/* begin gen:literal:operand: */
		anInstruction14 = genoperandoperand(MoveAwR, address8, reg);
		genLoadStackPointers(backEnd);
		/* begin MoveAw:R: */
		address9 = primFailCodeAddress();
		/* begin gen:literal:operand: */
		anInstruction15 = genoperandoperand(MoveAwR, address9, TempReg);
		flag("ask concrete code gen if move sets condition codes?");
		/* begin CmpCq:R: */
		anInstruction16 = genoperandoperand(CmpCqR, 0, TempReg);
		/* begin JumpNonZero: */
		jmp = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
		/* begin MoveMw:r:R: */
		offset1 = 0;
		/* begin gen:quickConstant:operand:operand: */
		anInstruction17 = genoperandoperandoperand(MoveMwrR, offset1, SPReg, ReceiverResultReg);
		/* begin RetN: */
		genoperand(RetN, BytesPerWord);
	}
	if (flags & PrimCallCollectsProfileSamples) {

		/* The sample is collected by cePrimReturnEnterCogCode for external calls */
		if (!(jmpSamplePrim == null)) {

			/* Call ceCheckProfileTick: to record sample and then continue. */
			jmpTarget(jmpSamplePrim, gLabel());
			assert(flags & PrimCallNeedsNewMethod);
			/* begin CallFullRT: */
			callTarget = ((unsigned long)ceCheckProfileTick);
			/* begin CallFull: */
			anInstruction28 = genoperand(CallFull, callTarget);

			/* begin Jump: */
			genoperand(Jump, ((sqInt)continuePostSamplePrim));
		}
		jmpTarget(jmpSampleNonPrim, gLabel());
		/* begin MoveCq:R: */
		anInstruction18 = genoperandoperand(MoveCqR, 0, TempReg);
		/* begin MoveR:Aw: */
		address10 = newMethodAddress();
		/* begin gen:operand:literal: */
		anInstruction19 = genoperandoperand(MoveRAw, TempReg, address10);
		/* begin CallFullRT: */
		callTarget1 = ((unsigned long)ceCheckProfileTick);
		/* begin CallFull: */
		anInstruction29 = genoperand(CallFull, callTarget1);

		/* begin Jump: */
		genoperand(Jump, ((sqInt)continuePostSampleNonPrim));
	}
	if (!(jmp == null)) {

		/* Jump to restore of receiver reg and proceed to frame build for failure. */
		jmpTarget(jmp, gLabel());
		/* begin MoveMw:r:R: */
		offset2 = BytesPerWord * (methodOrBlockNumArgs + (0));
		/* begin gen:quickConstant:operand:operand: */
		anInstruction20 = genoperandoperandoperand(MoveMwrR, offset2, SPReg, ReceiverResultReg);
	}
	return 0;
}


/*	Compile one method cache probe in an OpenPIC's lookup of selector.
	Answer the jump taken if the selector probe fails. */

	/* SimpleStackBasedCogit>>#compileOpenPICMethodCacheProbeFor:withShift:baseRegOrNone: */
static AbstractInstruction * NoDbgRegParms
compileOpenPICMethodCacheProbeForwithShiftbaseRegOrNone(sqInt selector, sqInt shift, sqInt baseRegOrNone)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *jumpSelectorMiss;
    sqInt offset;
    sqInt offset1;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ClassReg);
	annotateobjRef(gXorCwR(selector, ClassReg), selector);
	if ((shiftForWord()) > shift) {
		/* begin LogicalShiftLeftCq:R: */
		genoperandoperand(LogicalShiftLeftCqR, (shiftForWord()) - shift, ClassReg);
	}
	/* begin AndCq:R: */
	anInstruction = genoperandoperand(AndCqR, MethodCacheMask << (shiftForWord()), ClassReg);
	if (baseRegOrNone == NoReg) {
		/* begin MoveMw:r:R: */
		offset = (((usqInt)(methodCacheAddress()))) + (MethodCacheSelector << (shiftForWord()));
		/* begin gen:quickConstant:operand:operand: */
		anInstruction1 = genoperandoperandoperand(MoveMwrR, offset, ClassReg, TempReg);
	}
	else {
		/* begin AddR:R: */
		genoperandoperand(AddRR, baseRegOrNone, ClassReg);
		/* begin MoveMw:r:R: */
		anInstruction2 = genoperandoperandoperand(MoveMwrR, MethodCacheSelector << (shiftForWord()), ClassReg, TempReg);
	}
	annotateobjRef(gCmpCwR(selector, TempReg), selector);
	/* begin JumpNonZero: */
	jumpSelectorMiss = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	if (baseRegOrNone == NoReg) {
		/* begin MoveMw:r:R: */
		offset1 = (((usqInt)(methodCacheAddress()))) + (MethodCacheClass << (shiftForWord()));
		/* begin gen:quickConstant:operand:operand: */
		anInstruction3 = genoperandoperandoperand(MoveMwrR, offset1, ClassReg, TempReg);
	}
	else {
		/* begin MoveMw:r:R: */
		anInstruction4 = genoperandoperandoperand(MoveMwrR, MethodCacheClass << (shiftForWord()), ClassReg, TempReg);
	}
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SendNumArgsReg, TempReg);
	return jumpSelectorMiss;
}


/*	Compile the code for an open PIC. Perform a probe of the first-level
	method lookup cache followed by a call of ceSendFromInLineCacheMiss: if
	the probe fails. */

	/* SimpleStackBasedCogit>>#compileOpenPIC:numArgs: */
static void NoDbgRegParms
compileOpenPICnumArgs(sqInt selector, sqInt numArgs)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    sqInt cacheBaseReg;
    AbstractInstruction *itsAHit;
    AbstractInstruction *jumpBCMethod;
    AbstractInstruction *jumpClassMiss;
    AbstractInstruction *jumpSelectorMiss;
    sqInt offset;
    sqInt quickConstant;
    sqInt reg;

	compilePICAbort(numArgs);
	entry = genGetClassTagOfintoscratchReg(ReceiverResultReg, ClassReg, TempReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ClassReg, SendNumArgsReg);
	flag("lookupInMethodCacheSel:classTag:");
	cacheBaseReg = NoReg;
	jumpSelectorMiss = compileOpenPICMethodCacheProbeForwithShiftbaseRegOrNone(selector, 0, cacheBaseReg);
	/* begin JumpNonZero: */
	jumpClassMiss = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset = (cacheBaseReg == NoReg
		? (((usqInt)(methodCacheAddress()))) + (MethodCacheMethod << (shiftForWord()))
		: MethodCacheMethod << (shiftForWord()));
	/* begin gen:quickConstant:operand:operand: */
	anInstruction1 = genoperandoperandoperand(MoveMwrR, offset, ClassReg, SendNumArgsReg);
	itsAHit = anInstruction1;
	genLoadSlotsourceRegdestReg(HeaderIndex, SendNumArgsReg, ClassReg);
	jumpBCMethod = genJumpImmediate(ClassReg);
	jmpTarget(jumpBCMethod, picInterpretAbort);
	/* begin AddCq:R: */
	anInstruction2 = genoperandoperand(AddCqR, cmNoCheckEntryOffset, ClassReg);
	/* begin JumpR: */
	genoperand(JumpR, ClassReg);
	jmpTarget(jumpSelectorMiss, jmpTarget(jumpClassMiss, gLabel()));
	jumpSelectorMiss = compileOpenPICMethodCacheProbeForwithShiftbaseRegOrNone(selector, 1, cacheBaseReg);
	/* begin JumpZero: */
	genConditionalBranchoperand(JumpZero, ((sqInt)itsAHit));
	jmpTarget(jumpSelectorMiss, gLabel());
	jumpSelectorMiss = compileOpenPICMethodCacheProbeForwithShiftbaseRegOrNone(selector, 2, cacheBaseReg);
	/* begin JumpZero: */
	genConditionalBranchoperand(JumpZero, ((sqInt)itsAHit));
	jmpTarget(jumpSelectorMiss, gLabel());
	genPushRegisterArgsForNumArgsscratchReg(backEnd, numArgs, SendNumArgsReg);

	genSmalltalkToCStackSwitch(1);
	addDependent(methodLabel, annotateAbsolutePCRef(gMoveCwR(((sqInt)methodLabel), SendNumArgsReg)));
	compileCallFornumArgsargargargargresultRegsaveRegs(ceSendFromInLineCacheMiss, 1, SendNumArgsReg, null, null, null, NoReg, 0);
}


/*	Compile one method cache probe in a perform: primitive's lookup of
	selector. Answer the jump taken if the selector probe fails. */

	/* SimpleStackBasedCogit>>#compilePerformMethodCacheProbeFor:withShift:baseRegOrNone: */
static AbstractInstruction * NoDbgRegParms
compilePerformMethodCacheProbeForwithShiftbaseRegOrNone(sqInt selectorReg, sqInt shift, sqInt baseRegOrNone)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *jumpSelectorMiss;
    sqInt offset;
    sqInt offset1;

	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SendNumArgsReg, ClassReg);
	/* begin XorR:R: */
	genoperandoperand(XorRR, selectorReg, ClassReg);
	if ((shiftForWord()) > shift) {
		/* begin LogicalShiftLeftCq:R: */
		genoperandoperand(LogicalShiftLeftCqR, (shiftForWord()) - shift, ClassReg);
	}
	/* begin AndCq:R: */
	anInstruction = genoperandoperand(AndCqR, MethodCacheMask << (shiftForWord()), ClassReg);
	if (baseRegOrNone == NoReg) {
		/* begin MoveMw:r:R: */
		offset = (((usqInt)(methodCacheAddress()))) + (MethodCacheSelector << (shiftForWord()));
		/* begin gen:quickConstant:operand:operand: */
		anInstruction1 = genoperandoperandoperand(MoveMwrR, offset, ClassReg, TempReg);
	}
	else {
		/* begin AddR:R: */
		genoperandoperand(AddRR, baseRegOrNone, ClassReg);
		/* begin MoveMw:r:R: */
		anInstruction2 = genoperandoperandoperand(MoveMwrR, MethodCacheSelector << (shiftForWord()), ClassReg, TempReg);
	}
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, selectorReg, TempReg);
	/* begin JumpNonZero: */
	jumpSelectorMiss = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	if (baseRegOrNone == NoReg) {
		/* begin MoveMw:r:R: */
		offset1 = (((usqInt)(methodCacheAddress()))) + (MethodCacheClass << (shiftForWord()));
		/* begin gen:quickConstant:operand:operand: */
		anInstruction3 = genoperandoperandoperand(MoveMwrR, offset1, ClassReg, TempReg);
	}
	else {
		/* begin MoveMw:r:R: */
		anInstruction4 = genoperandoperandoperand(MoveMwrR, MethodCacheClass << (shiftForWord()), ClassReg, TempReg);
	}
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, SendNumArgsReg, TempReg);
	return jumpSelectorMiss;
}


/*	Compile a primitive. If possible, performance-critical primtiives will
	be generated by their own routines (primitiveGenerator). Otherwise,
	if there is a primitive at all, we call the C routine with the usual
	stack-switching dance, test the primFailCode and then either return
	on success or continue to the method body. */

	/* SimpleStackBasedCogit>>#compilePrimitive */
static sqInt
compilePrimitive(void)
{
    sqInt code;
    sqInt opcodeIndexAtPrimitive;
    PrimitiveDescriptor *primitiveDescriptor;
    void (*primitiveRoutine)(void);

	if (primitiveIndex == 0) {
		return 0;
	}

	/* Note opcodeIndex so that compileFallbackToInterpreterPrimitive:
	   can discard arg load instructions for unimplemented primitives. */
	code = 0;

	/* If a descriptor specifies an argument count (by numArgs >= 0) then it must match
	   for the generated code to be correct.  For example for speed many primitives use
	   ResultReceiverReg instead of accessing the stack, so the receiver better be at
	   numArgs down the stack.  Use the interpreter version if not. */
	opcodeIndexAtPrimitive = opcodeIndex;
	if ((((primitiveDescriptor = primitiveGeneratorOrNil())) != null)
	 && ((((primitiveDescriptor->primitiveGenerator)) != null)
	 && ((((primitiveDescriptor->primNumArgs)) < 0)
	 || (((primitiveDescriptor->primNumArgs)) == (argumentCountOf(methodObj)))))) {
		code = ((primitiveDescriptor->primitiveGenerator))();
	}
	if ((code < 0)
	 && (code != UnimplementedPrimitive)) {

		/* Generator failed, so no point continuing... */
		return code;
	}
	if (code == UnfailingPrimitive) {
		return 0;
	}
	if ((code == CompletePrimitive)
	 && (!(((primitiveIndexOfMethodheader(methodObj, methodHeader)) > 0)
 && ((longStoreBytecodeForHeader(methodHeader)) == (fetchByteofObject(initialPC + (sizeOfCallPrimitiveBytecode(methodHeader)), methodObj)))))) {
		return 0;
	}
	if (code == UnimplementedPrimitive) {
		opcodeIndex = opcodeIndexAtPrimitive;
	}
	if ((((primitiveRoutine = functionPointerForCompiledMethodprimitiveIndex(methodObj, primitiveIndex))) == null)
	 || (primitiveRoutine == (functionPointerForinClass(0, null)))) {
		return genFastPrimFail();
	}
	minValidCallAddress = ((minValidCallAddress < (((usqInt)primitiveRoutine))) ? minValidCallAddress : (((usqInt)primitiveRoutine)));
	return compileInterpreterPrimitive(primitiveRoutine);
}

	/* SimpleStackBasedCogit>>#extendedPushBytecode */
static sqInt
extendedPushBytecode(void)
{
    sqInt variableIndex;
    sqInt variableType;

	variableType = (((usqInt) byte1) >> 6) & 3;
	variableIndex = byte1 & 0x3F;
	if (variableType == 0) {
		return genPushReceiverVariable(variableIndex);
	}
	if (variableType == 1) {
		return genPushTemporaryVariable(variableIndex);
	}
	if (variableType == 2) {
		return genPushLiteralIndex(variableIndex);
	}
	return genPushLiteralVariable(variableIndex);
}

	/* SimpleStackBasedCogit>>#extendedStoreAndPopBytecode */
static sqInt
extendedStoreAndPopBytecode(void)
{
    AbstractInstruction *abstractInstruction;
    sqInt variableIndex;
    sqInt variableType;

	variableType = (((usqInt) byte1) >> 6) & 3;
	variableIndex = byte1 & 0x3F;
	if (variableType == 0) {
		return genStorePopReceiverVariable(1, variableIndex);
	}
	if (variableType == 1) {
		genStorePopTemporaryVariable(1, variableIndex);
		
#    if IMMUTABILITY
		/* begin annotateBytecode: */
		abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		(abstractInstruction->annotation = HasBytecodePC);

#    endif /* IMMUTABILITY */

		return 0;
	}
	if (variableType == 3) {
		return genStorePopLiteralVariable(1, variableIndex);
	}
	return EncounteredUnknownBytecode;
}

	/* SimpleStackBasedCogit>>#extendedStoreBytecode */
static sqInt
extendedStoreBytecode(void)
{
    AbstractInstruction *abstractInstruction;
    sqInt variableIndex;
    sqInt variableType;

	variableType = (((usqInt) byte1) >> 6) & 3;
	variableIndex = byte1 & 0x3F;
	if (variableType == 0) {
		return genStorePopReceiverVariable(0, variableIndex);
	}
	if (variableType == 1) {
		genStorePopTemporaryVariable(0, variableIndex);
		
#    if IMMUTABILITY
		/* begin annotateBytecode: */
		abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		(abstractInstruction->annotation = HasBytecodePC);

#    endif /* IMMUTABILITY */

		return 0;
	}
	if (variableType == 3) {
		return genStorePopLiteralVariable(0, variableIndex);
	}
	return EncounteredUnknownBytecode;
}

	/* SimpleStackBasedCogit>>#frameOffsetOfTemporary: */
static sqInt NoDbgRegParms
frameOffsetOfTemporary(sqInt index)
{
	return (index < methodOrBlockNumArgs
		? FoxCallerSavedIP + ((methodOrBlockNumArgs - index) * BytesPerWord)
		: (FoxMFReceiver - BytesPerWord) + ((methodOrBlockNumArgs - index) * BytesPerWord));
}


/*	Return from block, assuming result already loaded into ReceiverResultReg. */

	/* SimpleStackBasedCogit>>#genBlockReturn */
static sqInt
genBlockReturn(void)
{
	if (needsFrame) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, FPReg, SPReg);
		/* begin PopR: */
		genoperand(PopR, FPReg);
		/* begin PopR: */
		genoperand(PopR, LinkReg);

	}
	/* begin RetN: */
	genoperand(RetN, (methodOrBlockNumArgs + 1) * BytesPerWord);
	return 0;
}


/*	Can use any of the first 32 literals for the selector and pass up to 7
	arguments. 
 */

	/* SimpleStackBasedCogit>>#genExtendedSendBytecode */
static sqInt
genExtendedSendBytecode(void)
{
	return genSendnumArgs(byte1 & 0x1F, ((usqInt) byte1) >> 5);
}

	/* SimpleStackBasedCogit>>#genExtendedSuperBytecode */
static sqInt
genExtendedSuperBytecode(void)
{
	return genSendSupernumArgs(byte1 & 0x1F, ((usqInt) byte1) >> 5);
}

	/* SimpleStackBasedCogit>>#genFastPrimFail */
static sqInt
genFastPrimFail(void)
{
	primitiveIndex = 0;
	return UnfailingPrimitive;
}


/*	Suport for compileInterpreterPrimitive. Generate inline code so as to
	record the primitive
	trace as fast as possible. */

	/* SimpleStackBasedCogit>>#genFastPrimTraceUsing:and: */
static void NoDbgRegParms
genFastPrimTraceUsingand(sqInt r1, sqInt r2)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    sqInt offset;
    sqInt wordConstant;

	/* begin MoveCq:R: */
	anInstruction = genoperandoperand(MoveCqR, 0, r2);

	/* begin MoveAb:R: */
	address = primTraceLogIndexAddress();
	/* begin gen:literal:operand: */
	anInstruction1 = genoperandoperand(MoveAbR, address, r2);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, r2, r1);
	/* begin AddCq:R: */
	anInstruction2 = genoperandoperand(AddCqR, 1, r1);
	/* begin MoveR:Ab: */
	address1 = primTraceLogIndexAddress();
	/* begin gen:operand:literal: */
	anInstruction3 = genoperandoperand(MoveRAb, r1, address1);
	addDependent(methodLabel, annotateAbsolutePCRef(gMoveCwR(((sqInt)methodLabel), r1)));
	/* begin MoveMw:r:R: */
	offset = offsetof(CogMethod, selector);
	/* begin gen:quickConstant:operand:operand: */
	anInstruction4 = genoperandoperandoperand(MoveMwrR, offset, r1, TempReg);
	/* begin MoveCw:R: */
	wordConstant = ((sqInt)(primTraceLogAddress()));
	/* begin gen:literal:operand: */
	anInstruction5 = genoperandoperand(MoveCwR, wordConstant, r1);
	/* begin MoveR:Xwr:R: */
	genoperandoperandoperand(MoveRXwrR, TempReg, r2, r1);
}

	/* SimpleStackBasedCogit>>#genLongJumpIfFalse */
static sqInt
genLongJumpIfFalse(void)
{
    sqInt distance;
    sqInt target;

	distance = v3LongForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 2) + bytecodePC;
	return genJumpIfto(falseObject(), target);
}

	/* SimpleStackBasedCogit>>#genLongJumpIfTrue */
static sqInt
genLongJumpIfTrue(void)
{
    sqInt distance;
    sqInt target;

	distance = v3LongForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 2) + bytecodePC;
	return genJumpIfto(trueObject(), target);
}


/*	237		11101101	i i i i i i i i	Pop and Store Temporary Variable #iiiiiiii */

	/* SimpleStackBasedCogit>>#genLongStoreAndPopTemporaryVariableBytecode */
static sqInt
genLongStoreAndPopTemporaryVariableBytecode(void)
{
	return genStorePopTemporaryVariable(1, byte1);
}

	/* SimpleStackBasedCogit>>#genLongUnconditionalBackwardJump */
static sqInt
genLongUnconditionalBackwardJump(void)
{
    sqInt distance;
    sqInt targetpc;

	distance = v3LongBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	assert(distance < 0);
	targetpc = (distance + 2) + bytecodePC;
	return genJumpBackTo(targetpc);
}

	/* SimpleStackBasedCogit>>#genLongUnconditionalForwardJump */
static sqInt
genLongUnconditionalForwardJump(void)
{
    sqInt distance;
    sqInt targetpc;

	distance = v3LongBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	assert(distance >= 0);
	targetpc = (distance + 2) + bytecodePC;
	return genJumpTo(targetpc);
}


/*	Compile the code for a probe of the first-level method cache for a perform
	primtiive. The selector is assumed to be in Arg0Reg. Defer to
	adjustArgumentsForPerform: to
	adjust the arguments before the jump to the method. */

	/* SimpleStackBasedCogit>>#genLookupForPerformNumArgs: */
static sqInt NoDbgRegParms
genLookupForPerformNumArgs(sqInt numArgs)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    sqInt cacheBaseReg;
    AbstractInstruction *itsAHit;
    AbstractInstruction *jumpClassMiss;
    AbstractInstruction *jumpInterpret;
    AbstractInstruction *jumpSelectorMiss;
    sqInt offset;
    sqInt quickConstant;
    sqInt reg;


	/* N.B.  Can't assume TempReg already contains the tag because a method can
	   of course be invoked via the unchecked entry-point, e.g. as does perform:. */
	genGetInlineCacheClassTagFromintoforEntry(ReceiverResultReg, SendNumArgsReg, 0);
	flag("lookupInMethodCacheSel:classTag:");
	cacheBaseReg = NoReg;
	jumpSelectorMiss = compilePerformMethodCacheProbeForwithShiftbaseRegOrNone(Arg0Reg, 0, cacheBaseReg);
	/* begin JumpNonZero: */
	jumpClassMiss = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveMw:r:R: */
	offset = (cacheBaseReg == NoReg
		? (((usqInt)(methodCacheAddress()))) + (MethodCacheMethod << (shiftForWord()))
		: MethodCacheMethod << (shiftForWord()));
	/* begin gen:quickConstant:operand:operand: */
	anInstruction2 = genoperandoperandoperand(MoveMwrR, offset, ClassReg, SendNumArgsReg);
	itsAHit = anInstruction2;
	genLoadSlotsourceRegdestReg(HeaderIndex, SendNumArgsReg, ClassReg);

	/* Adjust arguments and jump to the method's unchecked entry-point. */
	jumpInterpret = genJumpImmediate(ClassReg);
	/* begin AddCq:R: */
	anInstruction = genoperandoperand(AddCqR, cmNoCheckEntryOffset, ClassReg);
	adjustArgumentsForPerform(numArgs);
	/* begin JumpR: */
	genoperand(JumpR, ClassReg);
	jmpTarget(jumpSelectorMiss, jmpTarget(jumpClassMiss, gLabel()));
	jumpSelectorMiss = compilePerformMethodCacheProbeForwithShiftbaseRegOrNone(Arg0Reg, 1, cacheBaseReg);
	/* begin JumpZero: */
	genConditionalBranchoperand(JumpZero, ((sqInt)itsAHit));
	jmpTarget(jumpSelectorMiss, gLabel());
	jumpSelectorMiss = compilePerformMethodCacheProbeForwithShiftbaseRegOrNone(Arg0Reg, 1, cacheBaseReg);
	/* begin JumpZero: */
	genConditionalBranchoperand(JumpZero, ((sqInt)itsAHit));
	jmpTarget(jumpSelectorMiss, jmpTarget(jumpInterpret, gLabel()));
	return 0;
}

	/* SimpleStackBasedCogit>>#genMoveFalseR: */
static AbstractInstruction * NoDbgRegParms
genMoveFalseR(sqInt reg)
{
    AbstractInstruction *anInstruction;
    sqInt constant;

	/* begin genMoveConstant:R: */
	constant = falseObject();
	return (shouldAnnotateObjectReference(constant)
		? annotateobjRef(gMoveCwR(constant, reg), constant)
		: (/* begin MoveCq:R: */
			(anInstruction = genoperandoperand(MoveCqR, constant, reg)),
			anInstruction));
}

	/* SimpleStackBasedCogit>>#genMoveTrueR: */
static AbstractInstruction * NoDbgRegParms
genMoveTrueR(sqInt reg)
{
    AbstractInstruction *anInstruction;
    sqInt constant;

	/* begin genMoveConstant:R: */
	constant = trueObject();
	return (shouldAnnotateObjectReference(constant)
		? annotateobjRef(gMoveCwR(constant, reg), constant)
		: (/* begin MoveCq:R: */
			(anInstruction = genoperandoperand(MoveCqR, constant, reg)),
			anInstruction));
}

	/* SimpleStackBasedCogit>>#genMustBeBooleanTrampolineFor:called: */
static sqInt NoDbgRegParms
genMustBeBooleanTrampolineForcalled(sqInt boolean, char *trampolineName)
{
    AbstractInstruction *anInstruction;

	zeroOpcodeIndex();
	assert(!(shouldAnnotateObjectReference(boolean)));
	/* begin AddCq:R: */
	anInstruction = genoperandoperand(AddCqR, boolean, TempReg);
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceSendMustBeBoolean, trampolineName, 1, TempReg, null, null, null, 0, 1, NoReg, 1);
}


/*	Generate the substitute return code for an external or FFI primitive call.
	On success simply return, extracting numArgs from newMethod.
	On primitive failure call ceActivateFailingPrimitiveMethod: newMethod. */

	/* SimpleStackBasedCogit>>#genPrimReturnEnterCogCodeEnilopmart: */
static void NoDbgRegParms
genPrimReturnEnterCogCodeEnilopmart(sqInt profiling)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    sqInt address1;
    sqInt address2;
    sqInt address3;
    sqInt address4;
    sqInt address5;
    sqInt address6;
    sqInt address7;
    sqInt address8;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction10;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction12;
    AbstractInstruction *anInstruction13;
    AbstractInstruction *anInstruction14;
    AbstractInstruction *anInstruction15;
    AbstractInstruction *anInstruction16;
    AbstractInstruction *anInstruction17;
    AbstractInstruction *anInstruction18;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    AbstractInstruction *anInstruction8;
    AbstractInstruction *anInstruction9;
    sqInt callTarget;
    AbstractInstruction *continuePostSample;
    AbstractInstruction * inst;
    AbstractInstruction *jmpFail;
    AbstractInstruction *jmpSample;
    sqInt quickConstant;
    sqInt reg;

	zeroOpcodeIndex();
	/* begin MoveCq:R: */
	quickConstant = varBaseAddress();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(MoveCqR, quickConstant, VarBaseReg);

	if (profiling) {

		/* Test nextProfileTick for being non-zero and call checkProfileTick: if so.
		   N.B. nextProfileTick is 64-bits so 32-bit systems need to test both halves. */
		/* begin MoveAw:R: */
		address = nextProfileTickAddress();
		/* begin gen:literal:operand: */
		anInstruction1 = genoperandoperand(MoveAwR, address, TempReg);
		/* begin MoveAw:R: */
		address1 = (nextProfileTickAddress()) + BytesPerWord;
		/* begin gen:literal:operand: */
		anInstruction2 = genoperandoperand(MoveAwR, address1, ClassReg);
		/* begin OrR:R: */
		genoperandoperand(OrRR, TempReg, ClassReg);

		/* begin JumpNonZero: */
		jmpSample = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
		/* begin Label */
		continuePostSample = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	}
	maybeCompileAllocFillerCheck();
	/* begin MoveAw:R: */
	address6 = primFailCodeAddress();
	/* begin gen:literal:operand: */
	anInstruction13 = genoperandoperand(MoveAwR, address6, TempReg);
	flag("ask concrete code gen if move sets condition codes?");
	/* begin CmpCq:R: */
	anInstruction14 = genoperandoperand(CmpCqR, 0, TempReg);
	/* begin JumpNonZero: */
	jmpFail = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	genLoadStackPointers(backEnd);
	/* begin MoveMw:r:R: */
	anInstruction6 = genoperandoperandoperand(MoveMwrR, 0, SPReg, ReceiverResultReg);
	/* begin MoveAw:R: */
	address4 = instructionPointerAddress();
	/* begin gen:literal:operand: */
	anInstruction7 = genoperandoperand(MoveAwR, address4, LinkReg);
	/* begin RetN: */
	genoperand(RetN, BytesPerWord);


	jmpTarget(jmpFail, gMoveAwR(newMethodAddress(), SendNumArgsReg));
	/* begin MoveAw:R: */
	address7 = cStackPointerAddress();
	/* begin gen:literal:operand: */
	anInstruction15 = genoperandoperand(MoveAwR, address7, SPReg);
	compileCallFornumArgsargargargargresultRegsaveRegs(ceActivateFailingPrimitiveMethod, 1, SendNumArgsReg, null, null, null, NoReg, 0);
	/* begin MoveAw:R: */
	address8 = instructionPointerAddress();
	reg = LinkReg;
	/* begin gen:literal:operand: */
	anInstruction16 = genoperandoperand(MoveAwR, address8, reg);
	genLoadStackPointers(backEnd);
	/* begin MoveMw:r:R: */
	anInstruction11 = genoperandoperandoperand(MoveMwrR, 0, SPReg, ReceiverResultReg);

	/* begin RetN: */
	genoperand(RetN, BytesPerWord);
	if (profiling) {

		/* Call ceCheckProfileTick: to record sample and then continue.  newMethod
		   should be up-to-date.  Need to save and restore the link reg around this call. */
		jmpTarget(jmpSample, gLabel());
		/* begin saveAndRestoreLinkRegAround: */
		inst = genoperand(PushR, LinkReg);
		/* begin CallFullRT: */
		callTarget = (unsigned long)ceCheckProfileTick;
		/* begin CallFull: */
		anInstruction17 = genoperand(CallFull, callTarget);


		/* begin PopR: */
		genoperand(PopR, LinkReg);
		/* begin Jump: */
		genoperand(Jump, ((sqInt)continuePostSample));
	}
}


/*	SistaV1: 230		11100110	iiiiiiii		PushNClosureTemps iiiiiiii */

	/* SimpleStackBasedCogit>>#genPushClosureTempsBytecode */
static sqInt
genPushClosureTempsBytecode(void)
{
    sqInt i;

	for (i = 1; i <= byte1; i += 1) {
		genPushLiteral(nilObject());
	}
	return 0;
}

	/* SimpleStackBasedCogit>>#genPushConstantFalseBytecode */
static sqInt
genPushConstantFalseBytecode(void)
{
	return genPushLiteral(falseObject());
}

	/* SimpleStackBasedCogit>>#genPushConstantNilBytecode */
static sqInt
genPushConstantNilBytecode(void)
{
	return genPushLiteral(nilObject());
}

	/* SimpleStackBasedCogit>>#genPushConstantTrueBytecode */
static sqInt
genPushConstantTrueBytecode(void)
{
	return genPushLiteral(trueObject());
}

	/* SimpleStackBasedCogit>>#genPushLiteralConstantBytecode */
static sqInt
genPushLiteralConstantBytecode(void)
{
	return genPushLiteralIndex(byte0 & 0x1F);
}


/*	<SmallInteger> */

	/* SimpleStackBasedCogit>>#genPushLiteralIndex: */
static sqInt NoDbgRegParms
genPushLiteralIndex(sqInt literalIndex)
{
    sqInt literal;

	literal = getLiteral(literalIndex);
	return genPushLiteral(literal);
}

	/* SimpleStackBasedCogit>>#genPushLiteralVariableBytecode */
static sqInt
genPushLiteralVariableBytecode(void)
{
	return genPushLiteralVariable(byte0 & 0x1F);
}

	/* SimpleStackBasedCogit>>#genPushQuickIntegerConstantBytecode */
static sqInt
genPushQuickIntegerConstantBytecode(void)
{
	return genPushLiteral((((byte0 - 117) << 1) | 1));
}

	/* SimpleStackBasedCogit>>#genPushReceiverVariableBytecode */
static sqInt
genPushReceiverVariableBytecode(void)
{
	return genPushReceiverVariable(byte0 & 15);
}

	/* SimpleStackBasedCogit>>#genPushTemporaryVariableBytecode */
static sqInt
genPushTemporaryVariableBytecode(void)
{
	return genPushTemporaryVariable(byte0 & 15);
}


/*	because selected by CoInterpreter>>quickPrimitiveGeneratorFor: */

	/* SimpleStackBasedCogit>>#genQuickReturnConst */
sqInt
genQuickReturnConst(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    sqInt constant;

	constant = quickPrimitiveConstantFor(primitiveIndex);
	annotateobjRef((isImmediate(constant)
		? (/* begin MoveCq:R: */
			(anInstruction = genoperandoperand(MoveCqR, constant, ReceiverResultReg)),
			anInstruction)
		: (/* begin MoveCw:R: */
			(anInstruction1 = genoperandoperand(MoveCwR, constant, ReceiverResultReg)),
			anInstruction1)), constant);
	genUpArrowReturn();
	return UnfailingPrimitive;
}


/*	because selected by CoInterpreter>>quickPrimitiveGeneratorFor: */

	/* SimpleStackBasedCogit>>#genQuickReturnInstVar */
sqInt
genQuickReturnInstVar(void)
{
    sqInt index;

	index = quickPrimitiveInstVarIndexFor(primitiveIndex);
	genLoadSlotsourceRegdestReg(index, ReceiverResultReg, ReceiverResultReg);
	genUpArrowReturn();
	return UnfailingPrimitive;
}


/*	because selected by CoInterpreter>>quickPrimitiveGeneratorFor: */

	/* SimpleStackBasedCogit>>#genQuickReturnSelf */
sqInt
genQuickReturnSelf(void)
{
	genUpArrowReturn();
	return UnfailingPrimitive;
}

	/* SimpleStackBasedCogit>>#genReturnFalse */
static sqInt
genReturnFalse(void)
{
    AbstractInstruction *anInstruction;
    sqInt constant;

	/* begin genMoveFalseR: */
	constant = falseObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, constant, ReceiverResultReg);
	}
	return genUpArrowReturn();
}

	/* SimpleStackBasedCogit>>#genReturnNil */
static sqInt
genReturnNil(void)
{
    AbstractInstruction *anInstruction;
    sqInt constant;

	/* begin genMoveConstant:R: */
	constant = nilObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, constant, ReceiverResultReg);
	}
	return genUpArrowReturn();
}

	/* SimpleStackBasedCogit>>#genReturnTrue */
static sqInt
genReturnTrue(void)
{
    AbstractInstruction *anInstruction;
    sqInt constant;

	/* begin genMoveTrueR: */
	constant = trueObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, ReceiverResultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, constant, ReceiverResultReg);
	}
	return genUpArrowReturn();
}


/*	Can use any of the first 64 literals for the selector and pass up to 3
	arguments. 
 */

	/* SimpleStackBasedCogit>>#genSecondExtendedSendBytecode */
static sqInt
genSecondExtendedSendBytecode(void)
{
	return genSendnumArgs(byte1 & 0x3F, ((usqInt) byte1) >> 6);
}

	/* SimpleStackBasedCogit>>#genSendLiteralSelector0ArgsBytecode */
static sqInt
genSendLiteralSelector0ArgsBytecode(void)
{
	return genSendnumArgs(byte0 & 15, 0);
}

	/* SimpleStackBasedCogit>>#genSendLiteralSelector1ArgBytecode */
static sqInt
genSendLiteralSelector1ArgBytecode(void)
{
	return genSendnumArgs(byte0 & 15, 1);
}

	/* SimpleStackBasedCogit>>#genSendLiteralSelector2ArgsBytecode */
static sqInt
genSendLiteralSelector2ArgsBytecode(void)
{
	return genSendnumArgs(byte0 & 15, 2);
}

	/* SimpleStackBasedCogit>>#genShortJumpIfFalse */
static sqInt
genShortJumpIfFalse(void)
{
    sqInt distance;
    sqInt target;

	distance = v3ShortForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 1) + bytecodePC;
	return genJumpIfto(falseObject(), target);
}

	/* SimpleStackBasedCogit>>#genShortUnconditionalJump */
static sqInt
genShortUnconditionalJump(void)
{
    sqInt distance;
    sqInt target;

	distance = v3ShortForwardBranchDistance(generatorAt(byte0), bytecodePC, 0, methodObj);
	target = (distance + 1) + bytecodePC;
	return genJumpTo(target);
}

	/* SimpleStackBasedCogit>>#genSpecialSelectorSend */
static sqInt
genSpecialSelectorSend(void)
{
    sqInt index;
    sqInt numArgs;

	index = byte0 - (
#if MULTIPLEBYTECODESETS
	(bytecodeSetOffset == 256
		? AltFirstSpecialSelector + 256
		: FirstSpecialSelector)
#else /* MULTIPLEBYTECODESETS */
	FirstSpecialSelector
#endif /* MULTIPLEBYTECODESETS */
	);
	numArgs = specialSelectorNumArgs(index);
	return genSendnumArgs((-index) - 1, numArgs);
}

	/* SimpleStackBasedCogit>>#genStoreAndPopReceiverVariableBytecode */
static sqInt
genStoreAndPopReceiverVariableBytecode(void)
{
	return genStorePopReceiverVariable(1, byte0 & 7);
}

	/* SimpleStackBasedCogit>>#genStoreAndPopRemoteTempLongBytecode */
static sqInt
genStoreAndPopRemoteTempLongBytecode(void)
{
	return genStorePopRemoteTempAt(1, byte1, byte2);
}

	/* SimpleStackBasedCogit>>#genStoreAndPopTemporaryVariableBytecode */
static sqInt
genStoreAndPopTemporaryVariableBytecode(void)
{
	return genStorePopTemporaryVariable(1, byte0 & 7);
}

	/* SimpleStackBasedCogit>>#genStoreRemoteTempLongBytecode */
static sqInt
genStoreRemoteTempLongBytecode(void)
{
	return genStorePopRemoteTempAt(0, byte1, byte2);
}


/*	If allocCheckFiller is true, words in newSpace from freeStart to
	scavengeThreshold are filled with their address, and after each call of a
	plugin primitive, the VM checks
	that freeStart points to a word containing the value of freeStart. This is
	a simple
	check for primitives overwriting the ends of an object. */

	/* SimpleStackBasedCogit>>#maybeCompileAllocFillerCheck */
static void
maybeCompileAllocFillerCheck(void)
{
    sqInt address;
    sqInt address1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *jmpOk;

	if (getCheckAllocFiller()) {
		/* begin MoveAw:R: */
		address = freeStartAddress();
		/* begin gen:literal:operand: */
		anInstruction = genoperandoperand(MoveAwR, address, ClassReg);
		/* begin MoveMw:r:R: */
		anInstruction1 = genoperandoperandoperand(MoveMwrR, 0, ClassReg, TempReg);
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, ClassReg, TempReg);
		/* begin JumpZero: */
		jmpOk = genConditionalBranchoperand(JumpZero, ((sqInt)0));
		/* begin MoveCq:R: */
		anInstruction2 = genoperandoperand(MoveCqR, PrimErrWritePastObject, TempReg);
		/* begin MoveR:Aw: */
		address1 = primFailCodeAddress();
		/* begin gen:operand:literal: */
		anInstruction3 = genoperandoperand(MoveRAw, TempReg, address1);
		jmpTarget(jmpOk, gLabel());
	}
}

	/* SimpleStackBasedCogit>>#numSpecialSelectors */
static sqInt
numSpecialSelectors(void)
{
	return 
#  if MULTIPLEBYTECODESETS
		(bytecodeSetOffset == 256
				? AltNumSpecialSelectors
				: NumSpecialSelectors)
#  else /* MULTIPLEBYTECODESETS */
		NumSpecialSelectors
#  endif /* MULTIPLEBYTECODESETS */
		;
}


/*	If there is a generator for the current primitive then answer it;
	otherwise answer nil. */

	/* SimpleStackBasedCogit>>#primitiveGeneratorOrNil */
static PrimitiveDescriptor *
primitiveGeneratorOrNil(void)
{
    PrimitiveDescriptor *primitiveDescriptor;
    static PrimitiveDescriptor primitiveGeneratorTable[MaxCompiledPrimitiveIndex+1] = {
	{ 0, -1 },
	{ genPrimitiveAdd, 1 },
	{ genPrimitiveSubtract, 1 },
	{ genPrimitiveLessThan, 1 },
	{ genPrimitiveGreaterThan, 1 },
	{ genPrimitiveLessOrEqual, 1 },
	{ genPrimitiveGreaterOrEqual, 1 },
	{ genPrimitiveEqual, 1 },
	{ genPrimitiveNotEqual, 1 },
	{ genPrimitiveMultiply, 1 },
	{ genPrimitiveDivide, 1 },
	{ genPrimitiveMod, 1 },
	{ genPrimitiveDiv, 1 },
	{ genPrimitiveQuo, 1 },
	{ genPrimitiveBitAnd, 1 },
	{ genPrimitiveBitOr, 1 },
	{ genPrimitiveBitXor, 1 },
	{ genPrimitiveBitShift, 1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ genPrimitiveAt, 1 },
	{ genPrimitiveAtPut, 2 },
	{ genPrimitiveSize, 0 },
	{ genPrimitiveStringAt, 1 },
	{ genPrimitiveStringAtPut, 2 },
	{ genFastPrimFail, -1 },
	{ genFastPrimFail, -1 },
	{ genFastPrimFail, -1 },
	{ genPrimitiveObjectAt, 1 },
	{ 0, -1 },
	{ genPrimitiveNew, 0 },
	{ genPrimitiveNewWithArg, 1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ genPrimitiveIdentityHash, 0 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ genPrimitiveNewMethod, 2 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ genPrimitivePerform, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ genPrimitiveIdentical, 1 },
	{ genPrimitiveClass, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ genPrimitiveNotIdentical, 1 },
	{ genPrimitiveAsCharacter, -1 },
	{ genPrimitiveCharacterValue, 0 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ genPrimitiveIdentityHash, 0 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ genFastPrimFail, -1 },
	{ genFastPrimFail, -1 },
	{ 0, -1 },
	{ genPrimitiveClosureValue, 0 },
	{ genPrimitiveClosureValue, 1 },
	{ genPrimitiveClosureValue, 2 },
	{ genPrimitiveClosureValue, 3 },
	{ genPrimitiveClosureValue, 4 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ 0, -1 },
	{ genPrimitiveClosureValue, 0 },
	{ genPrimitiveClosureValue, 1 }
};

	if (isQuickPrimitiveIndex(primitiveIndex)) {

		/* an unused one */
		primitiveDescriptor = (&(primitiveGeneratorTable[0]));
		(primitiveDescriptor->primitiveGenerator = quickPrimitiveGeneratorFor(primitiveIndex));
		return primitiveDescriptor;
	}
	if (((primitiveIndex >= 1) && (primitiveIndex <= MaxCompiledPrimitiveIndex))) {
		return (&(primitiveGeneratorTable[primitiveIndex]));
	}
	return null;
}

	/* SimpleStackBasedCogit>>#recordCallOffsetIn: */
void
recordCallOffsetIn(CogMethod *cogMethod)
{
    unsigned long offset;
    sqInt *offsetTable;

	offset = ((primSetFunctionLabel->address)) - (((sqInt)cogMethod));
	if ((externalSetPrimOffsets[(cogMethod->cmNumArgs)]) == null) {
		externalSetPrimOffsets[(cogMethod->cmNumArgs)] = offset;
	}
	else {
		assert((externalSetPrimOffsets[(cogMethod->cmNumArgs)]) == offset);
	}
	offsetTable = (isJump(primInvokeInstruction)
		? externalPrimJumpOffsets
		: externalPrimCallOffsets);
	offset = (((primInvokeInstruction->address)) + ((primInvokeInstruction->machineCodeSize))) - (((sqInt)cogMethod));
	if ((offsetTable[(cogMethod->cmNumArgs)]) == null) {
		offsetTable[(cogMethod->cmNumArgs)] = offset;
	}
	else {
		assert((offsetTable[(cogMethod->cmNumArgs)]) == offset);
	}
}

	/* SimpleStackBasedCogit>>#register:isInMask: */
static sqInt NoDbgRegParms
registerisInMask(sqInt reg, sqInt mask)
{
	return mask & (registerMaskFor(reg));
}


/*	We must ensure the ReceiverResultReg is live across the store check so
	that we can store into receiver inst vars in a frameless method since self
	exists only in ReceiverResultReg in a frameless method. So if
	ReceiverResultReg is
	caller-saved we use the fact that ceStoreCheck: answers its argument to
	reload ReceiverResultReg cheaply. Otherwise we don't care about the result
	and use the cResultRegister, effectively a no-op (see
	compileTrampoline...)  */

	/* SimpleStackBasedCogit>>#returnRegForStoreCheck */
static sqInt
returnRegForStoreCheck(void)
{
	return (callerSavedRegMask & (registerMaskFor(ReceiverResultReg))
		? ReceiverResultReg
		: V0);
}

	/* SimpleStackBasedCogit>>#rewritePrimInvocationIn:to: */
void
rewritePrimInvocationInto(CogMethod *cogMethod, void (*primFunctionPointer)(void))
{
    usqInt address;
    sqInt extent;
    sqInt flags;
    sqInt primIndex;

	assert(((cogMethod->cmType)) == CMMethod);
	primIndex = primitiveIndexOfMethodheader((cogMethod->methodObject), (cogMethod->methodHeader));
	flags = primitivePropertyFlags(primIndex);
	if (flags & PrimCallNeedsPrimitiveFunction) {
		storeLiteralbeforeFollowingAddress(backEnd, ((usqInt)primFunctionPointer), (((usqInt)cogMethod)) + (externalSetPrimOffsets[(cogMethod->cmNumArgs)]));
	}
	if (flags & PrimCallMayCallBack) {
		address = (((usqInt)cogMethod)) + (externalPrimJumpOffsets[(cogMethod->cmNumArgs)]);
		extent = rewriteJumpFullAttarget(backEnd, address, ((usqInt)primFunctionPointer));
	}
	else {
		address = (((usqInt)cogMethod)) + (externalPrimCallOffsets[(cogMethod->cmNumArgs)]);
		extent = rewriteCallFullAttarget(backEnd, address, ((usqInt)primFunctionPointer));
	}
	flushICacheFromto(processor, (((usqInt)cogMethod)) + cmNoCheckEntryOffset, (((usqInt)address)) + extent);
}

	/* SimpleStackBasedCogit>>#v3:Block:Code:Size: */
static sqInt NoDbgRegParms
v3BlockCodeSize(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(nExts <= 0);
	return ((fetchByteofObject(pc + 2, aMethodObj)) << 8) + (fetchByteofObject(pc + 3, aMethodObj));
}


/*	Answer the distance of a two byte forward long jump. */

	/* SimpleStackBasedCogit>>#v3:LongForward:Branch:Distance: */
static sqInt NoDbgRegParms
v3LongForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(nExts == 0);
	return (((fetchByteofObject(pc, aMethodObj)) & 3) << 8) + (fetchByteofObject(pc + 1, aMethodObj));
}


/*	Answer the distance of a two byte forward long jump. */

	/* SimpleStackBasedCogit>>#v3:Long:Branch:Distance: */
static sqInt NoDbgRegParms
v3LongBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(nExts == 0);
	return ((((fetchByteofObject(pc, aMethodObj)) & 7) - 4) << 8) + (fetchByteofObject(pc + 1, aMethodObj));
}


/*	N.B. This serves for both BlueBook/V3 and V4 short jumps. */

	/* SimpleStackBasedCogit>>#v3:ShortForward:Branch:Distance: */
static sqInt NoDbgRegParms
v3ShortForwardBranchDistance(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	assert(nExts == 0);
	return ((fetchByteofObject(pc, aMethodObj)) & 7) + 1;
}

	/* SimpleStackBasedCogit>>#voidCogCompiledCode */
void
voidCogCompiledCode(void)
{
    sqInt i;

	clearCogCompiledCode();
	for (i = 0; i <= MaxNumArgs; i += 1) {
		externalPrimJumpOffsets[i] = null;
		externalPrimCallOffsets[i] = null;
		externalSetPrimOffsets[i] = null;
	}
}


/*	Add a blockStart for an embedded block. For a binary tree walk block
	dispatch blocks must be compiled in pc/depth-first order but are scanned
	in breadth-first
	order, so do an insertion sort (which of course is really a bubble sort
	because we
	have to move everything higher to make room). */

	/* StackToRegisterMappingCogit>>#addBlockStartAt:numArgs:numCopied:span: */
static BlockStart * NoDbgRegParms
addBlockStartAtnumArgsnumCopiedspan(sqInt bytecodepc, sqInt numArgs, sqInt numCopied, sqInt span)
{
    BlockStart *blockStart;
    sqInt i;
    sqInt j;


	/* Transcript ensureCr; nextPutAll: 'addBlockStartAt: '; print: bytecodepc; cr; flush. */
	if (blockCount > 0) {
		i = blockCount - 1;
		while (1) {

			/* check for repeat addition during recompilation due to initialNil miscount. */
			blockStart = (&(blockStarts[i]));
			if (((blockStart->startpc)) == bytecodepc) {
				return blockStart;
			}
			if (!((((blockStart->startpc)) > bytecodepc)
			 && (i > 0))) break;
			i -= 1;
		}
		for (j = blockCount; j >= (i + 1); j += -1) {
			blockStarts[j] = (blockStarts[j - 1]);
		}
		blockStart = (&(blockStarts[i + 1]));
	}
	else {
		blockStart = (&(blockStarts[blockCount]));
	}
	blockCount += 1;
	(blockStart->startpc = bytecodepc);
	(blockStart->numArgs = numArgs);
	(blockStart->numCopied = numCopied);
	(blockStart->numInitialNils = 0);
	(blockStart->stackCheckLabel = null);
	(blockStart->hasInstVarRef = 0);
	(blockStart->span = span);
	return blockStart;
}


/*	e.g.	Receiver				Receiver
	Selector/Arg0	=>		Arg1
	Arg1					Arg2
	Arg2			sp->	retpc
	sp->	retpc */
/*	Generate code to adjust the possibly stacked arguments immediately
	before jumping to a method looked up by a perform primitive. */

	/* StackToRegisterMappingCogit>>#adjustArgumentsForPerform: */
static void NoDbgRegParms
adjustArgumentsForPerform(sqInt numArgs)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    sqInt index;

	assert((numRegArgs()) <= 2);
	assert(numArgs >= 1);
	if (numArgs <= 2) {
		if (numArgs == 2) {
			/* begin MoveR:R: */
			genoperandoperand(MoveRR, Arg1Reg, Arg0Reg);
		}
		return;
	}
	if ((2 + 1) == numArgs) {
		/* begin PopR: */
		genoperand(PopR, Arg1Reg);

		/* begin PopR: */
		genoperand(PopR, Arg0Reg);

		return;
	}
	for (index = (numArgs - 2); index >= 0; index += -1) {
		/* begin MoveMw:r:R: */
		anInstruction2 = genoperandoperandoperand(MoveMwrR, index * BytesPerWord, SPReg, TempReg);
		/* begin MoveR:Mw:r: */
		anInstruction3 = genoperandoperandoperand(MoveRMwr, TempReg, (index + 1) * BytesPerWord, SPReg);
	}
	/* begin PopR: */
	genoperand(PopR, TempReg);
	/* begin MoveR:Mw:r: */
	anInstruction4 = genoperandoperandoperand(MoveRMwr, TempReg, 0, SPReg);
}


/*	If the stack entry is already in a register not conflicting with regMask,
	answers it,
	else allocate a new register not conflicting with reg mask
 */

	/* StackToRegisterMappingCogit>>#allocateRegForStackEntryAt:notConflictingWith: */
static sqInt NoDbgRegParms
allocateRegForStackEntryAtnotConflictingWith(sqInt index, sqInt regMask)
{
    CogSimStackEntry *stackEntry;

	stackEntry = ssValue(index);
	if ((((stackEntry->type)) == SSRegister)
	 && (!(registerisInMask((stackEntry->registerr), regMask)))) {
		return (stackEntry->registerr);
	}
	return allocateRegNotConflictingWith(regMask);
}


/*	if there's a free register, use it */

	/* StackToRegisterMappingCogit>>#allocateRegNotConflictingWith: */
static sqInt NoDbgRegParms
allocateRegNotConflictingWith(sqInt regMask)
{
    sqInt reg;

	reg = availableRegisterOrNoneFor(backEnd, (liveRegisters()) | regMask);
	if (reg == NoReg) {

		/* No free register, choose one that does not conflict with regMask */
		reg = freeAnyRegNotConflictingWith(regMask);
	}
	if (reg == ReceiverResultReg) {

		/* If we've allocated RcvrResultReg, it's not live anymore */
		(optStatus.isReceiverResultRegLive = 0);
	}
	return reg;
}

	/* StackToRegisterMappingCogit>>#annotateBytecodeIfAnnotated: */
static void NoDbgRegParms
annotateBytecodeIfAnnotated(CogSimStackEntry *aSimStackEntry)
{
    AbstractInstruction *abstractInstruction;

	if ((aSimStackEntry->annotateUse)) {
		/* begin annotateBytecode: */
		if (prevInstIsPCAnnotated()) {
			/* begin Nop */
			abstractInstruction = gen(Nop);
		}
		else {
			/* begin Label */
			abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
		(abstractInstruction->annotation = HasBytecodePC);
		(aSimStackEntry->annotateUse = 0);
	}
}

	/* StackToRegisterMappingCogit>>#anyReferencesToRegister:inTopNItems: */
static sqInt NoDbgRegParms
anyReferencesToRegisterinTopNItems(sqInt reg, sqInt n)
{
    sqInt i;
    sqInt regMask;

	regMask = registerMaskFor(reg);
	for (i = simStackPtr; i >= ((simStackPtr - n) + 1); i += -1) {
		if ((registerMask(simStackAt(i))) & regMask) {
			return 1;
		}
	}
	return 0;
}


/*	This is a static version of ceCallCogCodePopReceiverArg0Regs
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* StackToRegisterMappingCogit>>#callCogCodePopReceiverArg0Regs */
void
callCogCodePopReceiverArg0Regs(void)
{
	realCECallCogCodePopReceiverArg0Regs();
}


/*	This is a static version of ceCallCogCodePopReceiverArg1Arg0Regs
	for break-pointing when debugging in C. */
/*	This exists only for break-pointing. */

	/* StackToRegisterMappingCogit>>#callCogCodePopReceiverArg1Arg0Regs */
void
callCogCodePopReceiverArg1Arg0Regs(void)
{
	realCECallCogCodePopReceiverArg1Arg0Regs();
}


/*	Loop over bytecodes, dispatching to the generator for each bytecode,
	handling fixups in due course.
 */

	/* StackToRegisterMappingCogit>>#compileAbstractInstructionsFrom:through: */
static sqInt NoDbgRegParms
compileAbstractInstructionsFromthrough(sqInt start, sqInt end)
{
    AbstractInstruction *abstractInstruction;
    sqInt debugBytecodePointers;
    BytecodeDescriptor *descriptor;
    BytecodeFixup *fixup;
    sqInt generateBranchAround;
    sqInt nExts;
    sqInt nextOpcodeIndex;
    sqInt result;

	traceSimStack();
	bytecodePC = start;
	nExts = 0;
	descriptor = null;
	deadCode = 0;
	while (1) {
		
		/* If there's no fixup following a return there's no jump to that code and it is dead. */
		fixup = fixupAt(bytecodePC - initialPC);
		if ((descriptor != null)
		 && ((descriptor->isReturn))) {
			deadCode = 1;
		}
		if ((((usqInt)((fixup->targetInstruction)))) > 0) {
			if ((((usqInt)((fixup->targetInstruction)))) >= 2) {
				mergeafterContinuation(fixup, !deadCode);
			}
			deadCode = 0;
		}
		byte0 = (fetchByteofObject(bytecodePC, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		loadSubsequentBytesForDescriptorat(descriptor, bytecodePC);
		nextOpcodeIndex = opcodeIndex;
		if (deadCode) {

			/* insert nops for dead code that is mapped so that bc to mc mapping is not many to one */
			if (((descriptor->isMapped))
			 || (inBlock
			 && ((descriptor->isMappedInBlock)))) {
				/* begin annotateBytecode: */
				abstractInstruction = gen(Nop);
				(abstractInstruction->annotation = HasBytecodePC);
			}
			result = 0;
		}
		else {
			result = ((descriptor->generator))();
		}
		if (!((descriptor->isExtension))) {

			/* extended bytecodes must consume their extensions */
			assert((extA == 0)
			 && (extB == 0));
		}
		traceDescriptor(descriptor);
		traceSimStack();
		if ((((((usqInt)((fixup->targetInstruction)))) >= 1) && ((((usqInt)((fixup->targetInstruction)))) <= 2))) {

			/* There is a fixup for this bytecode.  It must point to the first generated
			   instruction for this bytecode.  If there isn't one we need to add a label. */
			if (opcodeIndex == nextOpcodeIndex) {
				/* begin Label */
				genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
			(fixup->targetInstruction = abstractInstructionAt(nextOpcodeIndex));
		}
		/* begin maybeDumpLiterals: */
		if ((isUnconditionalBranch(descriptor))
		 || ((descriptor->isReturn))) {
			/* begin dumpLiterals: */
			generateBranchAround = !((isUnconditionalBranch(descriptor))
 || ((descriptor->isReturn)));
		}
		bytecodePC = (bytecodePC + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, bytecodePC, nExts, methodObj)
	: 0));
		if (!((result == 0)
		 && (bytecodePC <= end))) break;
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
	}
	/* begin checkEnoughOpcodes */
	if (opcodeIndex > numAbstractOpcodes) {
		error("Cog JIT internal error. Too many abstract opcodes.  Num opcodes heuristic is too optimistic.");
	}
	return result;
}

	/* StackToRegisterMappingCogit>>#compileBlockBodies */
static sqInt
compileBlockBodies(void)
{
    BlockStart *blockStart;
    sqInt compiledBlocksCount;
    sqInt i;
    sqInt initialIndexOfIRC;
    sqInt initialOpcodeIndex;
    sqInt initialStackPtr;
    sqInt result;
    sqInt savedNeedsFrame;
    sqInt savedNumArgs;
    sqInt savedNumTemps;

	initialIndexOfIRC = 0;
	assert(blockCount > 0);
	savedNeedsFrame = needsFrame;
	savedNumArgs = methodOrBlockNumArgs;
	savedNumTemps = methodOrBlockNumTemps;
	inBlock = 1;
	compiledBlocksCount = 0;
	while (compiledBlocksCount < blockCount) {
		blockStart = blockStartAt(compiledBlocksCount);
		scanBlock(blockStart);
		initialOpcodeIndex = opcodeIndex;
		/* begin saveForBlockCompile */
		
#    if NewspeakVM
		initialIndexOfIRC = indexOfIRC;

#    endif /* NewspeakVM */

		while (1) {
			compileBlockEntry(blockStart);
			initialStackPtr = simStackPtr;
			if (((result = compileAbstractInstructionsFromthrough(((blockStart->startpc)) + (pushNilSizenumInitialNils(methodObj, (blockStart->numInitialNils))), (((blockStart->startpc)) + ((blockStart->span))) - 1))) < 0) {
				return result;
			}
			if (initialStackPtr == simStackPtr) break;
			assert(initialStackPtr > simStackPtr);
			(blockStart->numInitialNils = (((blockStart->numInitialNils)) + simStackPtr) - initialStackPtr);
			(((blockStart->fakeHeader))->dependent = null);
			reinitializeFixupsFromthrough(((blockStart->startpc)) + ((blockStart->numInitialNils)), (((blockStart->startpc)) + ((blockStart->span))) - 1);
			bzero(abstractOpcodes + initialOpcodeIndex,
									(opcodeIndex - initialOpcodeIndex) * sizeof(AbstractInstruction));
			opcodeIndex = initialOpcodeIndex;
			/* begin resetForBlockCompile */
			
#      if NewspeakVM
			indexOfIRC = initialIndexOfIRC;

#      endif /* NewspeakVM */

		}
		compiledBlocksCount += 1;
	}
	needsFrame = savedNeedsFrame;
	methodOrBlockNumArgs = savedNumArgs;
	methodOrBlockNumTemps = savedNumTemps;
	return 0;
}


/*	Build a frame for a block activation. See CoInterpreter
	class>>initializeFrameIndices. closure (in ReceiverResultReg)
	arg0
	...
	argN
	caller's saved ip/this stackPage (for a base frame)
	fp->	saved fp
	method
	context (uninitialized?)
	receiver
	first temp
	...
	sp->	Nth temp
	Avoid use of SendNumArgsReg which is the flag determining whether
	context switch is allowed on stack-overflow. */
/*	Build a frame for a block activation. See CoInterpreter
	class>>initializeFrameIndices. Override to push the register receiver and
	register arguments, if any, and to correctly
	initialize the explicitly nilled/pushed temp entries (they are /not/ of
	type constant nil). */

	/* StackToRegisterMappingCogit>>#compileBlockFrameBuild: */
static void NoDbgRegParms
compileBlockFrameBuild(BlockStart *blockStart)
{
    AbstractInstruction *abstractInstruction;
    sqInt address;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction * cascade0;
    sqInt constant;
    sqInt i;
    sqInt ign;

	/* begin annotateBytecode: */
	abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	(abstractInstruction->annotation = HasBytecodePC);
	/* begin PushR: */
	genoperand(PushR, LinkReg);

	/* begin PushR: */
	genoperand(PushR, FPReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SPReg, FPReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, ReceiverResultReg, ClassReg);
	cascade0 = (blockStart->fakeHeader);
	addDependent(cascade0, annotateAbsolutePCRef(gPushCw(((sqInt)((blockStart->fakeHeader))))));
	setLabelOffset(cascade0, MFMethodFlagIsBlockFlag);
	annotateobjRef(gPushCw(nilObject()), nilObject());
	if ((blockStart->hasInstVarRef)) {

		/* Use ReceiverResultReg for Context to agree with store check trampoline */
		genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ClassReg, ReceiverResultReg);
		genLoadSlotsourceRegdestReg(ReceiverIndex, ReceiverResultReg, Arg0Reg);
		genEnsureOopInRegNotForwardedscratchRegupdatingSlotin(Arg0Reg, TempReg, ReceiverIndex, ReceiverResultReg);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, Arg0Reg, ReceiverResultReg);
	}
	else {
		genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ClassReg, Arg0Reg);
		genLoadSlotsourceRegdestReg(ReceiverIndex, Arg0Reg, ReceiverResultReg);
	}
	/* begin PushR: */
	genoperand(PushR, ReceiverResultReg);
	for (i = 0; i < ((blockStart->numCopied)); i += 1) {
		genLoadSlotsourceRegdestReg(i + ClosureFirstCopiedValueIndex, ClassReg, TempReg);
		/* begin PushR: */
		genoperand(PushR, TempReg);
	}
	/* begin MoveAw:R: */
	address = stackLimitAddress();
	/* begin gen:literal:operand: */
	anInstruction1 = genoperandoperand(MoveAwR, address, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, SPReg);
	/* begin JumpBelow: */
	genConditionalBranchoperand(JumpBelow, ((sqInt)stackOverflowCall));
	(blockStart->stackCheckLabel = annotateBytecode(gLabel()));
	methodOrBlockNumTemps = (((blockStart->numArgs)) + ((blockStart->numCopied))) + ((blockStart->numInitialNils));
	initSimStackForFramefulMethod((blockStart->startpc));
	if (((blockStart->numInitialNils)) > 0) {
		if (((blockStart->numInitialNils)) > 1) {
			/* begin genMoveConstant:R: */
			constant = nilObject();
			if (shouldAnnotateObjectReference(constant)) {
				annotateobjRef(gMoveCwR(constant, TempReg), constant);
			}
			else {
				/* begin MoveCq:R: */
				anInstruction = genoperandoperand(MoveCqR, constant, TempReg);
			}
			for (ign = 1; ign <= ((blockStart->numInitialNils)); ign += 1) {
				/* begin PushR: */
				genoperand(PushR, TempReg);
			}
		}
		else {
			annotateobjRef(gPushCw(nilObject()), nilObject());
		}
		methodOrBlockNumTemps = ((blockStart->numArgs)) + ((blockStart->numCopied));
	}
}


/*	Make sure ReceiverResultReg holds the receiver, loaded from the closure,
	which is what is initially in ReceiverResultReg. We must annotate the
	first instruction so that findMethodForStartBcpc:inHomeMethod: can
	function. We need two annotations because the first is a fiducial. */
/*	Make sure ReceiverResultReg holds the receiver, loaded from
	the closure, which is what is initially in ReceiverResultReg */

	/* StackToRegisterMappingCogit>>#compileBlockFramelessEntry: */
static void NoDbgRegParms
compileBlockFramelessEntry(BlockStart *blockStart)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;

	methodOrBlockNumTemps = (((blockStart->numArgs)) + ((blockStart->numCopied))) + ((blockStart->numInitialNils));
	initSimStackForFramelessBlock((blockStart->startpc));
	/* begin annotateBytecode: */
	abstractInstruction = (blockStart->entryLabel);
	(abstractInstruction->annotation = HasBytecodePC);
	/* begin annotateBytecode: */
	abstractInstruction1 = (blockStart->entryLabel);
	(abstractInstruction1->annotation = HasBytecodePC);
	genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ReceiverResultReg, TempReg);
	genLoadSlotsourceRegdestReg(ReceiverIndex, TempReg, ReceiverResultReg);
}

	/* StackToRegisterMappingCogit>>#compileCogMethod: */
static CogMethod * NoDbgRegParms
compileCogMethod(sqInt selector)
{
    sqInt allocSize;
    sqInt debugStackPointers;
    sqInt extra;
    sqInt fixupSize;
    sqInt numBlocks;
    sqInt numBytecodes;
    sqInt numCleanBlocks;
    sqInt opcodeSize;
    sqInt result;

	methodOrBlockNumTemps = tempCountOf(methodObj);
	hasYoungReferent = (isYoungObject(methodObj))
	 || (isYoung(selector));
	methodOrBlockNumArgs = argumentCountOf(methodObj);
	inBlock = 0;
	postCompileHook = null;
	maxLitIndex = -1;
	extra = ((((primitiveIndex = primitiveIndexOf(methodObj))) > 0)
	 && (!(isQuickPrimitiveIndex(primitiveIndex)))
		? 30
		: 10);

	/* initial estimate.  Actual endPC is determined in scanMethod. */
	initialPC = startPCOfMethod(methodObj);
	endPC = (isQuickPrimitiveIndex(primitiveIndex)
		? initialPC - 1
		: numBytesOf(methodObj));
	numBytecodes = (endPC - initialPC) + 1;
	/* begin allocateOpcodes:bytecodes:ifFail: */
	numAbstractOpcodes = (numBytecodes + extra) * 10;
	opcodeSize = (sizeof(CogAbstractInstruction)) * numAbstractOpcodes;
	fixupSize = (sizeof(CogBytecodeFixup)) * numAbstractOpcodes;
	allocSize = opcodeSize + fixupSize;
	if (allocSize > MaxStackAllocSize) {
		return ((CogMethod *) MethodTooBig);

		goto l1;
	}
	abstractOpcodes = alloca(allocSize);
	bzero(abstractOpcodes, allocSize);
	fixups = ((void *)((((usqInt)abstractOpcodes)) + opcodeSize));
	zeroOpcodeIndex();
	labelCounter = 0;
l1:	/* end allocateOpcodes:bytecodes:ifFail: */;
	if (((numBlocks = scanMethod())) < 0) {
		return ((CogMethod *) numBlocks);
	}
	numCleanBlocks = scanForCleanBlocks();
	allocateBlockStarts(numBlocks + numCleanBlocks);
	blockCount = 0;
	if (numCleanBlocks > 0) {
		addCleanBlockStarts();
	}
	if (!(maybeAllocAndInitIRCs())) {

		/* Inaccurate error code, but it'll do.  This will likely never fail. */
		return ((CogMethod *) InsufficientCodeSpace);
	}
	blockEntryLabel = null;
	(methodLabel->dependent = null);
	if (((result = compileEntireMethod())) < 0) {
		return ((CogMethod *) result);
	}
	return generateCogMethod(selector);
}


/*	Compile the abstract instructions for the entire method, including blocks. */
/*	Compile the abstract instructions for the entire method, including blocks. */

	/* StackToRegisterMappingCogit>>#compileEntireMethod */
static sqInt
compileEntireMethod(void)
{
    sqInt result;

	regArgsHaveBeenPushed = 0;
	compileAbort();
	compileEntry();
	if (((result = compilePrimitive())) < 0) {
		return result;
	}
	compileFrameBuild();
	if (((result = compileMethodBody())) < 0) {
		return result;
	}
	if (blockCount == 0) {
		return 0;
	}
	if (((result = compileBlockBodies())) < 0) {
		return result;
	}
	return compileBlockDispatch();
}


/*	Build a frame for a CogMethod activation. See CoInterpreter
	class>>initializeFrameIndices. receiver (in ReceiverResultReg)
	arg0
	...
	argN
	caller's saved ip/this stackPage (for a base frame)
	fp->	saved fp
	method
	context (uninitialized?)
	receiver
	first temp
	...
	sp->	Nth temp
	If there is a primitive and an error code the Nth temp is the error code.
	Ensure SendNumArgsReg is set early on (incidentally to nilObj) because
	it is the flag determining whether context switch is allowed on
	stack-overflow.  */
/*	Build a frame for a CogMethod activation. See CoInterpreter
	class>>initializeFrameIndices. Override to push the register receiver and
	register arguments, if any. */

	/* StackToRegisterMappingCogit>>#compileFrameBuild */
static void
compileFrameBuild(void)
{
    sqInt address;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    sqInt constant;
    sqInt i;
    sqInt iLimiT;
    AbstractInstruction *jumpSkip;

	if (!needsFrame) {
		initSimStackForFramelessMethod(initialPC);
		return;
	}
	genPushRegisterArgs();
	if (!needsFrame) {
		return;
	}
	/* begin PushR: */
	genoperand(PushR, LinkReg);

	/* begin PushR: */
	genoperand(PushR, FPReg);
	/* begin MoveR:R: */
	genoperandoperand(MoveRR, SPReg, FPReg);
	addDependent(methodLabel, annotateAbsolutePCRef(gPushCw(((sqInt)methodLabel))));
	/* begin genMoveConstant:R: */
	constant = nilObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, SendNumArgsReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, constant, SendNumArgsReg);
	}
	/* begin PushR: */
	genoperand(PushR, SendNumArgsReg);
	/* begin PushR: */
	genoperand(PushR, ReceiverResultReg);
	for (i = (methodOrBlockNumArgs + 1), iLimiT = (temporaryCountOfMethodHeader(methodHeader)); i <= iLimiT; i += 1) {
		/* begin PushR: */
		genoperand(PushR, SendNumArgsReg);
	}
	if (((primitiveIndexOfMethodheader(methodObj, methodHeader)) > 0)
	 && ((longStoreBytecodeForHeader(methodHeader)) == (fetchByteofObject(initialPC + (sizeOfCallPrimitiveBytecode(methodHeader)), methodObj)))) {
		compileGetErrorCode();
	}
	/* begin MoveAw:R: */
	address = stackLimitAddress();
	/* begin gen:literal:operand: */
	anInstruction3 = genoperandoperand(MoveAwR, address, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, SPReg);
	if (canContextSwitchIfActivatingheader(methodObj, methodHeader)) {
		/* begin JumpBelow: */
		genConditionalBranchoperand(JumpBelow, ((sqInt)stackOverflowCall));
		/* begin Label */
		stackCheckLabel = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	}
	else {
		/* begin JumpAboveOrEqual: */
		jumpSkip = genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)0));
		/* begin MoveCq:R: */
		anInstruction1 = genoperandoperand(MoveCqR, 0, SendNumArgsReg);
		/* begin Jump: */
		genoperand(Jump, ((sqInt)stackOverflowCall));
		jmpTarget(jumpSkip, (stackCheckLabel = gLabel()));
	}
	/* begin annotateBytecode: */
	(stackCheckLabel->annotation = HasBytecodePC);
	
#  if NewspeakVM
	if (numIRCs > 0) {
		/* begin PrefetchAw: */
		anInstruction2 = genoperand(PrefetchAw, theIRCs);
	}

#  endif /* NewspeakVM */

	initSimStackForFramefulMethod(initialPC);
}

	/* StackToRegisterMappingCogit>>#cPICMissTrampolineFor: */
static sqInt NoDbgRegParms
cPICMissTrampolineFor(sqInt numArgs)
{
	return picMissTrampolines[((numArgs < (2 + 1)) ? numArgs : (2 + 1))];
}


/*	Replaces the Blue Book double-extended send [132], in which the first byte
	was wasted on 8 bits of argument count. 
	Here we use 3 bits for the operation sub-type (opType), and the remaining
	5 bits for argument count where needed. 
	The last byte give access to 256 instVars or literals. 
	See also secondExtendedSendBytecode
 */

	/* StackToRegisterMappingCogit>>#doubleExtendedDoAnythingBytecode */
static sqInt
doubleExtendedDoAnythingBytecode(void)
{
    AbstractInstruction *abstractInstruction;
    sqInt opType;

	opType = ((usqInt) byte1) >> 5;
	if (opType == 0) {
		return genSendnumArgs(byte2, byte1 & 0x1F);
	}
	if (opType == 1) {
		return genSendSupernumArgs(byte2, byte1 & 0x1F);
	}
	
	switch (opType) {
	case 2:
		if (isReadMediatedContextInstVarIndex(byte2)) {
			genPushMaybeContextReceiverVariable(byte2);
		}
		else {
			genPushReceiverVariable(byte2);
			((ssTop())->annotateUse = 1);
			return 0;
		}
		break;
	case 3:
		genPushLiteralIndex(byte2);
		((ssTop())->annotateUse = 1);
		return 0;

	case 4:
		genPushLiteralVariable(byte2);
		break;
	case 7:
		genStorePopLiteralVariable(0, byte2);
		
#    if IMMUTABILITY

		/* genStorePop:LiteralVariable: annotates; don't annotate twice */
		return 0;

#    endif /* IMMUTABILITY */

		break;
	default:
		
		/* 5 & 6 */
		if (isWriteMediatedContextInstVarIndex(byte2)) {
			genStorePopMaybeContextReceiverVariable(opType == 6, byte2);
		}
		else {
			genStorePopReceiverVariable(opType == 6, byte2);
		}
		
#    if IMMUTABILITY

		/* genStorePop:LiteralVariable: annotates; don't annotate twice */
		return 0;

#    endif /* IMMUTABILITY */

;
	}
	assert(needsFrame);
	assert(!(prevInstIsPCAnnotated()));
	/* begin annotateBytecode: */
	abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	(abstractInstruction->annotation = HasBytecodePC);
	return 0;
}

	/* StackToRegisterMappingCogit>>#duplicateTopBytecode */
static sqInt
duplicateTopBytecode(void)
{
    CogSimStackEntry desc;

	desc = ssTopDescriptor();
	return ssPushDesc(desc);
}


/*	Make sure there's a flagged fixup at the targetIndex (pc relative to first
	pc) in fixups.
	Initially a fixup's target is just a flag. Later on it is replaced with a
	proper instruction. */

	/* StackToRegisterMappingCogit>>#ensureFixupAt: */
static BytecodeFixup * NoDbgRegParms
ensureFixupAt(sqInt targetIndex)
{
    BytecodeFixup *fixup;

	fixup = fixupAt(targetIndex);
	traceFixup(fixup);
	if ((((usqInt)((fixup->targetInstruction)))) <= 1) {

		/* convert a non-merge into a merge */
		(fixup->targetInstruction = ((AbstractInstruction *) 2));
		(fixup->simStackPtr = simStackPtr);
	}
	else {
		if (((fixup->simStackPtr)) <= -2) {

			/* this is the target of a backward branch and
			   so doesn't have a simStackPtr assigned yet. */
			(fixup->simStackPtr = simStackPtr);
		}
		else {
			assert(((fixup->simStackPtr)) == simStackPtr);
		}
	}
	return fixup;
}


/*	Make sure there's a flagged fixup at the targetIndex (pc relative to first
	pc) in fixups.
	Initially a fixup's target is just a flag. Later on it is replaced with a
	proper instruction. */

	/* StackToRegisterMappingCogit>>#ensureNonMergeFixupAt: */
static BytecodeFixup * NoDbgRegParms
ensureNonMergeFixupAt(sqInt targetIndex)
{
    BytecodeFixup *fixup;

	fixup = fixupAt(targetIndex);
	if (((fixup->targetInstruction)) == 0) {
		(fixup->targetInstruction = ((AbstractInstruction *) 1));
	}
	return fixup;
}

	/* StackToRegisterMappingCogit>>#ensureReceiverResultRegContainsSelf */
static void
ensureReceiverResultRegContainsSelf(void)
{
	if (needsFrame) {
		if (!((optStatus.isReceiverResultRegLive))) {
			ssAllocateRequiredReg(ReceiverResultReg);
			/* begin putSelfInReceiverResultReg */
			storeToReg((&simSelf), ReceiverResultReg);
		}
		(optStatus.isReceiverResultRegLive = 1);
	}
	else {
		assert((((simSelf.type)) == SSRegister)
		 && (((simSelf.registerr)) == ReceiverResultReg));
		assert(((optStatus.isReceiverResultRegLive))
		 && (((optStatus.ssEntry)) == ((&simSelf))));
	}
}

	/* StackToRegisterMappingCogit>>#evaluate:at: */
static void NoDbgRegParms
evaluateat(BytecodeDescriptor *descriptor, sqInt pc)
{
	byte0 = fetchByteofObject(pc, methodObj);
	assert(descriptor == (generatorAt(bytecodeSetOffset + byte0)));
	loadSubsequentBytesForDescriptorat(descriptor, pc);
	((descriptor->generator))();
}


/*	Spill the closest register on stack not conflicting with regMask. 
	Assertion Failure if regMask has already all the registers */

	/* StackToRegisterMappingCogit>>#freeAnyRegNotConflictingWith: */
static sqInt NoDbgRegParms
freeAnyRegNotConflictingWith(sqInt regMask)
{
    CogSimStackEntry *desc;
    sqInt index;
    sqInt reg;

	assert(needsFrame);
	reg = NoReg;
	index = ((simSpillBase < 0) ? 0 : simSpillBase);
	while ((reg == NoReg)
	 && (index < simStackPtr)) {
		desc = simStackAt(index);
		if (((desc->type)) == SSRegister) {
			if (!(regMask & (registerMaskFor((desc->registerr))))) {
				reg = (desc->registerr);
			}
		}
		index += 1;
	}
	assert(!((reg == NoReg)));
	ssAllocateRequiredReg(reg);
	return reg;
}


/*	Generate special versions of the ceCallCogCodePopReceiverAndClassRegs
	enilopmart that also pop register args from the stack to undo the pushing
	of register args in the abort/miss trampolines. */

	/* StackToRegisterMappingCogit>>#genCallPICEnilopmartNumArgs: */
static void (*genCallPICEnilopmartNumArgs(sqInt numArgs))(void)

{
    AbstractInstruction *anInstruction;
    sqInt endAddress;
    sqInt enilopmart;
    sqInt quickConstant;
    sqInt reg;
    sqInt size;

	zeroOpcodeIndex();
	/* begin MoveCq:R: */
	quickConstant = varBaseAddress();
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(MoveCqR, quickConstant, VarBaseReg);

	genLoadStackPointers(backEnd);
	/* begin PopR: */
	genoperand(PopR, ClassReg);
	/* begin PopR: */
	genoperand(PopR, TempReg);
	/* begin PopR: */
	reg = LinkReg;
	genoperand(PopR, reg);
	if (numArgs > 0) {
		if (numArgs > 1) {
			/* begin PopR: */
			genoperand(PopR, Arg1Reg);
			assert((numRegArgs()) == 2);
		}
		/* begin PopR: */
		genoperand(PopR, Arg0Reg);
	}
	/* begin PopR: */
	genoperand(PopR, ReceiverResultReg);
	/* begin JumpR: */
	genoperand(JumpR, TempReg);
	computeMaximumSizes();
	size = generateInstructionsAt(methodZoneBase);
	endAddress = outputInstructionsAt(methodZoneBase);
	assert((methodZoneBase + size) == endAddress);
	enilopmart = methodZoneBase;
	methodZoneBase = alignUptoRoutineBoundary(endAddress);
	stopsFromto(backEnd, endAddress, methodZoneBase - 1);
	recordGeneratedRunTimeaddress(trampolineNamenumRegArgs("ceCallPIC", numArgs), enilopmart);
	return ((void (*)(void)) enilopmart);
}


/*	SistaV1: 248		11111000 iiiiiiii		mjjjjjjj		Call Primitive #iiiiiiii +
	(jjjjjjj * 256) m=1 means inlined primitive, no hard return after
	execution. See EncoderForSistaV1's class comment and
	StackInterpreter>>#inlinePrimitiveBytecode: 
 */

	/* StackToRegisterMappingCogit>>#genCallPrimitiveBytecode */
static sqInt
genCallPrimitiveBytecode(void)
{
    sqInt prim;

	if (byte2 < 128) {
		return (bytecodePC == initialPC
			? 0
			: EncounteredUnknownBytecode);
	}
	prim = ((byte2 - 128) << 8) + byte1;
	return EncounteredUnknownBytecode;
}


/*	Generates the machine code for #== in the case where the instruction is
	not followed by a branch
 */

	/* StackToRegisterMappingCogit>>#genEqualsEqualsNoBranchArgIsConstant:rcvrIsConstant:argReg:rcvrReg: */
static sqInt NoDbgRegParms
genEqualsEqualsNoBranchArgIsConstantrcvrIsConstantargRegrcvrReg(sqInt argIsConstant, sqInt rcvrIsConstant, sqInt argReg, sqInt rcvrRegOrNone)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    sqInt constant;
    sqInt constant1;
    sqInt constant2;
    AbstractInstruction *jumpEqual;
    AbstractInstruction *jumpNotEqual;
    AbstractInstruction *label;
    sqInt resultReg;

	/* begin Label */
	label = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin genEqualsEqualsComparisonArgIsConstant:rcvrIsConstant:argReg:rcvrReg: */
	if (argIsConstant) {
		/* begin genCompConstant:R: */
		constant1 = ((ssTop())->constant);
		if (shouldAnnotateObjectReference(constant1)) {
			annotateobjRef(gCmpCwR(constant1, rcvrRegOrNone), constant1);
		}
		else {
			/* begin CmpCq:R: */
			anInstruction = genoperandoperand(CmpCqR, constant1, rcvrRegOrNone);
		}
	}
	else {
		if (rcvrIsConstant) {
			/* begin genCompConstant:R: */
			constant2 = ((ssValue(1))->constant);
			if (shouldAnnotateObjectReference(constant2)) {
				annotateobjRef(gCmpCwR(constant2, argReg), constant2);
			}
			else {
				/* begin CmpCq:R: */
				anInstruction1 = genoperandoperand(CmpCqR, constant2, argReg);
			}
		}
		else {
			/* begin CmpR:R: */
			genoperandoperand(CmpRR, argReg, rcvrRegOrNone);
		}
	}
	ssPop(2);
	resultReg = (rcvrRegOrNone == NoReg
		? argReg
		: rcvrRegOrNone);
	/* begin JumpZero: */
	jumpEqual = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	if (!argIsConstant) {
		genEnsureOopInRegNotForwardedscratchRegjumpBackTo(argReg, TempReg, label);
	}
	if (!rcvrIsConstant) {
		genEnsureOopInRegNotForwardedscratchRegjumpBackTo(rcvrRegOrNone, TempReg, label);
	}
	/* begin genMoveFalseR: */
	constant = falseObject();
	if (shouldAnnotateObjectReference(constant)) {
		annotateobjRef(gMoveCwR(constant, resultReg), constant);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction2 = genoperandoperand(MoveCqR, constant, resultReg);
	}
	/* begin Jump: */
	jumpNotEqual = genoperand(Jump, ((sqInt)0));
	jmpTarget(jumpEqual, genMoveTrueR(resultReg));
	jmpTarget(jumpNotEqual, gLabel());
	ssPushRegister(resultReg);
	return 0;
}


/*	Override to push the register receiver and register arguments, if any. */

	/* StackToRegisterMappingCogit>>#genExternalizePointersForPrimitiveCall */
static sqInt
genExternalizePointersForPrimitiveCall(void)
{
    sqInt address;
    sqInt address1;
    sqInt address2;
    sqInt address3;
    sqInt address4;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;

	genPushRegisterArgs();
	/* begin MoveR:Aw: */
	address4 = framePointerAddress();
	/* begin gen:operand:literal: */
	anInstruction4 = genoperandoperand(MoveRAw, FPReg, address4);
	
	/* Set coInterpreter stackPointer to the topmost argument, skipping the return address. */
	/* begin MoveR:Aw: */
	address = stackPointerAddress();
	/* begin gen:operand:literal: */
	anInstruction = genoperandoperand(MoveRAw, SPReg, address);
	/* begin MoveR:Aw: */
	address1 = instructionPointerAddress();
	/* begin gen:operand:literal: */
	anInstruction1 = genoperandoperand(MoveRAw, LinkReg, address1);

	return 0;
}


/*	Enilopmarts transfer control from C into machine code (backwards
	trampolines). 
 */
/*	Enilopmarts transfer control from C into machine code (backwards
	trampolines). Override to add version for generic and PIC-specific entry
	with reg args. */

	/* StackToRegisterMappingCogit>>#generateEnilopmarts */
static void
generateEnilopmarts(void)
{
	
#  if Debug
	/* begin genEnilopmartFor:forCall:called: */
	realCEEnterCogCodePopReceiverReg = genEnilopmartForandandforCallcalled(ReceiverResultReg, NoReg, NoReg, 0, "realCEEnterCogCodePopReceiverReg");
	ceEnterCogCodePopReceiverReg = enterCogCodePopReceiver;
	/* begin genEnilopmartFor:forCall:called: */
	realCECallCogCodePopReceiverReg = genEnilopmartForandandforCallcalled(ReceiverResultReg, NoReg, NoReg, 1, "realCEEnterCogCodePopReceiverReg");
	ceCallCogCodePopReceiverReg = callCogCodePopReceiver;
	/* begin genEnilopmartFor:and:forCall:called: */
	realCECallCogCodePopReceiverAndClassRegs = genEnilopmartForandandforCallcalled(ReceiverResultReg, ClassReg, NoReg, 1, "realCECallCogCodePopReceiverAndClassRegs");
	ceCallCogCodePopReceiverAndClassRegs = callCogCodePopReceiverAndClassRegs;

#  else /* Debug */
	/* begin genEnilopmartFor:forCall:called: */
	ceEnterCogCodePopReceiverReg = genEnilopmartForandandforCallcalled(ReceiverResultReg, NoReg, NoReg, 0, "ceEnterCogCodePopReceiverReg");
	/* begin genEnilopmartFor:forCall:called: */
	ceCallCogCodePopReceiverReg = genEnilopmartForandandforCallcalled(ReceiverResultReg, NoReg, NoReg, 1, "ceCallCogCodePopReceiverReg");
	/* begin genEnilopmartFor:and:forCall:called: */
	ceCallCogCodePopReceiverAndClassRegs = genEnilopmartForandandforCallcalled(ReceiverResultReg, ClassReg, NoReg, 1, "ceCallCogCodePopReceiverAndClassRegs");

#  endif /* Debug */

	genPrimReturnEnterCogCodeEnilopmart(0);
	cePrimReturnEnterCogCode = methodZoneBase;
	outputInstructionsForGeneratedRuntimeAt(cePrimReturnEnterCogCode);
	recordGeneratedRunTimeaddress("cePrimReturnEnterCogCode", cePrimReturnEnterCogCode);
	genPrimReturnEnterCogCodeEnilopmart(1);
	cePrimReturnEnterCogCodeProfiling = methodZoneBase;
	outputInstructionsForGeneratedRuntimeAt(cePrimReturnEnterCogCodeProfiling);
	recordGeneratedRunTimeaddress("cePrimReturnEnterCogCodeProfiling", cePrimReturnEnterCogCodeProfiling);
	
#  if Debug
	/* begin genEnilopmartFor:and:forCall:called: */
	realCECallCogCodePopReceiverArg0Regs = genEnilopmartForandandforCallcalled(ReceiverResultReg, Arg0Reg, NoReg, 1, "realCECallCogCodePopReceiverArg0Regs");
	ceCallCogCodePopReceiverArg0Regs = callCogCodePopReceiverArg0Regs;
	realCECallCogCodePopReceiverArg1Arg0Regs = genEnilopmartForandandforCallcalled(ReceiverResultReg, Arg0Reg, Arg1Reg, 1, "realCECallCogCodePopReceiverArg1Arg0Regs");
	ceCallCogCodePopReceiverArg1Arg0Regs = callCogCodePopReceiverArg1Arg0Regs;

#  else /* Debug */
	/* begin genEnilopmartFor:and:forCall:called: */
	ceCallCogCodePopReceiverArg0Regs = genEnilopmartForandandforCallcalled(ReceiverResultReg, Arg0Reg, NoReg, 1, "ceCallCogCodePopReceiverArg0Regs");
	ceCallCogCodePopReceiverArg1Arg0Regs = genEnilopmartForandandforCallcalled(ReceiverResultReg, Arg0Reg, Arg1Reg, 1, "ceCallCogCodePopReceiverArg1Arg0Regs");

#  endif /* Debug */

	ceCall0ArgsPIC = genCallPICEnilopmartNumArgs(0);
	ceCall1ArgsPIC = genCallPICEnilopmartNumArgs(1);
	ceCall2ArgsPIC = genCallPICEnilopmartNumArgs(2);
	assert((numRegArgs()) == 2);


}


/*	Generate the run-time entries for the various method and PIC entry misses
	and aborts.
	Read the class-side method trampolines for documentation on the various
	trampolines 
 */

	/* StackToRegisterMappingCogit>>#generateMissAbortTrampolines */
static void
generateMissAbortTrampolines(void)
{
    sqInt numArgs;
    sqInt numArgsLimiT;

	for (numArgs = 0, numArgsLimiT = (2 + 1); numArgs <= numArgsLimiT; numArgs += 1) {
		methodAbortTrampolines[numArgs] = (genMethodAbortTrampolineFor(numArgs));
	}
	for (numArgs = 0, numArgsLimiT = (2 + 1); numArgs <= numArgsLimiT; numArgs += 1) {
		picAbortTrampolines[numArgs] = (genPICAbortTrampolineFor(numArgs));
	}
	for (numArgs = 0, numArgsLimiT = (2 + 1); numArgs <= numArgsLimiT; numArgs += 1) {
		picMissTrampolines[numArgs] = (genPICMissTrampolineFor(numArgs));
	}
}


/*	Override to generate code to push the register arg(s) for <= numRegArg
	arity sends.
 */

	/* StackToRegisterMappingCogit>>#generateSendTrampolines */
static void
generateSendTrampolines(void)
{
    sqInt numArgs;

	for (numArgs = 0; numArgs < NumSendTrampolines; numArgs += 1) {
		ordinarySendTrampolines[numArgs] = (genSendTrampolineFornumArgscalledargargargarg(ceSendsupertonumArgs, numArgs, trampolineNamenumArgs("ceSend", numArgs), ClassReg, trampolineArgConstant(0), ReceiverResultReg, (numArgs <= (NumSendTrampolines - 2)
	? (/* begin trampolineArgConstant: */
		assert(numArgs >= 0),
		-2 - numArgs)
	: SendNumArgsReg)));
	}
	for (numArgs = 0; numArgs < NumSendTrampolines; numArgs += 1) {
		superSendTrampolines[numArgs] = (genSendTrampolineFornumArgscalledargargargarg(ceSendsupertonumArgs, numArgs, trampolineNamenumArgs("ceSuperSend", numArgs), ClassReg, trampolineArgConstant(1), ReceiverResultReg, (numArgs <= (NumSendTrampolines - 2)
	? (/* begin trampolineArgConstant: */
		assert(numArgs >= 0),
		-2 - numArgs)
	: SendNumArgsReg)));
	}
	firstSend = ordinarySendTrampolines[0];
	lastSend = superSendTrampolines[NumSendTrampolines - 1];
}


/*	Generate trampolines for tracing. In the simulator we can save a lot of
	time and avoid noise instructions in the lastNInstructions log by
	short-cutting these
	trampolines, but we need them in the real vm. */

	/* StackToRegisterMappingCogit>>#generateTracingTrampolines */
static void
generateTracingTrampolines(void)
{
	ceTraceLinkedSendTrampoline = genSafeTrampolineForcalledarg(ceTraceLinkedSend, "ceTraceLinkedSendTrampoline", ReceiverResultReg);
	ceTraceBlockActivationTrampoline = genTrampolineForcalled(ceTraceBlockActivation, "ceTraceBlockActivationTrampoline");
	ceTraceStoreTrampoline = genSafeTrampolineForcalledargarg(ceTraceStoreOfinto, "ceTraceStoreTrampoline", TempReg, ReceiverResultReg);
}

	/* StackToRegisterMappingCogit>>#genJumpBackTo: */
static sqInt NoDbgRegParms
genJumpBackTo(sqInt targetBytecodePC)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    sqInt address;
    AbstractInstruction *anInstruction;
    void *jumpTarget;
    void *jumpTarget1;

	ssFlushTo(simStackPtr);
	/* begin MoveAw:R: */
	address = stackLimitAddress();
	/* begin gen:literal:operand: */
	anInstruction = genoperandoperand(MoveAwR, address, TempReg);
	/* begin CmpR:R: */
	genoperandoperand(CmpRR, TempReg, SPReg);
	/* begin JumpAboveOrEqual: */
	jumpTarget = fixupAt(targetBytecodePC - initialPC);
	genConditionalBranchoperand(JumpAboveOrEqual, ((sqInt)jumpTarget));
	/* begin CallRT: */
	abstractInstruction1 = genoperand(Call, ceCheckForInterruptTrampoline);
	(abstractInstruction1->annotation = IsRelativeCall);
	/* begin annotateBytecode: */
	abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	(abstractInstruction->annotation = HasBytecodePC);
	/* begin Jump: */
	jumpTarget1 = fixupAt(targetBytecodePC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget1));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genJumpIf:to: */
static sqInt NoDbgRegParms
genJumpIfto(sqInt boolean, sqInt targetBytecodePC)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    AbstractInstruction *abstractInstruction2;
    AbstractInstruction *anInstruction;
    sqInt callTarget;
    CogSimStackEntry *desc;
    BytecodeFixup *fixup;
    void *jumpTarget;
    AbstractInstruction *ok;
    sqInt quickConstant;

	ssFlushTo(simStackPtr - 1);
	desc = ssTop();
	ssPop(1);
	if ((((desc->type)) == SSConstant)
	 && ((((desc->constant)) == (trueObject()))
	 || (((desc->constant)) == (falseObject())))) {

		/* Must arrange there's a fixup at the target whether it is jumped to or
		   not so that the simStackPtr can be kept correct. */

		/* Must enter any annotatedConstants into the map */
		fixup = ensureFixupAt(targetBytecodePC - initialPC);
		if ((desc->annotateUse)) {
			/* begin annotateBytecode: */
			if (prevInstIsPCAnnotated()) {
				/* begin Nop */
				abstractInstruction = gen(Nop);
			}
			else {
				/* begin Label */
				abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
			(abstractInstruction->annotation = HasBytecodePC);
		}
		/* begin annotateBytecode: */
		if (((desc->constant)) == boolean) {
			/* begin Jump: */
			abstractInstruction1 = genoperand(Jump, ((sqInt)fixup));
		}
		else {
			if (prevInstIsPCAnnotated()) {
				/* begin Nop */
				abstractInstruction1 = gen(Nop);
			}
			else {
				/* begin Label */
				abstractInstruction1 = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
		}
		(abstractInstruction1->annotation = HasBytecodePC);
		return 0;
	}
	popToReg(desc, TempReg);
	assert((objectAfter(falseObject())) == (trueObject()));
	annotateobjRef(gSubCwR(boolean, TempReg), boolean);
	/* begin JumpZero: */
	jumpTarget = ensureFixupAt(targetBytecodePC - initialPC);
	genConditionalBranchoperand(JumpZero, ((sqInt)jumpTarget));
	/* begin CmpCq:R: */
	quickConstant = (boolean == (falseObject())
		? (trueObject()) - (falseObject())
		: (falseObject()) - (trueObject()));
	/* begin gen:quickConstant:operand: */
	anInstruction = genoperandoperand(CmpCqR, quickConstant, TempReg);
	/* begin JumpZero: */
	ok = genConditionalBranchoperand(JumpZero, ((sqInt)0));
	/* begin CallRT: */
	callTarget = (boolean == (falseObject())
		? ceSendMustBeBooleanAddFalseTrampoline
		: ceSendMustBeBooleanAddTrueTrampoline);
	/* begin annotateCall: */
	abstractInstruction2 = genoperand(Call, callTarget);
	(abstractInstruction2->annotation = IsRelativeCall);
	jmpTarget(ok, annotateBytecode(gLabel()));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genJumpTo: */
static sqInt NoDbgRegParms
genJumpTo(sqInt targetBytecodePC)
{
    void *jumpTarget;

	ssFlushTo(simStackPtr);
	/* begin Jump: */
	jumpTarget = ensureFixupAt(targetBytecodePC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget));
	return 0;
}

	/* StackToRegisterMappingCogit>>#genMarshalledSend:numArgs:sendTable: */
static sqInt NoDbgRegParms
genMarshalledSendnumArgssendTable(sqInt selectorIndex, sqInt numArgs, sqInt *sendTable)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    sqInt annotation;
    sqInt tempOop;

	assert(needsFrame);
	/* begin annotationForSendTable: */
	if (sendTable == superSendTrampolines) {
		annotation = IsSuperSend;
		goto l1;
	}
	assert(sendTable == ordinarySendTrampolines);
	annotation = IsSendCall;
l1:	/* end annotationForSendTable: */;
	if ((annotation == IsSuperSend)
	 || (0)) {
		genEnsureOopInRegNotForwardedscratchReg(ReceiverResultReg, TempReg);
	}
	if (numArgs >= (NumSendTrampolines - 1)) {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, numArgs, SendNumArgsReg);
	}
	genLoadInlineCacheWithSelector(selectorIndex);
	((gCall(sendTable[((numArgs < (NumSendTrampolines - 1)) ? numArgs : (NumSendTrampolines - 1))]))->annotation = annotation);
	(optStatus.isReceiverResultRegLive = 0);
	return ssPushRegister(ReceiverResultReg);
}


/*	Generate the abort for a method. This abort performs either a call of
	ceSICMiss: to handle a single-in-line cache miss or a call of
	ceStackOverflow: to handle a
	stack overflow. It distinguishes the two by testing ResultReceiverReg. If
	the register is zero then this is a stack-overflow because a) the receiver
	has already
	been pushed and so can be set to zero before calling the abort, and b) the
	receiver must always contain an object (and hence be non-zero) on SIC
	miss.  */

	/* StackToRegisterMappingCogit>>#genMethodAbortTrampolineFor: */
static sqInt NoDbgRegParms
genMethodAbortTrampolineFor(sqInt numArgs)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *jumpSICMiss;

	zeroOpcodeIndex();
	/* begin CmpCq:R: */
	anInstruction1 = genoperandoperand(CmpCqR, 0, ReceiverResultReg);
	/* begin JumpNonZero: */
	jumpSICMiss = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	/* begin MoveR:Mw:r: */
	anInstruction = genoperandoperandoperand(MoveRMwr, LinkReg, 0, SPReg);

	compileTrampolineFornumArgsargargargargsaveRegspushLinkRegresultReg(ceStackOverflow, 1, SendNumArgsReg, null, null, null, 0, 0, NoReg);
	jmpTarget(jumpSICMiss, gLabel());
	genPushRegisterArgsForAbortMissNumArgs(backEnd, numArgs);
	return genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceSICMiss, trampolineNamenumRegArgs("ceMethodAbort", numArgs), 1, ReceiverResultReg, null, null, null, 0, 0, NoReg, 1);
}


/*	Generate the abort for a PIC. This abort performs either a call of
	ceInterpretMethodFromPIC:receiver: to handle invoking an uncogged
	target or a call of ceMNUFromPICMNUMethod:receiver: to handle an
	MNU dispatch in a closed PIC. It distinguishes the two by testing
	ClassReg. If the register is zero then this is an MNU. */

	/* StackToRegisterMappingCogit>>#genPICAbortTrampolineFor: */
static sqInt NoDbgRegParms
genPICAbortTrampolineFor(sqInt numArgs)
{
	zeroOpcodeIndex();
	genPushRegisterArgsForAbortMissNumArgs(backEnd, numArgs);
	return genInnerPICAbortTrampoline(trampolineNamenumRegArgs("cePICAbort", numArgs));
}

	/* StackToRegisterMappingCogit>>#genPICMissTrampolineFor: */
static sqInt NoDbgRegParms
genPICMissTrampolineFor(sqInt numArgs)
{
    sqInt startAddress;

	startAddress = methodZoneBase;
	zeroOpcodeIndex();
	genPushRegisterArgsForNumArgsscratchReg(backEnd, numArgs, SendNumArgsReg);
	genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(ceCPICMissreceiver, trampolineNamenumRegArgs("cePICMiss", numArgs), 2, ClassReg, ReceiverResultReg, null, null, 0, 1, NoReg, 1);
	return startAddress;
}

	/* StackToRegisterMappingCogit>>#genPopStackBytecode */
static sqInt
genPopStackBytecode(void)
{
    AbstractInstruction *anInstruction;

	annotateBytecodeIfAnnotated(ssTop());
	if (((ssTop())->spilled)) {
		/* begin AddCq:R: */
		anInstruction = genoperandoperand(AddCqR, BytesPerWord, SPReg);
	}
	ssPop(1);
	return 0;
}


/*	Check the argument count. Fail if wrong.
	Get the method from the outerContext and see if it is cogged. If so, jump
	to the
	block entry or the no-context-switch entry, as appropriate, and we're
	done. If not,
	invoke the interpreter primitive. */
/*	Check the argument count. Fail if wrong.
	Get the method from the outerContext and see if it is cogged. If so, jump
	to the
	block entry or the no-context-switch entry, as appropriate, and we're
	done. If not,
	invoke the interpreter primitive.
	Override to push the register args first. */

	/* StackToRegisterMappingCogit>>#genPrimitiveClosureValue */
static sqInt
genPrimitiveClosureValue(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *jumpBCMethod;
    AbstractInstruction *jumpFail1;
    AbstractInstruction *jumpFail2;
    AbstractInstruction *jumpFail3;
    AbstractInstruction *jumpFail4;
    AbstractInstruction *jumpFailNArgs;
    sqInt literal;
    sqInt offset;
    void (*primitiveRoutine)();
    sqInt quickConstant;
    sqInt result;

	genPushRegisterArgs();
	genLoadSlotsourceRegdestReg(ClosureNumArgsIndex, ReceiverResultReg, TempReg);
	/* begin CmpCq:R: */
	literal = ((methodOrBlockNumArgs << 1) | 1);
	anInstruction1 = genoperandoperand(CmpCqR, ((methodOrBlockNumArgs << 1) | 1), TempReg);
	/* begin JumpNonZero: */
	jumpFailNArgs = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(ClosureOuterContextIndex, ReceiverResultReg, ClassReg);
	jumpFail1 = genJumpImmediate(ClassReg);
	genGetCompactClassIndexNonImmOfinto(ClassReg, TempReg);
	genCmpClassMethodContextCompactIndexR(TempReg);
	/* begin JumpNonZero: */
	jumpFail2 = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
	genLoadSlotsourceRegdestReg(MethodIndex, ClassReg, SendNumArgsReg);
	jumpFail3 = genJumpImmediate(SendNumArgsReg);
	genGetFormatOfinto(SendNumArgsReg, TempReg);
	/* begin CmpCq:R: */
	quickConstant = firstCompiledMethodFormat();
	/* begin gen:quickConstant:operand: */
	anInstruction2 = genoperandoperand(CmpCqR, quickConstant, TempReg);
	/* begin JumpLess: */
	jumpFail4 = genConditionalBranchoperand(JumpLess, ((sqInt)0));
	genLoadSlotsourceRegdestReg(HeaderIndex, SendNumArgsReg, ClassReg);
	jumpBCMethod = genJumpImmediate(ClassReg);
	/* begin MoveM16:r:R: */
	offset = offsetof(CogMethod, blockEntryOffset);
	/* begin gen:quickConstant:operand:operand: */
	anInstruction3 = genoperandoperandoperand(MoveM16rR, offset, ClassReg, TempReg);
	/* begin AddR:R: */
	genoperandoperand(AddRR, ClassReg, TempReg);
	primitiveRoutine = functionPointerForCompiledMethodprimitiveIndex(methodObj, primitiveIndex);
	if (primitiveRoutine == primitiveClosureValueNoContextSwitch) {
		if (blockNoContextSwitchOffset == null) {
			return NotFullyInitialized;
		}
		/* begin SubCq:R: */
		anInstruction = genoperandoperand(SubCqR, blockNoContextSwitchOffset, TempReg);
	}
	/* begin JumpR: */
	genoperand(JumpR, TempReg);
	jmpTarget(jumpBCMethod, jmpTarget(jumpFail1, jmpTarget(jumpFail2, jmpTarget(jumpFail3, jmpTarget(jumpFail4, gLabel())))));
	if (((result = compileInterpreterPrimitive(primitiveRoutine))) < 0) {
		return result;
	}
	jmpTarget(jumpFailNArgs, gLabel());
	return CompletePrimitive;
}


/*	Generate an in-line perform primitive. The lookup code requires the
	selector to be in Arg0Reg.
	adjustArgumentsForPerform: adjusts the arguments once
	genLookupForPerformNumArgs: has generated the code for the lookup. */

	/* StackToRegisterMappingCogit>>#genPrimitivePerform */
static sqInt
genPrimitivePerform(void)
{
    AbstractInstruction *anInstruction;
    sqInt offset;

	if (methodOrBlockNumArgs > 2) {
		/* begin MoveMw:r:R: */
		offset = (methodOrBlockNumArgs - 1) * BytesPerWord;
		/* begin gen:quickConstant:operand:operand: */
		anInstruction = genoperandoperandoperand(MoveMwrR, offset, SPReg, Arg0Reg);
	}
	return genLookupForPerformNumArgs(methodOrBlockNumArgs);
}

	/* StackToRegisterMappingCogit>>#genPushActiveContextBytecode */
static sqInt
genPushActiveContextBytecode(void)
{
	assert(needsFrame);
	(optStatus.isReceiverResultRegLive = 0);
	ssAllocateCallRegandand(ReceiverResultReg, SendNumArgsReg, ClassReg);

	genGetActiveContextNumArgslargeinBlock(methodOrBlockNumArgs, methodNeedsLargeContext(methodObj), inBlock);
	return ssPushRegister(ReceiverResultReg);
}


/*	Block compilation. At this point in the method create the block. Note its
	start and defer generating code for it until after the method and any
	other preceding
	blocks. The block's actual code will be compiled later. */
/*	143 10001111 llllkkkk jjjjjjjj iiiiiiii	Push Closure Num Copied llll Num
	Args kkkk BlockSize jjjjjjjjiiiiiiii */

	/* StackToRegisterMappingCogit>>#genPushClosureCopyCopiedValuesBytecode */
static sqInt
genPushClosureCopyCopiedValuesBytecode(void)
{
    sqInt i;
    sqInt numArgs;
    sqInt numCopied;
    sqInt reg;
    sqInt startpc;

	assert(needsFrame);
	startpc = bytecodePC + (((generatorAt(byte0))->numBytes));
	addBlockStartAtnumArgsnumCopiedspan(startpc, (numArgs = byte1 & 15), (numCopied = ((usqInt) byte1) >> 4), (byte2 << 8) + byte3);
	/* begin genInlineClosure:numArgs:numCopied: */
	assert(getActiveContextAllocatesInMachineCode());
	(optStatus.isReceiverResultRegLive = 0);
	ssAllocateCallRegandand(ReceiverResultReg, SendNumArgsReg, ClassReg);
	genNoPopCreateClosureAtnumArgsnumCopiedcontextNumArgslargeinBlock(startpc + 1, numArgs, numCopied, methodOrBlockNumArgs, methodNeedsLargeContext(methodObj), inBlock);
	for (i = 1; i <= numCopied; i += 1) {
		reg = ssStorePoptoPreferredReg(1, TempReg);
		genStoreSourceRegslotIndexintoNewObjectInDestReg(reg, (ClosureFirstCopiedValueIndex + numCopied) - i, ReceiverResultReg);
	}
	ssPushRegister(ReceiverResultReg);

	return 0;
}

	/* StackToRegisterMappingCogit>>#genPushLiteralVariable: */
static sqInt NoDbgRegParms
genPushLiteralVariable(sqInt literalIndex)
{
    AbstractInstruction *anInstruction;
    sqInt association;
    sqInt freeReg;

	freeReg = allocateRegNotConflictingWith(0);

	/* N.B. Do _not_ use ReceiverResultReg to avoid overwriting receiver in assignment in frameless methods. */
	/* So far descriptors are not rich enough to describe the entire dereference so generate the register
	   load but don't push the result.  There is an order-of-evaluation issue if we defer the dereference. */
	association = getLiteral(literalIndex);
	/* begin genMoveConstant:R: */
	if (shouldAnnotateObjectReference(association)) {
		annotateobjRef(gMoveCwR(association, TempReg), association);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, association, TempReg);
	}
	genEnsureObjInRegNotForwardedscratchReg(TempReg, freeReg);
	genLoadSlotsourceRegdestReg(ValueIndex, TempReg, freeReg);
	ssPushRegister(freeReg);
	return 0;
}

	/* StackToRegisterMappingCogit>>#genPushLiteral: */
static sqInt NoDbgRegParms
genPushLiteral(sqInt literal)
{
	return ssPushConstant(literal);
}

	/* StackToRegisterMappingCogit>>#genPushMaybeContextReceiverVariable: */
static sqInt NoDbgRegParms
genPushMaybeContextReceiverVariable(sqInt slotIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *jmpDone;
    AbstractInstruction *jmpSingle;

	assert(needsFrame);
	ssAllocateCallRegand(ReceiverResultReg, SendNumArgsReg);
	ensureReceiverResultRegContainsSelf();
	if (callerSavedRegMask & (registerMaskFor(ReceiverResultReg))) {

		/* We have no way of reloading ReceiverResultReg since we need the inst var value as the result. */
		(optStatus.isReceiverResultRegLive = 0);
	}
	if (slotIndex == InstructionPointerIndex) {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, slotIndex, SendNumArgsReg);
		/* begin CallRT: */
		abstractInstruction = genoperand(Call, ceFetchContextInstVarTrampoline);
		(abstractInstruction->annotation = IsRelativeCall);
		return ssPushRegister(SendNumArgsReg);
	}
	genLoadSlotsourceRegdestReg(SenderIndex, ReceiverResultReg, TempReg);
	jmpSingle = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin MoveCq:R: */
	anInstruction1 = genoperandoperand(MoveCqR, slotIndex, SendNumArgsReg);
	/* begin CallRT: */
	abstractInstruction1 = genoperand(Call, ceFetchContextInstVarTrampoline);
	(abstractInstruction1->annotation = IsRelativeCall);
	/* begin Jump: */
	jmpDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpSingle, gLabel());
	genLoadSlotsourceRegdestReg(slotIndex, ReceiverResultReg, SendNumArgsReg);
	jmpTarget(jmpDone, gLabel());
	return ssPushRegister(SendNumArgsReg);
}

	/* StackToRegisterMappingCogit>>#genPushNewArrayBytecode */
static sqInt
genPushNewArrayBytecode(void)
{
    sqInt i;
    sqInt popValues;
    sqInt size;

	assert(needsFrame);
	(optStatus.isReceiverResultRegLive = 0);
	if ((popValues = byte1 > 0x7F)) {
		ssFlushTo(simStackPtr);
	}
	else {
		ssAllocateCallRegand(SendNumArgsReg, ReceiverResultReg);
	}
	size = byte1 & 0x7F;
	if (!popValues) {
		if (tryCollapseTempVectorInitializationOfSize(size)) {
			return 0;
		}
	}
	genNewArrayOfSizeinitialized(size, !popValues);
	if (popValues) {
		for (i = (size - 1); i >= 0; i += -1) {
			/* begin PopR: */
			genoperand(PopR, TempReg);
			genStoreSourceRegslotIndexintoNewObjectInDestReg(TempReg, i, ReceiverResultReg);
		}
		ssPop(size);
	}
	return ssPushRegister(ReceiverResultReg);
}

	/* StackToRegisterMappingCogit>>#genPushReceiverBytecode */
static sqInt
genPushReceiverBytecode(void)
{
	if ((optStatus.isReceiverResultRegLive)) {
		return ssPushRegister(ReceiverResultReg);
	}
	return ssPushDesc(simSelf);
}

	/* StackToRegisterMappingCogit>>#genPushReceiverVariable: */
static sqInt NoDbgRegParms
genPushReceiverVariable(sqInt index)
{
	ensureReceiverResultRegContainsSelf();
	return ssPushBaseoffset(ReceiverResultReg, slotOffsetOfInstVarIndex(index));
}


/*	Ensure that the register args are pushed before the retpc for methods with
	arity <= self numRegArgs.
 */
/*	This won't be as clumsy on a RISC. But putting the receiver and
	args above the return address means the CoInterpreter has a
	single machine-code frame format which saves us a lot of work. */

	/* StackToRegisterMappingCogit>>#genPushRegisterArgs */
static void
genPushRegisterArgs(void)
{
	if (!(regArgsHaveBeenPushed
		 || (methodOrBlockNumArgs > 2))) {
		genPushRegisterArgsForNumArgsscratchReg(backEnd, methodOrBlockNumArgs, SendNumArgsReg);
		regArgsHaveBeenPushed = 1;
	}
}

	/* StackToRegisterMappingCogit>>#genPushRemoteTempLongBytecode */
static sqInt
genPushRemoteTempLongBytecode(void)
{
    AbstractInstruction *anInstruction;
    sqInt offset;
    sqInt regMask;
    sqInt remoteTempReg;
    sqInt tempVectReg;

	tempVectReg = allocateRegNotConflictingWith(0);
	/* begin MoveMw:r:R: */
	offset = frameOffsetOfTemporary(byte2);
	/* begin gen:quickConstant:operand:operand: */
	anInstruction = genoperandoperandoperand(MoveMwrR, offset, FPReg, tempVectReg);
	/* begin availableRegOrNoneNotConflictingWith: */
	regMask = registerMaskFor(tempVectReg);
	remoteTempReg = availableRegisterOrNoneFor(backEnd, (liveRegisters()) | regMask);
	if (remoteTempReg == NoReg) {
		remoteTempReg = tempVectReg;
	}
	genLoadSlotsourceRegdestReg(byte1, tempVectReg, remoteTempReg);
	return ssPushRegister(remoteTempReg);
}


/*	If a frameless method (not a block), only argument temps can be accessed.
	This is assured by the use of needsFrameIfMod16GENumArgs: in pushTemp. */

	/* StackToRegisterMappingCogit>>#genPushTemporaryVariable: */
static sqInt NoDbgRegParms
genPushTemporaryVariable(sqInt index)
{
	assert(inBlock
	 || (needsFrame
	 || (index < methodOrBlockNumArgs)));
	return ssPushDesc(simStack[index]);
}


/*	In a frameless method ReceiverResultReg already contains self.
	In a frameful method, ReceiverResultReg /may/ contain self. */

	/* StackToRegisterMappingCogit>>#genReturnReceiver */
static sqInt
genReturnReceiver(void)
{
	if (needsFrame) {
		if (!((optStatus.isReceiverResultRegLive))) {
			/* begin putSelfInReceiverResultReg */
			storeToReg((&simSelf), ReceiverResultReg);
		}
	}
	return genUpArrowReturn();
}

	/* StackToRegisterMappingCogit>>#genReturnTopFromBlock */
static sqInt
genReturnTopFromBlock(void)
{
	assert(inBlock);
	popToReg(ssTop(), ReceiverResultReg);
	ssPop(1);
	return genBlockReturn();
}

	/* StackToRegisterMappingCogit>>#genReturnTopFromMethod */
static sqInt
genReturnTopFromMethod(void)
{
	popToReg(ssTop(), ReceiverResultReg);
	ssPop(1);
	return genUpArrowReturn();
}

	/* StackToRegisterMappingCogit>>#genSendSuper:numArgs: */
static sqInt NoDbgRegParms
genSendSupernumArgs(sqInt selectorIndex, sqInt numArgs)
{
	marshallSendArguments(numArgs);
	return genMarshalledSendnumArgssendTable(selectorIndex, numArgs, superSendTrampolines);
}


/*	Generate a trampoline with four arguments.
	Hack: a negative value indicates an abstract register, a non-negative
	value indicates a constant. */

	/* StackToRegisterMappingCogit>>#genSendTrampolineFor:numArgs:called:arg:arg:arg:arg: */
static sqInt NoDbgRegParms
genSendTrampolineFornumArgscalledargargargarg(void *aRoutine, sqInt numArgs, char *aString, sqInt regOrConst0, sqInt regOrConst1, sqInt regOrConst2, sqInt regOrConst3)
{
    sqInt routine;
    sqInt startAddress;

	startAddress = methodZoneBase;
	zeroOpcodeIndex();
	genPushRegisterArgsForNumArgsscratchReg(backEnd, numArgs, SendNumArgsReg);
	routine = null;
	if (!(routine == null)) {
		/* begin Call: */
		genoperand(Call, routine);
	}
	genTrampolineForcallednumArgsargargargargsaveRegspushLinkRegresultRegappendOpcodes(aRoutine, aString, 4, regOrConst0, regOrConst1, regOrConst2, regOrConst3, 0, 1, NoReg, 1);
	return startAddress;
}

	/* StackToRegisterMappingCogit>>#genSend:numArgs: */
static sqInt NoDbgRegParms
genSendnumArgs(sqInt selectorIndex, sqInt numArgs)
{
	marshallSendArguments(numArgs);
	return genMarshalledSendnumArgssendTable(selectorIndex, numArgs, ordinarySendTrampolines);
}

	/* StackToRegisterMappingCogit>>#genSpecialSelectorArithmetic */
static sqInt
genSpecialSelectorArithmetic(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    AbstractInstruction *anInstruction5;
    AbstractInstruction *anInstruction6;
    AbstractInstruction *anInstruction7;
    char annotateInst;
    sqInt argInt;
    sqInt argIsConst;
    sqInt argIsInt;
    sqInt index;
    AbstractInstruction *instToAnnotate;
    AbstractInstruction *jumpContinue;
    AbstractInstruction *jumpNotSmallInts;
    sqInt literal;
    sqInt literal1;
    BytecodeDescriptor *primDescriptor;
    sqInt rcvrInt;
    sqInt rcvrIsConst;
    sqInt rcvrIsInt;
    sqInt result;

	annotateInst = 0;
	primDescriptor = generatorAt(byte0);
	argIsInt = ((argIsConst = (((ssTop())->type)) == SSConstant))
	 && ((((argInt = ((ssTop())->constant))) & 1));
	rcvrIsInt = ((rcvrIsConst = (((ssValue(1))->type)) == SSConstant))
	 && ((((rcvrInt = ((ssValue(1))->constant))) & 1));
	if (argIsInt
	 && (rcvrIsInt)) {
		rcvrInt = (rcvrInt >> 1);
		argInt = (argInt >> 1);
		
		switch ((primDescriptor->opcode)) {
		case AddRR:
			result = rcvrInt + argInt;
			break;
		case SubRR:
			result = rcvrInt - argInt;
			break;
		case AndRR:
			result = rcvrInt & argInt;
			break;
		case OrRR:
			result = rcvrInt | argInt;
			break;
		default:
			error("Case not found and no otherwise clause");
		}
		if (isIntegerValue(result)) {

			/* Must enter any annotatedConstants into the map */
			annotateBytecodeIfAnnotated(ssValue(1));
			annotateBytecodeIfAnnotated(ssTop());
			return (ssPop(2),
				ssPushAnnotatedConstant(((result << 1) | 1)));
		}
		return genSpecialSelectorSend();
	}
	if ((rcvrIsConst
	 && (!rcvrIsInt))
	 || (argIsConst
	 && (!argIsInt))) {
		return genSpecialSelectorSend();
	}
	if (!(argIsInt
		 || (rcvrIsInt))) {
		return genSpecialSelectorSend();
	}
	if (argIsInt) {
		ssFlushTo(simStackPtr - 2);
		popToReg(ssValue(1), ReceiverResultReg);
		annotateInst = ((ssTop())->annotateUse);
		ssPop(2);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	}
	else {
		marshallSendArguments(1);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, Arg0Reg, TempReg);
	}
	if (argIsInt
	 || (rcvrIsInt)) {
		jumpNotSmallInts = genJumpNotSmallIntegerInScratchReg(TempReg);
	}
	else {
		/* begin genJumpNotSmallIntegersIn:andScratchReg: */
		genoperandoperand(AndRR, ReceiverResultReg, TempReg);
		jumpNotSmallInts = genJumpNotSmallIntegerInScratchReg(TempReg);
	}
	
	switch ((primDescriptor->opcode)) {
	case AddRR:
		if (argIsInt) {
			/* begin AddCq:R: */
			literal = argInt - ConstZero;
			anInstruction = genoperandoperand(AddCqR, argInt - ConstZero, ReceiverResultReg);
			instToAnnotate = anInstruction;
			/* begin JumpNoOverflow: */
			jumpContinue = genConditionalBranchoperand(JumpNoOverflow, ((sqInt)0));
			/* begin SubCq:R: */
			anInstruction1 = genoperandoperand(SubCqR, argInt - ConstZero, ReceiverResultReg);
		}
		else {
			genRemoveSmallIntegerTagsInScratchReg(ReceiverResultReg);
			/* begin AddR:R: */
			genoperandoperand(AddRR, Arg0Reg, ReceiverResultReg);
			/* begin JumpNoOverflow: */
			jumpContinue = genConditionalBranchoperand(JumpNoOverflow, ((sqInt)0));
			if (rcvrIsInt) {
				/* begin MoveCq:R: */
				anInstruction2 = genoperandoperand(MoveCqR, rcvrInt, ReceiverResultReg);
			}
			else {
				/* begin SubR:R: */
				genoperandoperand(SubRR, Arg0Reg, ReceiverResultReg);
				genSetSmallIntegerTagsIn(ReceiverResultReg);
			}
		}
		break;
	case SubRR:
		if (argIsInt) {
			/* begin SubCq:R: */
			anInstruction3 = genoperandoperand(SubCqR, argInt - ConstZero, ReceiverResultReg);
			instToAnnotate = anInstruction3;
			/* begin JumpNoOverflow: */
			jumpContinue = genConditionalBranchoperand(JumpNoOverflow, ((sqInt)0));
			/* begin AddCq:R: */
			literal1 = argInt - ConstZero;
			anInstruction4 = genoperandoperand(AddCqR, argInt - ConstZero, ReceiverResultReg);
		}
		else {
			genRemoveSmallIntegerTagsInScratchReg(Arg0Reg);
			/* begin SubR:R: */
			genoperandoperand(SubRR, Arg0Reg, ReceiverResultReg);
			/* begin JumpNoOverflow: */
			jumpContinue = genConditionalBranchoperand(JumpNoOverflow, ((sqInt)0));
			/* begin AddR:R: */
			genoperandoperand(AddRR, Arg0Reg, ReceiverResultReg);
			genSetSmallIntegerTagsIn(Arg0Reg);
		}
		break;
	case AndRR:
		if (argIsInt) {
			/* begin AndCq:R: */
			anInstruction5 = genoperandoperand(AndCqR, argInt, ReceiverResultReg);
			instToAnnotate = anInstruction5;
		}
		else {
			/* begin AndR:R: */
			genoperandoperand(AndRR, Arg0Reg, ReceiverResultReg);
		}
		/* begin Jump: */
		jumpContinue = genoperand(Jump, ((sqInt)0));
		break;
	case OrRR:
		if (argIsInt) {
			/* begin OrCq:R: */
			anInstruction6 = genoperandoperand(OrCqR, argInt, ReceiverResultReg);
			instToAnnotate = anInstruction6;
		}
		else {
			/* begin OrR:R: */
			genoperandoperand(OrRR, Arg0Reg, ReceiverResultReg);
		}
		/* begin Jump: */
		jumpContinue = genoperand(Jump, ((sqInt)0));
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	jmpTarget(jumpNotSmallInts, gLabel());
	if (argIsInt) {
		if (annotateInst) {
			/* begin annotateBytecode: */
			(instToAnnotate->annotation = HasBytecodePC);
		}
		/* begin MoveCq:R: */
		anInstruction7 = genoperandoperand(MoveCqR, argInt, Arg0Reg);
	}
	index = byte0 - (
#if MULTIPLEBYTECODESETS
	(bytecodeSetOffset == 256
		? AltFirstSpecialSelector + 256
		: FirstSpecialSelector)
#else /* MULTIPLEBYTECODESETS */
	FirstSpecialSelector
#endif /* MULTIPLEBYTECODESETS */
	);
	genMarshalledSendnumArgssendTable((-index) - 1, 1, ordinarySendTrampolines);
	jmpTarget(jumpContinue, gLabel());
	return 0;
}

	/* StackToRegisterMappingCogit>>#genSpecialSelectorClass */
static sqInt
genSpecialSelectorClass(void)
{
    sqInt topReg;

	topReg = registerOrNone(ssTop());
	ssPop(1);
	if ((topReg == NoReg)
	 || (topReg == ClassReg)) {
		ssAllocateRequiredRegand((topReg = SendNumArgsReg), ClassReg);
	}
	else {
		ssAllocateRequiredReg(ClassReg);
	}
	ssPush(1);
	popToReg(ssTop(), topReg);
	genGetClassObjectOfintoscratchReginstRegIsReceiver(topReg, ClassReg, TempReg, 0);
	return (ssPop(1),
		ssPushRegister(ClassReg));
}

	/* StackToRegisterMappingCogit>>#genSpecialSelectorComparison */
static sqInt
genSpecialSelectorComparison(void)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction2;
    char annotateInst;
    sqInt argInt;
    sqInt argIsInt;
    BytecodeDescriptor *branchDescriptor;
    BytecodeDescriptor *branchDescriptor1;
    sqInt descr;
    sqInt index;
    sqInt inlineCAB;
    AbstractInstruction *jumpNotSmallInts;
    void *jumpTarget;
    sqInt nExts;
    sqInt next;
    sqInt nextPC;
    sqInt nextPC1;
    sqInt postBranch;
    sqInt postBranchPC;
    sqInt postBranchPC1;
    BytecodeDescriptor *primDescriptor;
    BytecodeDescriptor *primDescriptor1;
    sqInt rcvrIsInt;
    sqInt target;
    sqInt targetBytecodePC;
    sqInt targetBytecodePC1;

	annotateInst = 0;
	ssFlushTo(simStackPtr - 2);
	primDescriptor = generatorAt(byte0);
	argIsInt = ((((ssTop())->type)) == SSConstant)
	 && ((((argInt = ((ssTop())->constant))) & 1));
	rcvrIsInt = ((((ssValue(1))->type)) == SSConstant)
	 && (((((ssValue(1))->constant)) & 1));
	if (argIsInt
	 && (rcvrIsInt)) {
		return genStaticallyResolvedSpecialSelectorComparison();
	}
	/* begin extractMaybeBranchDescriptorInto: */
	primDescriptor1 = generatorAt(byte0);
	nextPC1 = bytecodePC + ((primDescriptor1->numBytes));
	nExts = 0;
	while (1) {
		branchDescriptor1 = generatorAt((fetchByteofObject(nextPC1, methodObj)) + bytecodeSetOffset);
		if (!((branchDescriptor1->isExtension))) break;
		nExts += 1;
		nextPC1 += (branchDescriptor1->numBytes);
	}
	targetBytecodePC1 = (postBranchPC1 = 0);
	if (((branchDescriptor1->isBranchTrue))
	 || ((branchDescriptor1->isBranchFalse))) {
		targetBytecodePC1 = (nextPC1 + ((branchDescriptor1->numBytes))) + (((branchDescriptor1->spanFunction))(branchDescriptor1, nextPC1, nExts, methodObj));
		postBranchPC1 = nextPC1 + ((branchDescriptor1->numBytes));
	}
	branchDescriptor = branchDescriptor1;
	nextPC = nextPC1;
	postBranchPC = postBranchPC1;
	targetBytecodePC = targetBytecodePC1;


	/* Further, only interested in inlining = and ~= if there's a SmallInteger constant involved.
	   The relational operators successfully statically predict SmallIntegers; the equality operators do not. */
	inlineCAB = ((branchDescriptor->isBranchTrue))
	 || ((branchDescriptor->isBranchFalse));
	if (inlineCAB
	 && ((((primDescriptor->opcode)) == JumpZero)
	 || (((primDescriptor->opcode)) == JumpNonZero))) {
		inlineCAB = argIsInt
		 || (rcvrIsInt);
	}
	if (!inlineCAB) {
		return genSpecialSelectorSend();
	}
	if (argIsInt) {
		popToReg(ssValue(1), ReceiverResultReg);
		annotateInst = ((ssTop())->annotateUse);
		ssPop(2);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ReceiverResultReg, TempReg);
	}
	else {
		marshallSendArguments(1);
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, Arg0Reg, TempReg);
	}
	if (argIsInt
	 || (rcvrIsInt)) {
		jumpNotSmallInts = genJumpNotSmallIntegerInScratchReg(TempReg);
	}
	else {
		/* begin genJumpNotSmallIntegersIn:andScratchReg: */
		genoperandoperand(AndRR, ReceiverResultReg, TempReg);
		jumpNotSmallInts = genJumpNotSmallIntegerInScratchReg(TempReg);
	}
	if (argIsInt) {
		if (annotateInst) {
			/* begin annotateBytecode: */
			anInstruction = genoperandoperand(CmpCqR, argInt, ReceiverResultReg);
			abstractInstruction = anInstruction;
			(abstractInstruction->annotation = HasBytecodePC);
		}
		else {
			/* begin CmpCq:R: */
			anInstruction1 = genoperandoperand(CmpCqR, argInt, ReceiverResultReg);
		}
	}
	else {
		/* begin CmpR:R: */
		genoperandoperand(CmpRR, Arg0Reg, ReceiverResultReg);
	}
	genConditionalBranchoperand(((branchDescriptor->isBranchTrue)
		? (primDescriptor->opcode)
		: inverseBranchFor((primDescriptor->opcode))), ((usqInt)(ensureNonMergeFixupAt(targetBytecodePC - initialPC))));
	/* begin Jump: */
	jumpTarget = ensureNonMergeFixupAt(postBranchPC - initialPC);
	genoperand(Jump, ((sqInt)jumpTarget));
	jmpTarget(jumpNotSmallInts, gLabel());
	if (argIsInt) {
		/* begin MoveCq:R: */
		anInstruction2 = genoperandoperand(MoveCqR, argInt, Arg0Reg);
	}
	index = byte0 - (
#if MULTIPLEBYTECODESETS
	(bytecodeSetOffset == 256
		? AltFirstSpecialSelector + 256
		: FirstSpecialSelector)
#else /* MULTIPLEBYTECODESETS */
	FirstSpecialSelector
#endif /* MULTIPLEBYTECODESETS */
	);
	return genMarshalledSendnumArgssendTable((-index) - 1, 1, ordinarySendTrampolines);
}


/*	Decompose code generation for #== into a common constant-folding version,
	followed by a double dispatch throguh the objectRepresentation to a
	version that doesn't deal with forwarders and a version that does. */

	/* StackToRegisterMappingCogit>>#genSpecialSelectorEqualsEquals */
static sqInt
genSpecialSelectorEqualsEquals(void)
{
    BytecodeDescriptor *primDescriptor;
    sqInt result;

	primDescriptor = generatorAt(byte0);
	if ((isUnannotatableConstant(ssTop()))
	 && (isUnannotatableConstant(ssValue(1)))) {
		assert(!((primDescriptor->isMapped)));
		result = ((((ssTop())->constant)) == (((ssValue(1))->constant))
			? trueObject()
			: falseObject());
		ssPop(2);
		return ssPushConstant(result);
	}
	return genSpecialSelectorEqualsEqualsWithForwarders();
}

	/* StackToRegisterMappingCogit>>#genSpecialSelectorEqualsEqualsWithForwarders */
static sqInt
genSpecialSelectorEqualsEqualsWithForwarders(void)
{
    AbstractInstruction *anInstruction;
    AbstractInstruction *anInstruction1;
    AbstractInstruction *anInstruction11;
    AbstractInstruction *anInstruction12;
    AbstractInstruction *anInstruction2;
    AbstractInstruction *anInstruction3;
    AbstractInstruction *anInstruction4;
    sqInt arg;
    sqInt argReg;
    sqInt argReg1;
    BytecodeDescriptor *branchDescriptor;
    BytecodeDescriptor *branchDescriptor1;
    sqInt constant;
    sqInt constant1;
    sqInt descr;
    AbstractInstruction *finished;
    AbstractInstruction *finished1;
    usqInt fixup;
    AbstractInstruction *imm;
    AbstractInstruction *imm1;
    void *jumpTarget;
    void *jumpTarget1;
    AbstractInstruction *label;
    sqInt literal;
    sqInt nExts;
    sqInt next;
    sqInt nextPC;
    sqInt nextPC1;
    AbstractInstruction *ok;
    AbstractInstruction *ok1;
    sqInt postBranch;
    sqInt postBranchPC;
    sqInt postBranchPC1;
    BytecodeDescriptor *primDescriptor;
    sqInt quickConstant;
    sqInt quickConstant1;
    sqInt rcvr;
    sqInt rcvrReg;
    sqInt rcvrReg1;
    sqInt rNext;
    sqInt rNext1;
    sqInt rTop;
    sqInt rTop1;
    sqInt target;
    sqInt targetBytecodePC;
    sqInt targetBytecodePC1;
    sqInt topRegistersMask;
    sqInt unforwardArg;
    sqInt unforwardRcvr;

	/* begin extractMaybeBranchDescriptorInto: */
	primDescriptor = generatorAt(byte0);
	nextPC1 = bytecodePC + ((primDescriptor->numBytes));
	nExts = 0;
	while (1) {
		branchDescriptor1 = generatorAt((fetchByteofObject(nextPC1, methodObj)) + bytecodeSetOffset);
		if (!((branchDescriptor1->isExtension))) break;
		nExts += 1;
		nextPC1 += (branchDescriptor1->numBytes);
	}
	targetBytecodePC1 = (postBranchPC1 = 0);
	if (((branchDescriptor1->isBranchTrue))
	 || ((branchDescriptor1->isBranchFalse))) {
		targetBytecodePC1 = (nextPC1 + ((branchDescriptor1->numBytes))) + (((branchDescriptor1->spanFunction))(branchDescriptor1, nextPC1, nExts, methodObj));
		postBranchPC1 = nextPC1 + ((branchDescriptor1->numBytes));
	}
	branchDescriptor = branchDescriptor1;
	nextPC = nextPC1;
	postBranchPC = postBranchPC1;
	targetBytecodePC = targetBytecodePC1;

	unforwardRcvr = !(isUnannotatableConstant(ssValue(1)));
	unforwardArg = !(isUnannotatableConstant(ssTop()));
	/* begin allocateEqualsEqualsRegistersArgNeedsReg:rcvrNeedsReg:into: */
	assert(unforwardArg
	 || (unforwardRcvr));
	argReg1 = (rcvrReg1 = NoReg);
	if (unforwardArg) {
		if (unforwardRcvr) {
			/* begin allocateRegForStackTopTwoEntriesInto: */
			topRegistersMask = 0;
			rTop1 = (rNext1 = NoReg);
			if ((((ssTop())->type)) == SSRegister) {
				rTop1 = ((ssTop())->registerr);
			}
			if ((((ssValue(1))->type)) == SSRegister) {
				topRegistersMask = registerMaskFor((rNext1 = ((ssValue(1))->registerr)));
			}
			if (rTop1 == NoReg) {
				rTop1 = allocateRegNotConflictingWith(topRegistersMask);
			}
			if (rNext1 == NoReg) {
				rNext1 = allocateRegNotConflictingWith(registerMaskFor(rTop1));
			}
			assert(!(((rTop1 == NoReg)
 || (rNext1 == NoReg))));
			argReg1 = rTop1;
			rcvrReg1 = rNext1;

			popToReg(ssTop(), argReg1);
			popToReg(ssValue(1), rcvrReg1);
		}
		else {
			argReg1 = allocateRegForStackEntryAtnotConflictingWith(0, 0);
			popToReg(ssTop(), argReg1);
			if (((ssValue(1))->spilled)) {
				/* begin AddCq:R: */
				literal = BytesPerWord;
				anInstruction4 = genoperandoperand(AddCqR, BytesPerWord, SPReg);
			}
		}
	}
	else {
		assert(unforwardRcvr);
		assert(!((((ssTop())->spilled))));
		rcvrReg1 = allocateRegForStackEntryAtnotConflictingWith(1, 0);
		popToReg(ssValue(1), rcvrReg1);
	}
	assert(!((unforwardArg
 && (argReg1 == NoReg))));
	assert(!((unforwardRcvr
 && (rcvrReg1 == NoReg))));
	rcvrReg = rcvrReg1;
	argReg = argReg1;

	if (!(((branchDescriptor->isBranchTrue))
		 || ((branchDescriptor->isBranchFalse)))) {
		return genEqualsEqualsNoBranchArgIsConstantrcvrIsConstantargRegrcvrReg(!unforwardArg, !unforwardRcvr, argReg, rcvrReg);
	}
	ssFlushTo(simStackPtr - 2);
	/* begin Label */
	label = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
	/* begin genEqualsEqualsComparisonArgIsConstant:rcvrIsConstant:argReg:rcvrReg: */
	if (!unforwardArg) {
		/* begin genCompConstant:R: */
		constant = ((ssTop())->constant);
		if (shouldAnnotateObjectReference(constant)) {
			annotateobjRef(gCmpCwR(constant, rcvrReg), constant);
		}
		else {
			/* begin CmpCq:R: */
			anInstruction = genoperandoperand(CmpCqR, constant, rcvrReg);
		}
	}
	else {
		if (!unforwardRcvr) {
			/* begin genCompConstant:R: */
			constant1 = ((ssValue(1))->constant);
			if (shouldAnnotateObjectReference(constant1)) {
				annotateobjRef(gCmpCwR(constant1, argReg), constant1);
			}
			else {
				/* begin CmpCq:R: */
				anInstruction1 = genoperandoperand(CmpCqR, constant1, argReg);
			}
		}
		else {
			/* begin CmpR:R: */
			genoperandoperand(CmpRR, argReg, rcvrReg);
		}
	}
	ssPop(2);
	if ((((fixupAt(nextPC - initialPC))->targetInstruction)) == 0) {

		/* The next instruction is dead.  we can skip it. */
		deadCode = 1;
		ensureFixupAt(targetBytecodePC - initialPC);
		ensureFixupAt(postBranchPC - initialPC);
	}
	else {
		ssPushConstant(trueObject());
	}
	assert(unforwardArg
	 || (unforwardRcvr));
	if ((branchDescriptor->isBranchTrue)) {
		fixup = ((usqInt)(ensureNonMergeFixupAt(postBranchPC - initialPC)));
		/* begin JumpZero: */
		jumpTarget = ((void *) (((usqInt)(ensureNonMergeFixupAt(targetBytecodePC - initialPC)))));
		genConditionalBranchoperand(JumpZero, ((sqInt)jumpTarget));
	}
	else {

		/* branchDescriptor is branchFalse */
		fixup = ((usqInt)(ensureNonMergeFixupAt(targetBytecodePC - initialPC)));
		/* begin JumpZero: */
		jumpTarget1 = ((void *) (((usqInt)(ensureNonMergeFixupAt(postBranchPC - initialPC)))));
		genConditionalBranchoperand(JumpZero, ((sqInt)jumpTarget1));
	}
	if (unforwardArg) {
		if (unforwardRcvr) {
			genEnsureOopInRegNotForwardedscratchRegjumpBackTo(argReg, TempReg, label);
		}
		else {
			/* begin genEnsureOopInRegNotForwarded:scratchReg:ifForwarder:ifNotForwarder: */
			assert(argReg != TempReg);

			/* notionally
			   self genGetClassIndexOfNonImm: reg into: scratch.
			   cogit CmpCq: objectMemory isForwardedObjectClassIndexPun R: TempReg.
			   but the following is an instruction shorter: */
			imm = genJumpImmediate(argReg);
			/* begin MoveMw:r:R: */
			anInstruction2 = genoperandoperandoperand(MoveMwrR, 0, argReg, TempReg);
			/* begin AndCq:R: */
			quickConstant = (classIndexMask()) - (isForwardedObjectClassIndexPun());
			/* begin gen:quickConstant:operand: */
			anInstruction11 = genoperandoperand(AndCqR, quickConstant, TempReg);
			/* begin JumpNonZero: */
			ok = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
			genLoadSlotsourceRegdestReg(0, argReg, argReg);
			/* begin Jump: */
			genoperand(Jump, ((sqInt)(((void *) label))));
			if (fixup == 0) {
				/* begin Label */
				finished = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
			}
			else {
				finished = ((AbstractInstruction *) fixup);
			}
			jmpTarget(imm, jmpTarget(ok, finished));
		}
	}
	if (unforwardRcvr) {
		/* begin genEnsureOopInRegNotForwarded:scratchReg:ifForwarder:ifNotForwarder: */
		assert(rcvrReg != TempReg);

		/* notionally
		   self genGetClassIndexOfNonImm: reg into: scratch.
		   cogit CmpCq: objectMemory isForwardedObjectClassIndexPun R: TempReg.
		   but the following is an instruction shorter: */
		imm1 = genJumpImmediate(rcvrReg);
		/* begin MoveMw:r:R: */
		anInstruction3 = genoperandoperandoperand(MoveMwrR, 0, rcvrReg, TempReg);
		/* begin AndCq:R: */
		quickConstant1 = (classIndexMask()) - (isForwardedObjectClassIndexPun());
		/* begin gen:quickConstant:operand: */
		anInstruction12 = genoperandoperand(AndCqR, quickConstant1, TempReg);
		/* begin JumpNonZero: */
		ok1 = genConditionalBranchoperand(JumpNonZero, ((sqInt)0));
		genLoadSlotsourceRegdestReg(0, rcvrReg, rcvrReg);
		/* begin Jump: */
		genoperand(Jump, ((sqInt)(((void *) label))));
		if (fixup == 0) {
			/* begin Label */
			finished1 = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		}
		else {
			finished1 = ((AbstractInstruction *) fixup);
		}
		jmpTarget(imm1, jmpTarget(ok1, finished1));
	}
	return 0;
}


/*	Assumes both operands are ints */

	/* StackToRegisterMappingCogit>>#genStaticallyResolvedSpecialSelectorComparison */
static sqInt
genStaticallyResolvedSpecialSelectorComparison(void)
{
    sqInt argInt;
    BytecodeDescriptor *primDescriptor;
    sqInt rcvrInt;
    sqInt result;

	primDescriptor = generatorAt(byte0);
	argInt = ((ssTop())->constant);
	rcvrInt = ((ssValue(1))->constant);
	
	switch ((primDescriptor->opcode)) {
	case JumpLess:
		result = rcvrInt < argInt;
		break;
	case JumpLessOrEqual:
		result = rcvrInt <= argInt;
		break;
	case JumpGreater:
		result = rcvrInt > argInt;
		break;
	case JumpGreaterOrEqual:
		result = rcvrInt >= argInt;
		break;
	case JumpZero:
		result = rcvrInt == argInt;
		break;
	case JumpNonZero:
		result = rcvrInt != argInt;
		break;
	default:
		error("Case not found and no otherwise clause");
	}
	annotateBytecodeIfAnnotated(ssValue(1));
	annotateBytecodeIfAnnotated(ssTop());
	ssPop(2);
	return ssPushAnnotatedConstant((result
		? trueObject()
		: falseObject()));
}


/*	The only reason we assert needsFrame here is that in a frameless method
	ReceiverResultReg must and does contain only self, but the ceStoreCheck
	trampoline expects the target of the store to be in ReceiverResultReg. So
	in a frameless method we would have a conflict between the receiver and
	the literal store, unless we we smart enough to realise that
	ReceiverResultReg was unused after the literal variable store, unlikely
	given that methods
	return self by default. */

	/* StackToRegisterMappingCogit>>#genStorePop:LiteralVariable: */
static sqInt NoDbgRegParms
genStorePopLiteralVariable(sqInt popBoolean, sqInt litVarIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *anInstruction;
    sqInt association;
    sqInt immutabilityFailure;
    sqInt needStoreCheck;
    sqInt topReg;

	immutabilityFailure = 0;
	assert(needsFrame);
	
#  if IMMUTABILITY
	ssFlushTo(simStackPtr - 1);

#  endif /* IMMUTABILITY */

	needStoreCheck = !(isUnannotatableConstant(ssTop()));
	association = getLiteral(litVarIndex);
	(optStatus.isReceiverResultRegLive = 0);
	ssAllocateRequiredReg(ReceiverResultReg);
	/* begin genMoveConstant:R: */
	if (shouldAnnotateObjectReference(association)) {
		annotateobjRef(gMoveCwR(association, ReceiverResultReg), association);
	}
	else {
		/* begin MoveCq:R: */
		anInstruction = genoperandoperand(MoveCqR, association, ReceiverResultReg);
	}
	genEnsureObjInRegNotForwardedscratchReg(ReceiverResultReg, TempReg);
	
#  if IMMUTABILITY
	ssAllocateRequiredReg(ClassReg);
	topReg = ClassReg;
	ssStoreAndReplacePoptoReg(popBoolean, ClassReg);
	ssFlushTo(simStackPtr);
	immutabilityFailure = genImmutableCheckslotIndexsourceRegscratchRegneedRestoreRcvr(ReceiverResultReg, ValueIndex, ClassReg, TempReg, 0);

#  else /* IMMUTABILITY */
	topReg = allocateRegForStackEntryAtnotConflictingWith(0, registerMaskFor(ReceiverResultReg));
	ssStorePoptoReg(popBoolean, topReg);

#  endif /* IMMUTABILITY */

	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, topReg, TempReg);
		/* begin CallRT: */
		abstractInstruction = genoperand(Call, ceTraceStoreTrampoline);
		(abstractInstruction->annotation = IsRelativeCall);
	}
	genStoreSourceRegslotIndexdestRegscratchReginFrameneedsStoreCheck(topReg, ValueIndex, ReceiverResultReg, TempReg, needsFrame, needStoreCheck);
	
#  if IMMUTABILITY
	jmpTarget(immutabilityFailure, gLabel());

#  endif /* IMMUTABILITY */

	return 0;
}

	/* StackToRegisterMappingCogit>>#genStorePop:MaybeContextReceiverVariable: */
static sqInt NoDbgRegParms
genStorePopMaybeContextReceiverVariable(sqInt popBoolean, sqInt slotIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    AbstractInstruction *anInstruction;
    sqInt immutabilityFailure;
    AbstractInstruction *jmpDone;
    AbstractInstruction *jmpSingle;
    sqInt needStoreCheck;


	/* The reason we need a frame here is that assigning to an inst var of a context may
	   involve wholesale reorganization of stack pages, and the only way to preserve the
	   execution state of an activation in that case is if it has a frame. */
	immutabilityFailure = 0;
	assert(needsFrame);
	
#  if IMMUTABILITY
	ssFlushTo(simStackPtr - 1);

#  endif /* IMMUTABILITY */

	ssFlushUpThroughReceiverVariable(slotIndex);

	/* Note that ReceiverResultReg remains live after both
	   ceStoreContextInstVarTrampoline and ceStoreCheckTrampoline. */
	needStoreCheck = !(isUnannotatableConstant(ssTop()));
	ensureReceiverResultRegContainsSelf();
	ssPop(1);
	ssAllocateCallRegand(ClassReg, SendNumArgsReg);
	ssPush(1);
	genLoadSlotsourceRegdestReg(SenderIndex, ReceiverResultReg, TempReg);
	
#  if IMMUTABILITY
	ssStoreAndReplacePoptoReg(popBoolean, ClassReg);
	ssFlushTo(simStackPtr);

#  else /* IMMUTABILITY */
	ssStorePoptoReg(popBoolean, ClassReg);

#  endif /* IMMUTABILITY */

	jmpSingle = genJumpNotSmallIntegerInScratchReg(TempReg);
	/* begin MoveCq:R: */
	anInstruction = genoperandoperand(MoveCqR, slotIndex, SendNumArgsReg);
	/* begin CallRT: */
	abstractInstruction1 = genoperand(Call, ceStoreContextInstVarTrampoline);
	(abstractInstruction1->annotation = IsRelativeCall);
	/* begin Jump: */
	jmpDone = genoperand(Jump, ((sqInt)0));
	jmpTarget(jmpSingle, gLabel());
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, ClassReg, TempReg);
		/* begin CallRT: */
		abstractInstruction = genoperand(Call, ceTraceStoreTrampoline);
		(abstractInstruction->annotation = IsRelativeCall);
	}
	
#  if IMMUTABILITY
	immutabilityFailure = genImmutableCheckslotIndexsourceRegscratchRegneedRestoreRcvr(ReceiverResultReg, ValueIndex, ClassReg, TempReg, 1);

#  endif /* IMMUTABILITY */

	genStoreSourceRegslotIndexdestRegscratchReginFrameneedsStoreCheck(ClassReg, slotIndex, ReceiverResultReg, TempReg, 1, needStoreCheck);
	jmpTarget(jmpDone, gLabel());
	
#  if IMMUTABILITY
	jmpTarget(immutabilityFailure, gLabel());

#  endif /* IMMUTABILITY */

	return 0;
}

	/* StackToRegisterMappingCogit>>#genStorePop:ReceiverVariable: */
static sqInt NoDbgRegParms
genStorePopReceiverVariable(sqInt popBoolean, sqInt slotIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    sqInt immutabilityFailure;
    AbstractInstruction * inst;
    sqInt needStoreCheck;
    sqInt topReg;

	immutabilityFailure = 0;
	
#  if IMMUTABILITY
	assert(needsFrame);
	ssFlushTo(simStackPtr - 1);

#  endif /* IMMUTABILITY */

	ssFlushUpThroughReceiverVariable(slotIndex);

	/* Note that ReceiverResultReg remains live after ceStoreCheckTrampoline. */
	needStoreCheck = !(isUnannotatableConstant(ssTop()));
	ensureReceiverResultRegContainsSelf();
	
#  if IMMUTABILITY
	ssAllocateRequiredReg(ClassReg);
	topReg = ClassReg;
	ssStoreAndReplacePoptoReg(popBoolean, ClassReg);
	ssFlushTo(simStackPtr);
	immutabilityFailure = genImmutableCheckslotIndexsourceRegscratchRegneedRestoreRcvr(ReceiverResultReg, slotIndex, ClassReg, TempReg, 1);

#  else /* IMMUTABILITY */
	topReg = allocateRegForStackEntryAtnotConflictingWith(0, registerMaskFor(ReceiverResultReg));
	ssStorePoptoReg(popBoolean, topReg);

#  endif /* IMMUTABILITY */

	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, topReg, TempReg);
		/* begin evaluateTrampolineCallBlock:protectLinkRegIfNot: */
		if (needsFrame) {
			/* begin CallRT: */
			abstractInstruction = genoperand(Call, ceTraceStoreTrampoline);
			(abstractInstruction->annotation = IsRelativeCall);

		}
		else {
			/* begin saveAndRestoreLinkRegAround: */
			inst = genoperand(PushR, LinkReg);
			/* begin CallRT: */
			abstractInstruction1 = genoperand(Call, ceTraceStoreTrampoline);
			(abstractInstruction1->annotation = IsRelativeCall);


			/* begin PopR: */
			genoperand(PopR, LinkReg);
		}
	}
	genStoreSourceRegslotIndexdestRegscratchReginFrameneedsStoreCheck(topReg, slotIndex, ReceiverResultReg, TempReg, needsFrame, needStoreCheck);
	
#  if IMMUTABILITY
	jmpTarget(immutabilityFailure, gLabel());

#  endif /* IMMUTABILITY */

	return 0;
}


/*	The only reason we assert needsFrame here is that in a frameless method
	ReceiverResultReg must and does contain only self, but the ceStoreCheck
	trampoline expects the target of the store to be in ReceiverResultReg. So
	in a frameless method we would have a conflict between the receiver and
	the temote temp store, unless we we smart enough to realise that
	ReceiverResultReg was unused after the literal variable store, unlikely
	given that methods return self by default. */

	/* StackToRegisterMappingCogit>>#genStorePop:RemoteTemp:At: */
static sqInt NoDbgRegParms
genStorePopRemoteTempAt(sqInt popBoolean, sqInt slotIndex, sqInt remoteTempIndex)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *anInstruction;
    sqInt needStoreCheck;
    sqInt offset;
    sqInt topReg;

	assert(needsFrame);
	needStoreCheck = !(isUnannotatableConstant(ssTop()));
	topReg = allocateRegForStackEntryAtnotConflictingWith(0, registerMaskFor(ReceiverResultReg));
	ssAllocateRequiredReg(ReceiverResultReg);
	(optStatus.isReceiverResultRegLive = 0);
	ssStoreAndReplacePoptoReg(popBoolean, topReg);
	/* begin MoveMw:r:R: */
	offset = frameOffsetOfTemporary(remoteTempIndex);
	/* begin gen:quickConstant:operand:operand: */
	anInstruction = genoperandoperandoperand(MoveMwrR, offset, FPReg, ReceiverResultReg);
	if (traceStores > 0) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, topReg, TempReg);
		/* begin CallRT: */
		abstractInstruction = genoperand(Call, ceTraceStoreTrampoline);
		(abstractInstruction->annotation = IsRelativeCall);
	}
	return genStoreSourceRegslotIndexdestRegscratchReginFrameneedsStoreCheck(topReg, slotIndex, ReceiverResultReg, TempReg, needsFrame, needStoreCheck);
}

	/* StackToRegisterMappingCogit>>#genStorePop:TemporaryVariable: */
static sqInt NoDbgRegParms
genStorePopTemporaryVariable(sqInt popBoolean, sqInt tempIndex)
{
    AbstractInstruction *anInstruction;
    sqInt offset;
    sqInt reg;

	ssFlushUpThroughTemporaryVariable(tempIndex);
	reg = ssStorePoptoPreferredReg(popBoolean, TempReg);
	/* begin MoveR:Mw:r: */
	offset = frameOffsetOfTemporary(tempIndex);
	/* begin gen:operand:quickConstant:operand: */
	anInstruction = genoperandoperandoperand(MoveRMwr, reg, offset, FPReg);
	return 0;
}


/*	Generate a method return from within a method or a block.
	Frameless method activation looks like
	CISCs (x86):
	receiver
	args
	sp->	ret pc.
	RISCs (ARM):
	receiver
	args
	ret pc in LR.
	A fully framed activation is described in CoInterpreter
	class>initializeFrameIndices. Return pops receiver and arguments off the
	stack. Callee pushes the result. */

	/* StackToRegisterMappingCogit>>#genUpArrowReturn */
static sqInt
genUpArrowReturn(void)
{
    AbstractInstruction *abstractInstruction;
    AbstractInstruction *abstractInstruction1;
    sqInt offset;

	if (inBlock) {
		assert(needsFrame);
		/* begin CallRT: */
		abstractInstruction1 = genoperand(Call, ceNonLocalReturnTrampoline);
		(abstractInstruction1->annotation = IsRelativeCall);
		/* begin annotateBytecode: */
		abstractInstruction = genoperandoperand(Label, (labelCounter += 1), bytecodePC);
		(abstractInstruction->annotation = HasBytecodePC);
		return 0;
	}
	if (needsFrame) {
		/* begin MoveR:R: */
		genoperandoperand(MoveRR, FPReg, SPReg);
		/* begin PopR: */
		genoperand(PopR, FPReg);
		/* begin PopR: */
		genoperand(PopR, LinkReg);

		/* begin RetN: */
		genoperand(RetN, (methodOrBlockNumArgs + 1) * BytesPerWord);
	}
	else {
		/* begin RetN: */
		offset = ((methodOrBlockNumArgs > 2)
		 || (regArgsHaveBeenPushed)
			? (methodOrBlockNumArgs + 1) * BytesPerWord
			: 0);
		genoperand(RetN, offset);
	}
	return 0;
}


/*	Make sure there's a flagged fixup at the targetIndex (pc relative to first
	pc) in fixups.
	These are the targets of backward branches. A backward branch fixup's
	simStackPtr needs to be set when generating the code for the bytecode at
	the targetIndex.
	Initially a fixup's target is just a flag. Later on it is replaced with a
	proper instruction. */

	/* StackToRegisterMappingCogit>>#initializeFixupAt: */
static BytecodeFixup * NoDbgRegParms
initializeFixupAt(sqInt targetIndex)
{
    BytecodeFixup *fixup;

	fixup = fixupAt(targetIndex);
	(fixup->targetInstruction = ((AbstractInstruction *) 2));
	(fixup->simStackPtr = -2);
	return fixup;
}

	/* StackToRegisterMappingCogit>>#initSimStackForFramefulMethod: */
static void NoDbgRegParms
initSimStackForFramefulMethod(sqInt startpc)
{
    CogSimStackEntry *desc;
    sqInt i;

	(simSelf.type = SSBaseOffset);
	(simSelf.spilled = 1);
	(simSelf.annotateUse = 0);
	(simSelf.registerr = FPReg);
	(simSelf.offset = FoxMFReceiver);
	(optStatus.isReceiverResultRegLive = 0);
	(optStatus.ssEntry = (&simSelf));

	/* N.B. Includes num args */
	simSpillBase = methodOrBlockNumTemps;

	/* args */
	simStackPtr = simSpillBase - 1;
	for (i = 0; i < methodOrBlockNumArgs; i += 1) {
		desc = simStackAt(i);
		(desc->type = SSBaseOffset);
		(desc->spilled = 1);
		(desc->annotateUse = 0);
		(desc->registerr = FPReg);
		(desc->offset = FoxCallerSavedIP + ((methodOrBlockNumArgs - i) * BytesPerWord));
		(desc->bcptr = startpc);
	}
	for (i = methodOrBlockNumArgs; i <= simStackPtr; i += 1) {
		desc = simStackAt(i);
		(desc->type = SSBaseOffset);
		(desc->spilled = 1);
		(desc->annotateUse = 0);
		(desc->registerr = FPReg);
		(desc->offset = FoxMFReceiver - (((i - methodOrBlockNumArgs) + 1) * BytesPerWord));
		(desc->bcptr = startpc);
	}
}


/*	The register receiver (the closure itself) and args are pushed by the
	closure value primitive(s)
	and hence a frameless block has all arguments and copied values pushed to
	the stack. However,
	the method receiver (self) is put in the ReceiverResultRegister by the
	block entry. */

	/* StackToRegisterMappingCogit>>#initSimStackForFramelessBlock: */
static void NoDbgRegParms
initSimStackForFramelessBlock(sqInt startpc)
{
    CogSimStackEntry *desc;
    sqInt i;

	(simSelf.type = SSRegister);
	(simSelf.spilled = 0);
	(simSelf.annotateUse = 0);
	(simSelf.registerr = ReceiverResultReg);
	(optStatus.isReceiverResultRegLive = 1);
	(optStatus.ssEntry = (&simSelf));
	assert(methodOrBlockNumTemps >= methodOrBlockNumArgs);
	for (i = 0; i < methodOrBlockNumTemps; i += 1) {
		desc = simStackAt(i);
		(desc->type = SSBaseOffset);
		(desc->spilled = 1);
		(desc->annotateUse = 0);
		(desc->registerr = SPReg);
		(desc->offset = ((methodOrBlockNumArgs - 1) - i) * BytesPerWord);
		(desc->bcptr = startpc);
	}
	simSpillBase = (simStackPtr = methodOrBlockNumTemps - 1);
}

	/* StackToRegisterMappingCogit>>#initSimStackForFramelessMethod: */
static void NoDbgRegParms
initSimStackForFramelessMethod(sqInt startpc)
{
    CogSimStackEntry *desc;
    sqInt i;

	(simSelf.type = SSRegister);
	(simSelf.spilled = 0);
	(simSelf.annotateUse = 0);
	(simSelf.registerr = ReceiverResultReg);
	(optStatus.isReceiverResultRegLive = 1);
	(optStatus.ssEntry = (&simSelf));
	assert(methodOrBlockNumTemps >= methodOrBlockNumArgs);
	assert((numRegArgs()) <= 2);
	if (((methodOrBlockNumArgs >= 1) && (methodOrBlockNumArgs <= 2))) {
		desc = simStackAt(0);
		(desc->type = SSRegister);
		(desc->spilled = 0);
		(desc->annotateUse = 0);
		(desc->registerr = Arg0Reg);
		(desc->bcptr = startpc);
		if (methodOrBlockNumArgs > 1) {
			desc = simStackAt(1);
			(desc->type = SSRegister);
			(desc->spilled = 0);
			(desc->annotateUse = 0);
			(desc->registerr = Arg1Reg);
			(desc->bcptr = startpc);
		}
	}
	else {
		for (i = 0; i < methodOrBlockNumArgs; i += 1) {
			desc = simStackAt(i);
			(desc->type = SSBaseOffset);
			(desc->registerr = SPReg);
			(desc->spilled = 1);
			(desc->annotateUse = 0);
			(desc->offset = ((methodOrBlockNumArgs - 1) - i) * BytesPerWord);
			(desc->bcptr = startpc);
		}
	}
	simSpillBase = (simStackPtr = methodOrBlockNumArgs - 1);
}

	/* StackToRegisterMappingCogit>>#liveRegisters */
static sqInt
liveRegisters(void)
{
    sqInt i;
    sqInt regsSet;

	if (needsFrame) {
		regsSet = 0;
	}
	else {
		regsSet = registerMaskFor(ReceiverResultReg);
		if ((methodOrBlockNumArgs <= 2)
		 && (methodOrBlockNumArgs > 0)) {
			regsSet = regsSet | (registerMaskFor(Arg0Reg));
			if (methodOrBlockNumArgs > 1) {
				regsSet = regsSet | (registerMaskFor(Arg1Reg));
			}
		}
	}
	for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= simStackPtr; i += 1) {
		regsSet = regsSet | (registerMask(simStackAt(i)));
	}
	return regsSet;
}


/*	Spill everything on the simulated stack that needs spilling (that below
	receiver and arguments).
	Marshall receiver and arguments to stack and/or registers depending on arg
	count. If the args don't fit in registers push receiver and args (spill
	everything), but still assign
	the receiver to ReceiverResultReg. */

	/* StackToRegisterMappingCogit>>#marshallSendArguments: */
static void NoDbgRegParms
marshallSendArguments(sqInt numArgs)
{
    sqInt anyRefs;
    CogSimStackEntry * cascade0;
    sqInt numSpilled;

	ssFlushTo((simStackPtr - numArgs) - 1);
	if (numArgs > 2) {

		/* If there are no spills and no references to ReceiverResultReg
		   the fetch of ReceiverResultReg from the stack can be avoided
		   by assigning directly to ReceiverResultReg and pushing it. */
		numSpilled = numberOfSpillsInTopNItems(numArgs + 1);
		anyRefs = anyReferencesToRegisterinTopNItems(ReceiverResultReg, numArgs + 1);
		if ((numSpilled > 0)
		 || (anyRefs)) {
			ssFlushTo(simStackPtr);
			storeToReg(simStackAt(simStackPtr - numArgs), ReceiverResultReg);
		}
		else {
			cascade0 = simStackAt(simStackPtr - numArgs);
			storeToReg(cascade0, ReceiverResultReg);
			(cascade0->type = SSRegister);
			(cascade0->registerr = ReceiverResultReg);
			ssFlushTo(simStackPtr);
		}
	}
	else {

		/* Move the args to the register arguments, being careful to do
		   so last to first so e.g. previous contents don't get overwritten.
		   Also check for any arg registers in use by other args. */
		if (numArgs > 0) {
			if (numArgs > 1) {
				ssAllocateRequiredRegupThrough(Arg0Reg, simStackPtr - 2);
				ssAllocateRequiredRegupThrough(Arg1Reg, simStackPtr - 1);
			}
			else {
				ssAllocateRequiredRegupThrough(Arg0Reg, simStackPtr - 1);
			}
		}
		if (numArgs > 1) {
			popToReg(simStackAt(simStackPtr), Arg1Reg);
		}
		if (numArgs > 0) {
			popToReg(simStackAt((simStackPtr - numArgs) + 1), Arg0Reg);
		}
		popToReg(simStackAt(simStackPtr - numArgs), ReceiverResultReg);
	}
	ssPop(numArgs + 1);
}


/*	Merge control flow at a fixup. The fixup holds the simStackPtr at the jump
	to this target.
	See stackToRegisterMapping on the class side for a full description. */

	/* StackToRegisterMappingCogit>>#merge:afterContinuation: */
static void NoDbgRegParms
mergeafterContinuation(BytecodeFixup *fixup, sqInt mergeWithContinuation)
{
    sqInt i;

	traceMerge(fixup);
	(optStatus.isReceiverResultRegLive = 0);
	if (!mergeWithContinuation) {
		assert((((usqInt)((fixup->targetInstruction)))) >= 2);
		simStackPtr = (fixup->simStackPtr);
	}
	if ((((usqInt)((fixup->targetInstruction)))) <= 2) {

		/* This is either a forward or backward branch target.
		   The stack must be flushed. */
		ssFlushTo(simStackPtr);
		if (((fixup->simStackPtr)) <= -2) {

			/* This is the target of a backward branch.  It doesn't have a simStackPtr yet. */
			(fixup->simStackPtr = simStackPtr);
		}
		(fixup->targetInstruction = gLabel());
	}
	assert(simStackPtr >= ((fixup->simStackPtr)));
	simStackPtr = (fixup->simStackPtr);

	/* For now throw away all type information for values on the stack, but sometime consider
	   the more sophisticated merge described in the class side stackToRegisterMapping. */
	simSpillBase = methodOrBlockNumTemps;
	for (i = methodOrBlockNumTemps; i <= simStackPtr; i += 1) {
		mergeAtfrom(simStackAt(i), FoxMFReceiver - (((i - methodOrBlockNumArgs) + 1) * BytesPerOop), FPReg);
	}
}

	/* StackToRegisterMappingCogit>>#methodAbortTrampolineFor: */
static sqInt NoDbgRegParms
methodAbortTrampolineFor(sqInt numArgs)
{
	return methodAbortTrampolines[((numArgs < (2 + 1)) ? numArgs : (2 + 1))];
}

	/* StackToRegisterMappingCogit>>#needsFrameIfMod16GENumArgs: */
static sqInt NoDbgRegParms
needsFrameIfMod16GENumArgs(sqInt stackDelta)
{
	return (byte0 % 16) >= methodOrBlockNumArgs;
}


/*	As of August 2013, the code generator can't deal with spills in frameless
	methods (the
	issue is to do with the stack offset to get at an argument, which is
	changed when there's a spill).
	In e.g. TextColor>>#dominates: other ^other class == self class the second
	send of class
	needs also rto allocate a register that the first one used, but the first
	one's register can't be
	spilled. So avoid this by only allowing class to be sent if the stack
	contains a single element. */

	/* StackToRegisterMappingCogit>>#needsFrameIfStackGreaterThanOne: */
static sqInt NoDbgRegParms
needsFrameIfStackGreaterThanOne(sqInt stackDelta)
{
	return stackDelta > 1;
}

	/* StackToRegisterMappingCogit>>#numberOfSpillsInTopNItems: */
static sqInt NoDbgRegParms
numberOfSpillsInTopNItems(sqInt n)
{
    sqInt i;

	for (i = simStackPtr; i >= ((simStackPtr - n) + 1); i += -1) {
		if ((((simStackAt(i))->type)) == SSSpill) {
			return n - (simStackPtr - i);
		}
	}
	return 0;
}

	/* StackToRegisterMappingCogit>>#picAbortTrampolineFor: */
static sqInt NoDbgRegParms
picAbortTrampolineFor(sqInt numArgs)
{
	return picAbortTrampolines[((numArgs < (2 + 1)) ? numArgs : (2 + 1))];
}

	/* StackToRegisterMappingCogit>>#prevInstIsPCAnnotated */
static sqInt
prevInstIsPCAnnotated(void)
{
    sqInt prevIndex;
    AbstractInstruction *prevInst;

	if (!(opcodeIndex > 0)) {
		return 0;
	}
	prevIndex = opcodeIndex - 1;
	while (1) {
		if (prevIndex <= 0) {
			return 0;
		}
		prevInst = abstractInstructionAt(prevIndex);
		if (isPCMappedAnnotation((!((prevInst->annotation))
			? 0
			: (prevInst->annotation)))) {
			return 1;
		}
		if (!(((prevInst->opcode)) == Label)) break;
		prevIndex -= 1;
	}
	return 0;
}

	/* StackToRegisterMappingCogit>>#pushNilSize:numInitialNils: */
static sqInt NoDbgRegParms
pushNilSizenumInitialNils(sqInt aMethodObj, sqInt numInitialNils)
{
    sqInt (* const pushNilSizeFunction)(sqInt,sqInt) = v3PushNilSizenumInitialNils;

	return pushNilSizeFunction(aMethodObj, numInitialNils);
}


/*	When a block must be recompiled due to overestimating the
	numInitialNils fixups must be restored, which means rescannning
	since backward branches need their targets initialized. */

	/* StackToRegisterMappingCogit>>#reinitializeFixupsFrom:through: */
static void NoDbgRegParms
reinitializeFixupsFromthrough(sqInt start, sqInt end)
{
    BytecodeFixup * cascade0;
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt nExts;
    sqInt pc;
    sqInt targetPC;

	pc = start;
	nExts = 0;
	while (pc <= end) {
		cascade0 = fixupAt(pc - initialPC);
		(cascade0->targetInstruction = 0);
		(cascade0->simStackPtr = null);
		byte0 = (fetchByteofObject(pc, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		if ((isBranch(descriptor))
		 && (isBackwardBranchatextsin(descriptor, pc, nExts, methodObj))) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			initializeFixupAt(targetPC - initialPC);
		}
		if ((descriptor->isBlockCreation)) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			pc = (pc + ((descriptor->numBytes))) + distance;
		}
		else {
			pc += (descriptor->numBytes);
		}
		nExts = ((descriptor->isExtension)
			? nExts + 1
			: 0);
	}
}


/*	Scan the block to determine if the block needs a frame or not */

	/* StackToRegisterMappingCogit>>#scanBlock: */
static void NoDbgRegParms
scanBlock(BlockStart *blockStart)
{
    BytecodeDescriptor *descriptor;
    sqInt end;
    sqInt framelessStackDelta;
    sqInt nExts;
    sqInt numPushNils;
    sqInt (* const numPushNilsFunction)(struct _BytecodeDescriptor *,sqInt,sqInt,sqInt) = v3NumPushNils;
    sqInt pc;
    sqInt pushingNils;

	needsFrame = 0;
	prevBCDescriptor = null;
	methodOrBlockNumArgs = (blockStart->numArgs);
	inBlock = 1;
	pc = (blockStart->startpc);
	end = ((blockStart->startpc)) + ((blockStart->span));
	framelessStackDelta = (nExts = (extA = (extB = 0)));
	pushingNils = 1;
	while (pc < end) {
		byte0 = (fetchByteofObject(pc, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		if ((descriptor->isExtension)) {
			loadSubsequentBytesForDescriptorat(descriptor, pc);
			((descriptor->generator))();
		}
		if (!needsFrame) {
			if ((((descriptor->needsFrameFunction)) == null)
			 || (((descriptor->needsFrameFunction))(framelessStackDelta))) {
				needsFrame = 1;
			}
			else {
				framelessStackDelta += (descriptor->stackDelta);
			}
		}
		/* begin maybeNoteDescriptor:blockStart: */
		if ((descriptor->isInstVarRef)) {
			(blockStart->hasInstVarRef = 1);
		}
		if (pushingNils
		 && (!((descriptor->isExtension)))) {

			/* Count the initial number of pushed nils acting as temp initializers.  We can't tell
			   whether an initial pushNil is an operand reference or a temp initializer, except
			   when the pushNil is a jump target (has a fixup), which never happens:
			   self systemNavigation browseAllSelect:
			   [:m| | ebc |
			   (ebc := m embeddedBlockClosures
			   select: [:ea| ea decompile statements first isMessage]
			   thenCollect: [:ea| ea decompile statements first selector]) notEmpty
			   and: [(#(whileTrue whileFalse whileTrue: whileFalse:) intersection: ebc) notEmpty]]
			   or if the bytecode set has a push multiple nils bytecode.  We simply count initial nils.
			   Rarely we may end up over-estimating.  We will correct by checking the stack depth
			   at the end of the block in compileBlockBodies. */
			if (((numPushNils = numPushNilsFunction(descriptor, pc, nExts, methodObj))) > 0) {
				assert((((descriptor->numBytes)) == 1)
				 || (((descriptor->generator)) == genPushClosureTempsBytecode));
				(blockStart->numInitialNils = ((blockStart->numInitialNils)) + numPushNils);
			}
			else {
				pushingNils = 0;
			}
		}
		pc = (pc + ((descriptor->numBytes))) + (((descriptor->isBlockCreation)
	? ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj)
	: 0));
		if ((descriptor->isExtension)) {
			nExts += 1;
		}
		else {
			nExts = (extA = (extB = 0));
		}
		prevBCDescriptor = descriptor;
	}
	if (!needsFrame) {
		assert((framelessStackDelta >= 0)
		 && (((blockStart->numInitialNils)) >= framelessStackDelta));
		(blockStart->numInitialNils = ((blockStart->numInitialNils)) - framelessStackDelta);
	}
}


/*	Scan the method (and all embedded blocks) to determine
	- what the last bytecode is; extra bytes at the end of a method are used
	to encode things like source pointers or temp names
	- if the method needs a frame or not
	- what are the targets of any backward branches.
	- how many blocks it creates
	Answer the block count or on error a negative error code */

	/* StackToRegisterMappingCogit>>#scanMethod */
static sqInt
scanMethod(void)
{
    BytecodeDescriptor *descriptor;
    sqInt distance;
    sqInt framelessStackDelta;
    sqInt latestContinuation;
    sqInt nExts;
    sqInt numBlocks;
    sqInt pc;
    sqInt targetPC;

	needsFrame = 0;
	inBlock = 0;
	prevBCDescriptor = null;
	
#  if NewspeakVM
	numIRCs = 0;

#  endif /* NewspeakVM */

	if ((primitiveIndex > 0)
	 && (isQuickPrimitiveIndex(primitiveIndex))) {
		return 0;
	}
	pc = (latestContinuation = initialPC);
	numBlocks = (framelessStackDelta = (nExts = (extA = (extB = 0))));
	while (pc <= endPC) {
		byte0 = (fetchByteofObject(pc, methodObj)) + bytecodeSetOffset;
		descriptor = generatorAt(byte0);
		if ((descriptor->isExtension)) {
			if (((descriptor->opcode)) == Nop) {

				/* unknown bytecode tag; see Cogit class>>#generatorTableFrom: */
				return EncounteredUnknownBytecode;
			}
			loadSubsequentBytesForDescriptorat(descriptor, pc);
			((descriptor->generator))();
		}
		if (((descriptor->isReturn))
		 && (pc >= latestContinuation)) {
			endPC = pc;
		}
		if (!needsFrame) {
			if ((((descriptor->needsFrameFunction)) == null)
			 || (((descriptor->needsFrameFunction))(framelessStackDelta))) {
				needsFrame = 1;
			}
			else {
				framelessStackDelta += (descriptor->stackDelta);
			}
		}
		if (isBranch(descriptor)) {
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			if (isBackwardBranchatextsin(descriptor, pc, nExts, methodObj)) {
				initializeFixupAt(targetPC - initialPC);
			}
			else {
				latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
			}
		}
		if ((descriptor->isBlockCreation)) {
			numBlocks += 1;
			distance = ((descriptor->spanFunction))(descriptor, pc, nExts, methodObj);
			targetPC = (pc + ((descriptor->numBytes))) + distance;
			latestContinuation = ((latestContinuation < targetPC) ? targetPC : latestContinuation);
		}
		
#    if NewspeakVM
		if ((descriptor->hasIRC)) {
			numIRCs += 1;
		}

#    endif /* NewspeakVM */

		pc += (descriptor->numBytes);
		if ((descriptor->isExtension)) {
			nExts += 1;
		}
		else {
			nExts = (extA = (extB = 0));
		}
		prevBCDescriptor = descriptor;
	}
	return numBlocks;
}


/*	Allocate a register needed in a run-time call (i.e. flush uses of the
	register to the real stack). Since the run-time can smash any and
	all caller-saved registers also flush all caller-saved registers. */

	/* StackToRegisterMappingCogit>>#ssAllocateCallReg: */
static void NoDbgRegParms
ssAllocateCallReg(sqInt requiredReg)
{
	ssAllocateRequiredRegMaskupThrough(callerSavedRegMask | (registerMaskFor(requiredReg)), simStackPtr);
}


/*	Allocate registers needed in a run-time call (i.e. flush uses of the
	registers to the real stack). Since the run-time can smash any and
	all caller-saved registers also flush all caller-saved registers. */

	/* StackToRegisterMappingCogit>>#ssAllocateCallReg:and: */
static void NoDbgRegParms
ssAllocateCallRegand(sqInt requiredReg1, sqInt requiredReg2)
{
	ssAllocateRequiredRegMaskupThrough(callerSavedRegMask | ((registerMaskFor(requiredReg1)) | (registerMaskFor(requiredReg2))), simStackPtr);
}


/*	Allocate registers needed in a run-time call (i.e. flush uses of the
	registers to the real stack). Since the run-time can smash any and
	all caller-saved registers also flush all caller-saved registers. */

	/* StackToRegisterMappingCogit>>#ssAllocateCallReg:and:and: */
static void NoDbgRegParms
ssAllocateCallRegandand(sqInt requiredReg1, sqInt requiredReg2, sqInt requiredReg3)
{
	ssAllocateRequiredRegMaskupThrough(callerSavedRegMask | ((registerMaskFor(requiredReg1)) | ((registerMaskFor(requiredReg2)) | (registerMaskFor(requiredReg3)))), simStackPtr);
}

	/* StackToRegisterMappingCogit>>#ssAllocateRequiredRegMask:upThrough: */
static void NoDbgRegParms
ssAllocateRequiredRegMaskupThrough(sqInt requiredRegsMask, sqInt stackPtr)
{
    sqInt i;
    sqInt lastRequired;
    sqInt liveRegs;


	/* compute live regs while noting the last occurrence of required regs.
	   If these are not free we must spill from simSpillBase to last occurrence.
	   Note we are conservative here; we could allocate FPReg in frameless methods. */
	lastRequired = -1;
	liveRegs = registerMaskForand(FPReg, SPReg);
	for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= stackPtr; i += 1) {
		liveRegs = liveRegs | (registerMask(simStackAt(i)));
		if (((registerMask(simStackAt(i))) & requiredRegsMask) != 0) {
			lastRequired = i;
		}
	}
	if (!((liveRegs & requiredRegsMask) == 0)) {

		/* Some live, must spill */
		ssFlushTo(lastRequired);
		assert(((liveRegisters()) & requiredRegsMask) == 0);
	}
}

	/* StackToRegisterMappingCogit>>#ssAllocateRequiredReg: */
static void NoDbgRegParms
ssAllocateRequiredReg(sqInt requiredReg)
{
	ssAllocateRequiredRegMaskupThrough(registerMaskFor(requiredReg), simStackPtr);
}

	/* StackToRegisterMappingCogit>>#ssAllocateRequiredReg:and: */
static void NoDbgRegParms
ssAllocateRequiredRegand(sqInt requiredReg1, sqInt requiredReg2)
{
	ssAllocateRequiredRegMaskupThrough((registerMaskFor(requiredReg1)) | (registerMaskFor(requiredReg2)), simStackPtr);
}

	/* StackToRegisterMappingCogit>>#ssAllocateRequiredReg:upThrough: */
static void NoDbgRegParms
ssAllocateRequiredRegupThrough(sqInt requiredReg, sqInt stackPtr)
{
	ssAllocateRequiredRegMaskupThrough(registerMaskFor(requiredReg), stackPtr);
}

	/* StackToRegisterMappingCogit>>#ssFlushTo: */
static void NoDbgRegParms
ssFlushTo(sqInt index)
{
    sqInt i;

	for (i = methodOrBlockNumTemps; i < simSpillBase; i += 1) {
		assert(((simStackAt(i))->spilled));
	}
	if (simSpillBase <= index) {
		for (i = (((simSpillBase < 0) ? 0 : simSpillBase)); i <= index; i += 1) {
			assert(needsFrame);
			ensureSpilledAtfrom(simStackAt(i), frameOffsetOfTemporary(i), FPReg);
		}
		simSpillBase = index + 1;
	}
}


/*	Any occurrences on the stack of the value being stored (which is the top
	of stack)
	must be flushed, and hence any values colder than them stack. */

	/* StackToRegisterMappingCogit>>#ssFlushUpThroughReceiverVariable: */
static void NoDbgRegParms
ssFlushUpThroughReceiverVariable(sqInt slotIndex)
{
    CogSimStackEntry *desc;
    sqInt index;

	/* begin ssFlushUpThrough: */
	for (index = (simStackPtr - 1); index >= (((simSpillBase < 0) ? 0 : simSpillBase)); index += -1) {
		if (((((simStackAt(index))->type)) == SSBaseOffset)
		 && (((((simStackAt(index))->registerr)) == ReceiverResultReg)
		 && ((((simStackAt(index))->offset)) == (slotOffsetOfInstVarIndex(slotIndex))))) {
			ssFlushTo(index);
			goto l1;
		}
	}
l1:	/* end ssFlushUpThrough: */;
}


/*	Any occurrences on the stack of the value being stored (which is the top
	of stack)
	must be flushed, and hence any values colder than them stack. */

	/* StackToRegisterMappingCogit>>#ssFlushUpThroughTemporaryVariable: */
static void NoDbgRegParms
ssFlushUpThroughTemporaryVariable(sqInt tempIndex)
{
    CogSimStackEntry *desc;
    sqInt index;

	/* begin ssFlushUpThrough: */
	for (index = (simStackPtr - 1); index >= (((simSpillBase < 0) ? 0 : simSpillBase)); index += -1) {
		if (((((simStackAt(index))->type)) == SSBaseOffset)
		 && (((((simStackAt(index))->registerr)) == FPReg)
		 && ((((simStackAt(index))->offset)) == (frameOffsetOfTemporary(tempIndex))))) {
			ssFlushTo(index);
			goto l1;
		}
	}
l1:	/* end ssFlushUpThrough: */;
}

	/* StackToRegisterMappingCogit>>#ssPop: */
static void NoDbgRegParms
ssPop(sqInt n)
{
	assert(((simStackPtr - n) >= (methodOrBlockNumTemps - 1))
	 || ((!needsFrame)
	 && ((simStackPtr - n) >= -1)));
	simStackPtr -= n;
}

	/* StackToRegisterMappingCogit>>#ssPushAnnotatedConstant: */
static sqInt NoDbgRegParms
ssPushAnnotatedConstant(sqInt literal)
{
    CogSimStackEntry * cascade0;

	ssPush(1);
	updateSimSpillBase();
	cascade0 = ssTop();
	(cascade0->type = SSConstant);
	(cascade0->annotateUse = 1);
	(cascade0->spilled = 0);
	(cascade0->constant = literal);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPushBase:offset: */
static sqInt NoDbgRegParms
ssPushBaseoffset(sqInt reg, sqInt offset)
{
    CogSimStackEntry * cascade0;

	ssPush(1);
	updateSimSpillBase();
	cascade0 = ssTop();
	(cascade0->type = SSBaseOffset);
	(cascade0->spilled = 0);
	(cascade0->annotateUse = 0);
	(cascade0->registerr = reg);
	(cascade0->offset = offset);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPushConstant: */
static sqInt NoDbgRegParms
ssPushConstant(sqInt literal)
{
    CogSimStackEntry * cascade0;

	ssPush(1);
	updateSimSpillBase();
	cascade0 = ssTop();
	(cascade0->type = SSConstant);
	(cascade0->spilled = 0);
	(cascade0->annotateUse = 0);
	(cascade0->constant = literal);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPushDesc: */
static sqInt NoDbgRegParms
ssPushDesc(CogSimStackEntry simStackEntry)
{
	if (((simStackEntry.type)) == SSSpill) {
		(simStackEntry.type = SSBaseOffset);
	}
	(simStackEntry.spilled = 0);
	(simStackEntry.annotateUse = 0);
	(simStackEntry.bcptr = bytecodePC);
	simStack[(simStackPtr += 1)] = simStackEntry;
	updateSimSpillBase();
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPushRegister: */
static sqInt NoDbgRegParms
ssPushRegister(sqInt reg)
{
    CogSimStackEntry * cascade0;

	ssPush(1);
	updateSimSpillBase();
	cascade0 = ssTop();
	(cascade0->type = SSRegister);
	(cascade0->spilled = 0);
	(cascade0->annotateUse = 0);
	(cascade0->registerr = reg);
	(cascade0->bcptr = bytecodePC);
	return 0;
}

	/* StackToRegisterMappingCogit>>#ssPush: */
static void NoDbgRegParms
ssPush(sqInt n)
{
	simStackPtr += n;
}


/*	In addition to ssStorePop:toReg:, if this is a store and not
	a popInto I change the simulated stack to use the register 
	for the top value */

	/* StackToRegisterMappingCogit>>#ssStoreAndReplacePop:toReg: */
static void NoDbgRegParms
ssStoreAndReplacePoptoReg(sqInt popBoolean, sqInt reg)
{
    char topSpilled;

	topSpilled = ((ssTop())->spilled);
	ssStorePoptoReg(popBoolean
	 || (topSpilled), reg);
	if (!popBoolean) {
		if (!topSpilled) {
			ssPop(1);
		}
		ssPushRegister(reg);
	}
}


/*	Store or pop the top simulated stack entry to a register.
	Use preferredReg if the entry is not itself a register.
	Answer the actual register the result ends up in. */

	/* StackToRegisterMappingCogit>>#ssStorePop:toPreferredReg: */
static sqInt NoDbgRegParms
ssStorePoptoPreferredReg(sqInt popBoolean, sqInt preferredReg)
{
    sqInt actualReg;

	actualReg = preferredReg;
	if ((((ssTop())->type)) == SSRegister) {
		assert(!(((ssTop())->annotateUse)));
		assert(!(((ssTop())->spilled)));
		actualReg = ((ssTop())->registerr);
	}
	ssStorePoptoReg(popBoolean, actualReg);
	return actualReg;
}


/*	Store or pop the top simulated stack entry to a register.
	N.B.: popToReg: and storeToReg: does not generate anything if 
	it moves a register to the same register. */

	/* StackToRegisterMappingCogit>>#ssStorePop:toReg: */
static void NoDbgRegParms
ssStorePoptoReg(sqInt popBoolean, sqInt reg)
{
	if (popBoolean) {
		popToReg(ssTop(), reg);
		ssPop(1);
	}
	else {
		storeToReg(ssTop(), reg);
	}
}

	/* StackToRegisterMappingCogit>>#ssTop */
static CogSimStackEntry *
ssTop(void)
{
	return simStackAt(simStackPtr);
}

	/* StackToRegisterMappingCogit>>#ssTopDescriptor */
static CogSimStackEntry
ssTopDescriptor(void)
{
	return simStack[simStackPtr];
}

	/* StackToRegisterMappingCogit>>#ssValue: */
static CogSimStackEntry * NoDbgRegParms
ssValue(sqInt n)
{
	return simStackAt(simStackPtr - n);
}


/*	If the sequence of bytecodes is
	push: (Array new: 1)
	popIntoTemp: tempIndex
	pushConstant: const or pushTemp: n
	popIntoTemp: 0 inVectorAt: tempIndex
	collapse this into
	tempAt: tempIndex put: {const or temp}
	and answer true, otherwise answer false.
	One might think that we should look for a sequence of more than
	one pushes and pops but this is extremely rare.
	Exclude pushRcvr: n to avoid potential complications with context inst
	vars.  */

	/* StackToRegisterMappingCogit>>#tryCollapseTempVectorInitializationOfSize: */
static sqInt NoDbgRegParms
tryCollapseTempVectorInitializationOfSize(sqInt slots)
{
    BytecodeDescriptor *pushArrayDesc;
    BytecodeDescriptor *pushValueDesc;
    sqInt reg;
    sqInt remoteTempIndex;
    BytecodeDescriptor *storeArrayDesc;
    BytecodeDescriptor *storeValueDesc;
    sqInt tempIndex;

	if (slots != 1) {
		return 0;
	}
	pushArrayDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject(bytecodePC, methodObj)));
	assert(((pushArrayDesc->generator)) == genPushNewArrayBytecode);
	storeArrayDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject(bytecodePC + ((pushArrayDesc->numBytes)), methodObj)));
	if (((storeArrayDesc->generator)) == genStoreAndPopTemporaryVariableBytecode) {
		tempIndex = (fetchByteofObject(bytecodePC + ((pushArrayDesc->numBytes)), methodObj)) & 7;
	}
	else {
		if (!(((storeArrayDesc->generator)) == genLongStoreAndPopTemporaryVariableBytecode)) {
			return 0;
		}
		tempIndex = fetchByteofObject((bytecodePC + ((pushArrayDesc->numBytes))) + 1, methodObj);
	}
	pushValueDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject((bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes)), methodObj)));
	if (!((((pushValueDesc->generator)) == genPushLiteralConstantBytecode)
		 || ((((pushValueDesc->generator)) == genPushQuickIntegerConstantBytecode)
		 || (((pushValueDesc->generator)) == genPushTemporaryVariableBytecode)))) {
		return 0;
	}
	storeValueDesc = generatorAt(bytecodeSetOffset + (fetchByteofObject(((bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes))) + ((pushValueDesc->numBytes)), methodObj)));
	remoteTempIndex = fetchByteofObject((((bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes))) + ((pushValueDesc->numBytes))) + 2, methodObj);
	if (!((((storeValueDesc->generator)) == genStoreAndPopRemoteTempLongBytecode)
		 && (tempIndex == remoteTempIndex))) {
		return 0;
	}
	genNewArrayOfSizeinitialized(1, 0);
	evaluateat(pushValueDesc, (bytecodePC + ((pushArrayDesc->numBytes))) + ((storeArrayDesc->numBytes)));
	reg = ssStorePoptoPreferredReg(1, TempReg);
	genStoreSourceRegslotIndexintoNewObjectInDestReg(reg, 0, ReceiverResultReg);
	ssPushRegister(ReceiverResultReg);
	evaluateat(storeArrayDesc, bytecodePC + ((pushArrayDesc->numBytes)));

	/* + pushArrayDesc numBytes this gets added by nextBytecodePCFor:at:exts:in: */
	bytecodePC = ((bytecodePC + ((storeArrayDesc->numBytes))) + ((pushValueDesc->numBytes))) + ((storeValueDesc->numBytes));
	return 1;
}

	/* StackToRegisterMappingCogit>>#updateSimSpillBase */
static void
updateSimSpillBase(void)
{
	if (simSpillBase > simStackPtr) {
		simSpillBase = ((simStackPtr < 0) ? 0 : simStackPtr);
	}
}

	/* StackToRegisterMappingCogit>>#v3PushNilSize:numInitialNils: */
static sqInt NoDbgRegParms
v3PushNilSizenumInitialNils(sqInt aMethodObj, sqInt numInitialNils)
{
	return numInitialNils;
}

	/* StackToRegisterMappingCogit>>#v3:Num:Push:Nils: */
static sqInt NoDbgRegParms
v3NumPushNils(BytecodeDescriptor *descriptor, sqInt pc, sqInt nExts, sqInt aMethodObj)
{
	return (((descriptor->generator)) == genPushConstantNilBytecode
		? 1
		: 0);
}
